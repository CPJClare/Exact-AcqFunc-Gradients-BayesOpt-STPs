{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e0c7bd-257e-48d2-a948-09459df36a40"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Collecting Theano-PyMC\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyMC3\n",
            "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
            "\u001b[K     |████████████████████████████████| 872 kB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Collecting deprecat\n",
            "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting semver>=2.13.0\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=faaf8373f1b5b8beeed296b7cece9a63cbf923dbfc661df20021b3acce92fcdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529963 sha256=1bd22efd185821775628085442cf542709c40382e7ea42370efd64af1ef3ed90\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/af/8c/5dd7553522d74c52a7813806fc7ee1a9caa20a3f7c8fd850d5\n",
            "Successfully built pyGPGO Theano-PyMC\n",
            "Installing collected packages: Theano-PyMC, semver, deprecat, pyMC3, pyGPGO\n",
            "Successfully installed Theano-PyMC-1.1.2 deprecat-2.1.1 pyGPGO-0.5.1 pyMC3-3.11.5 semver-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import t\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "96546121-79c5-4aec-8a28-d847cf156dc4"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c96f06d-237b-410f-8b88-803056687f05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c96f06d-237b-410f-8b88-803056687f05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c96f06d-237b-410f-8b88-803056687f05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c96f06d-237b-410f-8b88-803056687f05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0565cb70-499e-4074-de79-a3320762e4a5"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "6179ca17-9535-402f-9cd5-cf0041343f5e"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102dfc60-7348-4a73-886a-363d65b21122"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "441efd19-9a4d-437d-a7d5-6525e6835264"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18398c9b-440f-4f84-9d32-085fc23a08a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18398c9b-440f-4f84-9d32-085fc23a08a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18398c9b-440f-4f84-9d32-085fc23a08a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18398c9b-440f-4f84-9d32-085fc23a08a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "34af812d-e09f-453a-cf83-13ce700db653"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-108c16d2-af68-42c5-96d7-87fde57f2acb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-108c16d2-af68-42c5-96d7-87fde57f2acb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-108c16d2-af68-42c5-96d7-87fde57f2acb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-108c16d2-af68-42c5-96d7-87fde57f2acb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util = 'CBM'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.1\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08\n",
        "\n",
        "df = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "def kronDelta(X, Xstar):                     # Kronecker's Delta method\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "def se(X, Xstar, sigmaf, l, sigman):         # S.E. kernel method\n",
        "    return sigmaf * np.exp(-0.5 * cdist(X, Xstar) ** 2 / l ** 2) + sigman * kronDelta(X, Xstar)\n",
        "\n",
        "def delta(X, Xstar):                         # Distance between training X and test Xstar vectors\n",
        "    return (X - Xstar)\n",
        "   \n",
        "def der_covmat(X, Xstar, sigmaf, l, sigman): # Covariance matrix derivative terms (i.e. exact, first-order)\n",
        "    nx = len(X)\n",
        "    ny = len(Xstar)\n",
        "    return np.round(np.array([(delta(np.atleast_2d(i), np.atleast_2d(j))[0] * se(np.atleast_2d(i), np.atleast_2d(j), sigmaf, l, sigman)[0]).sum() for (i, j) in itertools.product(X, Xstar)]).reshape(nx, ny), 8)\n",
        "\n",
        "class dtStudentProcess(tStudentProcess):    # Via inheritance, also optimises hyperparameters when opt = TRUE\n",
        "    \n",
        "    def AcqGrad(self, Xstar):               # Method returning exact, first-order derivatives of the STP's posterior mean and standard deviation\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = self.covfunc.K(self.X, Xstar).T\n",
        "        dKstar = der_covmat(self.X, Xstar, self.covfunc.sigmaf, self.covfunc.l, self.covfunc.sigman).T\n",
        "        \n",
        "        smd_adj = (self.nu + self.beta1 - 2) / (self.nu + self.n1 - 2)\n",
        "\n",
        "        alpha = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), self.y)\n",
        "        alpha_Kstar = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), Kstar.T)      \n",
        "        \n",
        "        dm = np.dot(dKstar, alpha)\n",
        "        ds = -2 * smd_adj * np.dot(dKstar, alpha_Kstar)\n",
        "        \n",
        "        return dm, ds           \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "Beta_CBM = dim\n",
        "\n",
        "class Acquisition_grad(Acquisition):    \n",
        "    def __init__(self, mode, eps=eps, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'CBM': self.CBM\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def CBM(self, y_global_orig, mean, std, ds, dm, nu=3.0):\n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - y_global_orig) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "\n",
        "        f = (std + self.eps) * (gamma + np.sqrt(Beta_CBM))\n",
        "        df = dsdx * (gamma + np.sqrt(Beta_CBM)) + (std + self.eps) * dmdx\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append(df)\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "        \n",
        "    def d_eval(self, y_global_orig, mean, std, ds, dm, nu=3.0):\n",
        "    \n",
        "        return self.f(y_global_orig, mean, std, ds, dm, nu=3.0, **self.params)\n",
        "        "
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAK8N5bwfuJ7"
      },
      "source": [
        "## GPGO_multi: \n",
        "\n",
        "class GPGO_multi(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        " \n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "   \n",
        "    def _optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        \n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr        \n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_exact = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_exact = np.empty((n_start,))\n",
        "        opt_exact = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_exact = np.array([res.x for res in opt_exact])\n",
        "        f_best_exact = np.array([np.atleast_1d(res.fun)[0] for res in opt_exact])\n",
        "        f_best_min_exact = min(f_best_exact)\n",
        "\n",
        "        self.x_best_exact = x_best_exact\n",
        "        self.f_best_exact = f_best_exact\n",
        "        self.f_best_min_exact = f_best_min_exact\n",
        "        self.best_exact = x_best_exact[np.argmin(f_best_exact)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_exact)\n",
        "\n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_exact = str(inverse * self.f_best_min_exact)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_exact = BOLD + OKGREEN + max_acqfunc_exact + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc_exact, max_acqfunc))\n",
        "        \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self._optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "class dGPGO(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        "\n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_approx = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_approx = np.empty((n_start,))\n",
        "        opt_approx = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_approx = np.array([res.x for res in opt_approx])\n",
        "        f_best_approx = np.array([np.atleast_1d(res.fun)[0] for res in opt_approx])\n",
        "        f_best_min_approx = min(f_best_approx)\n",
        "\n",
        "        self.x_best_approx = x_best_approx\n",
        "        self.f_best_approx = f_best_approx\n",
        "        self.f_best_min_approx = f_best_min_approx\n",
        "        self.best_approx = x_best_approx[np.argmin(f_best_approx)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_approx)\n",
        "    \n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_approx = str(inverse * self.f_best_min_approx)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_approx = BOLD + OKGREEN + max_acqfunc_approx + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc, max_acqfunc_approx))\n",
        "\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5696f8-b43e-4b17-c8db-e4e8a23184ff"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663857655.3953948"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6e6b8a-d628-4210-db64-8636b4269273"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO_multi(surrogate_approx_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 2.1588902305275783\t 2.1588902305275783\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 2.152653409324976\t 2.152653409324976\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 2.2210712593211897\t 2.2210712593211897\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8992034514090065\t 0.6536753952667645\t 2.1588076288278732\t 2.1588076288278732\n",
            "5  \t [ 7.66218678  9.79577207 13.          0.6996093  12.          0.27250817]\t 1.0035275335689886\t 0.6536753952667645\t 2.163714840018006\t 2.16371483932983\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.9004243658767852\t 0.6536753952667645\t 2.1949301867811504\t 2.1949301867811504\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6536753952667645\t 2.1959078394414746\t 2.195907839441465\n",
            "8  \t [8.51945771 8.4424986  8.         0.90741371 1.         0.49942468]\t 0.8757522803338091\t 0.6536753952667645\t 2.2190981543660286\t 2.2190981543660286\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 1.0632523501795186\t 0.6536753952667645\t 2.2134982983843328\t 2.2134982983843328\n",
            "10 \t [ 5.33531967  8.54366774  8.          0.66341534 14.          0.29734112]\t 0.998213042419686\t 0.6536753952667645\t 2.243684936952298\t 2.243684936952298\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6536753952667645\t 2.2576697502080996\t 2.2576697502080996\n",
            "12 \t [0.15776536 8.02750992 5.         0.65248282 3.         0.71659731]\t 0.8032223773845614\t 0.6536753952667645\t 2.2806593064519913\t 2.2806593064519913\n",
            "13 \t [4.13690736 2.14715696 6.         0.52611104 1.         0.96671642]\t 0.7093885008364936\t 0.6536753952667645\t 2.263468701601014\t 2.263468701601014\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6536753952667645\t 2.237445077882735\t 2.237445077882735\n",
            "15 \t [ 9.20512342  1.60831322 11.          0.87041344  2.          0.50117029]\t 0.8186293003915115\t 0.6536753952667645\t 2.218088234134784\t 2.218088234134784\n",
            "16 \t [ 1.7276597   4.40364756 12.          0.7865661  17.          0.71662208]\t 0.7414066870872308\t 0.6536753952667645\t 2.2087183767673166\t 2.2087183767673166\n",
            "17 \t [1.68476972 5.2908721  8.         0.92839616 1.         0.96471758]\t 0.670961172017669\t 0.6536753952667645\t 2.189321210516266\t 2.189321210516266\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8661734316276007\t 0.6536753952667645\t 2.1611774788570446\t 2.1611774788570446\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 1.0095429457834948\t 0.6536753952667645\t 2.1817839707259266\t 2.1817839707259266\n",
            "20 \t [ 5.68575652  2.73061603 14.          0.61811388 15.          0.91855302]\t 0.6649510133524581\t 0.6536753952667645\t 2.1823833533539707\t 2.1823833533539707\n",
            "21 \t [2.40961239 3.57254356 7.         0.65731549 7.         0.30828184]\t 0.9988781926791057\t 0.6536753952667645\t 2.1750226988824357\t 2.1750226988824357\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 1.060877500434967\t 0.6536753952667645\t 2.21143983101055\t 2.21143983101055\n",
            "23 \t [ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\t 0.6693366893520581\t 0.6536753952667645\t 2.2191452615320277\t 2.2191452615320277\n",
            "24 \t [9.91212104 3.52811735 6.         0.93018572 1.         0.49999318]\t 0.8890012000810771\t 0.6536753952667645\t 2.1912543395320085\t 2.191254339531897\n",
            "25 \t [ 9.92106016  5.52981723 11.          0.80826141 13.          0.31322593]\t 1.000587889017468\t 0.6536753952667645\t 2.178226788437914\t 2.178226788437914\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.6562345271802523\t 0.6536753952667645\t 2.2322652900257602\t 2.2322652900257602\n",
            "27 \t [ 2.52136808  8.51741902 14.          0.89185963  6.          0.23066693]\t 1.0608073786807473\t 0.6536753952667645\t 2.171379114270164\t 2.171379114270164\n",
            "28 \t [ 0.42024221  1.80970657 14.          0.62730009  9.          0.87538064]\t 0.6646291820080863\t 0.6536753952667645\t 2.1994196077422643\t 2.1994196077422643\n",
            "29 \t [ 7.40845157  8.58336508  5.          0.8318041  19.          0.36434664]\t 1.0097984953249557\t 0.6536753952667645\t 2.204230497843944\t 2.204230497843944\n",
            "30 \t [ 1.2654566   9.68568733  5.          0.57664611 17.          0.70355107]\t 0.804917733132231\t 0.6536753952667645\t 2.1682532859462182\t 2.1682532859462182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48973.66312746987"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79990107-1fbc-4d76-d814-9de9eeb77119"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO_multi(surrogate_approx_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m1.841901656436365\u001b[0m\t \u001b[1m\u001b[92m1.841901656436365\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6807577751383148\t 1.814000894105339\t 1.814000894105339\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.7073935536898857\t 0.6807577751383148\t 1.8117628559843082\t 1.8117628559843082\n",
            "4  \t [ 5.03756278  5.01206033 13.          0.59912629 19.          0.46413865]\t 0.7900256550528338\t 0.6807577751383148\t 1.8030699975927547\t 1.8030699975927547\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.7887181971022355\t 0.6807577751383148\t 1.8173444907490386\t 1.8173444907490386\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m1.829910938732708\u001b[0m\t \u001b[1m\u001b[92m1.829910938732708\u001b[0m\n",
            "7  \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]\t 0.8064071783057642\t 0.67907472219801\t 1.8146875464586727\t 1.8146875464586727\n",
            "8  \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]\t 0.872344629033322\t 0.67907472219801\t 1.828613524517862\t 1.828613524517862\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.7397571279868462\t 0.67907472219801\t 1.8547298999004174\t 1.8547298999004174\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\u001b[0m\t \u001b[1m\u001b[92m0.6684024492575475\u001b[0m\t \u001b[1m\u001b[92m0.6684024492575475\u001b[0m\t \u001b[1m\u001b[92m1.851718078209086\u001b[0m\t \u001b[1m\u001b[92m1.851718078209086\u001b[0m\n",
            "11 \t [4.59560507 9.66694693 5.         0.8652774  6.         0.90565092]\t 0.7323276592879555\t 0.6684024492575475\t 1.8381604242994145\t 1.8381604242994145\n",
            "12 \t [ 8.76507252  8.76898373 14.          0.51356786  6.          0.73624795]\t 0.6802600475884806\t 0.6684024492575475\t 1.835076276509338\t 1.8350762760607113\n",
            "13 \t [ 6.62295179  6.77584978 14.          0.65936287 12.          0.50955919]\t 0.7009189105357144\t 0.6684024492575475\t 1.8258023281001368\t 1.8258023281001368\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.7143733066956096\t 0.6684024492575475\t 1.82029924790175\t 1.8202992468247883\n",
            "15 \t [ 9.80429676  9.59801315  7.          0.61168386 14.          0.66107461]\t 0.6949698710548621\t 0.6684024492575475\t 1.8166821329275682\t 1.8166821329268166\n",
            "16 \t [ 3.79151097  4.0129324  10.          0.78656319  9.          0.57380624]\t 0.6970533395297733\t 0.6684024492575475\t 1.8107962938402078\t 1.8107962938402078\n",
            "17 \t [ 1.94467794  1.47584396  5.          0.91953126 11.          0.49707889]\t 0.8258856905247922\t 0.6684024492575475\t 1.8069990115061965\t 1.8069990115061965\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.6693925559674401\t 0.6684024492575475\t 1.8327481092260849\t 1.8327481092260849\n",
            "19 \t [ 6.92673077  1.23845568 10.          0.63463476  8.          0.28240746]\t 0.7984787223028406\t 0.6684024492575475\t 1.8703321516162024\t 1.8703321516162024\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.7918243780041875\t 0.6684024492575475\t 1.8595104097057782\t 1.8595104097057782\n",
            "21 \t [7.13284983 1.18470919 5.         0.63977211 3.         0.12223048]\t 0.8717594731267366\t 0.6684024492575475\t 1.849574909499684\t 1.849574909499684\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\u001b[0m\t \u001b[1m\u001b[92m0.664392530003631\u001b[0m\t \u001b[1m\u001b[92m0.664392530003631\u001b[0m\t \u001b[1m\u001b[92m1.8413817692544778\u001b[0m\t \u001b[1m\u001b[92m1.8413817692544778\u001b[0m\n",
            "23 \t [8.76774335 2.47727368 5.         0.77895852 8.         0.95970784]\t 0.7344723614600867\t 0.664392530003631\t 1.8666754409259765\t 1.8666754409259765\n",
            "24 \t [10.          2.47940597 15.          0.5         1.          1.        ]\t 0.6746035963066516\t 0.664392530003631\t 1.9050820525667567\t 1.9050820559017179\n",
            "25 \t [ 2.46935709  2.95588202 11.          0.96920461  1.          0.23876533]\t 0.8610027928639139\t 0.664392530003631\t 1.8588683042457552\t 1.8588683042457552\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.6666799570614775\t 0.664392530003631\t 1.838425691446617\t 1.838425691446617\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.6817048020092698\t 0.664392530003631\t 1.8645657478985573\t 1.8645657478985573\n",
            "28 \t [ 4.9644812   1.12270948  6.          0.71065886 17.          0.26866166]\t 0.816338550997086\t 0.664392530003631\t 1.8767075609829174\t 1.8767075609829174\n",
            "29 \t [ 5.98509126  0.06989145 14.          0.5561472  16.          0.1874862 ]\t 0.8641573587264293\t 0.664392530003631\t 1.8576572462169925\t 1.8576572462169925\n",
            "30 \t [5.55301534 4.43776121 9.         0.77874612 6.         0.99491253]\t 0.6713718258462102\t 0.664392530003631\t 1.8535238140545984\t 1.8535238140545984\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49678.066272258315"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b838ee-e765-406a-862e-28db346bfc2f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO_multi(surrogate_approx_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 2.3202890233926294\t 2.3202890233926294\n",
            "2  \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]\t 1.0212658686211613\t 0.7688389438662246\t 2.265960365978532\t 2.265960365978532\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7688389438662246\t 2.3010973817396887\t 2.3010973817396887\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 4.06522402  9.52384028  5.          0.68629723 13.          0.87617671]\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m2.327993206671531\u001b[0m\t \u001b[1m\u001b[92m2.327993206671531\u001b[0m\n",
            "5  \t [3.68953475 2.95525094 5.         0.6894371  8.         0.99869195]\t 0.7371180474782232\t 0.7354945860729\t 2.2755252788291527\t 2.2755252788291527\n",
            "6  \t [9.87422438 6.71772444 5.         0.63287091 5.         0.98483042]\t 0.7384798879960105\t 0.7354945860729\t 2.2329849823891017\t 2.2329849823891017\n",
            "7  \t [ 9.93262812  9.85709216 10.          0.50642105 13.          0.46421679]\t 0.875164050104317\t 0.7354945860729\t 2.197819015050021\t 2.197819015050021\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[3.50549632 8.04483305 8.         0.95341936 1.         0.79512535]\u001b[0m\t \u001b[1m\u001b[92m0.7104180654574984\u001b[0m\t \u001b[1m\u001b[92m0.7104180654574984\u001b[0m\t \u001b[1m\u001b[92m2.19335697668344\u001b[0m\t \u001b[1m\u001b[92m2.19335697668344\u001b[0m\n",
            "9  \t [ 2.90369752  3.11254054  6.          0.81932406 16.          0.23613277]\t 1.028007118123578\t 0.7104180654574984\t 2.161871781001194\t 2.161871781001046\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 4.43398983  0.1775468  13.          0.67757521 18.          0.85307217]\u001b[0m\t \u001b[1m\u001b[92m0.7055608319391503\u001b[0m\t \u001b[1m\u001b[92m0.7055608319391503\u001b[0m\t \u001b[1m\u001b[92m2.1892360864786427\u001b[0m\t \u001b[1m\u001b[92m2.1892360864786427\u001b[0m\n",
            "11 \t [ 3.53262431  2.07514765  7.          0.93520802 15.          0.4184813 ]\t 0.8751855836959452\t 0.7055608319391503\t 2.1615834846762048\t 2.1615834846762048\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\u001b[0m\t \u001b[1m\u001b[92m0.6998375974069359\u001b[0m\t \u001b[1m\u001b[92m0.6998375974069359\u001b[0m\t \u001b[1m\u001b[92m2.160381525747321\u001b[0m\t \u001b[1m\u001b[92m2.160381525747321\u001b[0m\n",
            "13 \t [ 9.38226635  4.01107902 14.          0.88645966 17.          0.87374815]\t 0.7003440175917423\t 0.6998375974069359\t 2.1151228397361437\t 2.1151228397361437\n",
            "14 \t [6.15306411 2.33581448 6.         0.86920046 3.         0.31798329]\t 0.9825132645814829\t 0.6998375974069359\t 2.093696916363803\t 2.0936964238096016\n",
            "15 \t [ 9.51708919  0.58391709 12.          0.88753946  6.          0.24646931]\t 1.020999155280005\t 0.6998375974069359\t 2.11288483879289\t 2.1128848383041974\n",
            "16 \t [ 9.4564052   2.76673793  5.          0.69991499 12.01513431  1.        ]\t 0.7298771657348961\t 0.6998375974069359\t 2.1299951346761183\t 2.129995110831869\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.6998375974069359\t 2.125954919645917\t 2.125954919559345\n",
            "18 \t [ 8.50267404  2.17033522  6.          0.50604942 19.          0.82390736]\t 0.7325461349588777\t 0.6998375974069359\t 2.1613167755149787\t 2.161316775503128\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8649856112240915\t 0.6998375974069359\t 2.1026922324863193\t 2.1026922324863193\n",
            "\u001b[1m\u001b[92m20\u001b[0m\t \u001b[1m\u001b[92m[9.42368876e-03 1.00000000e+01 1.29999992e+01 1.00000000e+00\n",
            " 2.43660651e+00 1.00000000e+00]\u001b[0m\t \u001b[1m\u001b[92m0.6557674769774243\u001b[0m\t \u001b[1m\u001b[92m0.6557674769774243\u001b[0m\t \u001b[1m\u001b[92m2.104798061437558\u001b[0m\t \u001b[1m\u001b[92m2.1047980717030517\u001b[0m\n",
            "21 \t [ 3.40633968  0.23269315 10.          0.64291679  9.          0.50934585]\t 0.7623669782968152\t 0.6557674769774243\t 2.0880101839287586\t 2.088010183900176\n",
            "22 \t [ 1.40977975  9.49664308  8.          0.9695019  14.          0.93686763]\t 0.6917781892887018\t 0.6557674769774243\t 2.0708813082668547\t 2.0708813082668547\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8752416347792465\t 0.6557674769774243\t 2.117942504389462\t 2.117942504389462\n",
            "24 \t [1.21670026 0.49349112 6.         0.80878089 1.         0.63341473]\t 0.7604801329888093\t 0.6557674769774243\t 2.101248615399535\t 2.101248615378671\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7185577429000575\t 0.6557674769774243\t 2.0935606006049596\t 2.0935606006049596\n",
            "26 \t [0.33454906 4.8293531  6.         0.75998498 5.         0.78354586]\t 0.7316345518920343\t 0.6557674769774243\t 2.0699558662127484\t 2.0699558283792125\n",
            "27 \t [ 1.45041858  5.98415075  9.          0.63619622 18.          0.89957135]\t 0.693084819326313\t 0.6557674769774243\t 2.0521978336496507\t 2.0521978336496507\n",
            "28 \t [6.24238389 5.54906007 5.         0.88066249 7.         0.28760678]\t 0.9899602538994958\t 0.6557674769774243\t 2.058879200522458\t 2.058879200522458\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.0229660667953924\t 0.6557674769774243\t 2.055263613710223\t 2.055263613710223\n",
            "30 \t [ 2.76169479  7.56736049 14.          0.89186254  5.          0.37512166]\t 0.875357004979349\t 0.6557674769774243\t 2.091122083504312\t 2.091122083504312\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48747.895869248736"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2c2cf3-62db-41bd-9f6e-43e827640cb7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO_multi(surrogate_approx_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 1.9131124072687666\t 1.9131124072687666\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 0.9436692731753087\t 0.6641721421409617\t 1.9852973716601767\t 1.9852973716601767\n",
            "3  \t [7.47521879 1.08446649 5.         0.82092246 1.         0.87686231]\t 0.7277791972054833\t 0.6641721421409617\t 2.035102776875354\t 2.035102776875354\n",
            "4  \t [ 1.21913591  5.39021078 12.          0.52306788  2.          0.57375676]\t 0.7297298564124828\t 0.6641721421409617\t 2.0052894456401367\t 2.005289445640136\n",
            "5  \t [ 3.69739657  6.8572859  10.          0.91202097 18.          0.74080664]\t 0.6992744288425523\t 0.6641721421409617\t 1.9822691596956359\t 1.9822691596395199\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6641721421409617\t 1.956998120305214\t 1.956998120305214\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.7531044966742895\t 0.6641721421409617\t 1.9906427094644121\t 1.9906427094644121\n",
            "8  \t [ 0.32236964  2.41893129 14.          0.88540422 15.          0.72064562]\t 0.6990250321451492\t 0.6641721421409617\t 1.9788941757086838\t 1.9788941757086838\n",
            "9  \t [ 1.11038107  0.47615514 11.          0.89886404  7.          0.4182336 ]\t 0.7718391756586225\t 0.6641721421409617\t 1.9596709550044522\t 1.9596709548491897\n",
            "10 \t [ 6.832625    9.87635293 14.          0.84450885 19.          0.20389666]\t 0.9426343969692278\t 0.6641721421409617\t 1.9548219228626569\t 1.954821921013653\n",
            "11 \t [ 9.26888317  0.34770884 13.          0.56989599  5.          0.4978041 ]\t 0.7807352013231845\t 0.6641721421409617\t 1.9803995808058783\t 1.9803995808058783\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.6923205913979871\t 0.6641721421409617\t 1.9762004436609883\t 1.9762004436609883\n",
            "13 \t [ 0.4387066   6.89707822  5.          0.5042882  15.          0.2274319 ]\t 0.940102100969289\t 0.6641721421409617\t 1.960774988750204\t 1.960774988750204\n",
            "14 \t [ 3.22282465  1.05364145  6.          0.75774626 12.          0.92739587]\t 0.7076032952079638\t 0.6641721421409617\t 1.9812994424902468\t 1.9812994424902468\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.7682434061303821\t 0.6641721421409617\t 1.9693572059190905\t 1.9693572059190905\n",
            "16 \t [0.18736012 2.87894429 5.         0.99715153 3.         0.38605574]\t 0.8039158782445464\t 0.6641721421409617\t 1.9639670650715002\t 1.9639670650713827\n",
            "17 \t [ 9.32106438  8.94628345 11.          0.69008755 12.          0.43568744]\t 0.7747090147969604\t 0.6641721421409617\t 1.965372074386126\t 1.965372074386126\n",
            "18 \t [ 5.7913209   0.66562836 12.          0.88967575 12.          0.45276187]\t 0.7701049123721093\t 0.6641721421409617\t 1.9887352741161324\t 1.9887352741161324\n",
            "19 \t [ 2.28250676  8.57781075 10.          0.71780124 12.          0.3772521 ]\t 0.7733889133490559\t 0.6641721421409617\t 1.97765414698723\t 1.97765414698723\n",
            "20 \t [ 9.66721268  1.8443589  13.          0.69291942 15.          0.16614767]\t 0.942153170975135\t 0.6641721421409617\t 1.953505861462106\t 1.953505861462106\n",
            "21 \t [3.83586625 6.82676995 9.         0.53079541 5.         0.93774826]\t 0.6805235814013784\t 0.6641721421409617\t 1.9570832503483868\t 1.9570832503483868\n",
            "22 \t [ 2.56416717  0.15610938 12.          0.9617952   2.          0.74332064]\t 0.7056949638714144\t 0.6641721421409617\t 1.9925905966232749\t 1.9925905966232749\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.6641721421409617\t 1.9635243861783949\t 1.9635243861783949\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.724172646323414\t 0.6641721421409617\t 1.9860742876123574\t 1.9860742876123574\n",
            "25 \t [4.21410488 1.53847897 8.         0.72947689 4.         0.95835056]\t 0.6751026509280861\t 0.6641721421409617\t 1.9787778752082885\t 1.9787778752082885\n",
            "26 \t [ 7.01360923  0.03074572 13.          0.56476682  9.          0.19217174]\t 0.9417712124079543\t 0.6641721421409617\t 1.98280263024935\t 1.98280263024935\n",
            "27 \t [ 9.5097348   7.3660116   9.          0.93170762 19.          0.34791577]\t 0.8162562136213343\t 0.6641721421409617\t 1.968842599713603\t 1.9688425996280114\n",
            "28 \t [8.0273803  9.87833752 7.         0.89111617 6.         0.4918673 ]\t 0.7835403275506838\t 0.6641721421409617\t 1.9723917272776506\t 1.9723917272776506\n",
            "29 \t [ 6.25251023  4.76484713  9.          0.6837293  11.          0.18403618]\t 0.9419703047602315\t 0.6641721421409617\t 1.9633101536760647\t 1.9633101536760647\n",
            "30 \t [ 9.17303226  5.74079031 12.          0.94675996 18.          0.70963979]\t 0.6976110469452883\t 0.6641721421409617\t 1.9797867020378543\t 1.9797867020378543\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50692.52474167973"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b11fb9-6393-4224-a4be-05c7a59d3547"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO_multi(surrogate_approx_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 2.0860184672108364\t 2.0860184672108364\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 2.125269664628449\t 2.125269664628449\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m2.146884063898179\u001b[0m\t \u001b[1m\u001b[92m2.146884063898179\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 2.1234825906720296\t 2.1234825906720296\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m2.1268424504864543\u001b[0m\t \u001b[1m\u001b[92m2.1268424504864543\u001b[0m\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.92565009216999\t 0.6989575443158274\t 2.08907622382845\t 2.08907622382845\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6989575443158274\t 2.1059082052436486\t 2.1059082052436486\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m2.097199633360337\u001b[0m\t \u001b[1m\u001b[92m2.0971996333602836\u001b[0m\n",
            "9  \t [ 9.65300209  9.8103831  14.          1.         20.          0.40118499]\t 0.8407630790027255\t 0.6747588495441635\t 2.0664529008824513\t 2.0664529008843386\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.6796390241442563\t 0.6747588495441635\t 2.0659158927938064\t 2.0659158927938064\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[ 9.59856601  5.80158816 13.          0.87084357 12.          0.93985002]\u001b[0m\t \u001b[1m\u001b[92m0.6685720557527122\u001b[0m\t \u001b[1m\u001b[92m0.6685720557527122\u001b[0m\t \u001b[1m\u001b[92m2.0416315281635122\u001b[0m\t \u001b[1m\u001b[92m2.0416315281635122\u001b[0m\n",
            "12 \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]\t 0.7387384974169141\t 0.6685720557527122\t 2.018807443242245\t 2.018807443242245\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7130088179210804\t 0.6685720557527122\t 2.0069997120092\t 2.0069997120092\n",
            "14 \t [ 0.          3.4571991   9.7459799   0.53432259 10.45952512  0.41699079]\t 0.7935777628200846\t 0.6685720557527122\t 1.9929572977449612\t 1.992957222440573\n",
            "15 \t [ 0.58064821  4.71463583  6.          0.62063943 16.          0.34296764]\t 0.9341803578618377\t 0.6685720557527122\t 1.9980386903773646\t 1.9980386903773646\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8392510578678525\t 0.6685720557527122\t 2.0133845394128036\t 2.0133845394128036\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 9.34484937  3.49003142 14.          0.90417251  7.          0.92435507]\u001b[0m\t \u001b[1m\u001b[92m0.6682628994459927\u001b[0m\t \u001b[1m\u001b[92m0.6682628994459927\u001b[0m\t \u001b[1m\u001b[92m2.0147909724844233\u001b[0m\t \u001b[1m\u001b[92m2.0147909724844233\u001b[0m\n",
            "18 \t [ 9.73905766  7.12200775  5.          0.85875901 11.          0.99496281]\t 0.7281481211112614\t 0.6682628994459927\t 2.0408032230245285\t 2.0408032230245285\n",
            "19 \t [ 7.38101511  7.5533833  14.          0.66040085  5.          0.11249251]\t 0.9294141992141697\t 0.6682628994459927\t 2.017009586683709\t 2.017009586683709\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7616619440927369\t 0.6682628994459927\t 2.048865886100926\t 2.048865886100926\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7413460349644984\t 0.6682628994459927\t 2.028041588062679\t 2.028041588062679\n",
            "22 \t [ 3.12623913  1.70372165 14.          0.65033852 15.          0.68304577]\t 0.7003442032528848\t 0.6682628994459927\t 2.0002078591590076\t 2.0002078591590076\n",
            "23 \t [ 8.9847384   0.87540416 10.          0.69162194 11.          0.79327778]\t 0.6899258103715984\t 0.6682628994459927\t 2.034670640714195\t 2.034670640714195\n",
            "24 \t [5.80891976 6.22815082 5.         0.60791835 2.         0.19304152]\t 0.9476839298613445\t 0.6682628994459927\t 1.9628076865157174\t 1.9628073298203348\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.6920167982810115\t 0.6682628994459927\t 1.9911940297354107\t 1.9911940297354107\n",
            "26 \t [ 5.67132229  9.81814752  5.          0.79391133 12.          0.94608078]\t 0.7312011065869157\t 0.6682628994459927\t 1.9829415016590999\t 1.9829415016590999\n",
            "27 \t [ 3.19568236  8.11750563 12.          0.61408734  2.          0.64741824]\t 0.7090525375195045\t 0.6682628994459927\t 1.9681840226940817\t 1.9681836792937726\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7099197558902939\t 0.6682628994459927\t 2.0108790219285884\t 2.0108790219285884\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7312561878518347\t 0.6682628994459927\t 1.9492792719884329\t 1.9492792719884329\n",
            "30 \t [ 8.63092412  8.2029463  14.          0.59974273 15.          0.18268985]\t 0.9278875692639537\t 0.6682628994459927\t 2.0062873539830353\t 2.0062873539830353\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50894.575048108905"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9d462a-9850-48f3-9132-7634ae84f520"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO_multi(surrogate_approx_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 2.1056923959828033\t 2.1056923959828033\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 2.1757174829941723\t 2.1757174829941723\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0228902128409325\t 0.7312157182363477\t 2.2282538070108284\t 2.2282538070108284\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0595990180003476\t 0.7312157182363477\t 2.2647745512029025\t 2.264774551201397\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m2.3038646172746113\u001b[0m\t \u001b[1m\u001b[92m2.3038646172746113\u001b[0m\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.9234519385526558\t 0.6939533330723558\t 2.2507678923175685\t 2.250767892316754\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.0610911324495744\t 0.6939533330723558\t 2.252265504981642\t 2.252265504981642\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m2.2832254567521764\u001b[0m\t \u001b[1m\u001b[92m2.2832254567521764\u001b[0m\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0250396556181756\t 0.6895189879978737\t 2.2431088285006116\t 2.2431088285006116\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m2.263288359869864\u001b[0m\t \u001b[1m\u001b[92m2.263288359869864\u001b[0m\n",
            "11 \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]\t 0.7493845671941612\t 0.6832941408312798\t 2.228831761378201\t 2.228831761378201\n",
            "12 \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]\t 1.0180101584031926\t 0.6832941408312798\t 2.2061970948030365\t 2.2061970948030365\n",
            "13 \t [10.  10.   5.   0.5  1.   0.1]\t 1.064194646860047\t 0.6832941408312798\t 2.224462285316612\t 2.224462285316612\n",
            "14 \t [ 1.35461816  3.68867636  7.          0.97358458 19.          0.99760691]\t 0.7008772370455423\t 0.6832941408312798\t 2.2469129053841788\t 2.2469129053835952\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 0.19887638  4.80873048 13.          0.98258992 19.          0.95584094]\u001b[0m\t \u001b[1m\u001b[92m0.6764580978528367\u001b[0m\t \u001b[1m\u001b[92m0.6764580978528367\u001b[0m\t \u001b[1m\u001b[92m2.222414446694615\u001b[0m\t \u001b[1m\u001b[92m2.222414446694615\u001b[0m\n",
            "16 \t [6.55109905 2.29203942 6.         0.7269974  8.         0.87997636]\t 0.7181103319607761\t 0.6764580978528367\t 2.19775560500312\t 2.19775560500312\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.9614697348345509\t 0.6764580978528367\t 2.180690370427854\t 2.180690370427854\n",
            "18 \t [ 4.48555971  3.69204095  9.          0.58646272 16.          0.41216867]\t 0.9310926555739572\t 0.6764580978528367\t 2.17955800515203\t 2.17955800515203\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6764580978528367\t 2.182586277280241\t 2.182586277280241\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9398497506465855\t 0.6764580978528367\t 2.23011951059909\t 2.23011951059909\n",
            "21 \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]\t 1.0152545517792837\t 0.6764580978528367\t 2.2570180676631306\t 2.257018067658259\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.6833221374902283\t 0.6764580978528367\t 2.2104199857490694\t 2.2104199857490694\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9387634302639226\t 0.6764580978528367\t 2.2149326688286486\t 2.2149326688286486\n",
            "24 \t [0.02966045 1.1870223  6.         0.92997678 6.         0.66621503]\t 0.8113301041670242\t 0.6764580978528367\t 2.2005655214688904\t 2.2005655214688904\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.6893334668436607\t 0.6764580978528367\t 2.238951086253467\t 2.238951086253467\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.7458275930604825\t 0.6764580978528367\t 2.175821411268594\t 2.175821411268594\n",
            "27 \t [ 3.07145128  8.24536112 10.          0.9499357   1.          0.14212758]\t 1.0601608868750403\t 0.6764580978528367\t 2.1943119529598376\t 2.1943119528068324\n",
            "28 \t [ 3.86031457  2.79254313 11.          0.81134713  7.          0.51906134]\t 0.8247215391269236\t 0.6764580978528367\t 2.1936158904849274\t 2.1936158896111597\n",
            "29 \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]\t 0.7283015120438618\t 0.6764580978528367\t 2.204770464109012\t 2.2047699493611423\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.786373065109467\t 0.6764580978528367\t 2.1751349910615008\t 2.1751349910615008\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47116.726055847466"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db22085-06b3-436e-fd35-95bbd31bff2c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO_multi(surrogate_approx_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.8461730749178773\t 0.6529031062312245\t 1.7338376670633802\t 1.7338376670633802\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7280339284910606\t 0.6529031062312245\t 1.7947616448028514\t 1.7947616448028514\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.6571137209723783\t 0.6529031062312245\t 1.793130642771869\t 1.793130642771869\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7458231993222018\t 0.6529031062312245\t 1.7712287700277423\t 1.7712287700277423\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.7838758112536788\t 0.6529031062312245\t 1.7774988854446665\t 1.7774988854446665\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 1.7922689995707937\t 1.7922689995707937\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 1.7808787189959623\t 1.7808787189959623\n",
            "8  \t [ 0.46626117  2.25760624  6.          0.85367342 17.          0.48531791]\t 0.8135396529627978\t 0.6529031062312245\t 1.808633063429621\t 1.808633063429621\n",
            "9  \t [5.70513125 8.30861013 6.         0.98680016 3.         0.16134411]\t 0.9984088714580504\t 0.6529031062312245\t 1.8234584257171522\t 1.8234584257171522\n",
            "10 \t [ 3.5721216   0.0452777  14.          0.8757848   8.          0.10300558]\t 0.9938990668172615\t 0.6529031062312245\t 1.8747538344113484\t 1.8747538344113484\n",
            "11 \t [ 6.35215     9.71205645 11.          0.67733044  6.          0.80174708]\t 0.6867359020307766\t 0.6529031062312245\t 1.9171650055702634\t 1.917164990211106\n",
            "12 \t [9.93412004 7.01728008 6.         0.60790736 8.         0.46475011]\t 0.8183353504315909\t 0.6529031062312245\t 1.9033556230004183\t 1.9033556230004183\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.7792188999132433\t 0.6529031062312245\t 1.9093939248219325\t 1.9093939248219325\n",
            "14 \t [ 5.05369665  2.67147005  5.          0.51290284 10.          0.64085   ]\t 0.7504591409344632\t 0.6529031062312245\t 1.9093906309226232\t 1.9093906309226232\n",
            "15 \t [ 0.30180848  0.36339665 10.          0.99951435 11.          0.54137142]\t 0.6900449537968393\t 0.6529031062312245\t 1.9056885127192762\t 1.9056885127192762\n",
            "16 \t [ 2.05114544  9.95025126  6.          0.79677111 13.          0.57904529]\t 0.7341986392214718\t 0.6529031062312245\t 1.8954404089587533\t 1.8954404089587533\n",
            "17 \t [9.91439686 1.1223406  9.         0.69987447 9.         0.50079002]\t 0.7024687257866902\t 0.6529031062312245\t 1.8903219934173463\t 1.8903219934173463\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.6910349298616485\t 0.6529031062312245\t 1.8887123689711556\t 1.8887123689706742\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 0.9937922112122403\t 0.6529031062312245\t 1.8778074255966586\t 1.8778074255966586\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.8385022169449027\t 0.6529031062312245\t 1.8950033915624478\t 1.8950033915624478\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7015179019308584\t 0.6529031062312245\t 1.960728987982573\t 1.960728987982573\n",
            "22 \t [ 3.39029064  2.39709901 13.          0.66131557 19.          0.59343116]\t 0.6960101468974939\t 0.6529031062312245\t 1.899653831008173\t 1.899653831008173\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.8346586316188039\t 0.6529031062312245\t 1.9034736673155923\t 1.9034736673155923\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 8.17909255  8.95640578 13.          0.94174624  1.          0.89014148]\u001b[0m\t \u001b[1m\u001b[92m0.6509486270988182\u001b[0m\t \u001b[1m\u001b[92m0.6509486270988182\u001b[0m\t \u001b[1m\u001b[92m1.920654951753097\u001b[0m\t \u001b[1m\u001b[92m1.920654951753086\u001b[0m\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7621762752757402\t 0.6509486270988182\t 1.882950600461265\t 1.882950600461265\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 0.9921424184439918\t 0.6509486270988182\t 1.9007374202365575\t 1.9007374202365575\n",
            "27 \t [ 5.69797742  9.57419645  5.          0.83200529 19.          0.51994919]\t 0.7639513606860872\t 0.6509486270988182\t 1.942432751229455\t 1.942432751229455\n",
            "28 \t [ 7.27114604  3.7137488   9.          0.55194413 17.          0.65085645]\t 0.6957804844340307\t 0.6509486270988182\t 1.9161546280366009\t 1.9161546280366009\n",
            "29 \t [ 8.45771374  9.11809502  7.          0.66307374 13.          0.48477383]\t 0.8027470112720296\t 0.6509486270988182\t 1.8827761938291512\t 1.8827761938291512\n",
            "30 \t [ 0.41344076  0.53197741 10.          0.82623488 16.          0.71102663]\t 0.6865872275156124\t 0.6509486270988182\t 1.9503851601662434\t 1.9503851601662434\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50989.0544469606"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa78474-f770-4767-e9c4-761b2a0e8aa3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO_multi(surrogate_approx_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 1.813166598869859\t 1.813166598869859\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 1.7947851119212799\t 1.7947851119212799\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 1.8304333713878373\t 1.8304333713878373\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 1.8233654480582715\t 1.8233654480582715\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 1.8478086930314992\t 1.8478086930314992\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 1.8418872888200168\t 1.8418872888200168\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 1.824819912630544\t 1.824819912630544\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 1.8456194734133666\t 1.8456194734133666\n",
            "9  \t [ 0.45485069  5.92046568 13.          0.54575641 15.          0.3753516 ]\t 0.8133506998200086\t 0.6653168057229354\t 1.8603315437050856\t 1.860331542829666\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.6700820921354065\t 0.6653168057229354\t 1.8700664950642165\t 1.8700664950642165\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6653168057229354\t 1.8557020046637964\t 1.8557020046607353\n",
            "12 \t [ 4.71588947  9.8420912  12.          0.6928841   2.          0.94179256]\t 0.6697506372969916\t 0.6653168057229354\t 1.8690195940562147\t 1.8690195940562147\n",
            "13 \t [8.84715023 2.54200416 9.         0.79480608 3.         0.41227405]\t 0.8075723681673436\t 0.6653168057229354\t 1.8563953553679744\t 1.8563953553679744\n",
            "14 \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]\t 0.9379435984221122\t 0.6653168057229354\t 1.8632775408629658\t 1.863277540862476\n",
            "15 \t [3.07945993 2.84634362 5.         0.96506701 8.         0.51639003]\t 0.7614771713708528\t 0.6653168057229354\t 1.887770339836277\t 1.887770339836277\n",
            "16 \t [ 7.9422818   9.38756024  5.          0.82722729 18.          0.59098418]\t 0.7622832123642608\t 0.6653168057229354\t 1.8866576387574794\t 1.8866576387574794\n",
            "17 \t [ 2.12586208  4.01516793 14.          0.99753944  1.          0.59182746]\t 0.7166739101169476\t 0.6653168057229354\t 1.8878275156261821\t 1.8878275156261821\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9301596203801468\t 0.6653168057229354\t 1.8691318505009884\t 1.8691318505009884\n",
            "19 \t [ 1.24817982  5.75156112 12.          0.56532786 19.          0.40494625]\t 0.8104031101648417\t 0.6653168057229354\t 1.9494093287081273\t 1.9494093287081273\n",
            "20 \t [ 6.84951512  0.65690232  5.          0.51903401 13.          0.510251  ]\t 0.7625222038183027\t 0.6653168057229354\t 1.8905086897878909\t 1.8905086897859216\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.713587872750312\t 0.6653168057229354\t 1.8836958205444474\t 1.8836958205444474\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.8265101138776348\t 0.6653168057229354\t 1.9174231419158527\t 1.9174231419158527\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7048213880431081\t 0.6653168057229354\t 1.8919936725360884\t 1.8919936725345097\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\u001b[0m\t \u001b[1m\u001b[92m0.6652912380850803\u001b[0m\t \u001b[1m\u001b[92m0.6652912380850803\u001b[0m\t \u001b[1m\u001b[92m1.9316330302443867\u001b[0m\t \u001b[1m\u001b[92m1.9316330302443867\u001b[0m\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8407613659642559\t 0.6652912380850803\t 1.8707808082249329\t 1.8707808082249329\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9338663333604857\t 0.6652912380850803\t 1.888927503349492\t 1.888927503349492\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8100270760776773\t 0.6652912380850803\t 1.8945837433810164\t 1.8945837433810164\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.675192856271044\t 0.6652912380850803\t 1.9318791422830222\t 1.9318791422830222\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.699572467500549\t 0.6652912380850803\t 1.93207361020839\t 1.93207361020839\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 0.930914842449664\t 0.6652912380850803\t 1.9107836506036517\t 1.9107836506036517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52609.47902158823"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a978e205-9160-41d8-ff86-1a206ecb2064"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO_multi(surrogate_approx_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 1.840974913162529\t 1.840974913162529\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 1.9824874047859387\t 1.9824874047859387\n",
            "3  \t [ 8.20707753  5.23681739  9.          0.99500664 19.          0.41686889]\t 0.7862089426832719\t 0.6448358819228919\t 1.9396172860854324\t 1.9396172860854324\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 1.9378967867394183\t 1.9378967867394183\n",
            "5  \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]\t 0.7377720407232845\t 0.6448358819228919\t 1.924283205750116\t 1.924283205750116\n",
            "6  \t [ 2.07399013  1.08547559 13.          0.90854674 16.          0.44415088]\t 0.7854445167823974\t 0.6448358819228919\t 1.9128939383445436\t 1.9128939383445436\n",
            "7  \t [6.35203132 8.3324364  9.         0.54516266 6.         0.26778796]\t 0.8384879719057332\t 0.6448358819228919\t 1.9139015160351236\t 1.9139015160351236\n",
            "8  \t [ 0.56883492  2.21937218  6.          0.84490274 16.          0.30898926]\t 0.8417982153735359\t 0.6448358819228919\t 1.925952894691766\t 1.925952894691766\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.788150408197674\t 0.6448358819228919\t 1.936754187241336\t 1.936754187241336\n",
            "10 \t [ 5.98496312  5.93098165 12.          0.98968567 10.          0.92685569]\t 0.6460649755186514\t 0.6448358819228919\t 1.936316869062126\t 1.936316869062126\n",
            "11 \t [2.63920029 2.84662126 8.         0.81372528 9.         0.70958016]\t 0.7107155274108488\t 0.6448358819228919\t 1.9147638458082106\t 1.9147638458082101\n",
            "12 \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]\t 0.8508904111239197\t 0.6448358819228919\t 1.9033642633587224\t 1.903364263356273\n",
            "13 \t [ 9.90759058  1.21564186 12.          0.74911905 17.          0.244927  ]\t 1.0470230913477547\t 0.6448358819228919\t 1.9151844869562449\t 1.9151844869562449\n",
            "14 \t [ 0.42678797  0.40430921 14.          0.96202194 10.          0.10119674]\t 1.0441321675998059\t 0.6448358819228919\t 1.956724602998808\t 1.956724602998808\n",
            "15 \t [ 7.86637663  7.38432154 14.          0.83328102 16.          0.44973567]\t 0.7879963377566217\t 0.6448358819228919\t 1.992994219846488\t 1.9929942139123142\n",
            "16 \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]\t 0.738886934813979\t 0.6448358819228919\t 1.9887325405883773\t 1.9887325382148635\n",
            "17 \t [ 7.81834149  9.72965303  8.          0.64259089 17.          0.22077726]\t 1.0465197239444557\t 0.6448358819228919\t 1.9833998781279003\t 1.983399639598239\n",
            "18 \t [2.32449242 8.80135208 8.         0.99642073 4.         0.14576968]\t 1.0446140483804913\t 0.6448358819228919\t 2.0361231568218727\t 2.0361231568218727\n",
            "19 \t [ 9.51504197  0.48338584  6.          0.77192355 13.          0.39589712]\t 0.8079627199466959\t 0.6448358819228919\t 2.0287659236338107\t 2.0287659236338107\n",
            "20 \t [ 9.4006826   2.14529633  7.          0.801278   16.          0.55170588]\t 0.7578480827583333\t 0.6448358819228919\t 2.0374314047748454\t 2.0374314047748454\n",
            "21 \t [0.93748744 2.66462057 5.         0.77408223 4.         0.19936714]\t 1.0509962346828625\t 0.6448358819228919\t 2.0537229704858917\t 2.0537229703136264\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.7865928825712862\t 0.6448358819228919\t 2.0509794732433346\t 2.0509794732433346\n",
            "23 \t [ 0.79581704  0.44548953 10.          0.5535323   5.          0.9139619 ]\t 0.6649440013666069\t 0.6448358819228919\t 2.1059120706382335\t 2.1059120706382335\n",
            "24 \t [ 2.1444801   6.0467731  14.          0.77412521 12.          0.37466595]\t 0.8356273239382881\t 0.6448358819228919\t 2.06303717983649\t 2.06303717983649\n",
            "25 \t [ 8.47674061  5.78052722 12.          0.53190312  3.          0.14993193]\t 1.0494124396464328\t 0.6448358819228919\t 2.0503916156586484\t 2.0503916156586484\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.6950503015339501\t 0.6448358819228919\t 2.0570028790714727\t 2.0570028790714727\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 2.074136795027846\t 2.074136795027846\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 0.8375129312365261\t 0.6448358819228919\t 2.0629343139126766\t 2.0629343139126766\n",
            "29 \t [ 7.12320801  5.62079639  5.          0.57720044 19.          0.34391463]\t 0.8518813415581681\t 0.6448358819228919\t 2.052350705147192\t 2.052350705147192\n",
            "30 \t [ 6.14078962  2.31372054 11.          0.9240952  13.          0.361681  ]\t 0.8314074749252223\t 0.6448358819228919\t 2.0386149956093687\t 2.0386149956093687\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01722a45-6d4c-44bc-843e-4d406cbc3f94"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO_multi(surrogate_approx_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 1.8892111592817085\t 1.8892111592817085\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 1.8527314884921047\t 1.8527314884921047\n",
            "3  \t [ 2.20772511  4.37663949 11.          0.65455258  3.          0.57545511]\t 0.7112447021396917\t 0.6669292375133978\t 1.8476723658663035\t 1.8476723658663035\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 1.8348187524063884\t 1.8348187524063884\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 3.75041373  9.81989522 14.          0.71370546 14.          0.97207881]\u001b[0m\t \u001b[1m\u001b[92m0.6475832890376199\u001b[0m\t \u001b[1m\u001b[92m0.6475832890376199\u001b[0m\t \u001b[1m\u001b[92m1.822020432188345\u001b[0m\t \u001b[1m\u001b[92m1.822020432188345\u001b[0m\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 0.8210163484458256\t 0.6475832890376199\t 1.7998337552088854\t 1.7998337552088854\n",
            "7  \t [ 9.67314628  9.09427799  9.          0.82851167 16.          0.96267251]\t 0.6524258272573389\t 0.6475832890376199\t 1.8200502965004763\t 1.8200502965002883\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7069523757910561\t 0.6475832890376199\t 1.8026002105020238\t 1.8026002105020238\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.661096368919013\t 0.6475832890376199\t 1.7972434073549175\t 1.7972434073549175\n",
            "10 \t [ 9.68988111  3.14723756  5.          0.57337272 11.          0.12853019]\t 0.8805076498265475\t 0.6475832890376199\t 1.785126737689549\t 1.7851267375309092\n",
            "11 \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]\t 0.662454600529182\t 0.6475832890376199\t 1.8122749202055275\t 1.8122749202055275\n",
            "12 \t [ 8.79417312  9.02268129 11.          0.87585483  1.          0.84249089]\t 0.6656143987957235\t 0.6475832890376199\t 1.8010061008917981\t 1.8010061008917981\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.823119322181516\t 0.6475832890376199\t 1.791428826480079\t 1.79142882550254\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.8166474442456968\t 0.6475832890376199\t 1.8046561509013943\t 1.8046561509013943\n",
            "15 \t [ 0.15128266  5.75290365 10.          0.52450544 13.          0.50574484]\t 0.7096440124563574\t 0.6475832890376199\t 1.8155291614057263\t 1.8155291614057263\n",
            "16 \t [ 0.04708663  5.63008151  7.          0.89049451 16.          0.24468474]\t 0.8805243043062951\t 0.6475832890376199\t 1.8119963219483353\t 1.8119963219483353\n",
            "17 \t [0.54815519 9.09457687 7.         0.55756737 9.         0.32110491]\t 0.8160888137431301\t 0.6475832890376199\t 1.8304469533550636\t 1.8304469533550636\n",
            "18 \t [ 6.17394409  4.04114422 10.          0.65058545  1.          0.14583054]\t 0.884659950113891\t 0.6475832890376199\t 1.8777724690355555\t 1.8777724690355555\n",
            "19 \t [ 3.78735015  9.68358783 10.          0.98414687 15.          0.22243198]\t 0.8826051292460525\t 0.6475832890376199\t 1.8460535525816062\t 1.8460535525816062\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 0.8804917195016874\t 0.6475832890376199\t 1.8803861608171002\t 1.8803861608171002\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7119792503375972\t 0.6475832890376199\t 1.8844716858827204\t 1.8844716858827204\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 0.8840919924947371\t 0.6475832890376199\t 1.8766101543011244\t 1.8766101543011244\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.6539666670983036\t 0.6475832890376199\t 1.8782454830647377\t 1.8782454830647377\n",
            "24 \t [ 8.33810851  9.8990204  14.          0.61893039  5.          0.69227045]\t 0.699282809687575\t 0.6475832890376199\t 1.893096628519133\t 1.893096628519133\n",
            "25 \t [ 8.21404851  8.60074735  5.          0.79731226 10.          0.34633832]\t 0.8239891419025721\t 0.6475832890376199\t 1.8953057902763\t 1.8953057415570316\n",
            "26 \t [0.72011027 2.41454939 5.         0.73329854 4.         0.80641154]\t 0.7249785454048165\t 0.6475832890376199\t 1.8980819639768876\t 1.8980819639768876\n",
            "27 \t [ 9.80190803  7.94317114 14.          0.54244107 12.          0.27327436]\t 0.8158699848951138\t 0.6475832890376199\t 1.873075526607103\t 1.8730755266069543\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 0.8822650514974324\t 0.6475832890376199\t 1.8656050367446515\t 1.8656050367446515\n",
            "29 \t [ 1.96225237  3.86496333  6.          0.92435335 11.          0.8799391 ]\t 0.6901318450550971\t 0.6475832890376199\t 1.900810175239723\t 1.900810175239723\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.81181886510441\t 0.6475832890376199\t 1.910345932854368\t 1.910345932854368\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49942.9444228931"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5204cfb-be81-4397-d5a9-7a7c82c04604"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO_multi(surrogate_approx_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 1.7719800273756232\t 1.7719800273756232\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m1.7669632135588516\u001b[0m\t \u001b[1m\u001b[92m1.7669632135588516\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 1.7455497205558128\t 1.7455497205558128\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 0.9235319432135773\t 0.6577294425265764\t 1.7620581524596006\t 1.7620581524596006\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.7883201967902798\t 0.6577294425265764\t 1.8244103569278647\t 1.8244103569278647\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.6922630708519245\t 0.6577294425265764\t 1.8361228109905843\t 1.8361228109905843\n",
            "7  \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]\t 0.6892145672079726\t 0.6577294425265764\t 1.823093173384735\t 1.823093173384196\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.8743477887688297\t 0.6577294425265764\t 1.8128928290509938\t 1.8128928290509938\n",
            "9  \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]\t 0.6852941374864567\t 0.6577294425265764\t 1.8399075803143972\t 1.8399075803143972\n",
            "10 \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]\t 0.7098807101273504\t 0.6577294425265764\t 1.8292020508340574\t 1.8292020508340574\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.8864529961319944\t 0.6577294425265764\t 1.8232333280708632\t 1.8232333280708632\n",
            "12 \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]\t 0.9231023673501877\t 0.6577294425265764\t 1.8465154973374451\t 1.8465154973374451\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 0.9234149203761113\t 0.6577294425265764\t 1.873605592977534\t 1.873605592977534\n",
            "14 \t [ 0.62966465  6.1940162  12.          0.81741232 11.          0.49382371]\t 0.763330830255445\t 0.6577294425265764\t 1.8980229439530556\t 1.8980229439530556\n",
            "15 \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]\t 0.9297173774466645\t 0.6577294425265764\t 1.8963917054809143\t 1.896391705460151\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7068100593711837\t 0.6577294425265764\t 1.916612698344637\t 1.916612698344637\n",
            "17 \t [ 8.04132914  5.28680001  8.          0.60118579 16.          0.65451176]\t 0.7024150837706379\t 0.6577294425265764\t 1.908522132240112\t 1.908522132240112\n",
            "18 \t [4.8061792  8.89898429 9.         0.78746867 6.         0.23513634]\t 0.9232996261586969\t 0.6577294425265764\t 1.9124795705053936\t 1.9124795705053936\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 0.9265282654642244\t 0.6577294425265764\t 1.921806648669735\t 1.921806648669735\n",
            "20 \t [0.56806539 7.69746805 6.         0.94796222 9.         0.37129588]\t 0.8772298745282174\t 0.6577294425265764\t 1.959505121906352\t 1.959505121906352\n",
            "21 \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]\t 0.7250537141107671\t 0.6577294425265764\t 1.9708820756321872\t 1.9708820756321872\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7286740032592812\t 0.6577294425265764\t 1.9543242269749586\t 1.9543242269749586\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7418835369809943\t 0.6577294425265764\t 1.9972950922754578\t 1.9972950922754578\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.8686347965869988\t 0.6577294425265764\t 1.9525163620585062\t 1.9525163620585062\n",
            "25 \t [8.78648556 8.67236761 7.         0.86300156 3.         0.51532161]\t 0.7380095705776981\t 0.6577294425265764\t 1.934196785613784\t 1.934196785613784\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.764405864026175\t 0.6577294425265764\t 1.9828347773851545\t 1.9828347773851545\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7332555811634872\t 0.6577294425265764\t 1.9442370917986322\t 1.9442370917986322\n",
            "28 \t [0.37569294 0.30864512 9.         0.6310655  7.         0.92576756]\t 0.6621924195468778\t 0.6577294425265764\t 1.929088547797823\t 1.929088547797823\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.6600116767225708\t 0.6577294425265764\t 1.9138239242103392\t 1.9138239242103392\n",
            "30 \t [4.8041921  4.06620309 5.         0.94317975 9.         0.20395595]\t 0.93061105311828\t 0.6577294425265764\t 1.946961588370418\t 1.946961588370218\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52451.32960260449"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c552d389-a2b0-4ced-cf57-9d7613bdaf8f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO_multi(surrogate_approx_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 1.9480535380628092\t 1.9480535380628092\n",
            "2  \t [ 3.78385301  2.21923666 12.          0.57141407  8.          0.55842631]\t 0.7285402508953416\t 0.7056203424268611\t 1.9288412333932206\t 1.9288412333932206\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 4.70630658  9.38750646 12.          0.7933865  10.          0.74968408]\u001b[0m\t \u001b[1m\u001b[92m0.6939932582164752\u001b[0m\t \u001b[1m\u001b[92m0.6939932582164752\u001b[0m\t \u001b[1m\u001b[92m1.9088963347329155\u001b[0m\t \u001b[1m\u001b[92m1.9088963347329155\u001b[0m\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.8009366885878899\t 0.6939932582164752\t 1.8840434025174555\t 1.8840434025174555\n",
            "5  \t [ 9.02656498  0.48984226 12.          0.66187047 14.          0.17842177]\t 0.9261950890540188\t 0.6939932582164752\t 1.892850966154169\t 1.892850966154169\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.7872412218199303\t 0.6939932582164752\t 1.9337262327748503\t 1.9337262327748503\n",
            "7  \t [ 9.92159613  3.53760601 14.          0.66495754  4.          0.92098158]\t 0.7037336633700015\t 0.6939932582164752\t 1.9332374446261489\t 1.9332374446261489\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.8017323350323444\t 0.6939932582164752\t 1.9166576467358265\t 1.9166576467358265\n",
            "9  \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]\t 0.7213506404912987\t 0.6939932582164752\t 1.9203313547215328\t 1.9203313547215328\n",
            "10 \t [ 2.00580329  2.31031601 14.          0.90401435 16.          0.44341936]\t 0.7698813922221472\t 0.6939932582164752\t 1.9097823839345018\t 1.9097823839345018\n",
            "11 \t [ 2.24226925  8.24518571  5.          0.69075261 11.          0.5179779 ]\t 0.7689331541513587\t 0.6939932582164752\t 1.9082024499586625\t 1.908202449930304\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.7202487480474815\t 0.6939932582164752\t 1.906638673782583\t 1.906638673782583\n",
            "13 \t [ 5.97904546  9.54654633 12.          0.85402391 19.          0.25521119]\t 0.7891186169314436\t 0.6939932582164752\t 1.8984976271961633\t 1.8984976271961633\n",
            "14 \t [ 0.609825    8.87388875 14.          0.9069446   2.          0.82580346]\t 0.6998436682886817\t 0.6939932582164752\t 1.900491013034382\t 1.900491013034382\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9310123715662361\t 0.6939932582164752\t 1.8911996832446798\t 1.8911996832446798\n",
            "16 \t [ 9.50979811  3.16002382 14.          0.62948949 10.          0.39138316]\t 0.775390231089039\t 0.6939932582164752\t 1.912548647085807\t 1.912548647085807\n",
            "17 \t [ 2.38620183  1.03950496 13.          0.6257051   6.          0.34211692]\t 0.7949227225244432\t 0.6939932582164752\t 1.9120423935381161\t 1.9120423935381161\n",
            "18 \t [3.82043232 0.90149463 5.         0.93713205 2.         0.73959641]\t 0.7410345449107776\t 0.6939932582164752\t 1.9332118082249987\t 1.9332118082249987\n",
            "19 \t [9.51121457 1.16444035 9.         0.81792407 9.         0.70590587]\t 0.6983390620759949\t 0.6939932582164752\t 1.9173447980548235\t 1.9173447980548235\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.6939932582164752\t 1.897381776732561\t 1.897381776732561\n",
            "21 \t [ 0.60383814  6.44796032 11.          0.78951032 16.          0.75679881]\t 0.694356779546439\t 0.6939932582164752\t 1.888519086845247\t 1.888519086845247\n",
            "22 \t [ 4.22119996  7.99655483  5.          0.78307763 14.          0.79061697]\t 0.7405746569621561\t 0.6939932582164752\t 1.936139383934082\t 1.936139383934082\n",
            "23 \t [8.06269287 6.47637245 9.         0.81164321 8.         0.55442999]\t 0.7232813229370987\t 0.6939932582164752\t 1.9133430406556433\t 1.9133430406556433\n",
            "24 \t [ 3.54377146  1.55114788  9.          0.60325108 18.          0.58026864]\t 0.7288271346270945\t 0.6939932582164752\t 1.8755938051853425\t 1.8755938051853425\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9328823718301782\t 0.6939932582164752\t 1.9142926685462363\t 1.9142926685462363\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 1.0206155   0.50876351 11.          0.82996077 17.          0.80891943]\u001b[0m\t \u001b[1m\u001b[92m0.6931022492573785\u001b[0m\t \u001b[1m\u001b[92m0.6931022492573785\u001b[0m\t \u001b[1m\u001b[92m1.95526130538092\u001b[0m\t \u001b[1m\u001b[92m1.95526130538092\u001b[0m\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 8.46446661  3.28716173 10.31041431  0.5        19.44077186  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6697545757800534\u001b[0m\t \u001b[1m\u001b[92m0.6697545757800534\u001b[0m\t \u001b[1m\u001b[92m1.941057127502651\u001b[0m\t \u001b[1m\u001b[92m1.941056696473803\u001b[0m\n",
            "28 \t [ 2.58558616  0.56131889 10.          0.88548273 13.          0.80616727]\t 0.6920038292043351\t 0.6697545757800534\t 1.9131459087814293\t 1.9131459087814293\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.7292686946198735\t 0.6697545757800534\t 1.9159989416501455\t 1.9159989416501455\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.9256181718283066\t 0.6697545757800534\t 1.890714103308586\t 1.890714103308586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53209.626126211784"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39f0a20-a588-448e-8102-53a76c0bf5a2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO_multi(surrogate_approx_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 2.2534590690909986\t 2.2534590690909986\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.6734860180774931\t 0.6628876451121497\t 2.179719119123623\t 2.179719119089436\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.6628876451121497\t 2.1121601277045015\t 2.1121601277045015\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.6797825903178236\t 0.6628876451121497\t 2.0847442438968007\t 2.0847442438968007\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.0980632271289044\t 0.6628876451121497\t 2.0423809780703746\t 2.0423809780703746\n",
            "6  \t [ 7.68636788  7.27927184 12.          0.97932089  3.          0.87363673]\t 0.6657443951678294\t 0.6628876451121497\t 2.1160361568348827\t 2.1160361568348827\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8250792636501453\t 0.6628876451121497\t 2.0766157923315234\t 2.0766157923315234\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1062273028353988\t 0.6628876451121497\t 2.072038518039403\t 2.072038518039403\n",
            "9  \t [ 6.80309585  9.43423094  7.          0.8851539  14.          0.77731456]\t 0.6905350263714448\t 0.6628876451121497\t 2.127885291733643\t 2.127885291733643\n",
            "10 \t [ 6.60596124  8.35313787  6.          0.72167152 19.          0.94552853]\t 0.7025896131486131\t 0.6628876451121497\t 2.0997159437405184\t 2.0997159437405184\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7370906275446215\t 0.6628876451121497\t 2.0766062727279753\t 2.0766062727279753\n",
            "12 \t [ 9.46545841  2.71414127  5.          0.83512297 13.          0.70984642]\t 0.7596192306405462\t 0.6628876451121497\t 2.06072600267908\t 2.06072600267908\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.9801878   7.62207926 11.          0.92097131  8.          0.96474414]\u001b[0m\t \u001b[1m\u001b[92m0.6582649380252287\u001b[0m\t \u001b[1m\u001b[92m0.6582649380252287\u001b[0m\t \u001b[1m\u001b[92m2.049487639723963\u001b[0m\t \u001b[1m\u001b[92m2.049487639717201\u001b[0m\n",
            "14 \t [ 6.64335896  4.21317694 13.          0.67704359  4.          0.77970128]\t 0.6746732785820976\t 0.6582649380252287\t 2.027706469829796\t 2.027706469829796\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.6582649380252287\t 2.009720825343973\t 2.0097208253439227\n",
            "16 \t [9.66123717 1.6749164  7.         0.52601834 9.         0.78339475]\t 0.6982122839928836\t 0.6582649380252287\t 1.9928854553208755\t 1.9928854553208755\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.105080285400748\t 0.6582649380252287\t 1.9798248465871986\t 1.9798248465871986\n",
            "18 \t [9.81792293 8.02628625 6.         0.84581675 1.         0.43435016]\t 0.8324792319640995\t 0.6582649380252287\t 2.010842383964405\t 2.010842383964405\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.0995998424487943\t 0.6582649380252287\t 2.0154420733446115\t 2.0154420733446115\n",
            "20 \t [ 2.43733809  3.83718859 13.          0.87000869 16.          0.41452306]\t 0.8189050631597883\t 0.6582649380252287\t 2.0528760761700355\t 2.0528760761700355\n",
            "21 \t [4.36648808 8.42254188 6.         0.54886836 3.         0.62627434]\t 0.7390982861353472\t 0.6582649380252287\t 2.042057989339477\t 2.042057989339477\n",
            "22 \t [ 2.54628391  7.46240954  5.57353361  0.5        16.89865896  0.1       ]\t 1.0997636857306623\t 0.6582649380252287\t 2.089406727254379\t 2.089406726636886\n",
            "23 \t [3.55859061 5.61875163 8.         0.5882063  1.         0.57036163]\t 0.7346535405920693\t 0.6582649380252287\t 2.119541101030152\t 2.119541101030152\n",
            "24 \t [1.5938649  0.20757679 5.         0.94973168 4.         0.41254588]\t 0.8381523439146795\t 0.6582649380252287\t 2.095632002942585\t 2.095632002942585\n",
            "25 \t [9.92248648 8.73301847 7.         0.58578431 6.         0.64802898]\t 0.7258609233436316\t 0.6582649380252287\t 2.07142545774428\t 2.07142545774428\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.672888499874982\t 0.6582649380252287\t 2.0680114995899572\t 2.0680114995899572\n",
            "27 \t [ 7.74005531  8.73318352 14.          0.77422043 15.          0.27051553]\t 0.923046327058876\t 0.6582649380252287\t 2.0525505138785434\t 2.0525505029708273\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.768583852631927\t 0.6582649380252287\t 2.0416547565990295\t 2.0416547565990295\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9197610970890002\t 0.6582649380252287\t 2.0583454902803893\t 2.0583454902803893\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.9166993865744176\t 0.6582649380252287\t 2.048824955190354\t 2.048824955190354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49331.664993400715"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc094bbe-5397-4951-be59-2d94feeb439a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO_multi(surrogate_approx_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 2.0703363057846262\t 2.0703363057846262\n",
            "2  \t [ 9.16780803  5.31613214 10.          0.57182868  6.          0.98158575]\t 0.6763772246849529\t 0.6747866005380063\t 2.1441710076251392\t 2.1441710076251392\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6747866005380063\t 2.0815422043996583\t 2.0815422043996583\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6747866005380063\t 2.0457122647266504\t 2.0457122647266504\n",
            "5  \t [ 9.22243919  0.59642165  6.          0.72537748 19.          0.46639325]\t 0.8253470890530193\t 0.6747866005380063\t 2.0979905095052365\t 2.0979905095052365\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 1.0131910395518218\t 0.6747866005380063\t 2.090487414603377\t 2.090487414603377\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 5.79577795  1.8570688  14.          0.83128935 19.          0.71549729]\u001b[0m\t \u001b[1m\u001b[92m0.672743180913679\u001b[0m\t \u001b[1m\u001b[92m0.672743180913679\u001b[0m\t \u001b[1m\u001b[92m2.1290344904358367\u001b[0m\t \u001b[1m\u001b[92m2.1290344904358367\u001b[0m\n",
            "8  \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]\t 0.8087127953472528\t 0.672743180913679\t 2.0931675508942154\t 2.0931675508942154\n",
            "9  \t [ 6.82711248  9.86843937 13.          0.52138031 17.          0.20003272]\t 1.0114628267773051\t 0.672743180913679\t 2.0847498274875\t 2.0847498274875\n",
            "10 \t [ 1.6361515   9.65601963  6.          0.78645605 10.          0.24059194]\t 1.0163848571205125\t 0.672743180913679\t 2.115231358859686\t 2.115231358859686\n",
            "11 \t [ 9.30217735  6.23147787  8.          0.97503033 15.          0.52511943]\t 0.7234253694323725\t 0.672743180913679\t 2.14223307145576\t 2.14223307145576\n",
            "12 \t [ 1.50285169  4.17593259 14.          0.69234646  6.          0.74044842]\t 0.677587403128438\t 0.672743180913679\t 2.1209249010114286\t 2.1209249010114286\n",
            "13 \t [ 9.52967585  8.1936199  11.          0.55796294 10.          0.99729185]\t 0.6733311328695132\t 0.672743180913679\t 2.0966687483703983\t 2.0966687483703983\n",
            "14 \t [4.48522578 6.54261798 5.         0.79314226 1.         0.29945677]\t 0.9752292115331169\t 0.672743180913679\t 2.0743076772803812\t 2.0743076772803812\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 1.13909448  9.99750981 12.          0.83097832  8.          0.96211319]\u001b[0m\t \u001b[1m\u001b[92m0.6681753308209242\u001b[0m\t \u001b[1m\u001b[92m0.6681753308209242\u001b[0m\t \u001b[1m\u001b[92m2.0920883449513736\u001b[0m\t \u001b[1m\u001b[92m2.0920883449513736\u001b[0m\n",
            "16 \t [ 6.17398984  7.07288493 12.          0.63300963  8.          0.36188703]\t 0.9625825839575025\t 0.6681753308209242\t 2.0720699651823664\t 2.0720699651823664\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.7105097809499443\t 0.6681753308209242\t 2.0852802036496\t 2.0852802036496\n",
            "18 \t [1.97879228 8.99345507 8.         0.55562265 8.         0.49118331]\t 0.8134492450677617\t 0.6681753308209242\t 2.089578358065379\t 2.089578358065379\n",
            "19 \t [ 3.46936711  8.05933995 13.          0.63796232  8.          0.58226276]\t 0.7204550280994024\t 0.6681753308209242\t 2.090426473989988\t 2.090426473989988\n",
            "20 \t [ 7.46504676  0.          6.08964528  0.62367028 11.18165528  0.93206243]\t 0.707104406935024\t 0.6681753308209242\t 2.0450075889982604\t 2.0450075899112616\n",
            "21 \t [ 1.52900897  2.49551652 10.          0.74070159  3.          0.79386687]\t 0.6772839651254358\t 0.6681753308209242\t 2.075376449990297\t 2.075376449990297\n",
            "22 \t [ 5.41628928  0.6457522  11.          0.53381263  8.          0.50847629]\t 0.7208636563336477\t 0.6681753308209242\t 2.0569401799306024\t 2.0569401799306024\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 1.008805594135994\t 0.6681753308209242\t 2.054145026626764\t 2.054145026626764\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.6871807270632571\t 0.6681753308209242\t 2.04742979376943\t 2.04742979376943\n",
            "25 \t [ 5.5386478   9.30162083  6.          0.50498383 14.          0.37570322]\t 0.8247413269393998\t 0.6681753308209242\t 2.0728252034953982\t 2.0728252034953982\n",
            "26 \t [ 7.99859192  1.27814403 11.          0.87670998 12.          0.48785901]\t 0.8089215294655372\t 0.6681753308209242\t 2.044198205176339\t 2.044198204883136\n",
            "27 \t [8.60914739 9.54673859 7.         0.78963544 7.         0.48348756]\t 0.815291878276993\t 0.6681753308209242\t 2.0366313196902035\t 2.0366313196902035\n",
            "28 \t [ 0.08962521  4.02073781 13.          0.7602714  18.          0.37402763]\t 0.9571588040283491\t 0.6681753308209242\t 2.0179981021045954\t 2.0179981021045954\n",
            "29 \t [ 9.79781036  7.70828329  5.          0.72056878 19.          0.87728226]\t 0.7263484375049021\t 0.6681753308209242\t 2.0374246337403137\t 2.0374246337403137\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.6762301508489591\t 0.6681753308209242\t 2.075847246603669\t 2.075847246603669\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51987.64926819376"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd186652-c48a-4f0b-cc4d-174d111d7961"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO_multi(surrogate_approx_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 2.0235993380712465\t 2.0235993380712465\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 1.9627197732844939\t 1.9627197732844939\n",
            "3  \t [ 7.5915683   5.13937898 12.          0.70919884  1.          0.76222697]\t 0.6599034896559471\t 0.6568473525973234\t 1.9833604860581564\t 1.9833604860581564\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.8615658015198442\t 0.6568473525973234\t 1.9412899752989823\t 1.9412899752989823\n",
            "5  \t [ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\t 0.730615339433918\t 0.6568473525973234\t 1.960800119689077\t 1.960800119689077\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.8514677232156771\t 0.6568473525973234\t 1.9443618253927004\t 1.9443618253927004\n",
            "7  \t [ 9.09795503  1.07150197  7.          0.98191679 19.          0.62951892]\t 0.6952220627574484\t 0.6568473525973234\t 1.957628742573861\t 1.9576287425738046\n",
            "8  \t [ 9.21941721  9.79827821 11.          0.81783228 11.          0.53477407]\t 0.6659586056207597\t 0.6568473525973234\t 1.9376847425916641\t 1.9376847425916641\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.7097411329660293\t 0.6568473525973234\t 1.9158548276068084\t 1.9158548275259628\n",
            "10 \t [ 8.47779105  8.43696768  5.          0.73890705 16.          0.66738091]\t 0.7564851327663848\t 0.6568473525973234\t 1.903713533919763\t 1.903713533919763\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.6638601166418586\t 0.6568473525973234\t 1.9004093732765648\t 1.9004093732765648\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.7350998875793917\t 0.6568473525973234\t 1.8844480619119055\t 1.8844480619119055\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.6855937848974291\t 0.6568473525973234\t 1.8790749798532358\t 1.8790749798521724\n",
            "14 \t [ 0.67244942  9.08791765  7.          0.79067069 13.          0.11985169]\t 0.9105891037840351\t 0.6568473525973234\t 1.869086558098399\t 1.869086558098399\n",
            "15 \t [3.91240074 6.5849714  5.         0.97211484 8.         0.11185491]\t 0.9123340390900221\t 0.6568473525973234\t 1.8897513931370629\t 1.8897513931370629\n",
            "16 \t [8.78569544 0.14730956 7.         0.66172647 2.         0.54513841]\t 0.7029675116471538\t 0.6568473525973234\t 1.9091623453644624\t 1.9091623421391317\n",
            "17 \t [4.50435964 1.42883317 8.         0.76583339 3.         0.4306355 ]\t 0.7929882304105694\t 0.6568473525973234\t 1.89943828780397\t 1.89943828780397\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.6653785933459865\t 0.6568473525973234\t 1.923465074676545\t 1.923465074676545\n",
            "19 \t [ 9.64875283  9.32176949  8.          0.85263567 19.          0.33410227]\t 0.849585847576698\t 0.6568473525973234\t 1.8897491797119066\t 1.8897491797119066\n",
            "20 \t [ 5.31037667  6.81676807  5.          0.53020463 18.          0.21260061]\t 0.9149718789671064\t 0.6568473525973234\t 1.8972506237779083\t 1.8972506237779083\n",
            "21 \t [ 9.28937895  1.2300363  13.          0.54126463 19.          0.2413571 ]\t 0.9115950849057539\t 0.6568473525973234\t 1.9591991951316665\t 1.9591991951316665\n",
            "22 \t [ 4.90087649  7.40954674 11.          0.53028779  8.          0.43614982]\t 0.7965594035331703\t 0.6568473525973234\t 1.9380082357762651\t 1.9380082253451911\n",
            "23 \t [ 1.04966198  1.72140723 11.          0.68060657  8.          0.5044115 ]\t 0.671250212686766\t 0.6568473525973234\t 1.945976078483506\t 1.945976078483506\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.756031776613528\t 0.6568473525973234\t 1.9417806277160325\t 1.9417806277160325\n",
            "25 \t [ 1.719002    1.73903169  5.          0.87805761 14.          0.46260902]\t 0.8248486263986295\t 0.6568473525973234\t 1.9761587507132057\t 1.9761587507132057\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.8070679905812153\t 0.6568473525973234\t 1.9646548914993982\t 1.9646548914993982\n",
            "27 \t [ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]\t 0.659126679409869\t 0.6568473525973234\t 1.9503442163133875\t 1.9503442163133875\n",
            "28 \t [ 3.85186676  3.1955202  13.          0.84289144 11.          0.29344016]\t 0.8541007539408902\t 0.6568473525973234\t 1.9222241205382815\t 1.9222241089004828\n",
            "29 \t [ 4.65617249  4.2358638  14.          0.83630546  4.          0.12527477]\t 0.9111271550835559\t 0.6568473525973234\t 1.9110149716454543\t 1.9110149329922381\n",
            "30 \t [ 8.04276314  4.60586342  8.          0.52625867 16.          0.88607792]\t 0.6768526749544357\t 0.6568473525973234\t 1.9458663923146866\t 1.9458663923146866\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50629.339378690864"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d1ea97-3324-4123-ba8c-ee5eca70d5fb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO_multi(surrogate_approx_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m2.3038238546063514\u001b[0m\t \u001b[1m\u001b[92m2.3038238546063514\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 2.2127290631456797\t 2.2127290631456797\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 2.2029457185694286\t 2.2029457185694286\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 2.191313624172012\t 2.191313624172012\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 2.206625876161531\t 2.206625876161531\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 2.1979859530191246\t 2.1979859530191246\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 2.1640725756855974\t 2.1640725756855974\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.7620148611738933\t 0.6878693399983744\t 2.1807721875863506\t 2.1807721875863506\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m2.158276124221017\u001b[0m\t \u001b[1m\u001b[92m2.158276124221017\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7199718018091047\t 0.6730441336589406\t 2.1259247504317456\t 2.1259247504317456\n",
            "11 \t [ 3.92379693  5.26427008  7.          0.52294127 13.          0.66328071]\t 0.7482193144353987\t 0.6730441336589406\t 2.103702589721769\t 2.103702589721769\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 2.0880514782049864\t 2.0880514782049864\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m2.0693187001876523\u001b[0m\t \u001b[1m\u001b[92m2.0693187001876523\u001b[0m\n",
            "14 \t [ 5.41155711  5.82534705 10.          0.62444801 12.          0.48368067]\t 0.8667049733212127\t 0.6551680070961308\t 2.0464146387435806\t 2.0464146387435806\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 0.8854668121365705\t 0.6551680070961308\t 2.050595144067894\t 2.050595144067894\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6551680070961308\t 2.0563117527326322\t 2.0563117527326322\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 0.9718611347031094\t 0.6551680070961308\t 2.0507385470392046\t 2.0507385470392046\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 0.8703303423168164\t 0.6551680070961308\t 2.0985186279711505\t 2.0985186279711505\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 0.8664298555004347\t 0.6551680070961308\t 2.0639552341647804\t 2.0639552341384415\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.8073058384557079\t 0.6551680070961308\t 2.083308988591958\t 2.083308988591958\n",
            "21 \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]\t 0.9496880408110411\t 0.6551680070961308\t 2.099498049916772\t 2.0994979502224416\n",
            "22 \t [ 9.03366199  7.80955039  7.          0.58807038 16.          0.37530235]\t 0.8718032531648561\t 0.6551680070961308\t 2.064747678736716\t 2.064747678736716\n",
            "23 \t [0.58596137 5.71336149 9.         0.70354751 9.         0.28160967]\t 0.9498200925027509\t 0.6551680070961308\t 2.0778531891439163\t 2.0778531891439163\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7113005276137964\t 0.6551680070961308\t 2.1018846561611846\t 2.1018846561611846\n",
            "25 \t [ 1.2601232   9.9585863  10.          0.70525992  2.          0.9880166 ]\t 0.6631852367566748\t 0.6551680070961308\t 2.087808800830299\t 2.087808800830299\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 0.8623919725421392\t 0.6551680070961308\t 2.0714983136678162\t 2.0714983136678162\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.7206151175283746\t 0.6551680070961308\t 2.0948289290964603\t 2.0948289290964603\n",
            "28 \t [1.37294589 2.61228134 9.         0.89667199 1.         0.42044841]\t 0.8676686566935652\t 0.6551680070961308\t 2.047551677662039\t 2.047551677662039\n",
            "29 \t [ 1.58467279  1.68272877 13.          0.86101343 12.          0.4100987 ]\t 0.8613126520852274\t 0.6551680070961308\t 2.088063905193452\t 2.088063905193452\n",
            "30 \t [ 9.46761139  2.8795209   5.          1.         16.63312573  0.89045459]\t 0.7247461575386234\t 0.6551680070961308\t 2.083308308619175\t 2.083307173966927\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50482.78878121671"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9501a5bd-7e41-4248-fda2-a5e8e04bc47b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO_multi(surrogate_approx_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 2.007782681040181\t 2.007782681040181\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 2.0284125266635806\t 2.0284125266635806\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 2.0114406268347342\t 2.0114406268347342\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 1.9839202454116676\t 1.9839202454116676\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 2.0303564293233944\t 2.0303564293233944\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 2.0373265477257183\t 2.0373265477257183\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 2.038215158866576\t 2.038215158866576\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 2.023405089201926\t 2.023405089201926\n",
            "9  \t [9.85206608 0.28191822 5.         0.52457928 8.         0.84714334]\t 0.7819517369688569\t 0.7141038418197827\t 2.03608656774452\t 2.03608656774452\n",
            "10 \t [ 0.2191332   8.51773955  5.          0.60657578 15.          0.49735822]\t 0.8316281392969092\t 0.7141038418197827\t 2.0222788925315838\t 2.0222788925315838\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 2.023245414153191\t 2.023245414153191\n",
            "12 \t [0.95504342 7.30424524 8.         0.76682007 6.         0.21761275]\t 0.9667342747401506\t 0.7141038418197827\t 2.0252714073801923\t 2.0252714073801923\n",
            "13 \t [ 7.51514915  5.57821555 12.          0.8704045   9.          0.10769764]\t 0.9654026035949915\t 0.7141038418197827\t 2.045797165214331\t 2.0457971395271923\n",
            "14 \t [5.79855217 7.64610678 9.         0.54644758 3.         0.68341681]\t 0.7349404110255493\t 0.7141038418197827\t 2.0620349102258055\t 2.0620348523990546\n",
            "15 \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]\t 0.8751160002928657\t 0.7141038418197827\t 2.052471329284823\t 2.052471329284823\n",
            "16 \t [ 5.22074709  0.74229772 13.          0.87455275  7.          0.44305495]\t 0.8053149455389029\t 0.7141038418197827\t 2.0574657300218795\t 2.0574657300218795\n",
            "17 \t [ 9.1928307   3.75120063 13.          0.61085648 16.          0.3130605 ]\t 0.8587285155589749\t 0.7141038418197827\t 2.0554290543747236\t 2.0554290543747236\n",
            "18 \t [ 0.17456981  4.44078349  6.          0.87411246 11.          0.7606398 ]\t 0.7575142025728411\t 0.7141038418197827\t 2.06256593826282\t 2.06256593826282\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]\u001b[0m\t \u001b[1m\u001b[92m0.7137199048529451\u001b[0m\t \u001b[1m\u001b[92m0.7137199048529451\u001b[0m\t \u001b[1m\u001b[92m2.088907570616667\u001b[0m\t \u001b[1m\u001b[92m2.088907570616667\u001b[0m\n",
            "20 \t [ 8.57333797  0.94219501 14.          0.51089969  3.          0.1953435 ]\t 0.9742874478076378\t 0.7137199048529451\t 2.0249246008385815\t 2.0249246008385815\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\u001b[0m\t \u001b[1m\u001b[92m0.6678102642866967\u001b[0m\t \u001b[1m\u001b[92m0.6678102642866967\u001b[0m\t \u001b[1m\u001b[92m2.094159942996645\u001b[0m\t \u001b[1m\u001b[92m2.094159942996645\u001b[0m\n",
            "22 \t [ 6.72796419  6.10053296 14.          0.56325639  2.          0.91580991]\t 0.672911524877989\t 0.6678102642866967\t 2.0592761017937775\t 2.059276096833065\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.7660042630046296\t 0.6678102642866967\t 2.0617434009657893\t 2.0617434009657893\n",
            "24 \t [9.30371298 5.41042714 5.         0.80825473 7.         0.72790994]\t 0.775406840278715\t 0.6678102642866967\t 2.0056656248804487\t 2.0056656248804487\n",
            "\u001b[1m\u001b[92m25\u001b[0m\t \u001b[1m\u001b[92m[ 7.62876014  2.36027139  9.30903388  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6557656230496235\u001b[0m\t \u001b[1m\u001b[92m0.6557656230496235\u001b[0m\t \u001b[1m\u001b[92m2.0277332700225728\u001b[0m\t \u001b[1m\u001b[92m2.0277333761652367\u001b[0m\n",
            "26 \t [ 9.68199458  9.34620738 11.          0.57663541 14.          0.24521092]\t 0.9699971507331904\t 0.6557656230496235\t 2.0408389553428994\t 2.0408389553428994\n",
            "27 \t [ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]\t 0.7275389527778259\t 0.6557656230496235\t 2.0451351360658347\t 2.0451351360658347\n",
            "28 \t [ 4.55919043  8.6591134   6.          0.8884863  12.          0.96165246]\t 0.7009533648321409\t 0.6557656230496235\t 2.012740562472344\t 2.012740562472344\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.7646380284813412\t 0.6557656230496235\t 2.0317642297537164\t 2.0317642297537164\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.7247998938700702\t 0.6557656230496235\t 1.9835821707653039\t 1.9835821707653039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49355.50973353244"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dadc00ae-3373-4477-8014-11c770eddfc1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO_multi(surrogate_approx_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.8853778201562241\t 0.6968179065224296\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.6968179065224296\t 0.6968179065224296\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.8778125354456613\t 0.6968179065224296\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7421252990295766\t 0.6968179065224296\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7041732589144625\t 0.6968179065224296\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.7694285284315747\t 0.6968179065224296\t 1.9196797456914716\t 1.9196797456914716\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m1.913895378326368\u001b[0m\t \u001b[1m\u001b[92m1.913895378326368\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.740342057576812\t 0.65697799905797\t 1.873411457602898\t 1.873411457602898\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.893321248053374\t 0.65697799905797\t 1.8660229189903692\t 1.8660229189903692\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.697182883066114\t 0.65697799905797\t 1.9072464483293146\t 1.9072464483293146\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 0.934413982456124\t 0.65697799905797\t 1.885758396834617\t 1.8857583968325407\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 0.9339136409907385\t 0.65697799905797\t 1.9280855018775094\t 1.9280855018775094\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.7385292363411576\t 0.65697799905797\t 1.9585882785133653\t 1.9585882785133653\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.7318688282028918\t 0.65697799905797\t 1.9473839112580924\t 1.9473839112580924\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.6917610853596872\t 0.65697799905797\t 1.9368438733713451\t 1.9368438733713451\n",
            "11 \t [2.26673282 9.18109909 5.         0.89654818 1.         0.23064839]\t 0.9345922648183839\t 0.65697799905797\t 1.9232579392796703\t 1.9232579392796703\n",
            "12 \t [ 0.62191196  4.69754177  5.          0.72971917 15.          0.95903084]\t 0.7251980612547309\t 0.65697799905797\t 1.9466916278001127\t 1.9466916278001127\n",
            "13 \t [ 8.34050252  7.45495891 14.          0.58875591  8.          0.92669456]\t 0.6608570085316285\t 0.65697799905797\t 1.9383824416463968\t 1.9383824416463968\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.7718546540038929\t 0.65697799905797\t 1.9220170833940597\t 1.9220170833778254\n",
            "15 \t [0.73985165 0.58861565 5.         0.76246476 8.         0.22502929]\t 0.9355351230643232\t 0.65697799905797\t 1.9205213882909011\t 1.9205213882909011\n",
            "16 \t [ 2.74922981  6.93422037  7.          0.64536331 17.          0.3979189 ]\t 0.7829163073478957\t 0.65697799905797\t 1.9407524250382435\t 1.9407524250382435\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 5.01391374  9.05765577 13.          0.9768187   1.          0.92456281]\u001b[0m\t \u001b[1m\u001b[92m0.6564534467026883\u001b[0m\t \u001b[1m\u001b[92m0.6564534467026883\u001b[0m\t \u001b[1m\u001b[92m1.9397045289898565\u001b[0m\t \u001b[1m\u001b[92m1.9397045289898565\u001b[0m\n",
            "18 \t [ 7.49379106  4.28777418 12.          0.51562956  7.          0.83771026]\t 0.7078067412607201\t 0.6564534467026883\t 1.9452351619978592\t 1.9452351619978592\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 0.932289957585124\t 0.6564534467026883\t 1.9708497626841122\t 1.9708497626841122\n",
            "20 \t [2.46492428 5.43160937 5.         0.80464169 6.         0.16325382]\t 0.9347869126515154\t 0.6564534467026883\t 1.9978057748650526\t 1.9978057748650526\n",
            "21 \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]\t 0.7726367108722194\t 0.6564534467026883\t 1.9547786696118956\t 1.9547786696118956\n",
            "22 \t [ 3.44634229  0.73068286  6.          0.98116529 13.          0.55221155]\t 0.751739833425298\t 0.6564534467026883\t 1.9607686603162142\t 1.9607686603162142\n",
            "23 \t [ 6.72349545  5.27194732 13.          0.74776676 17.          0.30949491]\t 0.8771141770175074\t 0.6564534467026883\t 1.9692524979703678\t 1.9692524979703678\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.6800999300330094\t 0.6564534467026883\t 1.9712754839385735\t 1.9712754839385735\n",
            "25 \t [ 3.75888009  4.48669956 11.          0.79480873  1.          0.40375096]\t 0.7782460025277567\t 0.6564534467026883\t 1.9960965382932818\t 1.9960965382932818\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.772806554469849\t 0.6564534467026883\t 1.9861062937559855\t 1.9861062937559855\n",
            "27 \t [ 2.38281778  0.41819082 12.          0.85009716 13.          0.76896773]\t 0.6936827551198295\t 0.6564534467026883\t 1.9513494932378732\t 1.9513494932378732\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 0.9252239486256577\t 0.6564534467026883\t 1.9339623447880798\t 1.9339623447880798\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.7153038490865153\t 0.6564534467026883\t 1.9419376985688652\t 1.9419376985688652\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 2.39862109  3.75790269 11.          0.82657555 17.          0.95299573]\u001b[0m\t \u001b[1m\u001b[92m0.6520837052008387\u001b[0m\t \u001b[1m\u001b[92m0.6520837052008387\u001b[0m\t \u001b[1m\u001b[92m1.9583447956600395\u001b[0m\t \u001b[1m\u001b[92m1.9583447956600395\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49468.64345138359"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0cae8e-10c2-47c2-fa51-76c3d12426e7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO_multi(surrogate_approx_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m1.9599144337511984\u001b[0m\t \u001b[1m\u001b[92m1.9599144337511984\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 1.9130871911263452\t 1.9130871911263452\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 1.8866328811894146\t 1.8866328811894146\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 1.9734994870247173\t 1.9734994870247173\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 1.9544577503534284\t 1.9544577503534284\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.7059767781587389\t 0.6773838424850286\t 1.9708848636567784\t 1.97088486353449\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.7065170119936448\t 0.6773838424850286\t 1.9501579144063104\t 1.9501579144063104\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.7317581740148223\t 0.6773838424850286\t 1.9328150595332731\t 1.9328150595332731\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.7857306346205829\t 0.6773838424850286\t 1.9223802626763353\t 1.9223802626763353\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 4.45643696  6.43761151 10.          0.59521711 15.          0.91320177]\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m1.9225353347023468\u001b[0m\t \u001b[1m\u001b[92m1.9225353347023468\u001b[0m\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.7333445147195274\t 0.6773536163008785\t 1.9059577194422321\t 1.9059577194422321\n",
            "12 \t [ 9.41792853  9.11293681  6.          0.87420995 11.          0.8007601 ]\t 0.7086968319816249\t 0.6773536163008785\t 1.9005639617672756\t 1.9005639512043306\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.0149681655113947\t 0.6773536163008785\t 1.8899974506189077\t 1.8899974429566033\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.7335321473751593\t 0.6773536163008785\t 1.9288525782285455\t 1.9288525782285455\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.767048132195449\t 0.6773536163008785\t 1.9222743046338007\t 1.9222743046338007\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.7391934581482711\t 0.6773536163008785\t 1.9204998876051893\t 1.9204998876051893\n",
            "17 \t [4.5467287  4.10200035 9.         0.56725941 2.         0.95321578]\t 0.6834809053345061\t 0.6773536163008785\t 1.9168716485340485\t 1.9168716485340485\n",
            "18 \t [ 7.9679648   6.50875696 12.          0.58580991 13.          0.19954847]\t 1.018322232391354\t 0.6773536163008785\t 1.8904160099466403\t 1.8904160099466403\n",
            "19 \t [ 2.76696568  4.32638207 10.          0.69065092 10.          0.32928339]\t 0.8606879483167145\t 0.6773536163008785\t 1.9304226572258625\t 1.9304226572258625\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.6776716071409558\t 0.6773536163008785\t 1.9449079679681804\t 1.9449079629104762\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.679119846341469\t 0.6773536163008785\t 1.9698179384432288\t 1.9698179384432288\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.7131407042423596\t 0.6773536163008785\t 1.919060444834457\t 1.919060444834457\n",
            "23 \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]\t 0.7458028061131368\t 0.6773536163008785\t 1.9851289396275742\t 1.9851289376052859\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 8.32281899  8.13330287 11.          0.96254932  9.          0.88712633]\u001b[0m\t \u001b[1m\u001b[92m0.667446549429236\u001b[0m\t \u001b[1m\u001b[92m0.667446549429236\u001b[0m\t \u001b[1m\u001b[92m1.9226150413589154\u001b[0m\t \u001b[1m\u001b[92m1.9226150413589154\u001b[0m\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.7487322203145116\t 0.667446549429236\t 1.9066009879587287\t 1.9066009879587287\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.7108432598487722\t 0.667446549429236\t 1.927060056151211\t 1.927060056151211\n",
            "27 \t [6.6672698  0.63840466 9.         0.87317079 8.         0.32475468]\t 0.8600427002690658\t 0.667446549429236\t 1.881777690408082\t 1.881777690408082\n",
            "28 \t [8.3735996  5.34104024 8.         0.56456303 7.         0.59553385]\t 0.7245806620781778\t 0.667446549429236\t 1.9101451280723725\t 1.9101451280723725\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.7131420295812025\t 0.667446549429236\t 1.9012152347245062\t 1.9012152347245062\n",
            "30 \t [9.30545715 2.21896205 9.         0.96965499 5.         0.61228081]\t 0.7128642744554409\t 0.667446549429236\t 1.9024926529294919\t 1.9024926529294919\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48534.64481811289"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa2c92f-ec11-4c8c-9b03-b004d97c6eb0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO_multi(surrogate_approx_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 2.077592441725547\t 2.077592441725547\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 2.0900164286368486\t 2.0900164286368486\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.7502219040814293\t 0.6597299542050263\t 2.1711136462755234\t 2.1711136462755234\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7367139517682284\t 0.6597299542050263\t 2.1322856717525567\t 2.1322856717525567\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8006234291185196\t 0.6597299542050263\t 2.098402154242618\t 2.098402154242618\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.058727127460609\t 0.6597299542050263\t 2.0850807736465464\t 2.0850807736465464\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.703165388931625\t 0.6597299542050263\t 2.137283731886915\t 2.137283731886915\n",
            "8  \t [ 2.63649501  9.62311075  7.          0.5192485  13.          0.19746315]\t 1.0640909980360433\t 0.6597299542050263\t 2.104909103094345\t 2.1049090957543495\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0651952678837315\t 0.6597299542050263\t 2.1484922329152645\t 2.1484922329152645\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.8036859734991779\t 0.6597299542050263\t 2.1846245113126104\t 2.1846245113126104\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0624486911635314\t 0.6597299542050263\t 2.1707108901528867\t 2.1707108901514234\n",
            "12 \t [ 6.27900589  9.12764923  5.          0.84263312 18.          0.79256191]\t 0.730579912896863\t 0.6597299542050263\t 2.2005238637950875\t 2.2005238611352245\n",
            "13 \t [ 6.23595836  9.32810182 13.          0.66281123 18.          0.41679152]\t 0.8037682530168745\t 0.6597299542050263\t 2.1784119966364677\t 2.1784119966364677\n",
            "14 \t [ 2.08109501  0.31399789  8.          0.78263012 11.          0.87673239]\t 0.6735019021239127\t 0.6597299542050263\t 2.1679233955179478\t 2.1679233955179478\n",
            "15 \t [ 6.97560183  1.48211849  9.          0.80794429 10.          0.21839694]\t 1.0602103565189318\t 0.6597299542050263\t 2.143052401509883\t 2.143052401509883\n",
            "16 \t [ 0.3999032   2.66263318 14.          0.55784408  3.          0.95411688]\t 0.6765956478595294\t 0.6597299542050263\t 2.1679334740006158\t 2.1679334740006158\n",
            "17 \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]\t 0.7117644991570005\t 0.6597299542050263\t 2.1452537423726628\t 2.1452537423726628\n",
            "18 \t [ 1.21632555  2.44839139  8.          0.8927599  17.          0.25270381]\t 0.878121266134469\t 0.6597299542050263\t 2.129174525337299\t 2.129174525337299\n",
            "19 \t [4.83067255 2.19904639 7.         0.5680519  3.         0.59514532]\t 0.7720408244337518\t 0.6597299542050263\t 2.127170355864055\t 2.127170355864055\n",
            "20 \t [ 5.3866253   1.98558863 14.          0.93996594  6.          0.18524928]\t 1.0595101751758718\t 0.6597299542050263\t 2.1260543439604405\t 2.1260543439604405\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.8784158308955667\t 0.6597299542050263\t 2.1698269208935717\t 2.1698269208935717\n",
            "22 \t [ 2.87514576  3.13712267 13.          0.97475974 17.          0.73021265]\t 0.6835469609962976\t 0.6597299542050263\t 2.1687465475768293\t 2.1687465475768293\n",
            "23 \t [ 7.7259419   7.24070659 12.          0.78792483 13.          0.54558593]\t 0.7474521691759894\t 0.6597299542050263\t 2.127060220934175\t 2.127060058067713\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.6902699854328027\t 0.6597299542050263\t 2.115681037839718\t 2.115681037839718\n",
            "25 \t [ 0.83358887  9.71793838 12.          0.52075624 11.          0.67770945]\t 0.6983988113329787\t 0.6597299542050263\t 2.134020901881686\t 2.134020901881686\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.7422712401342008\t 0.6597299542050263\t 2.1216441309503304\t 2.1216441309503304\n",
            "27 \t [10.         10.          8.68204812  0.5        17.82269921  0.1       ]\t 1.0628994401462992\t 0.6597299542050263\t 2.1384808424743293\t 2.1384806202863835\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.0600568728235613\t 0.6597299542050263\t 2.1191474554802285\t 2.1191474554802285\n",
            "29 \t [ 0.39565672  8.50724472  5.          0.74462587 17.          0.73375146]\t 0.7368138593297264\t 0.6597299542050263\t 2.1529594248246897\t 2.1529594248246897\n",
            "30 \t [ 0.89195001  6.01604215 14.          0.84121292  7.          0.44798682]\t 0.8038070345544759\t 0.6597299542050263\t 2.0972415636810187\t 2.0972415636810187\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49100.59813085487"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c94895e-6fce-478c-d5be-47afe6d768f5"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663859166.5281184"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0de8624-c74f-427d-da71-ecaf656122e8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 2.1588902305275783\t 2.1588902305275783\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 2.152653409324976\t 2.152653409324976\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 2.2210712593211897\t 2.2210712593211897\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8992034514090065\t 0.6536753952667645\t 2.1588076288278732\t 2.1588076288278732\n",
            "5  \t [0.         0.         5.         0.5        3.08862403 0.1       ]\t 1.0640504359985177\t 0.6536753952667645\t 2.163714840018006\t 2.16371483932983\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.9004243658767852\t 0.6536753952667645\t 2.2119673693343254\t 2.2119673693343254\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6536753952667645\t 2.211393699263328\t 2.211393699263328\n",
            "8  \t [8.51945771 8.4424986  8.         0.90741371 1.         0.49942468]\t 0.8757522803338091\t 0.6536753952667645\t 2.2331508812701824\t 2.2331508812701824\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 1.0632523501795186\t 0.6536753952667645\t 2.2265029862467576\t 2.2265029862467576\n",
            "10 \t [2.9041318  7.39326981 5.         0.58898617 5.         0.32854047]\t 1.0120361806256697\t 0.6536753952667645\t 2.255603282076852\t 2.255603282076852\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6536753952667645\t 2.2711685564568382\t 2.2711685564568382\n",
            "12 \t [ 6.69157798  8.70257949  6.          0.87919364 18.          0.65415334]\t 0.7797193534695033\t 0.6536753952667645\t 2.293191561360027\t 2.293191561360027\n",
            "13 \t [ 0.31984184  8.77960419  5.          0.79374224 16.          0.99761184]\t 0.7310969316491746\t 0.6536753952667645\t 2.2724375630341016\t 2.2724375630341016\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6536753952667645\t 2.2484234511597845\t 2.2484234511597845\n",
            "15 \t [6.82478079 2.20366901 5.         0.88422891 1.         0.83561656]\t 0.7357264382359029\t 0.6536753952667645\t 2.228873683916287\t 2.228873683916287\n",
            "16 \t [ 0.21685405  7.71152333 13.          0.94772928  9.          0.78016857]\t 0.6760611870438261\t 0.6536753952667645\t 2.2090239902206017\t 2.2090239902206017\n",
            "17 \t [1.68476972 5.2908721  8.         0.92839616 1.         0.96471758]\t 0.670961172017669\t 0.6536753952667645\t 2.1849684119789443\t 2.1849684119789443\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8661734316276007\t 0.6536753952667645\t 2.181372836620218\t 2.181372836620218\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 1.0095429457834948\t 0.6536753952667645\t 2.177511769261737\t 2.177511769261737\n",
            "20 \t [ 5.68575652  2.73061603 14.          0.61811388 15.          0.91855302]\t 0.6649510133524581\t 0.6536753952667645\t 2.1822127444471895\t 2.1822127444471895\n",
            "21 \t [ 9.72376714  9.82517342 14.          0.96896704 10.          0.66715413]\t 0.7365987830832396\t 0.6536753952667645\t 2.15949101505846\t 2.15949101505846\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 1.060877500434967\t 0.6536753952667645\t 2.184664862918776\t 2.184664862918776\n",
            "23 \t [ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\t 0.6693366893520581\t 0.6536753952667645\t 2.1934228728128664\t 2.1934228728128664\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[10.          8.71449465 15.          1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6504936383293095\u001b[0m\t \u001b[1m\u001b[92m0.6504936383293095\u001b[0m\t \u001b[1m\u001b[92m2.1661072844104434\u001b[0m\t \u001b[1m\u001b[92m2.1661072844082048\u001b[0m\n",
            "25 \t [ 9.92106016  5.52981723 11.          0.80826141 13.          0.31322593]\t 1.000587889017468\t 0.6504936383293095\t 2.1366587396740515\t 2.1366587396740515\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.6562345271802523\t 0.6504936383293095\t 2.193039729804123\t 2.193039729804123\n",
            "27 \t [ 9.80506138  4.80078528 13.          0.71095318 17.          0.3227225 ]\t 1.0006677560529766\t 0.6504936383293095\t 2.13232725217694\t 2.13232725217694\n",
            "28 \t [ 0.42024221  1.80970657 14.          0.62730009  9.          0.87538064]\t 0.6646291820080863\t 0.6504936383293095\t 2.1568520080400027\t 2.1568520082658673\n",
            "29 \t [ 7.90262912  2.42578102 10.          0.74527437  3.          0.26169759]\t 1.0011640755507307\t 0.6504936383293095\t 2.162989817663287\t 2.162989817663287\n",
            "30 \t [2.42300519 3.08035639 6.         0.74706361 9.         0.7000019 ]\t 0.7821160549751343\t 0.6504936383293095\t 2.1268188717936973\t 2.1268188717936973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47321.8408099896"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44148c8d-51d5-4bbe-a2c9-cc9dcfb1e020"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6547874419782912\u001b[0m\t \u001b[1m\u001b[92m0.6547874419782912\u001b[0m\t \u001b[1m\u001b[92m1.841901656436365\u001b[0m\t \u001b[1m\u001b[92m1.841901656436365\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6547874419782912\t 1.8044153209664306\t 1.8044153209664306\n",
            "3  \t [ 9.82078709  9.9850326  13.          0.56249358  3.          0.74498359]\t 0.683685379651464\t 0.6547874419782912\t 1.8035390614132059\t 1.8035390614132059\n",
            "4  \t [9.65259502 5.7740337  5.         0.69028314 1.         0.90626847]\t 0.7326570250862032\t 0.6547874419782912\t 1.7889414801061065\t 1.7889414801061065\n",
            "5  \t [1.25559631 9.8394609  9.         0.52015567 2.         0.32958416]\t 0.8058953821841264\t 0.6547874419782912\t 1.788685249571792\t 1.788685249571792\n",
            "6  \t [0.  0.  5.  0.5 1.  0.1]\t 0.8726019020039407\t 0.6547874419782912\t 1.808075136345471\t 1.8080751363452174\n",
            "7  \t [ 0.66591974  9.26661294 14.          0.96342421 18.          0.94909068]\t 0.6568524558078858\t 0.6547874419782912\t 1.8404534753548076\t 1.8404534753548076\n",
            "8  \t [ 7.73753078  4.7386917  10.          0.75300372 18.          0.75097316]\t 0.6740149070019592\t 0.6547874419782912\t 1.822277593821282\t 1.822277593821282\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.7397571279868462\t 0.6547874419782912\t 1.8103006473471583\t 1.8103006473471583\n",
            "10 \t [ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\t 0.6684024492575475\t 0.6547874419782912\t 1.8104237792971536\t 1.8104237792971536\n",
            "11 \t [4.59560507 9.66694693 5.         0.8652774  6.         0.90565092]\t 0.7323276592879555\t 0.6547874419782912\t 1.7991718616522139\t 1.7991718616522139\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[ 9.51486009  9.51681389 14.6322155   0.88876263 13.13820973  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6534767863205851\u001b[0m\t \u001b[1m\u001b[92m0.6534767863205851\u001b[0m\t \u001b[1m\u001b[92m1.7987575513233707\u001b[0m\t \u001b[1m\u001b[92m1.7987575450877773\u001b[0m\n",
            "13 \t [ 7.86086296  9.53235807  5.          0.78700181 16.          0.22516618]\t 0.8728710854388536\t 0.6534767863205851\t 1.787934133799781\t 1.787934133799781\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.7143733066956096\t 0.6534767863205851\t 1.8087901683937102\t 1.8087901683937102\n",
            "15 \t [ 9.92385114  1.42193513 10.          0.58826787  1.          0.80423472]\t 0.6817768071355952\t 0.6534767863205851\t 1.8062127965816253\t 1.8062127965816253\n",
            "16 \t [ 6.52098806  7.37654971 12.          0.62621853  7.          0.13475551]\t 0.8637260588745512\t 0.6534767863205851\t 1.7994012520135259\t 1.7994012520135259\n",
            "17 \t [ 1.94467794  1.47584396  5.          0.91953126 11.          0.49707889]\t 0.8258856905247922\t 0.6534767863205851\t 1.8144198774552331\t 1.8144198774552331\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.6693925559674401\t 0.6534767863205851\t 1.825167459356007\t 1.825167459356007\n",
            "19 \t [ 6.92673077  1.23845568 10.          0.63463476  8.          0.28240746]\t 0.7984787223028406\t 0.6534767863205851\t 1.8786666007866717\t 1.8786666007866717\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.7918243780041875\t 0.6534767863205851\t 1.8674958887449449\t 1.8674958887449449\n",
            "21 \t [7.13284983 1.18470919 5.         0.63977211 3.         0.12223048]\t 0.8717594731267366\t 0.6534767863205851\t 1.8572949307146824\t 1.8572949307146824\n",
            "22 \t [ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\t 0.664392530003631\t 0.6534767863205851\t 1.8488494160862838\t 1.8488494160862838\n",
            "23 \t [7.21426183 5.08323367 9.         0.61281609 5.         0.44227443]\t 0.7928241590855956\t 0.6534767863205851\t 1.8737796973356615\t 1.8737796973356615\n",
            "24 \t [ 0.46676511  3.42223934 13.          0.71405562 11.          0.87561456]\t 0.6646623391819284\t 0.6534767863205851\t 1.9167490639560003\t 1.9167490639560003\n",
            "25 \t [ 8.22593027  3.70832356  5.          0.80279417 18.          0.57200994]\t 0.768920640618771\t 0.6534767863205851\t 1.8695866611727026\t 1.8695866611727026\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.6666799570614775\t 0.6534767863205851\t 1.8410414820003351\t 1.8410414820003351\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.6817048020092698\t 0.6534767863205851\t 1.867064372578189\t 1.867064372578189\n",
            "28 \t [ 4.11831219  1.06523616 12.          0.63008078 16.          0.53873389]\t 0.7006937452963055\t 0.6534767863205851\t 1.8791148631293249\t 1.8791148631293249\n",
            "29 \t [ 5.23695984  7.3107296  12.          0.61613332 14.          0.59498605]\t 0.7013908908972221\t 0.6534767863205851\t 1.8516768584353405\t 1.8516768584353405\n",
            "30 \t [ 2.52791331  7.96092033  5.          0.81244897 13.          0.44538719]\t 0.8272705955178756\t 0.6534767863205851\t 1.8358423578450829\t 1.8358423578450829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48559.067114842015"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c50b7a-277d-4872-85ce-73579bf905c0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 2.3202890233926294\t 2.3202890233926294\n",
            "2  \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]\t 1.0212658686211613\t 0.7688389438662246\t 2.265960365978532\t 2.265960365978532\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7688389438662246\t 2.3010973817396887\t 2.3010973817396887\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 4.06522402  9.52384028  5.          0.68629723 13.          0.87617671]\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m2.327993206671531\u001b[0m\t \u001b[1m\u001b[92m2.327993206671531\u001b[0m\n",
            "5  \t [3.68953475 2.95525094 5.         0.6894371  8.         0.99869195]\t 0.7371180474782232\t 0.7354945860729\t 2.2755252788291527\t 2.2755252788291527\n",
            "6  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0276382267404158\t 0.7354945860729\t 2.2329849823891017\t 2.2329849823891017\n",
            "7  \t [9.34527135 5.20373839 7.         0.72717205 2.         0.5760477 ]\t 0.7767542399758847\t 0.7354945860729\t 2.260298460143954\t 2.260298460346213\n",
            "8  \t [ 4.07294602  2.75099703 11.          0.94499689 18.          0.14325348]\t 1.0205692033684926\t 0.7354945860729\t 2.2326835015888835\t 2.2326835015888835\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6548396524742095\u001b[0m\t \u001b[1m\u001b[92m0.6548396524742095\u001b[0m\t \u001b[1m\u001b[92m2.254357247312782\u001b[0m\t \u001b[1m\u001b[92m2.2543572473112374\u001b[0m\n",
            "10 \t [ 8.77606832  6.32160473  5.          0.71489692 18.          0.76442589]\t 0.7431092769036292\t 0.6548396524742095\t 2.2142544569128915\t 2.2142544569128915\n",
            "11 \t [ 3.53262431  2.07514765  7.          0.93520802 15.          0.4184813 ]\t 0.8751855836959452\t 0.6548396524742095\t 2.1901916381802646\t 2.1901916381802646\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.6998375974069359\t 0.6548396524742095\t 2.1872653771297226\t 2.1872653771297226\n",
            "13 \t [ 9.33577729  2.46045418 12.          0.8699722   6.          0.97914461]\t 0.682832117112808\t 0.6548396524742095\t 2.162382843910511\t 2.162382843910511\n",
            "14 \t [ 9.85636221  3.89791593  9.          0.61925349 14.          0.90156475]\t 0.692118262463878\t 0.6548396524742095\t 2.138093097396911\t 2.138093097396911\n",
            "15 \t [5.97394564 7.46137383 8.         0.54699832 6.         0.19599348]\t 1.0222519814188449\t 0.6548396524742095\t 2.1171934843463864\t 2.1171934843463864\n",
            "16 \t [ 8.57223094  6.11716063 14.          0.78874358 15.          0.92798816]\t 0.6812343172005548\t 0.6548396524742095\t 2.1379456488559616\t 2.1379456488559616\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.6548396524742095\t 2.1182180318306605\t 2.1182180318306605\n",
            "18 \t [ 9.29773536  1.3603477  10.          0.99088527 18.          0.4242806 ]\t 0.862153802827535\t 0.6548396524742095\t 2.118220763835304\t 2.118220763835304\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8649856112240915\t 0.6548396524742095\t 2.1295837563287447\t 2.1295837563287447\n",
            "20 \t [8.97398363 2.41897649 7.         0.81773512 8.         0.28324604]\t 0.9772699327834455\t 0.6548396524742095\t 2.1072272867270634\t 2.1072272867270634\n",
            "21 \t [7.41515841 0.52199956 6.         0.81915682 2.         0.1036162 ]\t 1.028379130939485\t 0.6548396524742095\t 2.1153844140702693\t 2.1153844140702693\n",
            "22 \t [ 2.77110475  0.35980325 10.          0.77088835  9.          0.78161047]\t 0.702308760297458\t 0.6548396524742095\t 2.127529400706164\t 2.127529400706164\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8752416347792465\t 0.6548396524742095\t 2.165841402196084\t 2.165841402196084\n",
            "24 \t [ 0.04997226  0.57243486  5.          0.9748128  12.          0.24835402]\t 1.0287999951759097\t 0.6548396524742095\t 2.150155459288183\t 2.150155459288183\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7185577429000575\t 0.6548396524742095\t 2.1611397828334002\t 2.1611397828334002\n",
            "26 \t [ 0.52943709  9.61505961 13.          0.7580575   4.          0.5803375 ]\t 0.7660076285356441\t 0.6548396524742095\t 2.1376072362039773\t 2.1376072362039773\n",
            "27 \t [ 0.50161196  6.73842363  5.          0.62422734 11.          0.68966684]\t 0.7728211277583844\t 0.6548396524742095\t 2.119228000434054\t 2.119228000434054\n",
            "28 \t [ 9.01763405  8.9342346  11.          0.78253186 14.          0.5899614 ]\t 0.7571328011102442\t 0.6548396524742095\t 2.128611154343946\t 2.128611154343946\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.0229660667953924\t 0.6548396524742095\t 2.1061194071543596\t 2.1061194071543596\n",
            "30 \t [ 0.56213381  4.41770035 10.          0.6803733   4.          0.67199979]\t 0.7355552741037803\t 0.6548396524742095\t 2.1398977137532893\t 2.1398977137532893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46877.10407555545"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKX_nfEaaAwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a92263-d1ed-46b9-990b-8627db00a25e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 1.9131124072687666\t 1.9131124072687666\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 0.9436692731753087\t 0.6641721421409617\t 1.9852973716601767\t 1.9852973716601767\n",
            "3  \t [7.47521879 1.08446649 5.         0.82092246 1.         0.87686231]\t 0.7277791972054833\t 0.6641721421409617\t 2.035102776875354\t 2.035102776875354\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6437292534451688\u001b[0m\t \u001b[1m\u001b[92m0.6437292534451688\u001b[0m\t \u001b[1m\u001b[92m2.0052894456401367\u001b[0m\t \u001b[1m\u001b[92m2.005289445640136\u001b[0m\n",
            "5  \t [ 0.13337167  3.07677647 14.          0.92270334  2.          0.56046161]\t 0.7175621988652162\t 0.6437292534451688\t 1.9623061423645785\t 1.9623061423645785\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6437292534451688\t 1.9428118135327717\t 1.9428118135327717\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.7531044966742895\t 0.6437292534451688\t 1.9779698069123781\t 1.9779698069123781\n",
            "8  \t [ 0.32236964  2.41893129 14.          0.88540422 15.          0.72064562]\t 0.6990250321451492\t 0.6437292534451688\t 1.967210827838897\t 1.967210827838897\n",
            "9  \t [ 3.09428939  2.08429737  5.          0.5        11.85122959  0.1       ]\t 0.9402842434891742\t 0.6437292534451688\t 1.9487821818363027\t 1.948782181672409\n",
            "10 \t [6.88830171 3.56529112 9.         0.53892548 7.         0.71497012]\t 0.7129045379089785\t 0.6437292534451688\t 1.9762092212089892\t 1.9762092212089892\n",
            "11 \t [ 5.06567259  4.87282999  5.          0.59003814 19.          0.62670426]\t 0.7603414476139758\t 0.6437292534451688\t 1.9617064882755908\t 1.9617064882755908\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.6923205913979871\t 0.6437292534451688\t 1.9556789247410975\t 1.9556789247410975\n",
            "13 \t [ 7.13917491  5.54513019 12.          0.96788225 17.          0.73426584]\t 0.6980297258319723\t 0.6437292534451688\t 1.9412430049742115\t 1.9412430049742115\n",
            "14 \t [1.36278916 2.3865226  8.         0.93147735 1.         0.78835231]\t 0.6981607806179005\t 0.6437292534451688\t 1.9294228235438364\t 1.9294228235438364\n",
            "15 \t [ 0.50761856  5.44188216 11.          0.71311926 13.          0.48848091]\t 0.7722955076178458\t 0.6437292534451688\t 1.9185360943940977\t 1.9185360943940977\n",
            "16 \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]\t 0.8312840491127815\t 0.6437292534451688\t 1.9167833070076212\t 1.9167833070076212\n",
            "17 \t [3.55913665 1.752351   8.         0.70851016 3.         0.2473213 ]\t 0.9424312136090938\t 0.6437292534451688\t 1.9224033914688317\t 1.9224033914688317\n",
            "18 \t [ 5.7913209   0.66562836 12.          0.88967575 12.          0.45276187]\t 0.7701049123721093\t 0.6437292534451688\t 1.9428245866925196\t 1.9428245866925196\n",
            "19 \t [ 2.28250676  8.57781075 10.          0.71780124 12.          0.3772521 ]\t 0.7733889133490559\t 0.6437292534451688\t 1.959469113476299\t 1.959469113476299\n",
            "20 \t [ 7.39797184  8.7826296  13.          0.53377308 19.          0.69293054]\t 0.7102370124868266\t 0.6437292534451688\t 1.9591570178636277\t 1.9591570178636277\n",
            "21 \t [ 2.94885486  0.8707386  12.          0.78283452  7.          0.76869321]\t 0.6880215184213588\t 0.6437292534451688\t 1.9169608071692839\t 1.9169608071692839\n",
            "22 \t [ 1.84655537  0.92635666  9.          0.60237883 14.          0.70534193]\t 0.7101596489776973\t 0.6437292534451688\t 1.955478694838224\t 1.955478694838224\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.6437292534451688\t 1.927561958632257\t 1.927561958632257\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.724172646323414\t 0.6437292534451688\t 1.9517641860533208\t 1.9517641860533208\n",
            "25 \t [9.14387233 8.82409497 7.         0.87227821 8.         0.52464991]\t 0.73021361391417\t 0.6437292534451688\t 1.9454968078585868\t 1.9454968078585868\n",
            "26 \t [3.60524491 1.19236957 9.         0.73012056 6.         0.89243922]\t 0.6694008469090542\t 0.6437292534451688\t 1.9545089547893495\t 1.9545089547893495\n",
            "27 \t [ 2.49277017  9.71877294 14.          0.64108163 15.          0.60597318]\t 0.7146840039689067\t 0.6437292534451688\t 1.91980838510027\t 1.919808431744108\n",
            "28 \t [0.398585   7.20110705 9.         0.96165187 5.         0.39561938]\t 0.7744683008201259\t 0.6437292534451688\t 1.9177117720674037\t 1.9177117720674037\n",
            "29 \t [ 8.18178764  9.98869521 14.          0.83418368 10.          0.41151726]\t 0.7724215015699015\t 0.6437292534451688\t 1.9092881360152445\t 1.9092881360152445\n",
            "30 \t [ 7.07372144  7.12421793  9.          0.88361829 18.          0.94084728]\t 0.6694778421709694\t 0.6437292534451688\t 1.9148751819313525\t 1.9148751819313525\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49658.75602012835"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3695ce-6bbb-4710-8d98-171377f41a7f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 2.0860184672108364\t 2.0860184672108364\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 2.125269664628449\t 2.125269664628449\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m2.146884063898179\u001b[0m\t \u001b[1m\u001b[92m2.146884063898179\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 2.1234825906720296\t 2.1234825906720296\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m2.1268424504864543\u001b[0m\t \u001b[1m\u001b[92m2.1268424504864543\u001b[0m\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.92565009216999\t 0.6989575443158274\t 2.08907622382845\t 2.08907622382845\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6989575443158274\t 2.1059082052436486\t 2.1059082052436486\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6458620128690523\u001b[0m\t \u001b[1m\u001b[92m0.6458620128690523\u001b[0m\t \u001b[1m\u001b[92m2.097199633360337\u001b[0m\t \u001b[1m\u001b[92m2.0971996333602836\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9277423136052668\t 0.6458620128690523\t 2.062175006268246\t 2.062175006268246\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.6796390241442563\t 0.6458620128690523\t 2.077879010767999\t 2.077879010767999\n",
            "11 \t [ 0.89740814  7.68177756 10.          0.50899891 18.          0.1637852 ]\t 0.929958591632978\t 0.6458620128690523\t 2.0529271252201844\t 2.0529271252201844\n",
            "12 \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]\t 0.7387384974169141\t 0.6458620128690523\t 2.0677164628171885\t 2.0677164628171885\n",
            "13 \t [ 7.62027901  8.36748806 13.          0.68088493 15.          0.89941602]\t 0.6746484007561842\t 0.6458620128690523\t 2.0534157897639362\t 2.0534157897639362\n",
            "14 \t [ 1.08413831  3.43645345  5.          0.5        14.47452195  0.1       ]\t 0.9483182036944408\t 0.6458620128690523\t 2.033247416344308\t 2.033247406241444\n",
            "15 \t [ 1.02937954  1.87162456 12.          0.80403735 18.          0.49076122]\t 0.779444839237101\t 0.6458620128690523\t 2.0566216221822846\t 2.0566216221822846\n",
            "16 \t [ 9.85923825  0.4401096  14.          0.51176114 16.          0.65114761]\t 0.7072532974379651\t 0.6458620128690523\t 2.048113326658554\t 2.048113326658554\n",
            "17 \t [ 9.34484937  3.49003142 14.          0.90417251  7.          0.92435507]\t 0.6682628994459927\t 0.6458620128690523\t 2.0363595325968764\t 2.0363595325968764\n",
            "18 \t [ 9.73905766  7.12200775  5.          0.85875901 11.          0.99496281]\t 0.7281481211112614\t 0.6458620128690523\t 2.0995789659150295\t 2.0995789659150295\n",
            "19 \t [ 2.91927839  7.3392069   6.          0.85847684 14.          0.50487035]\t 0.7871744338256177\t 0.6458620128690523\t 2.0109609262482673\t 2.0109609262482673\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7616619440927369\t 0.6458620128690523\t 2.0509935123329597\t 2.0509935123329597\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7413460349644984\t 0.6458620128690523\t 2.0301084004002266\t 2.0301084004002266\n",
            "22 \t [ 3.12623913  1.70372165 14.          0.65033852 15.          0.68304577]\t 0.7003442032528848\t 0.6458620128690523\t 2.00224953501736\t 2.00224953501736\n",
            "23 \t [ 0.19302552  7.40732602 14.          0.96196983 15.          0.6651316 ]\t 0.6933552649675729\t 0.6458620128690523\t 2.0365832319345563\t 2.0365832319345563\n",
            "24 \t [3.94047137 4.02714818 9.         0.84897818 1.         0.28601664]\t 0.9261840428765531\t 0.6458620128690523\t 1.9649616375882692\t 1.9649616375882692\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.6920167982810115\t 0.6458620128690523\t 1.9912342815129513\t 1.9912342815129513\n",
            "26 \t [ 0.65904826  3.00639193 10.          0.88267232 10.          0.15011078]\t 0.9287520803820832\t 0.6458620128690523\t 1.9829806171162194\t 1.9829806171162194\n",
            "27 \t [ 8.63550776  0.42604305  7.          0.87159448 12.          0.96938136]\t 0.6947969884242674\t 0.6458620128690523\t 1.9837813843979357\t 1.9837813843979357\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7099197558902939\t 0.6458620128690523\t 2.024787470265073\t 2.024787470265073\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7312561878518347\t 0.6458620128690523\t 1.9632036728069757\t 1.9632036728069757\n",
            "30 \t [ 4.26618531  5.80193116 14.          0.50854942 16.          0.74490807]\t 0.7077898406414209\t 0.6458620128690523\t 2.0268427439227796\t 2.0268427439227796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49933.520017673625"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhEolsxaG4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989f3630-c43a-4217-9f1f-911d1d3fd219"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 2.1056923959828033\t 2.1056923959828033\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 2.1757174829941723\t 2.1757174829941723\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0228902128409325\t 0.7312157182363477\t 2.2282538070108284\t 2.2282538070108284\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m2.2647745512029025\u001b[0m\t \u001b[1m\u001b[92m2.264774551201397\u001b[0m\n",
            "5  \t [ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\t 0.6939533330723558\t 0.6519505196682808\t 2.200602693938601\t 2.200602693938601\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.9234519385526558\t 0.6519505196682808\t 2.155766406907042\t 2.155766406907042\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.0610911324495744\t 0.6519505196682808\t 2.165643078141007\t 2.165643078141007\n",
            "8  \t [ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\t 0.6895189879978737\t 0.6519505196682808\t 2.205509074532052\t 2.205509074532052\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0250396556181756\t 0.6519505196682808\t 2.170149247284524\t 2.170149247284524\n",
            "10 \t [ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\t 0.6832941408312798\t 0.6519505196682808\t 2.196249633960187\t 2.196249633960187\n",
            "11 \t [ 8.51551086  2.70859558 10.          0.84297574  9.          0.42302662]\t 0.9225835870454052\t 0.6519505196682808\t 2.1653060822081196\t 2.1653060822081196\n",
            "12 \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]\t 1.0180101584031926\t 0.6519505196682808\t 2.171231788260619\t 2.171231788260619\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0641944470930125\t 0.6519505196682808\t 2.191649167605952\t 2.191649167605952\n",
            "14 \t [ 3.5216677   2.1967706  11.          0.74600018 10.          0.41151111]\t 0.924098127724531\t 0.6519505196682808\t 2.216788634529393\t 2.216788634529393\n",
            "15 \t [ 0.50127522  1.94924928 11.          0.89270197 19.          0.91286914]\t 0.6768798166626013\t 0.6519505196682808\t 2.2192545900637097\t 2.2192545900637097\n",
            "16 \t [ 4.8891514   9.63319929 13.          0.90452221  7.          0.96899492]\t 0.6778772824836011\t 0.6519505196682808\t 2.1944227922769572\t 2.1944227922769572\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.9614697348345509\t 0.6519505196682808\t 2.1749819000061685\t 2.1749819000061685\n",
            "18 \t [ 4.48555971  3.69204095  9.          0.58646272 16.          0.41216867]\t 0.9310926555739572\t 0.6519505196682808\t 2.173505689575449\t 2.173505689575449\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6519505196682808\t 2.176794546429921\t 2.176794546429921\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9398497506465855\t 0.6519505196682808\t 2.2325984349940176\t 2.2325984349940176\n",
            "21 \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]\t 1.0152545517792837\t 0.6519505196682808\t 2.251849050318399\t 2.251849050318399\n",
            "22 \t [ 0.15151883  3.04875397  5.          0.61495161 19.          0.79420245]\t 0.7938992290953346\t 0.6519505196682808\t 2.205337509954846\t 2.205337509954846\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9387634302639226\t 0.6519505196682808\t 2.2179468367601642\t 2.2179468367601642\n",
            "24 \t [8.12249915 9.52146586 8.         0.55686302 4.         0.21818921]\t 1.0606438147117943\t 0.6519505196682808\t 2.2034947967950695\t 2.2034947967950695\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.6893334668436607\t 0.6519505196682808\t 2.2624576021965566\t 2.2624576021965566\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.7458275930604825\t 0.6519505196682808\t 2.199226669345097\t 2.199226669345097\n",
            "27 \t [ 9.88239745  3.08226956 11.          0.65295835  2.          0.64174706]\t 0.7805648156360628\t 0.6519505196682808\t 2.2168004558931367\t 2.2168004558931367\n",
            "28 \t [5.9270225  4.64228615 5.         0.60674766 7.         0.57131582]\t 0.8654275908149657\t 0.6519505196682808\t 2.1942126909616624\t 2.1942126909616624\n",
            "29 \t [ 9.93142529  1.55453711  5.          0.69644974 13.          0.89571454]\t 0.7435142600117224\t 0.6519505196682808\t 2.208101174000998\t 2.208101174000998\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.786373065109467\t 0.6519505196682808\t 2.179292027480945\t 2.179292027480945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46832.22443034189"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYebx3RVaJ1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f67a2fcb-eec8-4ceb-de2e-db51c8572914"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.8461730749178773\t 0.6529031062312245\t 1.7338376670633802\t 1.7338376670633802\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7280339284910606\t 0.6529031062312245\t 1.7947616448028514\t 1.7947616448028514\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.6571137209723783\t 0.6529031062312245\t 1.793130642771869\t 1.793130642771869\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7458231993222018\t 0.6529031062312245\t 1.7712287700277423\t 1.7712287700277423\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.7838758112536788\t 0.6529031062312245\t 1.7774988854446665\t 1.7774988854446665\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 1.7922689995707937\t 1.7922689995707937\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 1.7808787189959623\t 1.7808787189959623\n",
            "8  \t [ 0.46626117  2.25760624  6.          0.85367342 17.          0.48531791]\t 0.8135396529627978\t 0.6529031062312245\t 1.808633063429621\t 1.808633063429621\n",
            "9  \t [5.70513125 8.30861013 6.         0.98680016 3.         0.16134411]\t 0.9984088714580504\t 0.6529031062312245\t 1.8234584257171522\t 1.8234584257171522\n",
            "10 \t [ 3.5721216   0.0452777  14.          0.8757848   8.          0.10300558]\t 0.9938990668172615\t 0.6529031062312245\t 1.8747538344113484\t 1.8747538344113484\n",
            "11 \t [ 0.          0.26297593  5.26246401  0.5        10.26246401  0.1       ]\t 1.0011804256482524\t 0.6529031062312245\t 1.9171650055702634\t 1.917164990211106\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[7.0602652  6.93790534 9.         0.99868525 6.         0.93828193]\u001b[0m\t \u001b[1m\u001b[92m0.6512010756034953\u001b[0m\t \u001b[1m\u001b[92m0.6512010756034953\u001b[0m\t \u001b[1m\u001b[92m1.9549207354499436\u001b[0m\t \u001b[1m\u001b[92m1.9549207354499436\u001b[0m\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.7792188999132433\t 0.6512010756034953\t 1.9355055337133087\t 1.9355055337133087\n",
            "14 \t [ 5.05369665  2.67147005  5.          0.51290284 10.          0.64085   ]\t 0.7504591409344632\t 0.6512010756034953\t 1.9340322728523147\t 1.9340322728523147\n",
            "15 \t [ 0.80466258  8.06348306  7.          0.77513285 17.          0.96959926]\t 0.6790417202245967\t 0.6512010756034953\t 1.929036913412309\t 1.929036913412309\n",
            "16 \t [ 1.46233253  4.21473795 12.          0.82588689  8.          0.69701346]\t 0.686927347743188\t 0.6512010756034953\t 1.917051901347863\t 1.917051901347863\n",
            "17 \t [ 0.08258912  2.04682383 12.          0.59206459 18.          0.58057909]\t 0.6960149194291863\t 0.6512010756034953\t 1.9065381037421525\t 1.9065381037421525\n",
            "\u001b[1m\u001b[92m18\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         19.90383112  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6415746011828174\u001b[0m\t \u001b[1m\u001b[92m0.6415746011828174\u001b[0m\t \u001b[1m\u001b[92m1.9020653559377552\u001b[0m\t \u001b[1m\u001b[92m1.9020653559372738\u001b[0m\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 0.9937922112122403\t 0.6415746011828174\t 1.8863065341359067\t 1.8863065341359067\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.8385022169449027\t 0.6415746011828174\t 1.8872355373354441\t 1.8872355373354441\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7015179019308584\t 0.6415746011828174\t 1.9682451618162153\t 1.9682451618162153\n",
            "22 \t [9.36551555 8.35926435 5.         0.8418078  9.         0.1220723 ]\t 0.9984569363237903\t 0.6415746011828174\t 1.9070299226024447\t 1.9070299226024447\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.8346586316188039\t 0.6415746011828174\t 1.9391884492954683\t 1.9391884492954683\n",
            "24 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0017306757451643\t 0.6415746011828174\t 1.9548437072464382\t 1.9548437072464329\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7621762752757402\t 0.6415746011828174\t 1.9466739655240468\t 1.9466739655240468\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 0.9921424184439918\t 0.6415746011828174\t 1.961878476794463\t 1.961878476794463\n",
            "27 \t [9.91546913 0.35662679 7.         0.87706909 8.         0.31009443]\t 0.8520314289074896\t 0.6415746011828174\t 2.0004438346127684\t 2.0004438346127684\n",
            "28 \t [ 2.61920828  0.74890646 14.          0.70116142 18.          0.54069228]\t 0.6934175200009414\t 0.6415746011828174\t 1.9797422131803588\t 1.9797422131803588\n",
            "29 \t [5.13805575 8.46039335 5.         0.82814397 6.         0.39527277]\t 0.833602430515404\t 0.6415746011828174\t 1.9454334697185778\t 1.9454334697185778\n",
            "30 \t [ 6.51356727  1.45057476 10.          0.5773341   4.          0.42302705]\t 0.7973763757188531\t 0.6415746011828174\t 2.0113850059163214\t 2.0113850059163214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49759.76528877992"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b36bec8-84eb-49da-857d-bc40f0e48ab7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 1.813166598869859\t 1.813166598869859\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 1.7947851119212799\t 1.7947851119212799\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 1.8304333713878373\t 1.8304333713878373\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 1.8233654480582715\t 1.8233654480582715\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 1.8478086930314992\t 1.8478086930314992\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 1.8418872888200168\t 1.8418872888200168\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 1.824819912630544\t 1.824819912630544\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 1.8456194734133666\t 1.8456194734133666\n",
            "9  \t [0.  0.  5.  0.5 1.  0.1]\t 0.9366264008615343\t 0.6653168057229354\t 1.8603315437050856\t 1.860331542829666\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.6700820921354065\t 0.6653168057229354\t 1.8946260592348803\t 1.8946260592348803\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6653168057229354\t 1.8788031310755429\t 1.8788031310755429\n",
            "12 \t [ 0.20192989  7.58476143 13.          0.98270421 14.          0.40270035]\t 0.8039385291078224\t 0.6653168057229354\t 1.8905358825674698\t 1.8905358825674698\n",
            "13 \t [8.84715023 2.54200416 9.         0.79480608 3.         0.41227405]\t 0.8075723681673436\t 0.6653168057229354\t 1.8953129967082571\t 1.8953129967082571\n",
            "14 \t [ 1.81172472  3.20020334  8.          0.50059125 18.          0.97749106]\t 0.6823725138335324\t 0.6653168057229354\t 1.8998902784398832\t 1.8998902784398832\n",
            "15 \t [3.63587924 9.92644255 5.         0.74785877 1.         0.42737692]\t 0.8438702768074448\t 0.6653168057229354\t 1.8876964763093589\t 1.8876964763093589\n",
            "16 \t [0.05861183 0.85510206 7.         0.55669041 9.         0.24118856]\t 0.9320720399646423\t 0.6653168057229354\t 1.8981603853423255\t 1.8981603853423255\n",
            "17 \t [2.76407972 8.95502778 9.         0.67297573 5.         0.56560976]\t 0.7213199372798768\t 0.6653168057229354\t 1.9184544016574607\t 1.9184544016574607\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9301596203801468\t 0.6653168057229354\t 1.9266379558148978\t 1.9266379558148978\n",
            "19 \t [ 1.24817982  5.75156112 12.          0.56532786 19.          0.40494625]\t 0.8104031101648417\t 0.6653168057229354\t 1.9611642021985576\t 1.9611642021985576\n",
            "20 \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]\t 0.6778496323948628\t 0.6653168057229354\t 1.9173588610935595\t 1.9173588610935595\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.713587872750312\t 0.6653168057229354\t 1.9022289255547298\t 1.9022289255547298\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.8265101138776348\t 0.6653168057229354\t 1.9349619491121586\t 1.9349619491121586\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m1.9091342128355335\u001b[0m\t \u001b[1m\u001b[92m1.909134212832192\u001b[0m\n",
            "24 \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\t 0.6652912380850803\t 0.6454226853941064\t 1.9435840580097608\t 1.9435840580097608\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8407613659642559\t 0.6454226853941064\t 1.8827081288633891\t 1.8827081288633891\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9338663333604857\t 0.6454226853941064\t 1.900361022424704\t 1.900361022424704\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8100270760776773\t 0.6454226853941064\t 1.9056281274467208\t 1.9056281274467208\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.675192856271044\t 0.6454226853941064\t 1.9423841461840317\t 1.9423841461840317\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.699572467500549\t 0.6454226853941064\t 1.942269433516068\t 1.942269433516068\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 0.930914842449664\t 0.6454226853941064\t 1.9256237925379889\t 1.9256237925379889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51081.55924427656"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8455e304-44b7-40b0-a037-03b91adbcb2e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 1.840974913162529\t 1.840974913162529\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 1.9824874047859387\t 1.9824874047859387\n",
            "3  \t [ 8.20707753  5.23681739  9.          0.99500664 19.          0.41686889]\t 0.7862089426832719\t 0.6448358819228919\t 1.9396172860854324\t 1.9396172860854324\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 1.9378967867394183\t 1.9378967867394183\n",
            "5  \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]\t 0.7377720407232845\t 0.6448358819228919\t 1.924283205750116\t 1.924283205750116\n",
            "6  \t [ 2.07399013  1.08547559 13.          0.90854674 16.          0.44415088]\t 0.7854445167823974\t 0.6448358819228919\t 1.9128939383445436\t 1.9128939383445436\n",
            "7  \t [6.35203132 8.3324364  9.         0.54516266 6.         0.26778796]\t 0.8384879719057332\t 0.6448358819228919\t 1.9139015160351236\t 1.9139015160351236\n",
            "8  \t [ 0.56883492  2.21937218  6.          0.84490274 16.          0.30898926]\t 0.8417982153735359\t 0.6448358819228919\t 1.925952894691766\t 1.925952894691766\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.788150408197674\t 0.6448358819228919\t 1.936754187241336\t 1.936754187241336\n",
            "10 \t [ 5.98496312  5.93098165 12.          0.98968567 10.          0.92685569]\t 0.6460649755186514\t 0.6448358819228919\t 1.936316869062126\t 1.936316869062126\n",
            "11 \t [10. 10. 15.  1. 20.  1.]\t 0.6505488267879174\t 0.6448358819228919\t 1.9147638458082106\t 1.9147638458082101\n",
            "12 \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]\t 0.8508904111239197\t 0.6448358819228919\t 1.8952588877065544\t 1.8952588877065544\n",
            "13 \t [1.75561603 6.13376087 5.         0.74047005 6.         0.77032586]\t 0.7376272669813917\t 0.6448358819228919\t 1.9074678050546883\t 1.9074678050546883\n",
            "14 \t [ 0.42678797  0.40430921 14.          0.96202194 10.          0.10119674]\t 1.0441321675998059\t 0.6448358819228919\t 1.9022482030932082\t 1.9022482030932082\n",
            "15 \t [0.         2.07936978 5.         0.5        1.         0.1       ]\t 1.0517934452387856\t 0.6448358819228919\t 1.9447280185790505\t 1.9447279973111573\n",
            "16 \t [ 7.23999956  0.75655238 11.          0.57850561 14.          0.8201476 ]\t 0.6691818859667797\t 0.6448358819228919\t 1.9779280392217908\t 1.9779280392217908\n",
            "17 \t [1.06462795 1.89851825 8.         0.90141515 8.         0.27329674]\t 0.8310600002305779\t 0.6448358819228919\t 1.9635642659156831\t 1.9635642659156831\n",
            "18 \t [2.32449242 8.80135208 8.         0.99642073 4.         0.14576968]\t 1.0446140483804913\t 0.6448358819228919\t 1.9939558579199974\t 1.9939558579199974\n",
            "19 \t [ 9.64898425  9.81436315  8.          0.51365612 15.          0.49723757]\t 0.8018388889031491\t 0.6448358819228919\t 1.9882239210971762\t 1.9882239210971762\n",
            "20 \t [ 9.4006826   2.14529633  7.          0.801278   16.          0.55170588]\t 0.7578480827583333\t 0.6448358819228919\t 1.998103659087673\t 1.998103659087673\n",
            "21 \t [ 4.24623163  7.02774535 15.          1.         19.76667982  1.        ]\t 0.650566898859372\t 0.6448358819228919\t 2.016230359936971\t 2.0162303564368727\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.7865928825712862\t 0.6448358819228919\t 1.9769046734296278\t 1.9769046734296278\n",
            "23 \t [ 4.99436711 10.         12.56578585  1.         15.56578585  1.        ]\t 0.6495344773700907\t 0.6448358819228919\t 2.036467684808057\t 2.0364676834178206\n",
            "24 \t [10.          4.0613792  13.72517995  1.         19.72517995  1.        ]\t 0.6506203636182215\t 0.6448358819228919\t 1.9935255651745676\t 1.9935255651428252\n",
            "25 \t [ 8.47674061  5.78052722 12.          0.53190312  3.          0.14993193]\t 1.0494124396464328\t 0.6448358819228919\t 1.968891365023994\t 1.968891365023994\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.6950503015339501\t 0.6448358819228919\t 1.9784476565407203\t 1.9784476565407203\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 1.9987356399388316\t 1.9987356399388316\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 0.8375129312365261\t 0.6448358819228919\t 1.9894483497332405\t 1.9894483497332405\n",
            "29 \t [ 7.12320801  5.62079639  5.          0.57720044 19.          0.34391463]\t 0.8518813415581681\t 0.6448358819228919\t 1.980683920913601\t 1.980683920913601\n",
            "30 \t [ 4.59009458  5.90114092 11.          0.80973999 14.          0.94248801]\t 0.6504750059521124\t 0.6448358819228919\t 1.9685469339499313\t 1.9685469339499313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce3e4ee-55af-40d7-fc2c-98bb5a908b83"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 1.8892111592817085\t 1.8892111592817085\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 1.8527314884921047\t 1.8527314884921047\n",
            "3  \t [ 2.20772511  4.37663949 11.          0.65455258  3.          0.57545511]\t 0.7112447021396917\t 0.6669292375133978\t 1.8476723658663035\t 1.8476723658663035\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 1.8348187524063884\t 1.8348187524063884\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 3.75041373  9.81989522 14.          0.71370546 14.          0.97207881]\u001b[0m\t \u001b[1m\u001b[92m0.6475832890376199\u001b[0m\t \u001b[1m\u001b[92m0.6475832890376199\u001b[0m\t \u001b[1m\u001b[92m1.822020432188345\u001b[0m\t \u001b[1m\u001b[92m1.822020432188345\u001b[0m\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 0.8210163484458256\t 0.6475832890376199\t 1.7998337552088854\t 1.7998337552088854\n",
            "7  \t [0.  0.  5.  0.5 1.  0.1]\t 0.8815800498680714\t 0.6475832890376199\t 1.8200502965004763\t 1.8200502965002883\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[10.          6.78215987 12.73413954  1.         10.73413954  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6423941455356202\u001b[0m\t \u001b[1m\u001b[92m0.6423941455356202\u001b[0m\t \u001b[1m\u001b[92m1.8507106283162698\u001b[0m\t \u001b[1m\u001b[92m1.8507106283162686\u001b[0m\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.661096368919013\t 0.6423941455356202\t 1.8308787974748186\t 1.8308787974748186\n",
            "10 \t [0.         2.22734427 5.         0.5        7.99368693 0.1       ]\t 0.8814015453098782\t 0.6423941455356202\t 1.816585304965738\t 1.8165853048346803\n",
            "11 \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]\t 0.662454600529182\t 0.6423941455356202\t 1.8413969092775098\t 1.8413969092775098\n",
            "12 \t [ 8.79417312  9.02268129 11.          0.87585483  1.          0.84249089]\t 0.6656143987957235\t 0.6423941455356202\t 1.8284972430282898\t 1.8284972430282898\n",
            "13 \t [10.         10.         15.          1.         18.76124676  1.        ]\t 0.6455443154718696\t 0.6423941455356202\t 1.8175289843986862\t 1.8175289789239137\n",
            "14 \t [ 3.89768175  5.29572603  8.          0.92074245 11.          0.31486353]\t 0.8106110145898601\t 0.6423941455356202\t 1.8050949381142871\t 1.8050949381142871\n",
            "15 \t [2.14023913 7.87482927 8.         0.56565632 3.         0.51657322]\t 0.7143214190270583\t 0.6423941455356202\t 1.815301072061901\t 1.815301072061901\n",
            "16 \t [ 0.79209787  5.77655365 11.          0.54385846 15.          0.82704826]\t 0.6707470768091746\t 0.6423941455356202\t 1.8077931747926368\t 1.8077931747926368\n",
            "17 \t [ 8.35606609  9.54397398  8.          0.89431505 16.          0.32940842]\t 0.8105681189470862\t 0.6423941455356202\t 1.8054818874181287\t 1.8054818874181287\n",
            "18 \t [ 0.19295602  0.79378594 12.          0.59003081  7.          0.10978379]\t 0.8849133129136291\t 0.6423941455356202\t 1.8075278266786625\t 1.8075278266786625\n",
            "19 \t [ 1.75909042  8.50460179 10.          0.61596511  8.          0.92202704]\t 0.6552140243198975\t 0.6423941455356202\t 1.8232701522124197\t 1.8232701522124197\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 0.8804917195016874\t 0.6423941455356202\t 1.836372807827838\t 1.836372807827838\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7119792503375972\t 0.6423941455356202\t 1.845687257912294\t 1.845687257912294\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 0.8840919924947371\t 0.6423941455356202\t 1.8358094101872364\t 1.8358094101872364\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.6539666670983036\t 0.6423941455356202\t 1.8389524875561947\t 1.8389524875561947\n",
            "24 \t [ 8.33810851  9.8990204  14.          0.61893039  5.          0.69227045]\t 0.699282809687575\t 0.6423941455356202\t 1.855475196524251\t 1.855475196524251\n",
            "25 \t [ 9.8750257   5.38059903  9.          0.71778174 19.          0.87413503]\t 0.6657607451774454\t 0.6423941455356202\t 1.858233513318619\t 1.858233513318619\n",
            "26 \t [ 0.41334249  8.31887156 14.          0.56806567  3.          0.60385777]\t 0.7174804114401528\t 0.6423941455356202\t 1.8502964635048968\t 1.8502964635048968\n",
            "27 \t [ 8.41854148  7.38245647  7.          0.57908813 12.          0.74367697]\t 0.7079468130001596\t 0.6423941455356202\t 1.8260183422618008\t 1.8260183422618008\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 0.8822650514974324\t 0.6423941455356202\t 1.8112851714668927\t 1.8112851714668927\n",
            "29 \t [ 6.51286665  1.39669624 14.          0.78787389  3.          0.11385444]\t 0.8836810798728383\t 0.6423941455356202\t 1.8492100748583948\t 1.8492100748583948\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.81181886510441\t 0.6423941455356202\t 1.8746564770961585\t 1.8746564770961585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50424.27457116489"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc333910-9370-4cd9-bf2a-161d3ee5348d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 1.7719800273756232\t 1.7719800273756232\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m1.7669632135588516\u001b[0m\t \u001b[1m\u001b[92m1.7669632135588516\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 1.7455497205558128\t 1.7455497205558128\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 0.9235319432135773\t 0.6577294425265764\t 1.7620581524596006\t 1.7620581524596006\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.7883201967902798\t 0.6577294425265764\t 1.8244103569278647\t 1.8244103569278647\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.6922630708519245\t 0.6577294425265764\t 1.8361228109905843\t 1.8361228109905843\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 8.22239698 10.         12.51158254  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6379613499899032\u001b[0m\t \u001b[1m\u001b[92m0.6379613499899032\u001b[0m\t \u001b[1m\u001b[92m1.823093173384735\u001b[0m\t \u001b[1m\u001b[92m1.823093173384196\u001b[0m\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.8743477887688297\t 0.6379613499899032\t 1.8034877328315948\t 1.8034877328315948\n",
            "9  \t [ 7.64065289  8.8630116  14.          0.9254486   9.          0.47351621]\t 0.7626076284004604\t 0.6379613499899032\t 1.8313934161574963\t 1.8313934161574963\n",
            "10 \t [ 1.06054513  2.23745512 13.          0.92745502  9.          0.16992758]\t 0.9226798533243917\t 0.6379613499899032\t 1.83434151861048\t 1.83434151861048\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.8864529961319944\t 0.6379613499899032\t 1.865694946917404\t 1.865694946917404\n",
            "12 \t [ 6.57200974  0.32012384 12.          0.93711127 11.          0.95294152]\t 0.6440920207844668\t 0.6379613499899032\t 1.8858925889828566\t 1.8858925889828566\n",
            "13 \t [1.37264123 4.42539257 5.         0.50284853 7.         0.43970984]\t 0.8076253627013447\t 0.6379613499899032\t 1.8696865419434603\t 1.8696865419434603\n",
            "14 \t [ 8.71522337  2.64896453  8.          0.8880663  13.          0.19932467]\t 0.9228060288203824\t 0.6379613499899032\t 1.8758194763321279\t 1.8758194763321279\n",
            "15 \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]\t 0.9297173774466645\t 0.6379613499899032\t 1.8985400163444568\t 1.8985400163444568\n",
            "16 \t [ 1.89793764  8.73729849 11.          0.54212945 19.          0.98798362]\t 0.662113773168444\t 0.6379613499899032\t 1.9185415237273384\t 1.9185415237273384\n",
            "17 \t [4.68258101 8.96288202 5.         0.97630328 6.         0.39227084]\t 0.8031528445623343\t 0.6379613499899032\t 1.9056865193599373\t 1.9056865193599373\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.698358780864823\t 0.6379613499899032\t 1.9091546654905205\t 1.9091546654905205\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 0.9265282654642244\t 0.6379613499899032\t 1.904844540027972\t 1.904844540027972\n",
            "20 \t [9.22875209 9.1986098  9.         0.90439491 3.         0.27523226]\t 0.8725625909092452\t 0.6379613499899032\t 1.911092554527922\t 1.911092554527922\n",
            "21 \t [ 3.32966927  6.72206515 14.          0.83912863 18.          0.84659432]\t 0.6883249973001357\t 0.6379613499899032\t 1.9556049258901422\t 1.9556049258901422\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7286740032592812\t 0.6379613499899032\t 1.9365132151280597\t 1.9365132151280597\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7418835369809943\t 0.6379613499899032\t 1.9804956260986335\t 1.9804956260986335\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.8686347965869988\t 0.6379613499899032\t 1.9359234709962896\t 1.9359234709962896\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 0.9247656684808231\t 0.6379613499899032\t 1.9180061076844115\t 1.9180061076844115\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.764405864026175\t 0.6379613499899032\t 1.982770573770825\t 1.982770573770825\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7332555811634872\t 0.6379613499899032\t 1.9441736597775066\t 1.9441736597775066\n",
            "28 \t [0.         0.71920747 8.0245093  0.5        8.0245093  0.1       ]\t 0.9263781767939019\t 0.6379613499899032\t 1.9290330649570993\t 1.9290330647103282\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.6600116767225708\t 0.6379613499899032\t 1.9330242038248135\t 1.9330242038248135\n",
            "30 \t [ 8.90038024  6.84704721 14.          0.51883719 15.          0.17155821]\t 0.9255113000968498\t 0.6379613499899032\t 1.9652937532381645\t 1.9652937532381645\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50731.822037997925"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e02e6bc-41a5-47e2-dae1-cccb6da83f6c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 1.9480535380628092\t 1.9480535380628092\n",
            "2  \t [ 3.78385301  2.21923666 12.          0.57141407  8.          0.55842631]\t 0.7285402508953416\t 0.7056203424268611\t 1.9288412333932206\t 1.9288412333932206\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 4.70630658  9.38750646 12.          0.7933865  10.          0.74968408]\u001b[0m\t \u001b[1m\u001b[92m0.6939932582164752\u001b[0m\t \u001b[1m\u001b[92m0.6939932582164752\u001b[0m\t \u001b[1m\u001b[92m1.9088963347329155\u001b[0m\t \u001b[1m\u001b[92m1.9088963347329155\u001b[0m\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.8009366885878899\t 0.6939932582164752\t 1.8840434025174555\t 1.8840434025174555\n",
            "5  \t [ 9.02656498  0.48984226 12.          0.66187047 14.          0.17842177]\t 0.9261950890540188\t 0.6939932582164752\t 1.892850966154169\t 1.892850966154169\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.7872412218199303\t 0.6939932582164752\t 1.9337262327748503\t 1.9337262327748503\n",
            "7  \t [ 9.92159613  3.53760601 14.          0.66495754  4.          0.92098158]\t 0.7037336633700015\t 0.6939932582164752\t 1.9332374446261489\t 1.9332374446261489\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.8017323350323444\t 0.6939932582164752\t 1.9166576467358265\t 1.9166576467358265\n",
            "9  \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]\t 0.7213506404912987\t 0.6939932582164752\t 1.9203313547215328\t 1.9203313547215328\n",
            "10 \t [ 2.00580329  2.31031601 14.          0.90401435 16.          0.44341936]\t 0.7698813922221472\t 0.6939932582164752\t 1.9097823839345018\t 1.9097823839345018\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[10.          5.17125849 14.36518135  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6502180205688785\u001b[0m\t \u001b[1m\u001b[92m0.6502180205688785\u001b[0m\t \u001b[1m\u001b[92m1.9082024499586625\u001b[0m\t \u001b[1m\u001b[92m1.908202449930304\u001b[0m\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.7202487480474815\t 0.6502180205688785\t 1.8900035463088347\t 1.8900035463088347\n",
            "13 \t [ 5.97904546  9.54654633 12.          0.85402391 19.          0.25521119]\t 0.7891186169314436\t 0.6502180205688785\t 1.8828548717925095\t 1.8828548717925095\n",
            "14 \t [4.78141019e-03 0.00000000e+00 6.24978833e+00 5.00000000e-01\n",
            " 4.24978833e+00 1.00000000e-01]\t 0.9343367579639097\t 0.6502180205688785\t 1.8856783893835227\t 1.8856783893834719\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9310123715662361\t 0.6502180205688785\t 1.90891029476925\t 1.90891029476925\n",
            "16 \t [ 3.08736763  8.9307732   8.          0.97392078 10.          0.55958339]\t 0.7224438046165756\t 0.6502180205688785\t 1.929089662880063\t 1.929089662880063\n",
            "17 \t [ 2.38620183  1.03950496 13.          0.6257051   6.          0.34211692]\t 0.7949227225244432\t 0.6502180205688785\t 1.9245333412004508\t 1.9245333412004508\n",
            "18 \t [ 3.78107951  0.45942362 10.          0.50753562 14.          0.98062991]\t 0.706698998449962\t 0.6502180205688785\t 1.9423431105296087\t 1.9423431105296087\n",
            "19 \t [9.51121457 1.16444035 9.         0.81792407 9.         0.70590587]\t 0.6983390620759949\t 0.6502180205688785\t 1.9103811497208756\t 1.9103811497208756\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.6502180205688785\t 1.902799959130674\t 1.902799959130674\n",
            "21 \t [ 0.60383814  6.44796032 11.          0.78951032 16.          0.75679881]\t 0.694356779546439\t 0.6502180205688785\t 1.8937488825659945\t 1.8937488825659945\n",
            "22 \t [ 4.22119996  7.99655483  5.          0.78307763 14.          0.79061697]\t 0.7405746569621561\t 0.6502180205688785\t 1.9410521962019303\t 1.9410521962019303\n",
            "23 \t [4.95914531 0.87379526 5.         0.9944488  1.         0.26445681]\t 0.8061596255501012\t 0.6502180205688785\t 1.9181443400310103\t 1.9181443400310103\n",
            "24 \t [ 3.54377146  1.55114788  9.          0.60325108 18.          0.58026864]\t 0.7288271346270945\t 0.6502180205688785\t 1.8872763631083034\t 1.8872763631083034\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9328823718301782\t 0.6502180205688785\t 1.925359976190879\t 1.925359976190879\n",
            "26 \t [ 1.0206155   0.50876351 11.          0.82996077 17.          0.80891943]\t 0.6931022492573785\t 0.6502180205688785\t 1.965749372448676\t 1.965749372448676\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 7.73125063  2.38838897 15.          1.          9.46015807  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6486175918156064\u001b[0m\t \u001b[1m\u001b[92m0.6486175918156064\u001b[0m\t \u001b[1m\u001b[92m1.9513424006072395\u001b[0m\t \u001b[1m\u001b[92m1.9513427562329249\u001b[0m\n",
            "28 \t [ 0.95326243  8.54359757 11.          0.78353092  5.          0.635258  ]\t 0.6959154097267148\t 0.6486175918156064\t 1.9218980608512257\t 1.9218980608512257\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.7292686946198735\t 0.6486175918156064\t 1.924730538052057\t 1.924730538052057\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.9256181718283066\t 0.6486175918156064\t 1.8993097054746577\t 1.8993097054746577\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50726.745623014824"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06666ad6-057b-463b-d4e2-e4dc9a85bf6d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 2.2534590690909986\t 2.2534590690909986\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10.          6.10411631 14.76729771  1.         19.76729771  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.648501739792713\u001b[0m\t \u001b[1m\u001b[92m0.648501739792713\u001b[0m\t \u001b[1m\u001b[92m2.179719119123623\u001b[0m\t \u001b[1m\u001b[92m2.179719119089436\u001b[0m\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.648501739792713\t 2.105447627355123\t 2.105447627355123\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.6797825903178236\t 0.648501739792713\t 2.07879465515818\t 2.07879465515818\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.0980632271289044\t 0.648501739792713\t 2.036983192459886\t 2.036983192459886\n",
            "6  \t [ 7.68636788  7.27927184 12.          0.97932089  3.          0.87363673]\t 0.6657443951678294\t 0.648501739792713\t 2.1113484993826868\t 2.1113484993826868\n",
            "7  \t [ 1.83205559  5.96122477  9.          0.60293091 14.          0.2543724 ]\t 0.9191321113264156\t 0.648501739792713\t 2.0722727879378398\t 2.0722727879378398\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1062273028353988\t 0.648501739792713\t 2.0877877397953415\t 2.0877877397953415\n",
            "9  \t [9.52796793 0.5269077  7.         0.61130342 2.         0.41024487]\t 0.8258632893631743\t 0.648501739792713\t 2.1420452809113115\t 2.1420452809113115\n",
            "10 \t [ 6.60596124  8.35313787  6.          0.72167152 19.          0.94552853]\t 0.7025896131486131\t 0.648501739792713\t 2.1337617713631674\t 2.1337617713631674\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7370906275446215\t 0.648501739792713\t 2.1087373306195873\t 2.1087373306195873\n",
            "12 \t [ 9.46545841  2.71414127  5.          0.83512297 13.          0.70984642]\t 0.7596192306405462\t 0.648501739792713\t 2.091116203103777\t 2.091116203103777\n",
            "13 \t [0.        0.        5.        0.5       5.4361019 0.1      ]\t 1.1004397521284215\t 0.648501739792713\t 2.078330577693061\t 2.0783305776803873\n",
            "14 \t [ 2.54563859  4.29868675 14.          0.69241189 17.          0.95945337]\t 0.6647142942648914\t 0.648501739792713\t 2.117244105420048\t 2.117244105420048\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.648501739792713\t 2.0943926135588242\t 2.0943926135588242\n",
            "16 \t [9.66123717 1.6749164  7.         0.52601834 9.         0.78339475]\t 0.6982122839928836\t 0.648501739792713\t 2.0741806908298885\t 2.0741806908298885\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.105080285400748\t 0.648501739792713\t 2.0575987555085824\t 2.0575987555085824\n",
            "18 \t [9.81792293 8.02628625 6.         0.84581675 1.         0.43435016]\t 0.8324792319640995\t 0.648501739792713\t 2.103230562288327\t 2.103230562288327\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.0995998424487943\t 0.648501739792713\t 2.094620946175169\t 2.094620946175169\n",
            "20 \t [ 9.35280568  2.44132886  8.          0.87489385 18.          0.92170626]\t 0.67440347483604\t 0.648501739792713\t 2.1173685954682604\t 2.1173685954682604\n",
            "21 \t [4.5891881  3.56149985 9.         0.57196292 5.         0.56648169]\t 0.7307933148442576\t 0.648501739792713\t 2.0914674321057802\t 2.0914674321057802\n",
            "22 \t [4.74151988e-03 7.73535708e+00 9.00000000e+00 8.10214170e-01\n",
            " 7.00000000e+00 8.51111303e-01]\t 0.6741140944144826\t 0.648501739792713\t 2.1353038556660646\t 2.1353038556660646\n",
            "23 \t [3.55859061 5.61875163 8.         0.5882063  1.         0.57036163]\t 0.7346535405920693\t 0.648501739792713\t 2.125472603934759\t 2.125472603934759\n",
            "24 \t [ 0.2594182   8.03698568 14.          0.55642831  5.          0.91542841]\t 0.6724111162410003\t 0.648501739792713\t 2.1014245157486133\t 2.1014245157486133\n",
            "25 \t [ 4.58851998  9.96722725 10.          0.86802391  9.          0.49712674]\t 0.8197897150933404\t 0.648501739792713\t 2.065001654023218\t 2.065001654023218\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.672888499874982\t 0.648501739792713\t 2.0685880323110974\t 2.0685880323110974\n",
            "27 \t [10.         10.          9.26284454  1.          5.26284454  1.        ]\t 0.6567408586710959\t 0.648501739792713\t 2.053113330982661\t 2.053113330301904\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.768583852631927\t 0.648501739792713\t 2.023388864553455\t 2.023388864553455\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9197610970890002\t 0.648501739792713\t 2.0407641660455855\t 2.0407641660455855\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.9166993865744176\t 0.648501739792713\t 2.0316680340004463\t 2.0316680340004463\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49402.95915471633"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411b7a1c-44ad-402d-ec64-6ece8dcc3f50"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 2.0703363057846262\t 2.0703363057846262\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6502979285238808\u001b[0m\t \u001b[1m\u001b[92m0.6502979285238808\u001b[0m\t \u001b[1m\u001b[92m2.1441710076251392\u001b[0m\t \u001b[1m\u001b[92m2.1441710076251392\u001b[0m\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6502979285238808\t 2.0744063280991045\t 2.0744063280991045\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6502979285238808\t 2.0393601634054024\t 2.0393601634054024\n",
            "5  \t [ 9.22243919  0.59642165  6.          0.72537748 19.          0.46639325]\t 0.8253470890530193\t 0.6502979285238808\t 2.092486485722169\t 2.092486485722169\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 1.0131910395518218\t 0.6502979285238808\t 2.0855168789698766\t 2.0855168789698766\n",
            "7  \t [9.50752677 9.21478059 7.         0.68709357 5.         0.7478709 ]\t 0.6980584298280876\t 0.6502979285238808\t 2.1245984157293023\t 2.1245984157293023\n",
            "8  \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]\t 0.8087127953472528\t 0.6502979285238808\t 2.093180595824421\t 2.093180595824421\n",
            "9  \t [ 2.48800603  5.10093097 14.          0.58870342  6.          0.75046851]\t 0.679436663814411\t 0.6502979285238808\t 2.0847598089730734\t 2.0847598089730734\n",
            "10 \t [ 1.6361515   9.65601963  6.          0.78645605 10.          0.24059194]\t 1.0163848571205125\t 0.6502979285238808\t 2.0575810425637693\t 2.0575810425637693\n",
            "11 \t [ 9.88809977  3.72297385  6.          0.68686416 11.          0.16446157]\t 1.0169921141610336\t 0.6502979285238808\t 2.089164053059461\t 2.089164053059461\n",
            "12 \t [ 7.35080411  8.42969833  8.          0.54853874 19.          0.64845929]\t 0.6929769156766643\t 0.6502979285238808\t 2.1165841724617533\t 2.1165841724617533\n",
            "13 \t [ 9.52967585  8.1936199  11.          0.55796294 10.          0.99729185]\t 0.6733311328695132\t 0.6502979285238808\t 2.094259748377378\t 2.094259748377378\n",
            "14 \t [ 9.50881705  0.8310658  14.          0.86317554 18.          0.16718532]\t 1.0124852561685407\t 0.6502979285238808\t 2.071945484207513\t 2.071945484207513\n",
            "15 \t [ 4.60180761  5.86373927 12.          0.57860802 15.          0.61913601]\t 0.7198975715482087\t 0.6502979285238808\t 2.0955119274045417\t 2.0955119274045417\n",
            "16 \t [ 8.31010382  9.50355486 13.          0.84869956  3.          0.58223088]\t 0.723020622181743\t 0.6502979285238808\t 2.0805204595997844\t 2.0805204595997844\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.7105097809499443\t 0.6502979285238808\t 2.0664101540750175\t 2.0664101540750175\n",
            "18 \t [ 0.96607499  0.08146515 10.          0.75402335  6.          0.63275599]\t 0.6767950914466152\t 0.6502979285238808\t 2.082502756751704\t 2.082502756751704\n",
            "19 \t [ 3.64013283  1.0493391  14.          0.89734746 15.          0.52150501]\t 0.7150456435464582\t 0.6502979285238808\t 2.0934161874304666\t 2.0934161874304666\n",
            "20 \t [5.97224362 8.03394616 7.         0.96002317 1.         0.52715411]\t 0.7313742520133284\t 0.6502979285238808\t 2.0466867190893874\t 2.0466867190893874\n",
            "21 \t [4.16561464 4.3151821  6.         0.76299318 2.         0.59049538]\t 0.7439602970032533\t 0.6502979285238808\t 2.0599139320492155\t 2.0599139320492155\n",
            "22 \t [ 2.89145179  8.95900591 10.          0.52398991  6.          0.6540998 ]\t 0.684154512907023\t 0.6502979285238808\t 2.0371336923084526\t 2.0371336923084526\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 1.008805594135994\t 0.6502979285238808\t 2.0320898922498554\t 2.0320898922498554\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.6871807270632571\t 0.6502979285238808\t 2.0260685998316603\t 2.0260685998316603\n",
            "25 \t [ 5.5386478   9.30162083  6.          0.50498383 14.          0.37570322]\t 0.8247413269393998\t 0.6502979285238808\t 2.0524362553963433\t 2.0524362553963433\n",
            "26 \t [ 7.99859192  1.27814403 11.          0.87670998 12.          0.48785901]\t 0.8089215294655372\t 0.6502979285238808\t 2.024258340115512\t 2.024258340115512\n",
            "27 \t [9.7885039  6.2033537  9.         0.65492398 1.         0.51990551]\t 0.7271140440834436\t 0.6502979285238808\t 2.017178741611689\t 2.017178741611689\n",
            "28 \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]\t 0.7224622612996938\t 0.6502979285238808\t 1.9928191950365082\t 1.9928191950365082\n",
            "29 \t [9.09159421 4.28903846 8.         0.95401179 5.         0.64339406]\t 0.6820768749664751\t 0.6502979285238808\t 1.9958300686284594\t 1.9958300686284594\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.6762301508489591\t 0.6502979285238808\t 2.0335835436911682\t 2.0335835436911682\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50951.410503900624"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8d8c83-26bb-4bc6-af77-8c2e13212e46"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 2.0235993380712465\t 2.0235993380712465\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 1.9627197732844939\t 1.9627197732844939\n",
            "3  \t [ 7.5915683   5.13937898 12.          0.70919884  1.          0.76222697]\t 0.6599034896559471\t 0.6568473525973234\t 1.9833604860581564\t 1.9833604860581564\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.8615658015198442\t 0.6568473525973234\t 1.9412899752989823\t 1.9412899752989823\n",
            "5  \t [ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\t 0.730615339433918\t 0.6568473525973234\t 1.960800119689077\t 1.960800119689077\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.8514677232156771\t 0.6568473525973234\t 1.9443618253927004\t 1.9443618253927004\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6491916518522693\u001b[0m\t \u001b[1m\u001b[92m0.6491916518522693\u001b[0m\t \u001b[1m\u001b[92m1.957628742573861\u001b[0m\t \u001b[1m\u001b[92m1.9576287425738046\u001b[0m\n",
            "8  \t [ 9.21941721  9.79827821 11.          0.81783228 11.          0.53477407]\t 0.6659586056207597\t 0.6491916518522693\t 1.9296822258841682\t 1.9296822258841682\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[ 9.57627476  9.33745748 15.          1.          5.56936218  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6482716832300982\u001b[0m\t \u001b[1m\u001b[92m0.6482716832300982\u001b[0m\t \u001b[1m\u001b[92m1.9083847476828988\u001b[0m\t \u001b[1m\u001b[92m1.908384747601113\u001b[0m\n",
            "10 \t [ 8.47779105  8.43696768  5.          0.73890705 16.          0.66738091]\t 0.7564851327663848\t 0.6482716832300982\t 1.8873040481902088\t 1.8873040481902088\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.6638601166418586\t 0.6482716832300982\t 1.8850321494873559\t 1.8850321494873559\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.7350998875793917\t 0.6482716832300982\t 1.8699210818987209\t 1.8699210818987209\n",
            "13 \t [ 7.39713594  3.35991644 14.          0.6025392  18.          0.38842452]\t 0.7902911115290869\t 0.6482716832300982\t 1.865896535713266\t 1.865896535713266\n",
            "14 \t [ 0.30003945  0.76498683 12.          0.61016683 19.          0.36909762]\t 0.8558439960503271\t 0.6482716832300982\t 1.869684030374327\t 1.869684030374327\n",
            "15 \t [ 0.95566099  3.27803887  7.          0.79832937 17.          0.8547564 ]\t 0.6862274453809547\t 0.6482716832300982\t 1.8825284922155796\t 1.8825284922155796\n",
            "16 \t [8.78569544 0.14730956 7.         0.66172647 2.         0.54513841]\t 0.7029675116471538\t 0.6482716832300982\t 1.8731638518283853\t 1.8731638518283853\n",
            "17 \t [ 8.86262657  4.80771183  7.          0.94053059 11.          0.89773164]\t 0.6755564834011178\t 0.6482716832300982\t 1.866583077871753\t 1.866583077871753\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.6653785933459865\t 0.6482716832300982\t 1.8683720606387688\t 1.8683720606387688\n",
            "19 \t [ 9.64875283  9.32176949  8.          0.85263567 19.          0.33410227]\t 0.849585847576698\t 0.6482716832300982\t 1.8533891020306301\t 1.8533891020306301\n",
            "20 \t [ 5.31037667  6.81676807  5.          0.53020463 18.          0.21260061]\t 0.9149718789671064\t 0.6482716832300982\t 1.8601252949087104\t 1.8601252949087104\n",
            "21 \t [5.22443689 7.89924289 6.         0.9713403  5.         0.74877367]\t 0.7211762120086169\t 0.6482716832300982\t 1.8757037843960387\t 1.8757037843960387\n",
            "22 \t [ 4.90087649  7.40954674 11.          0.53028779  8.          0.43614982]\t 0.7965594035331703\t 0.6482716832300982\t 1.886290996213469\t 1.886290996213469\n",
            "23 \t [ 7.26711337  0.14235978  5.          0.76462611 16.          0.41351262]\t 0.8266718126292492\t 0.6482716832300982\t 1.8941491372597186\t 1.8941491372597186\n",
            "24 \t [ 4.16359362  2.79691345 14.          0.87075333  6.          0.5765776 ]\t 0.6628948200762557\t 0.6482716832300982\t 1.9044422814678306\t 1.9044422814678306\n",
            "25 \t [ 1.719002    1.73903169  5.          0.87805761 14.          0.46260902]\t 0.8248486263986295\t 0.6482716832300982\t 1.933614224706912\t 1.933614224706912\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.8070679905812153\t 0.6482716832300982\t 1.9232512038155416\t 1.9232512038155416\n",
            "27 \t [ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]\t 0.659126679409869\t 0.6482716832300982\t 1.9102911640424391\t 1.9102911640424391\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 2.19860267  0.42105203 13.          0.92769696 11.          0.87600458]\u001b[0m\t \u001b[1m\u001b[92m0.6422107560773703\u001b[0m\t \u001b[1m\u001b[92m0.6422107560773703\u001b[0m\t \u001b[1m\u001b[92m1.8828617864680468\u001b[0m\t \u001b[1m\u001b[92m1.8828617864680468\u001b[0m\n",
            "29 \t [ 3.89851316 10.         15.          1.         12.62608855  1.        ]\t 0.6462115619951808\t 0.6422107560773703\t 1.8576722344671712\t 1.8576722334289173\n",
            "30 \t [ 1.37049407  7.85946389  5.          0.57853198 11.          0.51266434]\t 0.7579938987964742\t 0.6422107560773703\t 1.8758325911224916\t 1.8758325911224916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49510.79989667552"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09eb1ad-6a1d-4604-ec76-57e1f6c0f6d8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m2.3038238546063514\u001b[0m\t \u001b[1m\u001b[92m2.3038238546063514\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 2.2127290631456797\t 2.2127290631456797\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 2.2029457185694286\t 2.2029457185694286\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 2.191313624172012\t 2.191313624172012\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 2.206625876161531\t 2.206625876161531\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 2.1979859530191246\t 2.1979859530191246\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 2.1640725756855974\t 2.1640725756855974\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.7620148611738933\t 0.6878693399983744\t 2.1807721875863506\t 2.1807721875863506\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m2.158276124221017\u001b[0m\t \u001b[1m\u001b[92m2.158276124221017\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7199718018091047\t 0.6730441336589406\t 2.1259247504317456\t 2.1259247504317456\n",
            "11 \t [ 3.92379693  5.26427008  7.          0.52294127 13.          0.66328071]\t 0.7482193144353987\t 0.6730441336589406\t 2.103702589721769\t 2.103702589721769\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 2.0880514782049864\t 2.0880514782049864\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m2.0693187001876523\u001b[0m\t \u001b[1m\u001b[92m2.0693187001876523\u001b[0m\n",
            "14 \t [ 5.41155711  5.82534705 10.          0.62444801 12.          0.48368067]\t 0.8667049733212127\t 0.6551680070961308\t 2.0464146387435806\t 2.0464146387435806\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 0.8854668121365705\t 0.6551680070961308\t 2.050595144067894\t 2.050595144067894\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6551680070961308\t 2.0563117527326322\t 2.0563117527326322\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 0.9718611347031094\t 0.6551680070961308\t 2.0507385470392046\t 2.0507385470392046\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 0.8703303423168164\t 0.6551680070961308\t 2.0985186279711505\t 2.0985186279711505\n",
            "19 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9761208022264058\t 0.6551680070961308\t 2.0639552341647804\t 2.0639552341384415\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.8073058384557079\t 0.6551680070961308\t 2.088684443726267\t 2.088684443726267\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 7.94526849 10.         11.10265977  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6497986288967132\u001b[0m\t \u001b[1m\u001b[92m0.6497986288967132\u001b[0m\t \u001b[1m\u001b[92m2.1105764918531333\u001b[0m\t \u001b[1m\u001b[92m2.1105763833585804\u001b[0m\n",
            "22 \t [ 9.03366199  7.80955039  7.          0.58807038 16.          0.37530235]\t 0.8718032531648561\t 0.6497986288967132\t 2.0497569180084905\t 2.0497569180084905\n",
            "23 \t [ 1.30643471  9.21858448  9.          0.51787301 19.          0.17653473]\t 0.9732754583939892\t 0.6497986288967132\t 2.063491580682771\t 2.063491580682771\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7113005276137964\t 0.6497986288967132\t 2.090412825350301\t 2.090412825350301\n",
            "25 \t [ 1.2601232   9.9585863  10.          0.70525992  2.          0.9880166 ]\t 0.6631852367566748\t 0.6497986288967132\t 2.0766452206186523\t 2.0766452206186523\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 0.8623919725421392\t 0.6497986288967132\t 2.060610281305668\t 2.060610281305668\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.7206151175283746\t 0.6497986288967132\t 2.0844000729718855\t 2.0844000729718855\n",
            "28 \t [1.37294589 2.61228134 9.         0.89667199 1.         0.42044841]\t 0.8676686566935652\t 0.6497986288967132\t 2.0372049576571145\t 2.0372049576571145\n",
            "29 \t [ 1.58467279  1.68272877 13.          0.86101343 12.          0.4100987 ]\t 0.8613126520852274\t 0.6497986288967132\t 2.0782180089925575\t 2.0782180089925575\n",
            "30 \t [1.31008715 1.58514894 5.         0.81941497 3.         0.50874328]\t 0.8056573356008814\t 0.6497986288967132\t 2.0681812390378043\t 2.0681812390378043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50531.56595546403"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13864251-6ee3-4eec-aa86-4404df2c4a8c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 2.007782681040181\t 2.007782681040181\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 2.0284125266635806\t 2.0284125266635806\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 2.0114406268347342\t 2.0114406268347342\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 1.9839202454116676\t 1.9839202454116676\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 2.0303564293233944\t 2.0303564293233944\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 2.0373265477257183\t 2.0373265477257183\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 2.038215158866576\t 2.038215158866576\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 2.023405089201926\t 2.023405089201926\n",
            "9  \t [9.85206608 0.28191822 5.         0.52457928 8.         0.84714334]\t 0.7819517369688569\t 0.7141038418197827\t 2.03608656774452\t 2.03608656774452\n",
            "10 \t [ 0.2191332   8.51773955  5.          0.60657578 15.          0.49735822]\t 0.8316281392969092\t 0.7141038418197827\t 2.0222788925315838\t 2.0222788925315838\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 2.023245414153191\t 2.023245414153191\n",
            "12 \t [0.95504342 7.30424524 8.         0.76682007 6.         0.21761275]\t 0.9667342747401506\t 0.7141038418197827\t 2.0252714073801923\t 2.0252714073801923\n",
            "13 \t [0.        0.9070919 5.        0.5       1.        0.1      ]\t 0.973743062796521\t 0.7141038418197827\t 2.045797165214331\t 2.0457971395271923\n",
            "14 \t [ 7.35111323  4.42247898 14.          0.92954426  7.          0.31778445]\t 0.8561431043387969\t 0.7141038418197827\t 2.06352014265129\t 2.06352014265129\n",
            "15 \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]\t 0.8751160002928657\t 0.7141038418197827\t 2.0671722028497443\t 2.0671722028497443\n",
            "16 \t [6.14842106 3.92031042 5.         0.80436272 5.         0.42842685]\t 0.8298337600349435\t 0.7141038418197827\t 2.0725663894477213\t 2.0725663894477213\n",
            "17 \t [ 9.1928307   3.75120063 13.          0.61085648 16.          0.3130605 ]\t 0.8587285155589749\t 0.7141038418197827\t 2.069382903358234\t 2.069382903358234\n",
            "18 \t [ 5.52019288  4.04438509 14.          0.68962025 12.          0.65928036]\t 0.7200967455068522\t 0.7141038418197827\t 2.0737427011983147\t 2.0737427011983147\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]\u001b[0m\t \u001b[1m\u001b[92m0.7137199048529451\u001b[0m\t \u001b[1m\u001b[92m0.7137199048529451\u001b[0m\t \u001b[1m\u001b[92m2.100566790793505\u001b[0m\t \u001b[1m\u001b[92m2.100566790793505\u001b[0m\n",
            "20 \t [ 8.57333797  0.94219501 14.          0.51089969  3.          0.1953435 ]\t 0.9742874478076378\t 0.7137199048529451\t 2.036791715019652\t 2.0367917636452124\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\u001b[0m\t \u001b[1m\u001b[92m0.6678102642866967\u001b[0m\t \u001b[1m\u001b[92m0.6678102642866967\u001b[0m\t \u001b[1m\u001b[92m2.1048120248941538\u001b[0m\t \u001b[1m\u001b[92m2.1048120248941538\u001b[0m\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 5.71105683  9.4586208  15.          1.         10.40318867  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6451990217431166\u001b[0m\t \u001b[1m\u001b[92m0.6451990217431166\u001b[0m\t \u001b[1m\u001b[92m2.0695990127841806\u001b[0m\t \u001b[1m\u001b[92m2.0695990067412517\u001b[0m\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.7660042630046296\t 0.6451990217431166\t 2.0699012882547008\t 2.0699012882547008\n",
            "24 \t [9.30371298 5.41042714 5.         0.80825473 7.         0.72790994]\t 0.775406840278715\t 0.6451990217431166\t 2.013762109142311\t 2.013762109142311\n",
            "25 \t [ 0.26941126  0.          5.24688849  0.5        13.24688849  0.1       ]\t 0.9735784465348413\t 0.6451990217431166\t 2.0351918930782915\t 2.035191298688743\n",
            "26 \t [ 9.68199458  9.34620738 11.          0.57663541 14.          0.24521092]\t 0.9699971507331904\t 0.6451990217431166\t 2.0725617478562075\t 2.0725617478562075\n",
            "27 \t [ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]\t 0.7275389527778259\t 0.6451990217431166\t 2.0758522317485797\t 2.0758522317485797\n",
            "28 \t [ 4.55919043  8.6591134   6.          0.8884863  12.          0.96165246]\t 0.7009533648321409\t 0.6451990217431166\t 2.0429472600918013\t 2.0429472600918013\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.7646380284813412\t 0.6451990217431166\t 2.0608746895556096\t 2.0608746895556096\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.7247998938700702\t 0.6451990217431166\t 2.01254387999883\t 2.01254387999883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48181.78878166302"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d269c16c-22cd-449a-8b32-25b33ea87481"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9953081887469889\t 0.7220763687473127\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.7220763687473127\t 0.7220763687473127\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9889075947558364\t 0.7220763687473127\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7606594495187335\t 0.7220763687473127\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7225304513182221\t 0.7220763687473127\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8181138208820815\t 0.7220763687473127\t 2.0705388230222765\t 2.0705388230222765\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.6527007643358951\u001b[0m\t \u001b[1m\u001b[92m0.6527007643358951\u001b[0m\t \u001b[1m\u001b[92m2.059592043299453\u001b[0m\t \u001b[1m\u001b[92m2.059592043299453\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.7581381331811782\t 0.6527007643358951\t 2.0002723479759528\t 2.0002723479759528\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.995752758561317\t 0.6527007643358951\t 1.9829354991769916\t 1.9829354991769916\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.7153197782842456\t 0.6527007643358951\t 2.0416084787696613\t 2.0416084787696613\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         13.41892122  1.          7.41892122  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6435447991477096\u001b[0m\t \u001b[1m\u001b[92m0.6435447991477096\u001b[0m\t \u001b[1m\u001b[92m2.0118524893972403\u001b[0m\t \u001b[1m\u001b[92m2.0118524893949497\u001b[0m\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 1.0120318552286456\t 0.6435447991477096\t 1.9787124245621197\t 1.9787124245621197\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.745004296865836\t 0.6435447991477096\t 2.02290357466425\t 2.02290357466425\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.7386631133573338\t 0.6435447991477096\t 2.0083647433796616\t 2.0083647433796616\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.664354143494327\t 0.6435447991477096\t 1.994831787439539\t 1.994831787439539\n",
            "11 \t [ 4.88144715  8.15190527  6.          0.64651992 13.          0.17458086]\t 1.0121229762977084\t 0.6435447991477096\t 1.9742630280265718\t 1.9742630280265718\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.7593781021734818\t 0.6435447991477096\t 2.007756974804772\t 2.007756974804772\n",
            "13 \t [1.06249458 8.62681663 5.         0.59952112 1.         0.58280243]\t 0.8175267529902405\t 0.6435447991477096\t 2.0009527329176753\t 2.0009527329176753\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[ 7.80546868  4.310206   15.          1.          9.10759224  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6429167405173205\u001b[0m\t \u001b[1m\u001b[92m0.6429167405173205\u001b[0m\t \u001b[1m\u001b[92m2.000989158721219\u001b[0m\t \u001b[1m\u001b[92m2.00098915836254\u001b[0m\n",
            "15 \t [0.73985165 0.58861565 5.         0.76246476 8.         0.22502929]\t 1.011956540988281\t 0.6429167405173205\t 1.9809453756181352\t 1.9809453756181352\n",
            "16 \t [ 2.74922981  6.93422037  7.          0.64536331 17.          0.3979189 ]\t 0.8622373383763176\t 0.6429167405173205\t 2.0080975338067266\t 2.0080975338067266\n",
            "17 \t [9.98273363 0.40807687 5.         0.58049551 4.         0.30262691]\t 0.9970945517723454\t 0.6429167405173205\t 2.0127277578911875\t 2.0127277578911875\n",
            "18 \t [ 7.49379106  4.28777418 12.          0.51562956  7.          0.83771026]\t 0.6902334466391202\t 0.6429167405173205\t 2.0492593269491963\t 2.0492593269491963\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 1.0088210680321927\t 0.6429167405173205\t 2.067779064560742\t 2.067779064560742\n",
            "20 \t [2.46492428 5.43160937 5.         0.80464169 6.         0.16325382]\t 1.011717078840387\t 0.6429167405173205\t 2.098257425929882\t 2.098257425929882\n",
            "21 \t [ 8.85035918  6.89749862 12.          0.72158349 14.          0.78694849]\t 0.6753851064749854\t 0.6429167405173205\t 2.0618742900581104\t 2.0618742900581104\n",
            "22 \t [ 3.44634229  0.73068286  6.          0.98116529 13.          0.55221155]\t 0.7918727230418927\t 0.6429167405173205\t 2.0560877983811854\t 2.0560877983811854\n",
            "23 \t [ 9.53885612  7.77476011 11.          0.72419664  1.          0.36894154]\t 0.9966950049469988\t 0.6429167405173205\t 2.0641012494666895\t 2.0641012494666895\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.6770117185241518\t 0.6429167405173205\t 2.074042811471332\t 2.074042811471332\n",
            "25 \t [2.22225707 5.57999605 9.         0.88675284 1.         0.65438438]\t 0.7250509902266641\t 0.6429167405173205\t 2.0941407096270974\t 2.0941407096270974\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.8194429585323096\t 0.6429167405173205\t 2.0777956741338777\t 2.0777956741338777\n",
            "27 \t [ 0.26940054  2.6547659   9.          0.74896471 17.          0.58800101]\t 0.7511288137515004\t 0.6429167405173205\t 2.045071601623363\t 2.045071601623363\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 1.003549466667358\t 0.6429167405173205\t 2.0294915841789463\t 2.0294915841789463\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.7575197707232916\t 0.6429167405173205\t 2.040899681335732\t 2.040899681335732\n",
            "30 \t [ 6.37097579  5.69315713 13.          0.83848815 18.          0.96944598]\t 0.6457466715801707\t 0.6429167405173205\t 2.0563708945232184\t 2.0563708945232184\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47957.67102445356"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d43470-d50f-487e-9d07-372ffbc84ca4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m1.9599144337511984\u001b[0m\t \u001b[1m\u001b[92m1.9599144337511984\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 1.9130871911263452\t 1.9130871911263452\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 1.8866328811894146\t 1.8866328811894146\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 1.9734994870247173\t 1.9734994870247173\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 1.9544577503534284\t 1.9544577503534284\n",
            "6  \t [ 1.75894705  6.57560516  5.          0.5        11.74941436  0.1       ]\t 1.0123750187307672\t 0.6773838424850286\t 1.9708848636567784\t 1.97088486353449\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.7065170119936448\t 0.6773838424850286\t 2.022448709505022\t 2.022448709505022\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 8.78531367  5.16236615 10.          0.71284072  9.          0.88546543]\u001b[0m\t \u001b[1m\u001b[92m0.6722375711719282\u001b[0m\t \u001b[1m\u001b[92m0.6722375711719282\u001b[0m\t \u001b[1m\u001b[92m1.999754721460113\u001b[0m\t \u001b[1m\u001b[92m1.999754721460113\u001b[0m\n",
            "9  \t [ 2.19431997  0.03640407  7.          0.62674231 12.          0.80025129]\t 0.6943584427070677\t 0.6722375711719282\t 1.9748334330521755\t 1.9748334330521755\n",
            "10 \t [0.  0.  5.  0.5 1.  0.1]\t 1.012959712728477\t 0.6722375711719282\t 1.9565346135577255\t 1.9565345967885557\n",
            "11 \t [ 8.347612    9.05501181  5.          0.50033019 10.          0.41046448]\t 0.7834119309620006\t 0.6722375711719282\t 1.995829642182066\t 1.995829642182066\n",
            "12 \t [ 6.11039048  8.9398787   9.          0.84431675 14.          0.73928782]\t 0.7102000973560662\t 0.6722375711719282\t 1.9910273384795698\t 1.9910273384795698\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.0149681655113947\t 0.6722375711719282\t 1.976946595570512\t 1.976946595570512\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.7335321473751593\t 0.6722375711719282\t 2.0123650137133198\t 2.0123650137133198\n",
            "15 \t [ 8.99876272  0.14180428 14.          0.5207566  10.          0.28841204]\t 0.8640399232649498\t 0.6722375711719282\t 1.9977923830219457\t 1.9977923830219457\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.7391934581482711\t 0.6722375711719282\t 2.006534762759408\t 2.006534762759408\n",
            "17 \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]\t 0.7280806792663158\t 0.6722375711719282\t 1.9982204766907439\t 1.9982204766907439\n",
            "18 \t [ 7.9679648   6.50875696 12.          0.58580991 13.          0.19954847]\t 1.018322232391354\t 0.6722375711719282\t 2.04708946529502\t 2.04708946529502\n",
            "19 \t [ 2.76696568  4.32638207 10.          0.69065092 10.          0.32928339]\t 0.8606879483167145\t 0.6722375711719282\t 2.005014392350935\t 2.005014392350935\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.6776716071409558\t 0.6722375711719282\t 2.019729375844528\t 2.019729375844528\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.679119846341469\t 0.6722375711719282\t 2.0374378362115193\t 2.0374378362115193\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.7131407042423596\t 0.6722375711719282\t 1.985881991081504\t 1.985881991081504\n",
            "23 \t [1.4132483  7.02689088 5.         0.5        1.         0.1       ]\t 1.0128744897299744\t 0.6722375711719282\t 2.0475233959014623\t 2.047523395223883\n",
            "24 \t [9.2527463  5.48357582 5.         0.70904629 2.         0.53145819]\t 0.7709681184461903\t 0.6722375711719282\t 2.0091205202181506\t 2.0091205202181506\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.7487322203145116\t 0.6722375711719282\t 1.998421417156771\t 1.998421417156771\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.7108432598487722\t 0.6722375711719282\t 2.0150818382295275\t 2.0150818382295275\n",
            "27 \t [ 4.33299944  1.85245224 13.          0.79609381  9.          0.59046368]\t 0.7092377742537539\t 0.6722375711719282\t 1.9690723055093307\t 1.9690723055093307\n",
            "28 \t [ 4.53470807  2.6500816   5.          0.70480421 17.          0.65004423]\t 0.7697998132860621\t 0.6722375711719282\t 1.982823890597432\t 1.982823890597432\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.7131420295812025\t 0.6722375711719282\t 1.9751351396307668\t 1.9751351396307668\n",
            "30 \t [9.30545715 2.21896205 9.         0.96965499 5.         0.61228081]\t 0.7128642744554409\t 0.6722375711719282\t 1.9742925072155397\t 1.9742925072155397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50024.41521167483"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e460919c-9c4e-46b3-ad5e-57443b703ebb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 2.077592441725547\t 2.077592441725547\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 2.0900164286368486\t 2.0900164286368486\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.7502219040814293\t 0.6597299542050263\t 2.1711136462755234\t 2.1711136462755234\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7367139517682284\t 0.6597299542050263\t 2.1322856717525567\t 2.1322856717525567\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8006234291185196\t 0.6597299542050263\t 2.098402154242618\t 2.098402154242618\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.058727127460609\t 0.6597299542050263\t 2.0850807736465464\t 2.0850807736465464\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.703165388931625\t 0.6597299542050263\t 2.137283731886915\t 2.137283731886915\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 9.3078326 10.        15.         1.        20.         1.       ]\u001b[0m\t \u001b[1m\u001b[92m0.6408926751525865\u001b[0m\t \u001b[1m\u001b[92m0.6408926751525865\u001b[0m\t \u001b[1m\u001b[92m2.104909103094345\u001b[0m\t \u001b[1m\u001b[92m2.1049090957543495\u001b[0m\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0651952678837315\t 0.6408926751525865\t 2.069511621359389\t 2.069511621359389\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.8036859734991779\t 0.6408926751525865\t 2.1126700196079407\t 2.1126700196079407\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0624486911635314\t 0.6408926751525865\t 2.103185336035465\t 2.103185336035465\n",
            "12 \t [ 6.27900589  9.12764923  5.          0.84263312 18.          0.79256191]\t 0.730579912896863\t 0.6408926751525865\t 2.137554689934328\t 2.137554689934328\n",
            "13 \t [6.3101326  8.61804899 7.         0.66826014 6.         0.89905701]\t 0.6870759519223828\t 0.6408926751525865\t 2.1190742948308663\t 2.1190742948308663\n",
            "14 \t [ 0.30329279  8.44985963 11.          0.88949602 12.          0.98063814]\t 0.6581410006205839\t 0.6408926751525865\t 2.097169132594667\t 2.097169132594667\n",
            "15 \t [ 3.5266353   3.62825369 14.          0.9501826  16.          0.91321928]\t 0.6526439057061743\t 0.6408926751525865\t 2.07451581889758\t 2.07451581889758\n",
            "16 \t [1.51752921 8.74454394 5.         0.58818521 9.         0.96193229]\t 0.726853528653156\t 0.6408926751525865\t 2.0550407590690205\t 2.0550407590690205\n",
            "17 \t [8.4112622  6.61129193 7.         0.60328014 5.         0.90260887]\t 0.6916923925215309\t 0.6408926751525865\t 2.0448232469521757\t 2.0448232469521757\n",
            "18 \t [ 7.12036371  2.07341345  8.          0.8344432  12.          0.81503216]\t 0.6925988539602622\t 0.6408926751525865\t 2.0273412014980274\t 2.0273412014980274\n",
            "19 \t [4.83067255 2.19904639 7.         0.5680519  3.         0.59514532]\t 0.7720408244337518\t 0.6408926751525865\t 2.0131026850046165\t 2.0131026850046165\n",
            "20 \t [ 5.3866253   1.98558863 14.          0.93996594  6.          0.18524928]\t 1.0595101751758718\t 0.6408926751525865\t 2.023734915766644\t 2.023734915766644\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.8784158308955667\t 0.6408926751525865\t 2.0683809291922715\t 2.0683809291922715\n",
            "22 \t [ 2.50374214  3.96509776 10.          0.87420897  5.          0.98362259]\t 0.661093889506255\t 0.6408926751525865\t 2.0710954656451297\t 2.0710954656451297\n",
            "23 \t [ 5.86852957  9.2552543  14.          0.74343957 14.          0.26209686]\t 0.8830540745289366\t 0.6408926751525865\t 2.0293509987971987\t 2.0293509987971987\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.6902699854328027\t 0.6408926751525865\t 2.0322728301410815\t 2.0322728301410815\n",
            "25 \t [0.         0.5494974  5.         0.5        9.83307728 0.1       ]\t 1.0673951734730103\t 0.6408926751525865\t 2.054031441564745\t 2.0540302681721645\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.7422712401342008\t 0.6408926751525865\t 2.07456788507702\t 2.07456788507702\n",
            "27 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0679096170180373\t 0.6408926751525865\t 2.093119877796744\t 2.093119599760454\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.0600568728235613\t 0.6408926751525865\t 2.0753691980532025\t 2.0753691980532025\n",
            "29 \t [ 0.39565672  8.50724472  5.          0.74462587 17.          0.73375146]\t 0.7368138593297264\t 0.6408926751525865\t 2.110297941362751\t 2.110297941362751\n",
            "30 \t [ 0.89195001  6.01604215 14.          0.84121292  7.          0.44798682]\t 0.8038070345544759\t 0.6408926751525865\t 2.054414989143528\t 2.054414989143528\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49345.03933994111"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a62730f-e5fc-4de1-e2ae-d7759f405280"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1433.5055549144745"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95e84cd-d6b3-4fba-8e0c-b3ac2fd9f291"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50113.58666242189"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6607b31e-b087-4a2c-db3b-5b9f7f4d1b9e"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49294.366953021745"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2024be3-62ed-4bf4-a125-9441a5f75de4"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  48747.895869248736,\n",
              "  48747.895869248736,\n",
              "  48747.895869248736,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4de22ad-74b8-49c4-b451-c0f7770fd151"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([47321.8408099896,\n",
              "  47321.8408099896,\n",
              "  46877.10407555545,\n",
              "  46877.10407555545,\n",
              "  46877.10407555545,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "74194189-7b16-49b8-dfe4-5dec9e6c1500"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Purple', label='RMSE: Approx STP CBM gradients')\n",
        "plt.plot(min_rmse_exact, color = 'Orange', label='RMSE: Exact STP dCBM gradients', ls='--')\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualize!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAETCAYAAAAoF0GbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeViUVfvA8e8MMKAyg2JsAiZqauWC+76bGInlgiu4pGavmtpLllqWuWbuoq9mmrup5ZKZaypZikto5pILuAGyKgiIyDa/P+bHkwgDaMIQ3J/r4nJ4zpxn7hmHueec85xzVHq9Xo8QQghhhNrUAQghhCjeJFEIIYTIkyQKIYQQeZJEIYQQIk+SKIQQQuRJEoUQQog8SaIQQgiRJ0kUolTbv38/NWvWpEmTJkRHRwOQkZFB7969qVmzJjNnzgQgKiqKzz77jA4dOlC7dm2aNm1Kz549+eqrr5Rz+fr6UrNmTWrWrEmtWrVo1qwZb7/9NhcuXCiy55P1+GFhYUX2mKLkk0QhSjUPDw+6dOnC/fv3+eyzzwBYs2YN586do3Llyrz//vvcuHGDN998k82bN/Pw4UM8PDxo164dGRkZrF69Osc5GzdujI+PD5UqVeLYsWOMHTu2qJ+WEM+VuakDEMLUPvvsM06dOsXhw4dZsmQJX3/9NSqVihkzZlCmTBlmzJhBXFwcbm5ubN68mfLlyyt1r1y5kuN8nTp1YvDgwVy5coVu3boRFhZGamoqGo2G5ORk/P39OXjwIHfv3qVy5coMGTKEt956CwC9Xs/WrVvZsGEDoaGh2NnZ4enpyciRI7G0tOT+/ftMnjyZkydPkpycjJ2dHa1atWLq1KnUrFlTiaFjx44ArFu3jqZNmxbyKyhKOmlRiFLP1taWyZMnA+Dv709KSgr9+/enSZMmpKSkEBgYCMCgQYOyJQkg24dzlp9//pnp06czadIkANq3b49GowFg4sSJfPPNN5iZmdGlSxdu3brFRx99xO7duwHYtGkTn376KREREbz++utkZGSwfPlyZsyYAcA333zD/v37qVKlCj169KBatWqcPXsWgIEDByox9OjRg4EDB+Lo6Pg8XypRSkmLQggMXVAODg5ERUUB4OPjA8D9+/dJT08HwNnZGYCjR48yfPhwpe6T39pPnz7N6dOnAVCpVNSvXx+Au3fvsm/fPsDwge/s7EytWrWYOXMmGzZsoGvXrmzcuBGAjz/+mO7du3P58mXefPNNvvvuOz7++GMllrp16+Ll5UW1atWwsrJS6qxbtw6AUaNG4eLiUgivlCiNpEUhBLB69WqioqJQqVQAzJ49GwAbGxvMzQ3fpyIjIwFDwhg4cCAWFha5nmvixIlcuXKFffv2YWNjw/z58zl9+jTh4eEAWFlZKUmnatWqAEpZ1r/VqlXLVp6ZmUlERASDBg2iVatWfPvtt3h7e9O4cWM+/PBDMjMzn+8LIsRjJFGIUu/69essXrwYlUrFokWLsLW1JSAggJ07d2JlZUWzZs0AWL9+PUlJSVSrVo2PP/5Y+SZvjJubG/b29gDcvHlTSQ4pKSncuXMHgBs3bgB/t1ay/r1+/Xq2f9VqNU5OTpQvX55Vq1Zx5swZfvjhB6pXr87u3bs5c+aMcj8wjHUI8bxI15Mo1TIzM5k0aRKPHj1iwIABeHh4kJmZybhx45g1axYtW7Zk0qRJ9O/fn6tXr+Lp6Unz5s1RqVQ8fPgw13P+/PPPhIeHc/PmTa5evYparaZOnTpUrFgRDw8P9u/fz5AhQ2jQoIHSFTVgwADl36lTpzJjxgxOnTrFiRMnAOjVqxeWlpYsWbKEw4cPU6NGDSwsLJQWiLW1NQBOTk6Eh4czdepUqlSpwvvvv0/ZsmUL+2UUJZzZlClTppg6CCFMZe3atXz33Xc4Ozvj7++PRqPhpZde4tq1a1y8eJHbt2/j4+ODp6cnDx484Pbt2/z5559ERERQvXp1BgwYQPv27bG0tGTHjh2Eh4dz584dzp07R2xsLDVq1GDSpEk0b94cgNatW5Oamsq1a9c4f/48rq6ufPDBB8pVT1kJ5caNG/z+++9YW1vTr18//Pz8MDc3JykpiaCgIM6cOcPFixdxcHBg9OjRylVOdnZ2nDt3jkuXLnHu3DkGDx5MmTJlTPb6ipJBJRsXCSGEyIuMUQghhMiTJAohhBB5kkQhhBAiT5IohBBC5EkShRBCiDyVyHkUQUFBpg5BCCH+lRo2bJjjWIlMFJD7kxVCCGGcsS/Z0vUkhBAiT5IohBBC5KlQE0VKSgqdOnVi+/bthISEMGDAAHx8fPjkk0+U5ZJ37dpFz5498fb25rvvvgMgLS0NPz8/+vXrh4+PD6GhoQBcvnyZvn370rdvX2U3MiGEEIWrUBPFsmXLsLGxAWDu3Lm88847bNiwAScnJ/bu3UtycjJLly5lzZo1rF+/nrVr1xIfH8/u3bvR6XR8++23vPvuu8ybNw+AGTNmMGnSJDZv3kxSUhK//PJLYYYvhBCCQkwUISEhBAcH065dOwBu3bpF3bp1AcPCaMeOHePcuXPUqVMHrVaLlZUVDRo04MyZMwQGBvLaa68B0KJFC86cOUNqairh4eHKOdq3b6/sPCaEEKLwFFqimD17NhMmTFB+r1GjhtIC+PXXX4mNjSU2NhZbW1vlPra2tsTExGQ7rlarUalUxMbGotPplPtWrFiRmJiYwgpfCCHE/yuURLFz507c3d1xdXVVjn300Ufs3buXgQMHotfrc91YxdhCtk9z339Kn6n/Zz+yGK8QooQplHkUAQEBhIaGEhAQQGRkJBqNBkdHR7766ivA0KKIjo7G3t6e2NhYpV50dDTu7u7Y29sTExNDrVq1SEtLQ6/XY2dnR3x8vHLfqKgoZfew5+WXqb8Q8FnAPzpHlXZVGLBvAOaWJXaKingOwsLC8PLyonbt2gCkpqZSo0YNpkyZgpmZGR06dKBv37688847Sp3Zs2ezf/9+Dh8+TFpaGtOmTePq1auYmZlhZmbGF198QaVKlfD19SU5OTnbhkW9e/fGy8vLaDxnz56lb9++7Ny5k5dffrnwnngeTp48yaJFi1Cr1Tx48IA333yTwYMH4+fnR3R0NOHh4Zibm+Pg4EC1atUYNmyY8hrq9XpSU1MZPny40m2dJT09nYULF/Lbb79RpkwZLCws+Pjjj6lZsyb+/v78+OOPODg4kJ6ejp2dHbNnz6ZMmTL4+vri5ubG1KlTlXNt2LCBadOmceXKlef+/K9evcq0adNYv349//nPf1i2bNlT1b9z5w6xsbFK9/zzVCifZgsXLlRu+/v74+zszO+//05qairt2rVj+/btvPnmm9SrV49PPvmEhIQEzMzMOHPmDJMmTSIpKYl9+/bRunVrjhw5QtOmTbGwsKBq1ar8/vvvNGrUiAMHDuDr6/tc4671Vq1/VD8lPoUTC06wb9w+ui7r+pyiEiWVm5sb69evV36fMGECP/74I2+99RZ2dnYcOnRISRR6vZ4LFy4o9929ezdqtZrNmzcDsGPHDjZt2sQHH3wAwKxZs6hRo0aBY9m9ezdubm789NNPJksUn376KevWrcPBwYGUlBQGDx6Mp6encjGLv78/FSpUwMfHBzAk28dfw/j4eLp3707r1q2zbVO7cuVKEhIS2LFjByqVijNnzjB69Gj27t0LwMCBA5VzTpw4kUOHDtG1q+Hv96+//iItLU3ZH/3w4cPY2dkV+mvxtEkC4MSJEyQnJ/97EkVuunbtyocffoi/vz+NGjVSBrn9/PwYOnQoKpWKUaNGodVq8fT05Pjx4/Tr1w+NRsMXX3wBwKRJk/j000/JzMykXr16tGjR4rnG6FDXAYe6Dv/oHGpzNcfnHKdyy8rU9Xn+/2Gi5Kpbty63bt0CQKPRUK5cOYKDg6levTpBQUFUq1ZN2fo0ISGBBw8eKHW7d+9eoMfI7ZtqRkYG+/fvZ8GCBXz00UdKspkwYQJly5bl+vXrxMXFMWvWLHQ6HWPHjqVKlSrcvHmTOnXqMGXKFCZMmICFhQXx8fHMnz+fTz/9lNDQUFJTUxkzZgy1a9fG19eXzZs3k5GRQf/+/dm0aVO2ccf4+HiSk5MBsLKyUpJgQZUvXx47OztiYmKydXtv3ryZXbt2oVKpAGjQoAHbtm3D3Dz7x19GRgZxcXE4OPz9GVC3bl2OHTtGu3btiIiIwNzcHI1Gk+Oxjx8/zsyZM3nhhRdwc3PD1taWJk2a8M0335CcnMxHH33EqVOn2L9/P5mZmbRt25bRo0cTGRnJ2LFj0Wg01KxZUzlf06ZNOXnyJMHBwUydOhWVSkW5cuX44osvSEhIYMKECbi6unLlyhVefvll/Pz8WLJkCebm5jg5OZGYmMiGDRuwsLCgVq1a/3g6QaEnivfee0+5/f333+co79KlC126dMl2zMzMjFmzZuW4b/Xq1dm0adPzD/I56jizI+Enw9k9YjeO7o7Y136+3WPi+Tu37hxnvzn7XM9Z/+361BtYr8D3T0tL49ChQ/Tr10855uHhwY8//sj777/Pnj176Ny5M0ePHgWgW7du7NixAw8PD9q2bUvnzp1p1KhRvo+T2zfV48ePU61aNRo3bkz58uU5e/Ys9evXBwzdNmvWrOHw4cMsXbqUiRMncuXKFZYsWYKjoyO9evXi8uXLANjY2DBt2jR27tyJRqNhw4YNREVFMXDgQGWf8BUrVvDo0SNGjBiRLUkAjB07ll69etGkSRNatWpF165dlcvrCyIsLIz4+HicnJyUY4mJiVhaWuZ4rMd/X7duHfv37ycyMpIaNWrQoEEDpczDw4OtW7fSrl079uzZw2uvvUZwcHCOx547dy5ffvklNWvWZMCAAbRs2RIwdCft378fjUbDqVOn2LRpE2q1mo4dOzJ48GDWrVuHp6cngwYNYsWKFTm6tKZNm6bsf75x40Y2btyIl5cXFy9eZMGCBVSsWJE2bdrw0Ucf0b17dypUqEDHjh3x8vJixYoVODk5sW3bNlJSUrK1sp6WzMx+ztTmanpu7olGq2Frr608Snxk6pBEMXXjxg18fX3x9fWlZcuWNG3alE6dOinlHTt25ODBg2RkZHDq1CmaNGmilFWoUIEdO3YwY8YMypYti5+fH4sXL1bKJ06cqJzb19dXmbSam927dytdLV5eXvz0009KWVar3d3dnRs3bgBQpUoVnJycUKlU1KtXj+vXrwMoXR4XLlygadOmADg4OKDRaJRuoQsXLhASEpLreEn//v3Zt28fnTt35vjx47zxxhtER0cX6DX08fHhs88+Y/bs2bm2FPIycOBA1q9fz8GDB3nllVfw9/dXyho1asSff/5JSkoKBw4cUPYmf1J4eDivvPIKZmZmtGnTRjles2ZNpQViZWWFj48PAwcOJC4ujvj4eEJCQpSknPWaPe7PP/9k8uTJ+Pr6smvXLu7evQtA5cqVsbOzQ61WY29vT2JiYrZ6Xbt2ZdSoUaxZs4a2bdv+oyQBJXhRQFPSOmnptaUX6zquY9fQXfTa0ktp9orip97Aek/17f95ebx/fcyYMbi5uWUr1+l0uLi4sGbNGurVq5ftAzA1NRVzc3MaNWpEo0aN8Pb2xtfXlzFjxgAFH6N49OgRhw8f5uLFi2zYsIG0tDQSEhKYNGkSAJmZmcp9s97Djx/T6/XK8ax+/Kzjj8eqVqtJT0/n4cOHZGZmZuv3z5KSkoKdnR3du3ene/fuTJw4kWPHjuXZrfbkOM+TtFot6enpxMbG8sILLyjHL168yCuvvJLj/h4eHkyZMkX5Xa1W07JlSzZu3EiZMmWyXc5vzON/61lJIjw8nDVr1rBjxw7KlSunJGa9Xo9abfi+/vjrmqVMmTKsW7cu2znDwsIwMzPLdr8nr7YcMWIEXl5e7N+/n0GDBrFhwwYqVKiQb+zGSIuikFRpW4WOMzty6btLnFx80tThiGJu/PjxzJ07l4cPH2Y73qVLF1asWEHnzp2zHZ80aRLbtm1Tfo+MjMzWL19Qhw8fplmzZuzevZsffviBPXv2ULVqVU6eNLxns1YTPXv2LNWqVQPg9u3bREdHk5mZyblz56hevXq2c9apU0epHxERgVqtRqfTsXr1ajw9PenUqROrV6/OVufmzZv06NFDGXfJzMwkOjr6mZ7TkwYMGMCsWbOUZYOCgoKYMGECqampOe577ty5HAnb2P/B4+zs7AgJCSEjI4Njx47lKI+Li8PW1pZy5cpx8eJFwsPDSUtLw83NTblIIes1e1ytWrWU7saffvopz0nGKpWK9PR0MjMzWbBgAXZ2dgwZMgR3d3fu3LljtF5BSIuiELUY34LQ46Ec/OAgzo2dcW3xz9/0omRydXXFw8ODZcuW8d///lc53qlTJ+bOnZvjwo2sCzu2b9+ORqPB3Nw82zfhiRMnZrs8tmnTpowePTrHYPbu3bvp1atXtnP36NFD6X7KGk+IiIhgzpw5gOFb/IIFCwgODqZBgwa89NJL2eq/8cYbnDp1Cl9fX9LS0pg6dSrh4eEcOHCAzZs3k5mZibe3N2+88QbOzs6AoTtr+PDhDB48GCsrK9LS0ujQoUOBxl3yM2zYMJYvX0737t2xsbFBq9WybNkyLC0tgb/HKAAsLS1zjI82btwYjUaTZ6IYN24c7733Hi4uLlStWlVpJWR5+eWXKVeuHH379qVhw4b07duXzz//nBkzZjBu3DgOHjyYawvw448/ZvLkyXz99ddYWloyb948kpKSco2hfv36fPTRR0pC6tOnD1qtFldX1398JZtKXwJniAUFBRWb/ShS4lNY0XAF6Y/SGXF2BOXsypk6JCEKZMKECXh4eNC+fXvlWFhYGGPGjGH79u0mjKz4+e2336hSpQouLi58+umnNG7cOM95K8WVsc9O6XoqZFblrfD+3pvk2GS2999OZkbOfkghxL+bXq9n9OjRDBgwgPj4eDw8PEwd0nMlLYoicmbVGX4c9iNtJreh/dT2+VcQQogiJi0KE2swtAHuQ9w5Ou0o1/ZeM3U4QghRYJIoipDnUk8c6jqww2cH8bfi868ghBDFgCSKImRRxoLe23qTmZ7Jd97fkf4o3dQhCSFEviRRFDHb6ra8ueZN7py+w/7/7jd1OEIIkS+ZR2ECL3d/meYfNCdwbiCVW1amTv86pg5JFLHitMz440ttZ6lTpw4ffvjhP3qOSUlJ/PHHH7Rq1Srb8cjISCZPnszDhw9JSUnhpZde4vPPP2fdunX88ssvJCQkEBUVpczPWLVqFV26dMHR0REzMzMePXpEy5YtGTt2rNHH3rBhA3Fxcbz33nvExsYyffp0bt++jVqt5sUXX+Szzz5Dp9Nle60ePnxI27ZtlfXpatasyfz583njjTeU844ZM4a4uLg8Z4M/q6yYO3XqxMGDB5VZ9gV1+vRpqlatSsWKFZ97bJIoTKTTrE6Enwznx+E/4ujuiN0rhb90sSheitMy448vtf28XLx4kWPHjuVIFIsWLaJHjx68/vrrgGF58V9//ZVhw4YxbNgwTp48ycaNG7OtXQXw9ddfU65cOTIzMxkyZIiy5UB+PvzwQ7p3764kypUrV/L5558ry5dnvVYZGRl4enrSp08f7O3tcXV1Zffu3UqiSEpK4vr16/9oKYyCePnll59pgty2bdt4++23JVGUJGpzNb229OKr+l+xtedWhp0ahqXW0tRhCRMy1TLjxty8eZPx48ezZcsWwsLCGDduHFu2bGH9+vU5lstOSEjggw8+ICkpCa1Wy/z585k6dSpJSUlUqVKFPn36KOdNSEjINrv48Y2BCkKtVlOnTh1u3bqVLVEEBgYqS33b2dnh6upKSEgICQkJ2VpTQ4YMISUlJcd5Hzx4gJmZmdISc3JyIioqivv372NjY8OhQ4do1KgRISEhOequWLGCn376CVdXV9LT0xkyZAinTp0iNDSUsLAw1qxZw8SJE4mKiiI5OZn33nuP9u3b5xrz44nywIEDfPPNN5ibm1O7dm0mTJjA9u3bCQoK4t69e9y4cYOhQ4dSqVIlfv75Z65du4a/vz/ffPMNFy5cICMjg379+tGjR4+neo1zvOb/qLb4R7ROWnpt7sXdq3f5cfiPso2qKf3cLufP1f8ZytKTcy+/vsZQnhKbs+wpZS0z/uqrryrHspYZB5RlxrN069aNa9eu4eHhwcyZM/n9998L9DhPsyFOlSpVaNOmDdu2bWPu3Ll8/PHHykJ+mzZtYuvWrWzfvp2kpCRWrVpFq1at2LRpE82bNycwMJChQ4cq39AfN3z4cBYsWEC/fv1YsmSJkhwLKiUlhZMnT1KnTvYu23nz5jFnzhxWr15NXFwcYFhd9slv52ZmZpQr9/cKCVkr7Xbp0oWePXtibW2tlHXo0IEDBw4AsHfv3lyX8YiPj2fjxo1s2bKFKVOmcOrUKaUsLS2NTZs2kZiYSKtWrdiwYQOLFi1SVqjNLeYsDx48YNmyZaxbt44NGzYQERGhrL119epVlixZwtKlS9mwYQMtW7bk5ZdfZtasWZQtW5aAgAA2b97Mpk2blDWu/glpUZhYlXZV6DCjA4cmHsK1pStN38u51LAombKWyAa4cuUKw4YNy7HMeN++fRkzZgynTp1SVnSFv5cZDwoK4rfffsPPz4+ePXsq/dpPrvU0c+bMPBfYe3y9IzB0Rb322muMGDGCvn37UqtWLWUiVtZy2ebm5spy2ZcuXVLGDAYPHgxgdJkPd3d3Dh06xLFjxzh69Ci9evViwYIFObqonjR8+HBl1dTevXvn6FoLDw+nVi3DLpWNGzfm0SPDEv/5LTOe1fWUmprK6NGjefnll5W1tbp06cK0adPo3LkzsbGxVK5cOUf927dvU6NGDaysrLCyssq2w1zWbZ1Ox/nz59myZQtqtVrZ1tlYzADBwcHcuXOHoUOHAoa9NbIW93N3d8fMzAxHR8ccS4yXL1+eKlWq8J///IcuXbrw1ltv5fn8C0ISRTHQ8sOWhB4P5YDfAcpXKU+FqoXbB5oXnYsOK5t/tnb9v1KnAONl5mXzLrd6Ie9yI4rDMuNZjI1RZK1mm7UPgrHlss3MzHJdJjs3KSkplClThk6dOtGpUyfq16/PTz/9lG+iyBqjMObxhfiyWudVq1Zl0aJFOe574cIF5UKCLBqNhrZt2/L7778riaJ69ercu3ePrVu30qFDh1wf9/GlwiH7MuNZLbDdu3dz//59Nm3aRHx8vLIQY24xP163du3arFq1Ktvx7du359hz40krV67k4sWLyqrA33zzTZ73z48kimJApVbx1tq3WNFwBZu7Pd32j8+bQ10H3j33rkljKI3Gjx/PsGHDaNWqFWXKlFGOd+nShdmzZ/Pll19mu/+kSZNo2rQp3t7ewLMvM56fefPm8d5773H06FH27NlD5cqVc10uu3bt2pw4cYK6deuyefNmLC0tlT0oHpeZmYmXlxfLli1TliePjIzExcXlH8fq4ODA9evXcXNz49SpU7i7u1O1alUcHR3ZuHEjAwYMAGD16tVcunRJWQ33cX/++WeOhNW5c2dWrlxpdHdNZ2dnrl27RlpaGomJidkuOsgSFxeHi4sLarWagwcPKkuc5xZzFjc3N0JCQrh79y4VK1Zk8eLFObrxHqdSqcjIyCAsLIzDhw8zcOBAXn311X88PgGSKIqNMhXKMOzEMG7+ctNkMVz49gLX9lzLthmNKBqmWmY8y5NdTzY2NgwfPpw7d+7Qvn173N3d8fX15dtvv811uWx/f38+/PBDfH19KVeuHHPnzuXOnTvMnTsXR0dHpftErVYzb968bLFmrbj6T40bN46xY8dSqVIlHB0dleMLFixg6tSpbN26lbJly1KrVi2mT5+e47VKS0ujZs2a2S6HBUOy3rdvH9WqVSMsLCzH477wwgt07doVb29vqlWrRt26dXNsLNS5c2f+85//8Mcff9CzZ08cHR1ZsmSJ0ZjBsGnRpEmTGD58OBqNhldeeQV7e+NbKzdp0oQxY8bg7+/P2bNn2bNnDxYWFvTs2fOpXsfcyKKAQnFi0Qn2j9vP+JjxlH2hbP4VhBCAoTuoa9eumJub4+XlxapVq3J88P8bGPvslBaFUOicDRvOJ4QnSKIQ4inExsbSu3dvNBoNXl5e/8okkRdJFEKhddYCkBCWgGO9kvVGF6IwvfPOO9lm0Zc0Mo9CKHQuhhZFYnhiPvcUQpQmkiiEwtrRGlSGrichhMgiiUIozCzMsHawlhaFECIbSRQiG62zloQwaVEIIf4miUJko3PRSYtCCJGNJAqRjdZZK2MUQohsJFGIbHTOOlLiUkhLTjN1KEKIYkIShchGmUshrQohxP+TRCGykbkUQognSaIQ2Ty+jIcQQoAkCvGErK4naVEIIbJIohDZWGot0Wg10qIQQigkUYgcdM46EsOkRSGEMJBEIXLQueikRSGEUEiiEDlonbUyRiGEUBT6fhQpKSl07dqVkSNH4urqyvz58zE3N6ds2bJ8+eWXJCYm4uXlpWx0XqFCBRYvXkxiYiJ+fn4kJiZStmxZ5s2bR/ny5Tl+/Djz58/HzMyMNm3aMGrUqMJ+CqWO1llLYkQimRmZqM3ku4QQpV2hfwosW7YMGxsbAGbNmsWMGTNYv3499evXZ8uWLYBhE/H169ezfv16Fi9eDMDatWtp0qQJ3377LZ07d+brr78GYPr06fj7+/Ptt99y7NgxgoODC/splDo6Zx36DD0Poh6YOhQhRDFQqIkiJCSE4OBg2rVrBxhaC/Hx8QDcv3+fChUqGK0bGBjIa6+9BkD79u0JDAwkNDQUGxsbnJycUKvVtG3blsDAwMJ8CqVS1qQ7GacQQkAhJ4rZs2czYcIE5fdJkyYxatQoPDw8CAoKonv37oBhv9kxY8bQt29fdu3apRyztbUFoGLFikRHRxMTE6McA7C1tSUmJqYwn0KpJHMphBCPy3OMIjQ0lL179xIUFER4eDgAlSpVonHjxnTp0gVXV1ejdXfu3Im7u3u2+0ybNo0lS5bQsGFDZs+ezaZNm+jRowdjx46lW7duJCYm4u3tTbNmzbKdS6/X/5PnKJ6SzM4WQjzOaKIYNWoUR44cITMzEycnJ+zt7dHr9Vy9epWjR4+yYMECOlTGQ1YAACAASURBVHbsiL+/f671AwICCA0NJSAggMjISDQaDQkJCTRs2BCAFi1a8OOPPzJw4EB69uwJGFoItWvX5vr169jb2xMTE4NWqyUqKgp7e3vs7e2JjY1VHiPruHi+ytmXQ22ulg2MhBBAHokiOjqazz//nA4dOlCxYsVsZXfv3uXw4cNs3brV6IkXLlyo3Pb398fZ2ZnVq1cTHBxM9erVOX/+PC+++CInTpzgyJEjTJw4keTkZC5fvoybmxstW7Zk3759jBw5kgMHDtC6dWtcXFxISkoiLCwMR0dHjhw5wty5c5/DyyAep1Kr0FaSS2SFEAYqfRH062QliipVqvDll19iYWGBjY0NM2fOpGzZsnzyySfcuHGDjIwM+vXrR8+ePXnw4AHjx48nPj4enU7HnDlz0Gq1nD59WkkOnTt3ZujQoTkeLygoSGm5iGezqsUqLMpYMPDQQFOHIoQoIsY+O/NMFLdu3UKtVuPq6sqNGzfYunUrlpaWDBw4MNugcnEjieKf+877O6LORzH68mhThyKEKCLGPjvzHMweNGgQffr0YcSIEbz99tvKFUbnz59n1apVhROpKBa0zlqu7b2GXq9HpVKZOhwhhAkZTRS//PILkZGRqFQqtm3bRkREBKNHjyY2NpadO3dy+vRpABo3blxkwYqio3PRkfYgjUcJj7CysTJ1OEIIEzKaKM6cOYNKpeKvv/7i3r17qFQqMjIyiImJIT09nZMnTwKSKEqqx+dSSKIQonQzOuHu/fffx9HRkbNnz3L58mVeeeUVxo4dyyuvvIKTkxOjR49m9Gjpvy6pZC6FECJLnjOz58+fz0svvUS9evWYMWMGYBjg7tGjR5EEJ0xHZmcLIbLkOZhdv379HIPWX375ZaEGJIoHpUUhk+6EKPVkDWmRK3Mrc8pULCNdT0IISRTCOJ2zTrqehBCSKIRxstOdEAIKkCji4uK4e/cuYNgj4ocffuDRo0eFHpgwPa2zVsYohBD5b4X67rvvUqtWLTw9PRkyZAgqlYqjR48yb968oohPmJDORceD6AdkpGZgpjEzdThCCBPJt0URHBxM7dq1+e2332jQoAHe3t789ttvRRGbMLGsK58SI6T7SYjSLN9EkZmZSVRUFGfOnKFNmzY0aNBAup5KCZlLIYSAAiSKunXrsmTJEs6cOUOLFi24desWzs7ORRGbMDGZnS2EgAKMUSxYsIBdu3ZRpUoV6tatS0REBO7u7kURmzAxnYtMuhNC5NOiyMjIoFu3bpQrV4527doB4OHhQdu2bYsiNmFiVhWsMLcyl64nIUq5PBOFmZkZL730Erdv3y6qeEQxolKpZC6FECL/rqeHDx+ycuVKjh07hr29PWD4AFm2bFmhBydMT+eskzEKIUq5fBPFH3/8AcClS5e4dOkSgOx4VoroXHSEBoaaOgwhhAnlmygOHTpUFHGIYkrrrCXxTqJsiSpEKZZvonB2diY1NZXw8HCZP1EKaZ21ZDzK4OHdh5R9oaypwxFCmEC+ieLnn3/mo48+Ijk5Odvxv/76q9CCEsXH43MpJFEIUTrlO+FuwYIFODo6otfradu2LVqtFk9Pz6KITRQDMpdCCJFvoggNDcXb2xuVSoWvry9jx44lMjKyKGITxYAs4yGEyLfrycrKinLlymFubs4333xDcnIyly9fLorYRDFg7WgNKlnGQ4jSLN9E0bx5c+7fv4+npyc//PADAG+88UahByaKBzMLM6wdrKVFIUQplm+iWLRoEWBYRbZr164AtGrVqnCjEsWKzkW2RBWiNDOaKFavXm20UkhICIMHDy6MeEQxpHXWEhcSZ+owhBAmYjRRzJ49G5VKhV6vz1GmUqkkUZQiWmctt47eMnUYQggTMZooZs6cKTNxBWCYS5ESl0LawzQsyliYOhwhRBEzmih69OhRlHGIYuzxS2Rtq9uaOBohRFEzmigaNGhgtJJKpSIoKKhQAhLFz+OT7iRRCFH6GE0U5cuXL8o4RDEmW6IKUboZTRSHDx8uyjhEMSazs4Uo3fKdR5GWlsby5cs5evQoKpWKNm3aMGLECCwsZFCztLDUWqLRaqRFIUQplW+imDNnDuvWrUOtNiwLdf78eRITE5k4cWKhByeKD52LjsQwaVEIURrluyjg3r176dGjB3/88Qd//PEH3bt3Z8+ePUURmyhGZEtUIUqvfBPFo0ePcHNzQ6PRoNFoqFKlylNtYJSSkkKnTp3Yvn07p0+fpl+/fvj6+jJixAju378PwMqVK+nVqxfe3t788ssvACQmJvLOO+/Qr18/hg4dSnx8PADHjx+nV69e9OnTh6VLlz7LcxbPQOuslTEKIUqpfLueGjVqxMKFCzly5AgqlYpz587Rrl27Aj/AsmXLsLGxAWDWrFnMnTuXqlWrsnz5crZs2cLrr7/Onj172Lx5M0lJSfTv359WrVqxdu1amjRpwrBhw9iyZQtff/0148ePZ/r06axatQoHBwd8fHzw8PCgevXqz/wCiILROmtJjEgkMyMTtVm+3y+EECVIvn/xn376Ke7u7pw5c4agoCDq16/P5MmTC3TykJAQgoODlcRSoUIFpWVw//59KlSowMmTJ2ndujUajQZbW1ucnZ0JDg4mMDCQ1157DYD27dsTGBhIaGgoNjY2ODk5oVaradu2LYGBgc/41MXT0Lno0GfoeRD9wNShCCGKWL4tCkdHRzZu3KhshVq2bMG3w5w9ezaTJ09m586dAEyaNAkfHx90Oh02Njb4+fmxcuVKbG3/nsRla2tLTEwMsbGxyvGKFSsSHR1NTExMjvuGhoYWOB7x7JS5FGEJaJ20Jo5GCFGU8mxRnDx5El9fX+rXr0/Lli0ZMWIEp06dKtCJd+7cibu7O66ursqxadOmsWTJEvbv30/Dhg3ZtGlTjnq5LUKY2zFRtGQuhRCll9EWxalTpxg6dCjp6enKsdOnT/P222+zZs0aGjVqlOeJAwICCA0NJSAggMjISDQaDQkJCTRs2BCAFi1a8OOPP9KsWTNu3Lih1IuKisLe3h57e3tiYmLQarXZjsXGxua4ryh8MjtbiNLLaIviq6++wsLCgrlz53Lq1ClOnjzJ3LlzsbCwYPny5fmeeOHChWzbto2tW7fi7e3NyJEjcXBwIDg4GDDMx3jxxRdp1qwZAQEBpKamEhUVRXR0NNWrV6dly5bs27cPgAMHDtC6dWtcXFxISkoiLCyM9PR0jhw5QsuWLZ/TSyHyUs6+HGpztbQohCiFjLYoLl26xMCBA5Vd7QC6du3KtWvX+O67757pwT7//HM++eQTLCwssLGxYebMmeh0Onr37o2Pjw8qlYopU6agVqvx9fVl/Pjx9O/fH51Ox5w5cwCYMmUKfn5+AHh6euLm5vZMsYino1Kr0FbSkhAmLQohShujiSIxMZEaNWrkOP7SSy+RkPB0Hxbvvfeecnvz5s05yn19ffH19c12rFy5cvzvf//Lcd/GjRuzZcuWp3p88XzIXAohSiejiSI9PZ1JkybluBQ2IyODjIyMQg9MFD86Zx1R56NMHYYQoogZTRSVKlUqyjjEv4DWRcu1vdfQ6/Wy+6EQpYgsMy4KTOesI+1BGo8SHmFlY2XqcIQQRUTWYhAFJnMphCidJFGIApO5FEKUTpIoRIFJi0KI0kkShSgwaVEIUToZTRS7d+9m/fr1AERERNCnTx/q169P3759ldnVonQxtzKnTMUyMulOiFLGaKL43//+p6zMunDhQs6dO4eFhQUXLlxg6tSpRRagKF50zjrpehKilDGaKCIiIqhVqxZgWODP0tKSgwcPMm7cOC5evFhkAYriRWZnC1H6GE0UFhYW3Lp1i8DAQO7fv4+7uzs2NjZYW1vLZKtSTOcie2cLUdoYTRTNmzfnq6++4u2330alUimLA549e5bKlSsXWYCieNE6a3kQ9YCMVFnGRYjSwujM7GnTpuHo6MiNGzdo1KgR3t7epKWlkZqaSr9+/YoyRlGMZF35lBiRSPkXy5s4GiFEUTCaKHQ6HRMnTsx2zMLCggULFhR6UKL4enwuhSQKIUoHo4niySShVquxt7enbdu2uLu7F3pgonjSuchcCiFKG6OJYseOHbkeX758OdOnT6dnz56FFpQovpRJdzKXQohSw2ii+P7777P9rtfriYqKYs6cOaxcuVISRSllVcEKcytzuURWiFLEaKKoXbt2jmN16tTh/PnzrF27tlCDEsWXSqWSuRRClDJGE0Vuk+piYmLYv38/Tk5OhRqUKN5kLoUQpYvRRNGzZ89cJ9bp9XqmTZtWqEGJ4k3nrCPsRJipwxBCFBGjieKtt97KlihUKhV2dna0bt2aRo0aFUlwonjSOmtJCE+QLVGFKCWMJoovvviiKOMQ/yJaZy0ZjzJ4ePchZV8oa+pwhBCFzOgSHvPmzVNWj81NaGgo8+bNK5SgRPEmcymEKF3ynEexcuVKqlWrRp06dbC3t0ev1xMdHc2FCxcICQnBzs4OPz+/ooxXFAPKMh7hiTjWczRxNEKIwmY0URw+fJgffviBn376iX379vHw4UMArKyscHd3Z8iQIXh5eRVZoKL4yFrGQybdCVE6GE0UGo0Gb29vvL29yczMJC4uDoAKFSqgVssOqqWZtaM1qKTrSYjSwmiieJxaraZixYqFHYv4lzCzMMPawVom3QlRSkjTQDwTnYtsiSpEaSGJQjwTrbNWxiiEKCUkUYhnkjXpTghR8hlNFKNHj+bMmTOkpKSwZMkSwsIMSzb89ttvdO/evcgCFMWTzllHSlwKaQ/TTB2KEKKQGU0UP//8M5GRkTx8+JClS5cqk+8SEhK4fPlykQUoiqesSXcyTiFEyVegrie9Xl/YcYh/GZlLIUTpkeflsb/88gs3b94EYN++fVy+fJlLly4VRVyimFN2upNxCiFKvDwTxQ8//KDc3rJli3JbVgwVWS0K6XoSouQzmihmzZpVlHGIfxlLrSWWOktpUQhRChhNFHJlk8iPbIkqROlgNFHs3r2buLg4fH19iYiIYNy4cVy9epWaNWsyffp0qlevXqAHSElJoWvXrowcOZKAgABlzaj4+Hjc3d0ZMWIEXl5eyh7dFSpUYPHixSQmJuLn50diYiJly5Zl3rx5lC9fnuPHjzN//nzMzMxo06YNo0aNeg4vg3gWOmedDGYLUQoYverpf//7n3JJ7MKFCzl37hwWFhZcuHCBqVOnFvgBli1bho2NDQCLFy9m/fr1rF+/ntq1a+Pt7Q2Am5ubcnzx4sUArF27liZNmvDtt9/SuXNnvv76awCmT5+Ov78/3377LceOHSM4OPjZnrn4x6RFIUTpYDRRREREUKtWLQACAgKwtLTk4MGDjBs3josXLxbo5CEhIQQHB9OuXbtsx69fv05iYiJ169Y1WjcwMJDXXnsNgPbt2xMYGEhoaCg2NjY4OTmhVqtp27YtgYGBBYpFPH86Fx2JEYlkZmSaOhQhRCEymigsLCy4desWgYGB3L9/H3d3d2xsbLC2ti7wVU+zZ89mwoQJOY6vW7cOHx8f5ffY2FjGjBlD37592bVrl3LM1tYWgIoVKxIdHU1MTIxyDMDW1paYmJiCPVPx3Gmdtegz9DyIfmDqUIQQhcjoGEXz5s356quvWLFiBSqViq5duwJw9uxZKleunO+Jd+7cibu7O66urtmOp6amEhQUxJQpUwAoX748Y8eOpVu3biQmJuLt7U2zZs2y1ZEJf8WTMpciLAGtk9bE0QghCovRRDFt2jQcHR25ceMGjRo1wtvbm7S0NFJTU+nbt2++Jw4ICCA0NJSAgAAiIyPRaDQ4Ojqi1+uzdTlZW1vTs2dPwNBCqF27NtevX8fe3p6YmBi0Wi1RUVHY29tjb29PbGysUjfruDCNbHMpGps4GCFEoTGaKHQ6HRMnTsx2zMLCggULFhToxAsXLlRu+/v74+zsTIsWLVi+fLky9gFw4sQJjhw5wsSJE0lOTuby5cu4ubnRsmVL9u3bx8iRIzlw4ACtW7fGxcWFpKQkwsLCcHR05MiRI8ydO/dpn7N4TrLWe5K5FEKUbEYTxZNJ4nEqlYqZM2c+0wPGxMRk67pq1KgRO3fupE+fPmRkZPDOO+/g4OCAr68v48ePp3///uh0OubMmQPAlClT8PPzA8DT0xM3N7dnikP8c+XsyqG2UMuVT0KUcCq9kQGAWrVqKYPWT95FpVLx119/FX50zygoKIiGDRuaOoxSYeGLC3mx7Yt0XycTNIX4tzP22Wm0RVG2bFmSk5N58cUX6d69Oy1atECtln2ORHYyl0KIks/oJ/+xY8eYOXMmdnZ2LFy4kDFjxvDzzz9jZ2enzKIWQueskzEKIUo4o4miTJky9OjRgw0bNvD5559z7949vvrqK2WegxAAWhdpUQhR0hnteoqMjGTbtm3s2LGD8PBw6tWrR8+ePXnjjTeKMj5RzOmcdaQmpfIo4RGWOktThyOEKARGE0WHDh3Q6/W4uroyduxYqlatChj2zAbo3Llz0UQoirXHd7qze8XOxNEIIQqD0USRmWlYv+f27dssWrRIOa7X64v9VU+i6Dy+050kCiFKJqOJYvTo0UUZh/iXypp0J+MUQpRcz5Qorl69WijBiH8fbaX/73qSK5+EKLHynBixf/9+Vq5cyalTpwC4cuUKo0aNkt3vhMLcypwyFcvIBkZClGBGWxTTp09n48aNypjEoEGD2LhxI2lpabz66qtFGaMo5nTOOul6EqIEM5oo9u7dS7169RgwYAAnT55kzZo1ODs78/HHH9OhQ4eijLFonZsM+rTsxyo2BdfuoM+Ec5Ny1rFrA86ekJECkYfAuXRdQqxzkUQhRElmNFHcu3ePCRMm4OXlRYsWLfj+++/54IMPSnaSALi2FNKTsx+rNsyQKAAuL8xZB5UhUdy/BMf7Q/cIMC9b6KEWF1pnLXeC7pg6DCFEITGaKPR6PatXr+ann34iPT0dlUrF2rVr+eGHH1CpVCxbtqwo4yw6ve4ZL1OpoW+K8fK0REhLgNBt4Ob7/GMrprTOWh5EPSAjNQMzjZmpwxFCPGdGEwXApUuXuHTpkvL7H3/8AVDgrVBLHfs2YF0dQlaWqkSRNZciMSKR8i+WN3E0QojnzWiiOHToUFHGUTKoVFB9GPwxARKugq6GqSMqEo/PpZBEIUTJYzRRODs7F2UcJYfbIDj3MYSsgvqzTR1NkVCW8ZC5FEKUSHl2PYlnUMYRWmwEu5amjqTIKF1PcuWTECWSJIrC8GIfU0dQpKwqWGFuZS6T7oQooWTLusJyZx/8+ZmpoygSKpVK5lIIUYJJoigsMb/BxenwINTUkRQJrbNWxiiEKKEkURSWam8bZnJfX2PqSIqELOMhRMkliaKwWFcFh45w/RtDwijhsloUer3e1KEIIZ4zSRSFqdoweHATog6bOpJCp3XWkvEog4d3H5o6FCHEcyaJojC5vgUVm0F6yf/wzJp0J+MUQpQ8cnlsYTKzAo9AU0dRJB6fS+FYz9HE0QghnidpURSF9IeQcMXUURQqZXa2zKUQosSRRFEUjr4Jv/aEEjzQa+1oDSrpehKiJJJEURQq94b7F+HuSVNHUmjMLMywdrSWS2SFKIEkURSFF/uAeTnD8uMlmMylEKJkksHsomChhcp94NZmaLDA8HsJpHXWEnoslN3v7jZ1KEKUStZO1rT5uA1q8+fbBpBEUVSqDTNMvgv/Car0NXU0haL669UJOxHG5Z2XTR2KEKWStpKWVh+1kkTxr/VCM+gSBBXqmzqSQtNoRCMajWhk6jCEEM+ZJIqiolKBbQNTRyGEEE9NBrOLkl4Pp0fDucmmjkQIIQpMEkVRUqngUTRc+x9kPDJ1NEIIUSCSKIpatWGQeg/Cdpo6EiGEKBBJFEXNsROUe7HEz6kQQpQchT6YnZKSQteuXRk5ciQBAQHExcUBEB8fj7u7O9OmTWPlypXs27cPlUrF6NGjadu2LYmJifj5+ZGYmEjZsmWZN28e5cuX5/jx48yfPx8zMzPatGnDqFGjCvspPF8qNVR9G85/Bkk3wNrN1BEJIUSeCj1RLFu2DBsbGwAWL16sHJ84cSLe3t6EhoayZ88eNm/eTFJSEv3796dVq1asXbuWJk2aMGzYMLZs2cLXX3/N+PHjmT59OqtWrcLBwQEfHx88PDyoXr16YT+N56va25ASDSozU0cihBD5KtSup5CQEIKDg2nXrl2249evXycxMZG6dety8uRJWrdujUajwdbWFmdnZ4KDgwkMDOS1114DoH379gQGBhIaGoqNjQ1OTk6o1Wratm1LYOC/cBnvsi7QeAmUq2zqSIQQIl+Fmihmz57NhAkTchxft24dPj4+AMTGxmJra6uU2draEhMTk+14xYoViY6OJiYmJtf7/ivp9RD9K9w7a+pIhBAiT4WWKHbu3Im7uzuurq7ZjqemphIUFESzZs1yrZfbnsslch/mzDT4rRdcmGbqSIQQIk+FNkYREBBAaGgoAQEBREZGotFocHR0RK/XU7duXeV+9vb23LhxQ/k9KioKe3t77O3tiYmJQavVZjsWGxub477/SmYacBsElxfAw0goI7vCCSGKp0JrUSxcuJBt27axdetWvL29GTlyJC1atOD8+fPUqlVLuV+zZs0ICAggNTWVqKgooqOjqV69Oi1btmTfvn0AHDhwgNatW+Pi4kJSUhJhYWGkp6dz5MgRWrZsWVhPofBVGwr6dLixztSRCCGEUUW+1lNMTAyVK/89iFupUiV69+6Nj48PKpWKKVOmoFar8fX1Zfz48fTv3x+dTsecOXMAmDJlCn5+fgB4enri5vYvvrxUVxPsWkPIKnh5vGHmthBCFDMqfQkcAAgKCqJhw4amDqNgrq+Ds37gcRqsq5g6GiFEKWbss1NWjzW1F/safsw0po5ECCFyJYnC1LIShD4TMtMlYQghih1Z66k4SImBXdVk/SchRLEkiaI4sHwBNOUlUQghiiVJFMWBSmVYfjzuLNw7Y+pohBAiGxmjKC6q9IezH8DZD6HFBsMEvHtnIGJfzvtWfxcsbSH2BEQdzlleYwxYWEP0UYj5LWd5rQ8MYyGRP8PdU9nLLF+AKr5gXub5PC8hxL+eJIriQlPBsPz4tf/BwzuGRHH3FJz7OOd9Xb0NiSL619zLq75tSBSRh+DC1JzlNccCGgjfA1cWZC8zt4aqQwy3b24yLDXi0AHKueY4jRCidJB5FMVNRiqozQ37VmRmgD4j533UFobuqnzL0w1XUz1N+aNYKFvJcPvndhD9i+G29iVDwnDuavgRQpQ4Mo/i3+Lxy2PVZkAee1bkW57Pf29u5VlJAqDjYYi/AFGHIPKwoYWRGvd3ojj/OVRoAPZtQGOT92MJIf61JFEI41RqqFDX8FPrfUMLJDXeUJYSDZe+gIwUwwZMto0MLY7qw8C6KqTEQvSRnOd8oQWUdTYshBjza85yuzZQxgEehMLdEznLHTqAZUXD7oD3fs9Z7tjZkLQSrkH8HznLK70B5mXh/l9w/0LOcuc3Dck67k9IvJKz3LWn4XW5dwaSQp4oVEPlnoabsacg+dYTxRpwedNwO+aYoYvxcWblwNnTcDvqF3gUnb3cwgacOhtuRx4y7L3+OE1FcOxguH1nP6QnZC+3cjAkdYDw3ZDxMHt5GRewa264HboT9GnZy8tVgYqNDbdvfw880RlhXR1s6xtaumHbyUFXC8rXgYxHEL4rZ7lNHbCpBWlJELE3Z3mF+qCtbngPRh7MWW7b2LC6QWl/7xUCSRSi4NTmYPWC4baVPfSK//8B9UOGQfW/5hg+DKyrGt7ov/XOeY7W26Fsd4j7I/fy9gegzGuGP9TcyjsHGv5Yo47AyaE5yz0vGP5Y7+yBM+Nylr95C8wrQ+h2+POTnOW97hn+WG9tgkuzc5b3TTX8sYasMownZXt9LP/+Y726BG6uz15u+cLfieKvuRC2M3t5OTdwvm64fXG64WKDx5Wv+3eiOPcx3D2ZvfyFFn8nirP/hfuXspc7efydKE6PhOTQ7OWuvcDuO8PtE0MgLT57edUhfyeKY/0MC1o+rsYYQ6LQp+X+f/fqJEOiSEvIvbzeLLCZYEiQuZU3WmJIFA9u5V7ebK0hUZT2914hkDEK8fykJRk+PDTlIT3Z8M3rSeVcwUIHaYnw4HYu5S8aBuJT70NyWM5yazfDt7LUOEi+k7NcWw3MrODRXcM3xxzlLxn+GFNiDK2iJ+lqGbr0HkYZxmueZPOKYXwn+Y4hhsepVIZyMMSeev+JcjPDN2YwPPe0xOzlagvQ1TDcTroJ6Q+yl5tZGj4oAZKuQ/oTLQLzMoYkDZAYbPjm/jgLa8PrC5Bw1XChQrZy3d8XLdz/K+f4laa84Rs5QPxFcrC0hTJOhnr3/8ql/AXDN/bMdEjI5RuzlT1Y2RnG6RKv5Swv42R4jIwUSHzyGzWG2OS9948Y++yURCGEEAIw/tkpE+6EEELkSRKFEEKIPEmiEEIIkSdJFEIIIfIkiUIIIUSeJFEIIYTIkyQKIYQQeSqxM7ODgoJMHYIQQpQIJXLCnRBCiOdHup6EEELkSRKFEEKIPEmieMzVq1fp1KkTGzZseKb6X375JX369KFnz54cOHDgqeo+fPiQsWPH4uPjg7e3N0eO5LJMcgGkpKTQqVMntm/PZZnnPJw8eZJmzZrh6+uLr68v06ZNe+rH3rVrF926daNHjx4EBAQ8Vd3vvvtOeWxfX1/q16//VPUfPHjA6NGj8fX1pW/fvvz6ay7LSOchMzOTyZMn07dvX3x9fQkJyWXRuVw8+Z6JiIjA19eX/v37M3bsWFJTU5+qPsC6det49dVXefDgQR41jT/+4MGD8fHxYfDgwcTExDxV/bNnz9KvXz98fX0ZOnQo9+7de6r6WX799Vdq1qz51PFPmDABLy8v5X2Q3/voyfppaWn4+fnRq1cvBg0axP379/Osn9s5xowZsTPUagAADmpJREFUozy+l5cXkydPfqr6p0+fVl7DESNG5BnDk3VDQkIYMGAAPj4+fPLJJ6SnpxutCzk/c572/VdQJXYw+2klJyczbdo0mjdv/kz1T5w4wbVr19iyZQtxcXF0796dzp07F7j+kSNHqF27NsOHDyc8PJy3336b9u3bP3Ucy5Ytw8bm2TYRatKkCYsXL36munFxcSxdupRt27aRnJyMv78/7dq1K3B9b29vvL29ATh16hR79+ayH0EeduzYgZubG35+fkRFRTFo0CD27ctlv3EjDh06RGJiIps3b+b27dvMmDGDr776Ks86ub1nFi9eTP/+/Xn99deZP38+33//Pf379y9w/Z07d3L37l3s7e3zjTm3+gsXLqR37954enqyceNGVq9ezYcffljg+qtXr+bLL7/E1dWVJUuWsHXrVt59990C1wd49OgRK1aswM7O7qnjB/jvf/9boPd+bvW3bt1KhQoVmDdvHlu2bOH333+nY8eOT3WOx/8GJk6cqLwvC1p/1qxZzJ07l6pVq7J8+XK2bNnCO++8U6C6c+fO5Z133qFt27YsXbqUvXv34uXlletj5/aZ07x58wK//56GtCj+n0aj4euvvy7QH2huGjduzKJFiwDQ6XQ8fPiQjIxctik1wtPTk+HDhwOGb4UODg5PHUNISAjBwcFP9QH9vAQGBtK8eXOsra2xt7d/phZJlqVLlzJy5MinqlOhQgXi4w37JyQkJFChQoWnqn/z5k3q1q0LQOXKlblz506+/3+5vWdOnjypfDC1b9+ewMDAp6rfqVMn3n//fVQqVb4x51b/s88+w8PDA8j+mhS0/uLFi3F1dUWv1xMVFYWjo+NT1QdYvnw5/fv3R6PRGKmZd/2Cyq3+kSNH6NatGwB9+vTJM0nkF8P169dJTExU3hcFrf/4637//n2j78Xc6t66dUt5vNatW3Ps2DGjj53bZ87TvP+ehiSK/2dubo7V/7V390FRlXsAx7/Imy0mr8kAIwQmL9bGEprCIM7sDGPhTGBTCglMfzATbRCiEC9KkiS4zOZoyyRgNGnmIJKJ0RS+DQGaJIgm5cswOpOAghAMGVAIe//Yy17xwrKHS/fOpeczwx+7nB/nYefZ8zvnOc/5PXPnTjve3NwcmUwGQEVFBaGhoZibG1mmdBJRUVGkpqaSlZUlOVatVpORkSE5bkxraysJCQlER0cb7aATaWtrY2hoiISEBF577bVpd9Aff/wRFxeXKc9GH7VmzRo6OjoICwsjJiaG9PR0SfHe3t7U19czMjLCzZs3uX37Nr29vUZjJuozg4ODhgOko6Oj0aGfieLnzZtncpsnipfJZJibmzMyMsKhQ4cmPRudLB6gtraWF154ge7ubsNB19T4W7duce3aNV588cVptR/g4MGDxMXFkZKSYnToa6L49vZ2amtriY2NJSUlxWiiNNYG0A8BxsTESI7PysrirbfeYvXq1TQ1NbF27VqTY729vfnuO/069XV1dXR3T7AuxT9NdMyR0v+kEIlihp06dYqKigrefffdacWXlZWxd+9e0tLSkDJz+dixYygUChYuXDit/T755JMkJiayd+9e1Go1W7ZskTy+2dfXR2FhITt37iQzM1NS+8dUVFRM+sUyprKyEldXV06ePMn+/fvZvn27pPhVq1Yhl8vZsGED+/fvx8vLa1rtf9j/aub5yMgI77zzDitWrJjWUGpoaCjffvstXl5elJSUSIrNz88nMzNT8j7HREREkJqayoEDB/Dz86OwsFBSvE6nw9PTk88++4zFixdPOXw4mT///JOmpiZWrFghOTY3N5fCwkKqq6sJDAzk0KFDJsemp6fzzTffEBcXh06nM6kPTXbMmcn+JxLFDKqrq6OoqIh9+/bx+OOPS4ptaWnhzp07APj5+TEyMjLljcSH1dTUcPr0adatW8eRI0f46KOPOHfunMnxzs7OhIeHY2Zmhru7O05OTnR2dpoc7+joSEBAABYWFri7u2NjYyOp/WMaGhok38gGuHjxIiEhIQD4+vrS1dUlaegPICUlhbKyMt577z36+/txdHSU3A6ZTMbQ0BAAnZ2d0x5W+U9kZmbi4eFBYmKi5NiTJ/VrUZuZmRnOiE3V2dnJzZs3SU1NZd26dXR1dU15Rv6ooKAg/Pz8AFAqldy4cUNSvJOTE8uW6ZdrDQkJobW1VVL8mAsXLhgdcjLm+vXrhsV/goODaWmZYH3sSbi4uFBcXMyBAwfw9/fHzc3N6PaPHnP+qv4nEsUM+e233ygoKKC4uBg7OzvJ8Y2NjXzyyScAdHd3MzAwIGmcfffu3XzxxReUl5fz6quvolKpCA4ONjn++PHjlJaWAnDv3j16enok3ScJCQnh/PnzjI6O0tvbK7n9oO/YNjY2U45tT8TDw4PLly8D+uEHGxsbSUN/165dM5wJ19bWsmTJEubMkf71CA4Oprq6GoATJ06wcuVKyX/jP3H8+HEsLS15++23pxWv1Wq5elW/jOnly5fx9PQ0OdbZ2ZlTp05RXl5OeXk5CxYskDyDMCkpidu39Wt5NzQ0sHjxYknxoaGhhhlvP/30k6T2P+zKlSv4+vpOK9bJycmQoK5cuYKHh4fJsR9++KFhptfRo0dRKpWTbjvRMeev6n/iyex/amlpQa1W097ejoWFBc7Ozmi1WpMP+ocPH0ar1Y7rmGq1GldXV5Pih4aG2LJlC3fu3GFoaIjExESjncQYrVaLm5sbL7/8sskx9+/fJzU1lf7+foaHh0lMTGTVqlWS9ltWVkZFRQUAb7755pQ3Eh/V0tLC7t27+fjjjyXFgX56bFZWFj09PTx48IDk5GRJwy6jo6NkZWXR2tqKtbU1Go0GFxeXKdv7aJ/RaDRkZGTwxx9/4OrqSn5+PpaWlibHBwcHc+7cOS5duoRcLkehUEw6a2mi+J6eHqytrQ33OhYtWkROTo7J8WlpaeTl5WFubs7cuXMpKCiY9Mpqqu+MUqnkzJkzkj6/mJgYSkpKeOyxx5DJZOTn50vav0ajYceOHdy7dw+ZTIZarcbJyUlSG7RaLVqtlsDAQMLDwyeNnSw+JSWFgoICLC0tsbW1JS8vj/nz55sUm5qaSm5uLjqdjqVLlxodxpvomLNz5062bt1qUv+TQiQKQRAEwSgx9CQIgiAYJRKFIAiCYJRIFIIgCIJRIlEIgiAIRolEIQiCIBglEoUw67S1teHj4zPuZ+nSpf+1/SuVymk9NDhdRUVFfPrpp+Pe6+7uxt/ff8qngl955RXJdbWEvx9RPVaYtZYsWUJ8fDzAjMwlN8XIyAhbt25leHj4v7I/gOLiYuzt7Xn99dcN7x08eBCdTkdERITR2PXr15Odnc0vv/yCu7v7X9xS4f+VuKIQZi0HBweCgoIMP8nJyTz99NNcv36dS5cu4efnZyi+OHYVkJ+fz/Lly4mKiqKjowPQPzGelJTEsmXLCAkJQaPRGMqDKJVKFAoFOTk5BAYGcuPGDd5//31DccajR4/i4+PDpk2bCA8PJygoiOrqajZv3oxCoUClUhnWHGhubmb9+vUEBASwevVqqqqqgH9dIUVFRREfH89zzz3H5s2b0el0xMbGMjAwQHt7Oz4+Pob9VlVVsXz5cmxsbAD9Q5jBwcHI5XLCwsL46quvAH2FUZ1OJ7msu/D3IhKFMGvV19cbkoRKpWLbtm3Y2tqSnZ1NdnY2zs7O46r0DgwMMDAwQFRUFM3NzeTl5QGQmprK2bNniYuLQ6lUsm/fvnFDOoODg3R1dZGeno6Dg8OEbbl48SLR0dH09vayceNG5s+fT2BgIKdPn6ampoa+vj4SEhLo7+8nISEBNzc30tLSDOU0QF9SY9myZXh6elJVVUVTUxMqlQorKyvs7e3ZtWsX0dHRdHV1cfv2beRyOaAvdV1YWMhTTz1Fbm4uL730EqOjo4C+3ISLiwuNjY0z/vkLs4cYehJmLX9/fzZu3Ajo6/U7ODiQk5NDUlISAKWlpePKes+ZM4fs7GysrKw4duwYP/zwA7///jsXLlxAp9ONq2R69uxZYmNjDa/VarXRQpARERHExsZSUlJCd3c3mZmZVFZWUl9fT1tbGxYWFvT19dHX18euXbsMcefPnycsLMzw/7zxxhuYmZnR0tJCW1sbkZGRWFhYIJPJWLNmDYCh5tVYQTiZTMYTTzzBrVu3aGpq4tlnnx23qNaCBQtob2+f3ocs/C2IRCHMWvb29v9WGPHh+vzGav0/TKfT4evrO26Ni4cTjEwmm7Ja8FitH0tLS+bOnYuVlZWhaOHDVW4jIyPH3Vd4uHro2MqFY3FjVwXG2j22z8rKSqqrq7l69Srbtm2joaEBjUYzbjtBmIxIFMKs1dXVxddff2147efnh0ajYeXKldy/f58dO3YQFBRkqJI7OjpKbm4uDg4O3L17l7CwMGxsbHj++edpbGyksbERZ2dnmpqa8PLymnYZ6okoFArs7Oyoq6tDLpfz4MEDampqUKlUUxaWtLW15ddff+XLL79ELpcbihl2dXUB+oKPBQUFBAQE8Mwzz1BVVWX43dh2Uqu0Cn8vIlEIs9bPP//Mpk2bDK/HykZv376dwcFB1q5dS3Z2tmFxHplMxrx58ygrK0OhUBjuX4xVJP38888ZHh7G29ubyMjIGW2rnZ0dRUVFqNVqPvjgA6ytrVEoFLi5uU15xh8fH8+ePXvIyMggOTkZlUrFwoULDesgWFhY0NHRwZkzZxgaGmLRokWGIbnu7m7u3r07I+sqC7OXqB4rCOhnL/X29tLc3Py/bsqM2LNnD6WlpXz//feGmU8TOXLkCNnZ2Zw4cUJMjxUmJWY9CcIstGHDBszMzKisrDS63eHDh1EqlSJJCEaJKwpBEATBKHFFIQiCIBglEoUgCIJglEgUgiAIglEiUQiCIAhGiUQhCIIgGCUShSAIgmDUPwD+aUuwT4MuhgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967471ef-1ca8-4c98-c909-3958c0c6453d"
      },
      "source": [
        "time_approx, time_exact\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1511.1325137615204, 1433.5055549144745)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64d74e0-928a-43b1-c902-32c3c1a78d1f"
      },
      "source": [
        "min(min_rmse_exact), min(min_rmse_approx)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46832.22443034189, 47116.726055847466)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}