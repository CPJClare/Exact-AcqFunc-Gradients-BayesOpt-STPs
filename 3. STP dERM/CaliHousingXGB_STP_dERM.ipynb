{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21fb4644-455f-47e7-b77f-2147217cdb2c"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Collecting Theano-PyMC\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting pyMC3\n",
            "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
            "\u001b[K     |████████████████████████████████| 872 kB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Collecting semver>=2.13.0\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting deprecat\n",
            "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=05129243c0cb05491c413e934303f9da3cb9de9850ca30c2f9e304cd137725f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529963 sha256=e7fb74cdaefefaeb2dea75668231a022b88c3030dc2e4c7a63911701f01a84bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/af/8c/5dd7553522d74c52a7813806fc7ee1a9caa20a3f7c8fd850d5\n",
            "Successfully built pyGPGO Theano-PyMC\n",
            "Installing collected packages: Theano-PyMC, semver, deprecat, pyMC3, pyGPGO\n",
            "Successfully installed Theano-PyMC-1.1.2 deprecat-2.1.1 pyGPGO-0.5.1 pyMC3-3.11.5 semver-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import t\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "19cd7f03-a82d-4d16-d69a-af237a01e8cd"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd74d162-8769-4c5a-ab82-d13c9472b42e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd74d162-8769-4c5a-ab82-d13c9472b42e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd74d162-8769-4c5a-ab82-d13c9472b42e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd74d162-8769-4c5a-ab82-d13c9472b42e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b16a395-87ee-4f21-e01d-639392aa857f"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "49268ae3-e60a-4b0d-836a-e15e126a3a69"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458cc475-0304-4d49-bb81-c0ab091eab16"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "7990dd7d-2e81-4839-c505-e9a9d162103a"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b5b2af3-0839-44ec-a05d-01b4d404bdcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b5b2af3-0839-44ec-a05d-01b4d404bdcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b5b2af3-0839-44ec-a05d-01b4d404bdcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b5b2af3-0839-44ec-a05d-01b4d404bdcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c2fd5902-c656-462b-abb8-53f9c4176861"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a0cd7a5-22d9-42e7-8a27-2945469b0b48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a0cd7a5-22d9-42e7-8a27-2945469b0b48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a0cd7a5-22d9-42e7-8a27-2945469b0b48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a0cd7a5-22d9-42e7-8a27-2945469b0b48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util = 'ERM'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.1\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08\n",
        "\n",
        "df = 3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "def kronDelta(X, Xstar):                     # Kronecker's Delta method\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "def se(X, Xstar, sigmaf, l, sigman):         # S.E. kernel method\n",
        "    return sigmaf * np.exp(-0.5 * cdist(X, Xstar) ** 2 / l ** 2) + sigman * kronDelta(X, Xstar)\n",
        "\n",
        "def delta(X, Xstar):                         # Distance between training X and test Xstar vectors\n",
        "    return (X - Xstar)\n",
        "   \n",
        "def der_covmat(X, Xstar, sigmaf, l, sigman): # Covariance matrix derivative terms (i.e. exact, first-order)\n",
        "    nx = len(X)\n",
        "    ny = len(Xstar)\n",
        "    return np.round(np.array([(delta(np.atleast_2d(i), np.atleast_2d(j))[0] * se(np.atleast_2d(i), np.atleast_2d(j), sigmaf, l, sigman)[0]).sum() for (i, j) in itertools.product(X, Xstar)]).reshape(nx, ny), 8)\n",
        "\n",
        "class dtStudentProcess(tStudentProcess):    # Via inheritance, also optimises hyperparameters when opt = TRUE\n",
        "    \n",
        "    def AcqGrad(self, Xstar):               # Method returning exact, first-order derivatives of the STP's posterior mean and standard deviation\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = self.covfunc.K(self.X, Xstar).T\n",
        "        dKstar = der_covmat(self.X, Xstar, self.covfunc.sigmaf, self.covfunc.l, self.covfunc.sigman).T\n",
        "        \n",
        "        smd_adj = (self.nu + self.beta1 - 2) / (self.nu + self.n1 - 2)\n",
        "\n",
        "        alpha = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), self.y)\n",
        "        alpha_Kstar = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), Kstar.T)      \n",
        "        \n",
        "        dm = np.dot(dKstar, alpha)\n",
        "        ds = -2 * smd_adj * np.dot(dKstar, alpha_Kstar)\n",
        "        \n",
        "        return dm, ds           \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "class Acquisition_grad(Acquisition):    \n",
        "    def __init__(self, mode, eps=eps, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'ERM': self.ERM\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def ERM(self, tau, mean, std, ds, dm, nu=3.0):\n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - tau) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (gamma * t.cdf(gamma, df=nu) + (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma, df=nu))\n",
        "        df1 = f / (std + self.eps) * dsdx \n",
        "        df2 = (std + self.eps) * (t.cdf(gamma, df=nu) * dmdx + gamma * t.pdf(gamma, df=nu) \\\n",
        "            * (1 - (nu + gamma ** 2)/(nu - 1) + 2/(nu - 1) * dmdx))\n",
        "        df = (df1 + df2)[0]\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append(df)\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "        \n",
        "    def d_eval(self, tau, mean, std, ds, dm, nu=3.0):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, nu=3.0, **self.params)\n",
        "        "
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAK8N5bwfuJ7"
      },
      "source": [
        "## GPGO_multi: \n",
        "\n",
        "class GPGO_multi(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        " \n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "   \n",
        "    def _optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        \n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr        \n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_exact = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_exact = np.empty((n_start,))\n",
        "        opt_exact = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_exact = np.array([res.x for res in opt_exact])\n",
        "        f_best_exact = np.array([np.atleast_1d(res.fun)[0] for res in opt_exact])\n",
        "        f_best_min_exact = min(f_best_exact)\n",
        "\n",
        "        self.x_best_exact = x_best_exact\n",
        "        self.f_best_exact = f_best_exact\n",
        "        self.f_best_min_exact = f_best_min_exact\n",
        "        self.best_exact = x_best_exact[np.argmin(f_best_exact)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_exact)\n",
        "\n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_exact = str(inverse * self.f_best_min_exact)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_exact = BOLD + OKGREEN + max_acqfunc_exact + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc_exact, max_acqfunc))\n",
        "        \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self._optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "class dGPGO(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        "\n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_approx = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_approx = np.empty((n_start,))\n",
        "        opt_approx = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_approx = np.array([res.x for res in opt_approx])\n",
        "        f_best_approx = np.array([np.atleast_1d(res.fun)[0] for res in opt_approx])\n",
        "        f_best_min_approx = min(f_best_approx)\n",
        "\n",
        "        self.x_best_approx = x_best_approx\n",
        "        self.f_best_approx = f_best_approx\n",
        "        self.f_best_min_approx = f_best_min_approx\n",
        "        self.best_approx = x_best_approx[np.argmin(f_best_approx)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_approx)\n",
        "    \n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_approx = str(inverse * self.f_best_min_approx)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_approx = BOLD + OKGREEN + max_acqfunc_approx + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc, max_acqfunc_approx))\n",
        "\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00d1eaf-331c-466f-d71e-79992871c30b"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663857643.018844"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "920ef766-520d-411b-bbba-80b7903167f3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO_multi(surrogate_approx_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 0.48592102208482957\t 0.48592102208482957\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 0.48451724411241526\t 0.48451724411241526\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 0.4999166707794104\t 0.4999166707794104\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8992034514090065\t 0.6536753952667645\t 0.4859024301703329\t 0.4859024301703329\n",
            "5  \t [ 7.66218678  9.79577207 13.          0.6996093  12.          0.27250817]\t 1.0035275335689886\t 0.6536753952667645\t 0.487006940745659\t 0.4870069404015714\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.9004243658767852\t 0.6536753952667645\t 0.49403286224646287\t 0.49403286224646287\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6536753952667645\t 0.49425291140740046\t 0.49425291140740046\n",
            "8  \t [8.51945771 8.4424986  8.         0.90741371 1.         0.49942468]\t 0.8757522803338091\t 0.6536753952667645\t 0.4994725661338488\t 0.4994725661325293\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 1.0632523501795186\t 0.6536753952667645\t 0.4982121558350019\t 0.49821215554869264\n",
            "10 \t [ 5.33531967  8.54366774  8.          0.66341534 14.          0.29734112]\t 0.998213042419686\t 0.6536753952667645\t 0.5050065365143114\t 0.5050065365143114\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6536753952667645\t 0.5081542254024635\t 0.5081542254024635\n",
            "12 \t [0.15776536 8.02750992 5.         0.65248282 3.         0.71659731]\t 0.8032223773845614\t 0.6536753952667645\t 0.5133286935493603\t 0.5133286935493603\n",
            "13 \t [4.13690736 2.14715696 6.         0.52611104 1.         0.96671642]\t 0.7093885008364936\t 0.6536753952667645\t 0.5094594480413741\t 0.5094594480413741\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6536753952667645\t 0.5036020747815992\t 0.5036020747815992\n",
            "15 \t [ 9.20512342  1.60831322 11.          0.87041344  2.          0.50117029]\t 0.8186293003915115\t 0.6536753952667645\t 0.49924525421769317\t 0.49924525421769317\n",
            "16 \t [ 0.28990425  5.36117717 14.          0.57624837 11.          0.76620972]\t 0.684834878460344\t 0.6536753952667645\t 0.49713629535070436\t 0.49713629535070436\n",
            "17 \t [9.89075686 3.1845712  7.         0.97857363 4.         0.9759273 ]\t 0.6801108747587014\t 0.6536753952667645\t 0.4915703415755473\t 0.4915703415755473\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8661734316276007\t 0.6536753952667645\t 0.4855064222700851\t 0.4855064222700851\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 1.0095429457834948\t 0.6536753952667645\t 0.490192080567237\t 0.490192080567237\n",
            "20 \t [ 5.68575652  2.73061603 14.          0.61811388 15.          0.91855302]\t 0.6649510133524581\t 0.6536753952667645\t 0.48947563522171994\t 0.48947563522171994\n",
            "21 \t [ 4.24749509  3.24255224  7.          0.8801903  13.          0.4270878 ]\t 0.8793783048750949\t 0.6536753952667645\t 0.4887356158040615\t 0.4887356158040615\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 1.060877500434967\t 0.6536753952667645\t 0.4944268152370693\t 0.4944268152370693\n",
            "23 \t [ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\t 0.6693366893520581\t 0.6536753952667645\t 0.49629136761212456\t 0.49629136761212456\n",
            "24 \t [ 0.16562572  5.49678748 12.          0.55633977  3.          0.26135543]\t 1.0150736425885374\t 0.6536753952667645\t 0.4900853171672323\t 0.4900853171672323\n",
            "25 \t [ 9.92106016  5.52981723 11.          0.80826141 13.          0.31322593]\t 1.000587889017468\t 0.6536753952667645\t 0.48972868780008033\t 0.48972868780007744\n",
            "26 \t [3.36948929 7.81948595 7.         0.9299977  1.         0.27903469]\t 1.0001699070421377\t 0.6536753952667645\t 0.5019214901580303\t 0.5019214901580303\n",
            "27 \t [ 2.52136808  8.51741902 14.          0.89185963  6.          0.23066693]\t 1.0608073786807473\t 0.6536753952667645\t 0.49373507717927023\t 0.49373507717927023\n",
            "28 \t [0.72761348 1.82196215 5.         0.79281157 6.         0.99771556]\t 0.7301068319230399\t 0.6536753952667645\t 0.4998383191367564\t 0.4998383191367564\n",
            "29 \t [ 7.40845157  8.58336508  5.          0.8318041  19.          0.36434664]\t 1.0097984953249557\t 0.6536753952667645\t 0.5015789332395109\t 0.5015789332395109\n",
            "30 \t [ 1.2654566   9.68568733  5.          0.57664611 17.          0.70355107]\t 0.804917733132231\t 0.6536753952667645\t 0.4934118653224772\t 0.4934118653224772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48973.66312746987"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586faadc-7d2f-445f-fb50-666917f72780"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO_multi(surrogate_approx_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.4145735257624059\u001b[0m\t \u001b[1m\u001b[92m0.4145735257624059\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6807577751383148\t 0.4082936478724333\t 0.4082936478724333\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.7073935536898857\t 0.6807577751383148\t 0.40778991231330813\t 0.40778991231330813\n",
            "4  \t [ 5.03756278  5.01206033 13.          0.59912629 19.          0.46413865]\t 0.7900256550528338\t 0.6807577751383148\t 0.40583333175231867\t 0.40583333175231867\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.7887181971022355\t 0.6807577751383148\t 0.40904622152568754\t 0.40904622152568487\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.4118746660646468\u001b[0m\t \u001b[1m\u001b[92m0.4118746660646468\u001b[0m\n",
            "7  \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]\t 0.8064071783057642\t 0.67907472219801\t 0.40844819895175327\t 0.40844819895175316\n",
            "8  \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]\t 0.872344629033322\t 0.67907472219801\t 0.41158264526782007\t 0.41158264526782007\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.7397571279868462\t 0.67907472219801\t 0.41746089498698635\t 0.41746089498698635\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\u001b[0m\t \u001b[1m\u001b[92m0.6684024492575475\u001b[0m\t \u001b[1m\u001b[92m0.6684024492575475\u001b[0m\t \u001b[1m\u001b[92m0.416782996934471\u001b[0m\t \u001b[1m\u001b[92m0.416782996934471\u001b[0m\n",
            "11 \t [4.59560507 9.66694693 5.         0.8652774  6.         0.90565092]\t 0.7323276592879555\t 0.6684024492575475\t 0.4137314526785484\t 0.4137314526785484\n",
            "12 \t [ 8.76507252  8.76898373 14.          0.51356786  6.          0.73624795]\t 0.6802600475884806\t 0.6684024492575475\t 0.41303727553437436\t 0.4130372753099545\n",
            "13 \t [ 6.62295179  6.77584978 14.          0.65936287 12.          0.50955919]\t 0.7009189105357144\t 0.6684024492575475\t 0.4109499038176583\t 0.41094990369792117\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.7143733066956096\t 0.6684024492575475\t 0.40971127500591425\t 0.40971127500591425\n",
            "15 \t [ 9.80429676  9.59801315  7.          0.61168386 14.          0.66107461]\t 0.6949698710548621\t 0.6684024492575475\t 0.40889713863685934\t 0.40889713863685934\n",
            "16 \t [ 3.79151097  4.0129324  10.          0.78656319  9.          0.57380624]\t 0.6970533395297733\t 0.6684024492575475\t 0.40757235939608\t 0.40757235939608\n",
            "17 \t [ 1.94467794  1.47584396  5.          0.91953126 11.          0.49707889]\t 0.8258856905247922\t 0.6684024492575475\t 0.40671767058548863\t 0.40671767058548863\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.6693925559674401\t 0.6684024492575475\t 0.41251325378637343\t 0.41251325378637343\n",
            "19 \t [ 6.92673077  1.23845568 10.          0.63463476  8.          0.28240746]\t 0.7984787223028406\t 0.6684024492575475\t 0.42097263543411423\t 0.42097263543411423\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.7918243780041875\t 0.6684024492575475\t 0.41853688773131514\t 0.41853688773131514\n",
            "21 \t [7.13284983 1.18470919 5.         0.63977211 3.         0.12223048]\t 0.8717594731267366\t 0.6684024492575475\t 0.416300614495133\t 0.416300614495133\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\u001b[0m\t \u001b[1m\u001b[92m0.664392530003631\u001b[0m\t \u001b[1m\u001b[92m0.664392530003631\u001b[0m\t \u001b[1m\u001b[92m0.41445651003430234\u001b[0m\t \u001b[1m\u001b[92m0.41445651003430234\u001b[0m\n",
            "23 \t [8.76774335 2.47727368 5.         0.77895852 8.         0.95970784]\t 0.7344723614600867\t 0.664392530003631\t 0.4201495863596451\t 0.4201495863596451\n",
            "24 \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]\t 0.7953122343367733\t 0.664392530003631\t 0.4287941118871781\t 0.42879411021991154\n",
            "25 \t [ 9.70148981  3.84860271 14.          0.8648022   1.          0.77351018]\t 0.6761632488275804\t 0.664392530003631\t 0.4205352862147516\t 0.4205352862147516\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.6666799570614775\t 0.664392530003631\t 0.412525059037991\t 0.412525059037991\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.6817048020092698\t 0.664392530003631\t 0.4184655077654576\t 0.4184655077654576\n",
            "28 \t [ 4.9644812   1.12270948  6.          0.71065886 17.          0.26866166]\t 0.816338550997086\t 0.664392530003631\t 0.4212380978177044\t 0.4212380978177044\n",
            "29 \t [ 6.25409576  9.66919464  9.          0.55640442 19.          0.48201317]\t 0.7923994561772171\t 0.664392530003631\t 0.41640554996519197\t 0.41640554996519197\n",
            "30 \t [5.55301534 4.43776121 9.         0.77874612 6.         0.99491253]\t 0.6713718258462102\t 0.664392530003631\t 0.4148348373605365\t 0.4148348373605365\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49678.066272258315"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9904c7c6-1458-4993-d349-607b93942ba4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO_multi(surrogate_approx_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 0.5222485137409463\t 0.5222485137409463\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.46535469  7.06056184  5.          0.53518488 13.          0.98930148]\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.5100202695647403\u001b[0m\t \u001b[1m\u001b[92m0.5100202695647403\u001b[0m\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7347345488605661\t 0.4963890106933756\t 0.4963890106933756\n",
            "4  \t [ 6.69378835  1.1746468   5.          0.75549171 16.          0.73450657]\t 0.7722220514333056\t 0.7347345488605661\t 0.5054110759082608\t 0.5054110759082608\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[8.5662852  7.62282167 7.         0.57679587 9.         0.92751362]\u001b[0m\t \u001b[1m\u001b[92m0.7056354714684\u001b[0m\t \u001b[1m\u001b[92m0.7056354714684\u001b[0m\t \u001b[1m\u001b[92m0.49719051617280285\u001b[0m\t \u001b[1m\u001b[92m0.49719051617280285\u001b[0m\n",
            "6  \t [5.7225441  2.61495097 6.         0.67527106 6.         0.33729846]\t 0.983509408209931\t 0.7056354714684\t 0.48745617658492457\t 0.48745617658492457\n",
            "7  \t [ 6.56033613  1.17774647 12.          0.5376295  15.          0.81305603]\t 0.7061518218591949\t 0.7056354714684\t 0.49268792997537036\t 0.49268792997537036\n",
            "8  \t [3.50549632 8.04483305 8.         0.95341936 1.         0.79512535]\t 0.7104180654574984\t 0.7056354714684\t 0.4849163758758863\t 0.4849163758758863\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[ 8.89682762  0.79017134 14.          0.58366818  8.          0.97456627]\u001b[0m\t \u001b[1m\u001b[92m0.6882258735708705\u001b[0m\t \u001b[1m\u001b[92m0.6882258735708705\u001b[0m\t \u001b[1m\u001b[92m0.47838995133070605\u001b[0m\t \u001b[1m\u001b[92m0.47838995133070605\u001b[0m\n",
            "10 \t [3.28340726 7.81144764 9.         0.96528359 7.         0.1686463 ]\t 1.0208805187492747\t 0.6882258735708705\t 0.47201014343342423\t 0.47201014343342423\n",
            "11 \t [ 3.53262431  2.07514765  7.          0.93520802 15.          0.4184813 ]\t 0.8751855836959452\t 0.6882258735708705\t 0.4785998913424873\t 0.4785998913424873\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.6998375974069359\t 0.6882258735708705\t 0.478851573006493\t 0.478851573006493\n",
            "13 \t [ 3.26032277  7.80574265 14.          0.88329978  3.          0.24845127]\t 1.021317881731207\t 0.6882258735708705\t 0.4739289376229196\t 0.4739289376229196\n",
            "14 \t [ 9.85636221  3.89791593  9.          0.61925349 14.          0.90156475]\t 0.692118262463878\t 0.6882258735708705\t 0.4792654309536639\t 0.4792654309536639\n",
            "15 \t [ 8.58495733  5.09928748 13.          0.89538108  1.          0.67774369]\t 0.7408787247915003\t 0.6882258735708705\t 0.4746101921787451\t 0.47461018626591966\n",
            "16 \t [ 0.06586296  0.99454605  7.          0.96788459 19.          0.29892258]\t 0.9749484468246118\t 0.6882258735708705\t 0.47140502884329044\t 0.47140502543255564\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.6882258735708705\t 0.4750023041644379\t 0.47500230412107786\n",
            "\u001b[1m\u001b[92m18\u001b[0m\t \u001b[1m\u001b[92m[9.83745664 3.68679807 9.         0.98607907 6.         0.93173856]\u001b[0m\t \u001b[1m\u001b[92m0.685538272783727\u001b[0m\t \u001b[1m\u001b[92m0.685538272783727\u001b[0m\t \u001b[1m\u001b[92m0.46754107948419127\u001b[0m\t \u001b[1m\u001b[92m0.46754107948419127\u001b[0m\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8649856112240915\t 0.685538272783727\t 0.4724672679567583\t 0.4724672679567583\n",
            "20 \t [ 3.58262831  2.79375979  9.          0.709183   11.          0.30931145]\t 0.9766713924391162\t 0.685538272783727\t 0.46920443546419555\t 0.46920443546419555\n",
            "21 \t [ 9.83060339  5.43479292  5.          0.93965116 19.          0.81693736]\t 0.7430400763458248\t 0.685538272783727\t 0.47124169366197965\t 0.47124169366197965\n",
            "22 \t [ 2.77110475  0.35980325 10.          0.77088835  9.          0.78161047]\t 0.702308760297458\t 0.685538272783727\t 0.4666115962477745\t 0.4666115962477745\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8752416347792465\t 0.685538272783727\t 0.47734252568420393\t 0.47734252568420393\n",
            "24 \t [1.21670026 0.49349112 6.         0.80878089 1.         0.63341473]\t 0.7604801329888093\t 0.685538272783727\t 0.47409152491337225\t 0.4740915249133485\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7185577429000575\t 0.685538272783727\t 0.4718190899377832\t 0.4718190899377832\n",
            "26 \t [ 5.07665331  4.6343883  14.          0.62511663 16.          0.73650486]\t 0.7300649872465008\t 0.685538272783727\t 0.46684039718329345\t 0.46684039718329345\n",
            "27 \t [ 8.21944232  0.76315735 14.          0.70782001  3.          0.58640207]\t 0.771954843353409\t 0.685538272783727\t 0.462481277212103\t 0.462481277212103\n",
            "28 \t [ 9.01763405  8.9342346  11.          0.78253186 14.          0.5899614 ]\t 0.7571328011102442\t 0.685538272783727\t 0.46509035091386786\t 0.46509035091386786\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.0229660667953924\t 0.685538272783727\t 0.46029665185428126\t 0.46029665185428126\n",
            "30 \t [ 0.56213381  4.41770035 10.          0.6803733   4.          0.67199979]\t 0.7355552741037803\t 0.685538272783727\t 0.4685143300408858\t 0.4685143300408858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48624.2920853472"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de2d1d5-43a9-4bac-ceb8-ede701e00ebd"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO_multi(surrogate_approx_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 0.4306015759774582\t 0.4306015759774582\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 0.9436692731753087\t 0.6641721421409617\t 0.44684890128315974\t 0.44684890128315974\n",
            "3  \t [7.47521879 1.08446649 5.         0.82092246 1.         0.87686231]\t 0.7277791972054833\t 0.6641721421409617\t 0.4580590560201699\t 0.4580590560201699\n",
            "4  \t [ 1.21913591  5.39021078 12.          0.52306788  2.          0.57375676]\t 0.7297298564124828\t 0.6641721421409617\t 0.45134869888265366\t 0.45134869888265366\n",
            "5  \t [ 3.69739657  6.8572859  10.          0.91202097 18.          0.74080664]\t 0.6992744288425523\t 0.6641721421409617\t 0.44616731412304517\t 0.4461673140949871\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6641721421409617\t 0.4404793318506837\t 0.4404793318506837\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.7531044966742895\t 0.6641721421409617\t 0.4480520249932909\t 0.4480520249932909\n",
            "8  \t [ 0.32236964  2.41893129 14.          0.88540422 15.          0.72064562]\t 0.6990250321451492\t 0.6641721421409617\t 0.44540767583548735\t 0.44540767583548735\n",
            "9  \t [ 1.11038107  0.47615514 11.          0.89886404  7.          0.4182336 ]\t 0.7718391756586225\t 0.6641721421409617\t 0.4410809309455812\t 0.4410809309455812\n",
            "10 \t [ 6.832625    9.87635293 14.          0.84450885 19.          0.20389666]\t 0.9426343969692278\t 0.6641721421409617\t 0.43998951533450537\t 0.4399895144100035\n",
            "11 \t [ 9.26888317  0.34770884 13.          0.56989599  5.          0.4978041 ]\t 0.7807352013231845\t 0.6641721421409617\t 0.4457465110283473\t 0.4457465110283473\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.6923205913979871\t 0.6641721421409617\t 0.44480137310701584\t 0.44480137310701584\n",
            "13 \t [ 0.4387066   6.89707822  5.          0.5042882  15.          0.2274319 ]\t 0.940102100969289\t 0.6641721421409617\t 0.44132942592179164\t 0.44132942592179164\n",
            "14 \t [ 3.22282465  1.05364145  6.          0.75774626 12.          0.92739587]\t 0.7076032952079638\t 0.6641721421409617\t 0.44594905106753085\t 0.44594905106752386\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.7682434061303821\t 0.6641721421409617\t 0.44326110346229725\t 0.4432611034536896\n",
            "16 \t [0.18736012 2.87894429 5.         0.99715153 3.         0.38605574]\t 0.8039158782445464\t 0.6641721421409617\t 0.44204789552049595\t 0.44204789552049595\n",
            "17 \t [ 9.32106438  8.94628345 11.          0.69008755 12.          0.43568744]\t 0.7747090147969604\t 0.6641721421409617\t 0.44236413372311467\t 0.44236413372311467\n",
            "18 \t [ 5.7913209   0.66562836 12.          0.88967575 12.          0.45276187]\t 0.7701049123721093\t 0.6641721421409617\t 0.44762270120175884\t 0.44762270120175884\n",
            "19 \t [ 2.28250676  8.57781075 10.          0.71780124 12.          0.3772521 ]\t 0.7733889133490559\t 0.6641721421409617\t 0.44512857131288264\t 0.44512857131288264\n",
            "20 \t [ 9.66721268  1.8443589  13.          0.69291942 15.          0.16614767]\t 0.942153170975135\t 0.6641721421409617\t 0.43969329739887836\t 0.43969329739887836\n",
            "21 \t [3.83586625 6.82676995 9.         0.53079541 5.         0.93774826]\t 0.6805235814013784\t 0.6641721421409617\t 0.4404985067286531\t 0.4404984756399211\n",
            "22 \t [ 2.56416717  0.15610938 12.          0.9617952   2.          0.74332064]\t 0.7056949638714144\t 0.6641721421409617\t 0.4484904536410802\t 0.4484904536410802\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.6641721421409617\t 0.44194825776298474\t 0.44194825776298474\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.724172646323414\t 0.6641721421409617\t 0.4470237688101675\t 0.4470237688101675\n",
            "25 \t [4.21410488 1.53847897 8.         0.72947689 4.         0.95835056]\t 0.6751026509280861\t 0.6641721421409617\t 0.4453814990259689\t 0.4453814990259689\n",
            "26 \t [ 7.01360923  0.03074572 13.          0.56476682  9.          0.19217174]\t 0.9417712124079543\t 0.6641721421409617\t 0.44628738718396976\t 0.44628738718396976\n",
            "27 \t [ 9.5097348   7.3660116   9.          0.93170762 19.          0.34791577]\t 0.8162562136213343\t 0.6641721421409617\t 0.44314527626918615\t 0.44314527626918615\n",
            "28 \t [8.0273803  9.87833752 7.         0.89111617 6.         0.4918673 ]\t 0.7835403275506838\t 0.6641721421409617\t 0.44394411073113177\t 0.44394411073113177\n",
            "29 \t [ 6.25251023  4.76484713  9.          0.6837293  11.          0.18403618]\t 0.9419703047602315\t 0.6641721421409617\t 0.4419000295113494\t 0.4419000295113494\n",
            "30 \t [ 9.17303226  5.74079031 12.          0.94675996 18.          0.70963979]\t 0.6976110469452883\t 0.6641721421409617\t 0.4456085648396777\t 0.4456085648396777\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50692.52474167973"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b817b788-12a9-494e-ff9d-71c6245742b4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO_multi(surrogate_approx_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 0.4695191127095293\t 0.4695191127095293\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 0.47835373607547427\t 0.47835373607547427\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.48321868515709215\u001b[0m\t \u001b[1m\u001b[92m0.48321868515709215\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 0.4779515031151883\t 0.4779515031151883\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.4787077372660694\u001b[0m\t \u001b[1m\u001b[92m0.4787077372660694\u001b[0m\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.92565009216999\t 0.6989575443158274\t 0.47020734975294665\t 0.47020734975294665\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6989575443158274\t 0.47399587662265713\t 0.47399587662265713\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.47203575928901736\u001b[0m\t \u001b[1m\u001b[92m0.47203575928901736\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9277423136052668\t 0.6747588495441635\t 0.4651153130589337\t 0.4651153130589337\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.6796390241442563\t 0.6747588495441635\t 0.4685703623715472\t 0.4685703623715472\n",
            "11 \t [ 9.88162042  4.98501997  7.          0.71514689 11.          0.88825005]\t 0.6938260252917123\t 0.6747588495441635\t 0.4629128172431785\t 0.46291281473637724\n",
            "12 \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]\t 0.7387384974169141\t 0.6747588495441635\t 0.4582968064134916\t 0.4582968064134916\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7130088179210804\t 0.6747588495441635\t 0.45543426652900454\t 0.4554342443282724\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.6833142835714986\t 0.6747588495441635\t 0.45229666772397065\t 0.452296632083688\n",
            "15 \t [ 0.69381482  7.09764326  5.          0.79260103 13.          0.36148114]\t 0.9417860014577227\t 0.6747588495441635\t 0.4503755015001306\t 0.4503755015001306\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8392510578678525\t 0.6747588495441635\t 0.45383041807573177\t 0.45383041807573177\n",
            "17 \t [ 6.56637184  9.40150707  8.          0.97457564 11.          0.85712178]\t 0.6937780374760996\t 0.6747588495441635\t 0.45333461447527207\t 0.45333461447527207\n",
            "18 \t [ 9.73541293  8.42044427 14.          0.53390677 16.          0.10576782]\t 0.9298944113695408\t 0.6747588495441635\t 0.46968054679657095\t 0.46968054679657095\n",
            "19 \t [ 2.91927839  7.3392069   6.          0.85847684 14.          0.50487035]\t 0.7871744338256177\t 0.6747588495441635\t 0.45441988950593026\t 0.45441988950593026\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7616619440927369\t 0.6747588495441635\t 0.46332345565270294\t 0.46332345565270294\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7413460349644984\t 0.6747588495441635\t 0.45857449217276397\t 0.45857449217276397\n",
            "22 \t [ 5.47781498  1.88597438 13.          0.63648698 17.          0.7577705 ]\t 0.6880606886203108\t 0.6747588495441635\t 0.45226792119984494\t 0.45226792119984494\n",
            "23 \t [ 0.14337166  3.83051228 13.          0.67084469 13.          0.27589041]\t 0.9247196191844409\t 0.6747588495441635\t 0.45963421575302266\t 0.45963421575302266\n",
            "24 \t [10.         10.         15.          1.          4.07006887  0.1       ]\t 1.0037277185025977\t 0.6747588495441635\t 0.44776650327276923\t 0.4477666310544542\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.6920167982810115\t 0.6747588495441635\t 0.45531028926258044\t 0.45531028926258044\n",
            "26 \t [ 0.65904826  3.00639193 10.          0.88267232 10.          0.15011078]\t 0.9287520803820832\t 0.6747588495441635\t 0.45325273032324853\t 0.45325273032324853\n",
            "27 \t [ 3.19568236  8.11750563 12.          0.61408734  2.          0.64741824]\t 0.7090525375195045\t 0.6747588495441635\t 0.4529948526251207\t 0.45299469394172387\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7099197558902939\t 0.6747588495441635\t 0.4623127729650588\t 0.4623127729650588\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7312561878518347\t 0.6747588495441635\t 0.4484568342202092\t 0.4484568342202092\n",
            "30 \t [2.95141826 5.73718821 5.         0.67688433 2.         0.54293886]\t 0.8180396312898794\t 0.6747588495441635\t 0.4607506868836601\t 0.4607506868836601\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51363.44782689601"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b7c5a6-4626-4d5c-cf00-f1008452690a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO_multi(surrogate_approx_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 0.4739473024786077\t 0.4739473024786077\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 0.4897084845727703\t 0.4897084845727703\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0228902128409325\t 0.7312157182363477\t 0.5015333119984576\t 0.5015333119984576\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0595990180003476\t 0.7312157182363477\t 0.5097533674663782\t 0.5097533674663782\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.5185517235379828\u001b[0m\t \u001b[1m\u001b[92m0.5185517235379828\u001b[0m\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.9234519385526558\t 0.6939533330723558\t 0.5066007615848027\t 0.5066007615843957\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.0610911324495744\t 0.6939533330723558\t 0.5069378428639899\t 0.5069378428639899\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m0.5139062802956024\u001b[0m\t \u001b[1m\u001b[92m0.5139062802956024\u001b[0m\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0250396556181756\t 0.6895189879978737\t 0.504876866554579\t 0.504876866554579\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m0.5094188568906145\u001b[0m\t \u001b[1m\u001b[92m0.5094188568906145\u001b[0m\n",
            "11 \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]\t 0.7493845671941612\t 0.6832941408312798\t 0.5016633974343949\t 0.5016633974343949\n",
            "12 \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]\t 1.0180101584031926\t 0.6832941408312798\t 0.49656880752818583\t 0.49656880752818583\n",
            "13 \t [10.  10.   5.   0.5  1.   0.1]\t 1.064194646860047\t 0.6832941408312798\t 0.5006799197874583\t 0.5006799197874583\n",
            "14 \t [ 1.35461816  3.68867636  7.          0.97358458 19.          0.99760691]\t 0.7008772370455423\t 0.6832941408312798\t 0.5057330846761269\t 0.5057330846758351\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 0.19887638  4.80873048 13.          0.98258992 19.          0.95584094]\u001b[0m\t \u001b[1m\u001b[92m0.6764580978528367\u001b[0m\t \u001b[1m\u001b[92m0.6764580978528367\u001b[0m\t \u001b[1m\u001b[92m0.5002189941563118\u001b[0m\t \u001b[1m\u001b[92m0.5002189941563118\u001b[0m\n",
            "16 \t [6.55109905 2.29203942 6.         0.7269974  8.         0.87997636]\t 0.7181103319607761\t 0.6764580978528367\t 0.49466880477747793\t 0.49466880477747793\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.9614697348345509\t 0.6764580978528367\t 0.490827777496511\t 0.490827777496511\n",
            "18 \t [ 4.48555971  3.69204095  9.          0.58646272 16.          0.41216867]\t 0.9310926555739572\t 0.6764580978528367\t 0.4905729057630926\t 0.4905729057630926\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6764580978528367\t 0.49125450646479063\t 0.49125450646479063\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9398497506465855\t 0.6764580978528367\t 0.5019532428439561\t 0.5019532428439561\n",
            "21 \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]\t 1.0152545517792837\t 0.6764580978528367\t 0.50800754529298\t 0.50800754529298\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.6833221374902283\t 0.6764580978528367\t 0.4975192919332021\t 0.4975192919332021\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9387634302639226\t 0.6764580978528367\t 0.49853500248474997\t 0.49853500248474997\n",
            "24 \t [0.02966045 1.1870223  6.         0.92997678 6.         0.66621503]\t 0.8113301041670242\t 0.6764580978528367\t 0.49530125818859405\t 0.49530125818859405\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.6893334668436607\t 0.6764580978528367\t 0.5039410457587091\t 0.5039410457587091\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.7458275930604825\t 0.6764580978528367\t 0.48973187665306495\t 0.48973187665306495\n",
            "27 \t [ 3.07145128  8.24536112 10.          0.9499357   1.          0.14212758]\t 1.0601608868750403\t 0.6764580978528367\t 0.49389371076657523\t 0.49389371064851423\n",
            "28 \t [ 3.86031457  2.79254313 11.          0.81134713  7.          0.51906134]\t 0.8247215391269236\t 0.6764580978528367\t 0.49373704054567324\t 0.49373704054567324\n",
            "29 \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]\t 0.7283015120438618\t 0.6764580978528367\t 0.49624744489897044\t 0.49624744489897044\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.786373065109467\t 0.6764580978528367\t 0.48957737782501853\t 0.48957737782501853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47116.726055847466"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc7dec7-742f-46c5-ce7d-c5350a7a0db9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO_multi(surrogate_approx_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [ 9.55468323  6.82913854  8.          0.82455943 12.          0.31160837]\t 0.8416584500129389\t 0.6529031062312245\t 0.3902505825570243\t 0.3902505825570243\n",
            "2  \t [2.83505123 7.40646731 5.         0.9495005  1.         0.64955503]\t 0.7502652164309447\t 0.6529031062312245\t 0.40348521161525486\t 0.4034852116152547\n",
            "3  \t [ 9.16018191  2.71212808 10.          0.9776402  19.          0.41742389]\t 0.7822778484971837\t 0.6529031062312245\t 0.4049519394932865\t 0.4049519394932865\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7458231993222018\t 0.6529031062312245\t 0.40833741939225926\t 0.40833741939225926\n",
            "5  \t [ 6.19812193  5.75755827  5.          0.80922676 17.          0.36934488]\t 0.8870271108470653\t 0.6529031062312245\t 0.4086557911435084\t 0.4086557911435084\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 0.41739162348150755\t 0.41739162348150755\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 0.4136547658435985\t 0.4136547658435985\n",
            "8  \t [ 1.95327375  0.09413692  7.          0.63967551 19.          0.52105045]\t 0.718715865573951\t 0.6529031062312245\t 0.41867332225331105\t 0.41867332225331105\n",
            "9  \t [0.19352615 0.96857518 7.         0.99703217 1.         0.36778699]\t 0.8539978950304207\t 0.6529031062312245\t 0.41699131148305535\t 0.41699131148305535\n",
            "10 \t [ 3.23063104  1.13251329 14.          0.56093148  7.          0.35241226]\t 0.8450769378247118\t 0.6529031062312245\t 0.42106507726264303\t 0.42106507726264303\n",
            "11 \t [9.32031429 7.90309325 6.         0.69040988 5.         0.24485333]\t 0.9942828878488736\t 0.6529031062312245\t 0.4242028367029127\t 0.4242028367027315\n",
            "12 \t [ 8.73271627  9.30388015 13.          0.94065667  9.          0.80274839]\t 0.6799490868442287\t 0.6529031062312245\t 0.43298464663639336\t 0.43298464663639336\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.7792188999132433\t 0.6529031062312245\t 0.4297834864284089\t 0.4297834864284089\n",
            "14 \t [ 2.03397746  9.6248515   8.          0.66158474 19.          0.33227831]\t 0.8437028230621703\t 0.6529031062312245\t 0.42978386316433415\t 0.42978386316433415\n",
            "15 \t [ 0.30180848  0.36339665 10.          0.99951435 11.          0.54137142]\t 0.6900449537968393\t 0.6529031062312245\t 0.43172296051194803\t 0.43172296051194803\n",
            "16 \t [7.5058071  0.77198166 5.         0.94542975 7.         0.89710815]\t 0.7217956619874041\t 0.6529031062312245\t 0.4293623954113066\t 0.4293623954113066\n",
            "17 \t [0.28724107 2.08032021 5.         0.86509086 7.         0.81284053]\t 0.7434519339650589\t 0.6529031062312245\t 0.4282823370359452\t 0.4282823370359452\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.6910349298616485\t 0.6529031062312245\t 0.4271337526442173\t 0.4271337526442173\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 0.9937922112122403\t 0.6529031062312245\t 0.42550390652861647\t 0.42550390652861647\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.8385022169449027\t 0.6529031062312245\t 0.4323880746381819\t 0.4323880746381819\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7015179019308584\t 0.6529031062312245\t 0.4438387555222676\t 0.4438387555222676\n",
            "22 \t [ 3.39029064  2.39709901 13.          0.66131557 19.          0.59343116]\t 0.6960101468974939\t 0.6529031062312245\t 0.430081798276285\t 0.430081798276285\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.8346586316188039\t 0.6529031062312245\t 0.43084228096752203\t 0.43084228096752203\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 8.17909255  8.95640578 13.          0.94174624  1.          0.89014148]\u001b[0m\t \u001b[1m\u001b[92m0.6509486270988182\u001b[0m\t \u001b[1m\u001b[92m0.6509486270988182\u001b[0m\t \u001b[1m\u001b[92m0.4346059551814639\u001b[0m\t \u001b[1m\u001b[92m0.4346059551814639\u001b[0m\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7621762752757402\t 0.6509486270988182\t 0.426087101361631\t 0.426087101361631\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 0.9921424184439918\t 0.6509486270988182\t 0.4299968738144674\t 0.4299968738144674\n",
            "27 \t [ 9.52069962  2.24557222  6.          0.67775909 16.          0.66099186]\t 0.7280725204948648\t 0.6509486270988182\t 0.43926319955858545\t 0.43926319955858545\n",
            "28 \t [8.06744097 9.51402341 9.         0.76286961 4.         0.62039131]\t 0.7008200042517302\t 0.6509486270988182\t 0.43274937487574855\t 0.43274937487574855\n",
            "29 \t [5.13805575 8.46039335 5.         0.82814397 6.         0.39527277]\t 0.833602430515404\t 0.6509486270988182\t 0.4252926998507347\t 0.4252926998507347\n",
            "30 \t [ 0.41344076  0.53197741 10.          0.82623488 16.          0.71102663]\t 0.6865872275156124\t 0.6509486270988182\t 0.44091327759130877\t 0.44091327759130877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50989.0544469606"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1665a4e7-b4b8-4e79-d70a-0c76eded3886"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO_multi(surrogate_approx_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 0.4081058654691961\t 0.4081058654691961\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 0.40396857731543717\t 0.40396857731543717\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 0.41199225472552337\t 0.41199225472552337\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 0.41040141305178446\t 0.41040141305178446\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 0.41590307611908867\t 0.41590307611908867\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 0.4145702917516164\t 0.4145702917516164\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 0.41072878259820683\t 0.41072878259820683\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 0.4154103285836257\t 0.4154103285836257\n",
            "9  \t [ 0.45485069  5.92046568 13.          0.54575641 15.          0.3753516 ]\t 0.8133506998200086\t 0.6653168057229354\t 0.4187217078156283\t 0.41872170737793746\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.6700820921354065\t 0.6653168057229354\t 0.4209128417020487\t 0.4209128417020487\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6653168057229354\t 0.41767969543032674\t 0.41767969543032674\n",
            "12 \t [3.47378168 0.90493309 7.         0.70332668 6.         0.717685  ]\t 0.7108804508392579\t 0.6653168057229354\t 0.4206772061873262\t 0.4206772061873262\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 0.9373386140641772\t 0.6653168057229354\t 0.4190359770479214\t 0.4190359770479214\n",
            "14 \t [ 1.81172472  3.20020334  8.          0.50059125 18.          0.97749106]\t 0.6823725138335324\t 0.6653168057229354\t 0.4250677573127437\t 0.4250677573127437\n",
            "15 \t [3.63587924 9.92644255 5.         0.74785877 1.         0.42737692]\t 0.8438702768074448\t 0.6653168057229354\t 0.4226352877711128\t 0.4226352877711128\n",
            "16 \t [ 9.16315882  7.02859227 13.          0.91683113 12.          0.59454859]\t 0.7079716532380765\t 0.6653168057229354\t 0.4248269659738531\t 0.4248269659738531\n",
            "17 \t [0.26711089 1.47965823 5.         0.94483199 1.         0.67844469]\t 0.7386069861707144\t 0.6653168057229354\t 0.42275175109712476\t 0.42275175109712476\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9301596203801468\t 0.6653168057229354\t 0.4410995173075114\t 0.4410995173075114\n",
            "19 \t [ 4.10272358  0.68972827 14.          0.96902802  1.          0.19814279]\t 0.9303071311772037\t 0.6653168057229354\t 0.42416588401567185\t 0.42416588401567185\n",
            "20 \t [ 0.08104756  1.56379545 13.          0.82067653  9.          0.33988189]\t 0.8284104461966239\t 0.6653168057229354\t 0.4332219709308128\t 0.4332219709308128\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.713587872750312\t 0.6653168057229354\t 0.4276456622886705\t 0.4276456622886705\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.8265101138776348\t 0.6653168057229354\t 0.43504019865729104\t 0.43504019865729104\n",
            "23 \t [ 2.79030091  9.29552584 14.          0.65942887  1.          0.91947706]\t 0.6758970722194303\t 0.6653168057229354\t 0.42923707535415223\t 0.42923707535415223\n",
            "24 \t [8.42786765 8.07477576 9.         0.79361942 4.         0.77129548]\t 0.6787445278324089\t 0.6653168057229354\t 0.43749851861145095\t 0.43749851861145095\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8407613659642559\t 0.6653168057229354\t 0.4240126341295795\t 0.4240126341295795\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9338663333604857\t 0.6653168057229354\t 0.4279754403880675\t 0.4279754403880675\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8100270760776773\t 0.6653168057229354\t 0.42915268188614325\t 0.42915268188614325\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.675192856271044\t 0.6653168057229354\t 0.43741423129439705\t 0.43741423129439705\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.699572467500549\t 0.6653168057229354\t 0.4373818322622247\t 0.4373818322622247\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 0.930914842449664\t 0.6653168057229354\t 0.4336308570557443\t 0.4336308570557443\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51215.275242059324"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b1f798-72ca-4032-e1d9-4337c161fb3d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO_multi(surrogate_approx_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 0.414364935239825\t 0.414364935239825\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 0.44621643652697535\t 0.44621643652697535\n",
            "3  \t [ 8.20707753  5.23681739  9.          0.99500664 19.          0.41686889]\t 0.7862089426832719\t 0.6448358819228919\t 0.4365672696915609\t 0.4365672696915609\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 0.43618002128327243\t 0.43618002128327243\n",
            "5  \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]\t 0.7377720407232845\t 0.6448358819228919\t 0.43311588901177367\t 0.43311588901177367\n",
            "6  \t [ 2.07399013  1.08547559 13.          0.90854674 16.          0.44415088]\t 0.7854445167823974\t 0.6448358819228919\t 0.4305524031931954\t 0.4305524031931954\n",
            "7  \t [6.35203132 8.3324364  9.         0.54516266 6.         0.26778796]\t 0.8384879719057332\t 0.6448358819228919\t 0.4307791878525005\t 0.43077918785105745\n",
            "8  \t [ 0.56883492  2.21937218  6.          0.84490274 16.          0.30898926]\t 0.8417982153735359\t 0.6448358819228919\t 0.43349170106034635\t 0.43349170106034635\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.788150408197674\t 0.6448358819228919\t 0.4359228460405331\t 0.4359228460405331\n",
            "10 \t [ 5.98496312  5.93098165 12.          0.98968567 10.          0.92685569]\t 0.6460649755186514\t 0.6448358819228919\t 0.43582441486750956\t 0.43582441486750956\n",
            "11 \t [2.63920029 2.84662126 8.         0.81372528 9.         0.70958016]\t 0.7107155274108488\t 0.6448358819228919\t 0.430973280243006\t 0.430973280243006\n",
            "12 \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]\t 0.8508904111239197\t 0.6448358819228919\t 0.42840747272327484\t 0.42840747272261437\n",
            "13 \t [ 9.90759058  1.21564186 12.          0.74911905 17.          0.244927  ]\t 1.0470230913477547\t 0.6448358819228919\t 0.431067957826543\t 0.4310679576902994\n",
            "14 \t [ 0.42678797  0.40430921 14.          0.96202194 10.          0.10119674]\t 1.0441321675998059\t 0.6448358819228919\t 0.4404177688326951\t 0.44041776882061356\n",
            "15 \t [ 7.86637663  7.38432154 14.          0.83328102 16.          0.44973567]\t 0.7879963377566217\t 0.6448358819228919\t 0.44858130078443975\t 0.4485812978173526\n",
            "16 \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]\t 0.738886934813979\t 0.6448358819228919\t 0.44762208410458\t 0.44762208410458\n",
            "17 \t [ 7.81834149  9.72965303  8.          0.64259089 17.          0.22077726]\t 1.0465197239444557\t 0.6448358819228919\t 0.4464218150896956\t 0.44642169592163744\n",
            "18 \t [2.32449242 8.80135208 8.         0.99642073 4.         0.14576968]\t 1.0446140483804913\t 0.6448358819228919\t 0.4582887221988024\t 0.4582887221988024\n",
            "19 \t [ 9.51504197  0.48338584  6.          0.77192355 13.          0.39589712]\t 0.8079627199466959\t 0.6448358819228919\t 0.45663276292855615\t 0.45663276292855615\n",
            "20 \t [ 9.4006826   2.14529633  7.          0.801278   16.          0.55170588]\t 0.7578480827583333\t 0.6448358819228919\t 0.45858318144321253\t 0.45858318144321253\n",
            "21 \t [0.93748744 2.66462057 5.         0.77408223 4.         0.19936714]\t 1.0509962346828625\t 0.6448358819228919\t 0.4622500719634297\t 0.4622500719634297\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.7865928825712862\t 0.6448358819228919\t 0.4616325682168611\t 0.4616325682168611\n",
            "23 \t [ 0.79581704  0.44548953 10.          0.5535323   5.          0.9139619 ]\t 0.6649440013666069\t 0.6448358819228919\t 0.4739967456555623\t 0.4739967456249229\n",
            "24 \t [ 2.1444801   6.0467731  14.          0.77412521 12.          0.37466595]\t 0.8356273239382881\t 0.6448358819228919\t 0.4643465057033499\t 0.4643465057033499\n",
            "25 \t [ 8.47674061  5.78052722 12.          0.53190312  3.          0.14993193]\t 1.0494124396464328\t 0.6448358819228919\t 0.4615002537730937\t 0.4615002537730937\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.6950503015339501\t 0.6448358819228919\t 0.4629883108533383\t 0.4629883108533383\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 0.4668447968771351\t 0.4668447968771351\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 0.8375129312365261\t 0.6448358819228919\t 0.4643233527447779\t 0.4643233527447779\n",
            "29 \t [ 7.12320801  5.62079639  5.          0.57720044 19.          0.34391463]\t 0.8518813415581681\t 0.6448358819228919\t 0.4619412038309305\t 0.4619412038309305\n",
            "30 \t [ 6.14078962  2.31372054 11.          0.9240952  13.          0.361681  ]\t 0.8314074749252223\t 0.6448358819228919\t 0.4588495831900904\t 0.45884958270812876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48fd0c5e-3a28-4841-c884-78863ab3bbf8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO_multi(surrogate_approx_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 0.4252219050926418\t 0.4252219050926418\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 0.41701109438766176\t 0.41701109438766176\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 0.8792946548244501\t 0.6669292375133978\t 0.41587239172629975\t 0.41587239172629975\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 0.42509730508636695\t 0.42509730508636695\n",
            "5  \t [ 2.36407072  4.99081503 14.          0.6287111   1.          0.46714602]\t 0.7578758817373941\t 0.6669292375133978\t 0.4209611765717424\t 0.4209611765717424\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 0.8210163484458256\t 0.6669292375133978\t 0.4206500197488401\t 0.4206500197488401\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 9.67314628  9.09427799  9.          0.82851167 16.          0.96267251]\u001b[0m\t \u001b[1m\u001b[92m0.6524258272573389\u001b[0m\t \u001b[1m\u001b[92m0.6524258272573389\u001b[0m\t \u001b[1m\u001b[92m0.4236590412994604\u001b[0m\t \u001b[1m\u001b[92m0.42365904129936416\u001b[0m\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7069523757910561\t 0.6524258272573389\t 0.41870244990931665\t 0.41870244990931665\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.661096368919013\t 0.6524258272573389\t 0.4165481820520892\t 0.4165481820520892\n",
            "10 \t [ 9.68988111  3.14723756  5.          0.57337272 11.          0.12853019]\t 0.8805076498265475\t 0.6524258272573389\t 0.4130456687212841\t 0.4130456687212841\n",
            "11 \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]\t 0.662454600529182\t 0.6524258272573389\t 0.4182619531445539\t 0.418261953113317\n",
            "12 \t [ 2.40528406  7.71427622 14.          0.55203588 14.          0.3470708 ]\t 0.8154596077767258\t 0.6524258272573389\t 0.41514581341288254\t 0.41514581341288254\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.823119322181516\t 0.6524258272573389\t 0.4172621560167953\t 0.41726215554548635\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.8166474442456968\t 0.6524258272573389\t 0.41934225108593254\t 0.41934225107888107\n",
            "15 \t [ 9.86913094  2.54287696 14.          0.86051843  2.          0.74044264]\t 0.6976866250322032\t 0.6524258272573389\t 0.42104907609937703\t 0.42104907609937703\n",
            "16 \t [ 5.4403592   7.13848238  5.          0.81873153 10.          0.54902401]\t 0.7411100451417394\t 0.6524258272573389\t 0.4192382714430232\t 0.4192382714430232\n",
            "17 \t [0.54815519 9.09457687 7.         0.55756737 9.         0.32110491]\t 0.8160888137431301\t 0.6524258272573389\t 0.41892154817960237\t 0.41892154817960237\n",
            "18 \t [ 0.49044348  4.29162711  6.          0.90143847 14.          0.72296472]\t 0.71907697660315\t 0.6524258272573389\t 0.4260745509963043\t 0.4260745509963043\n",
            "19 \t [ 1.75909042  8.50460179 10.          0.61596511  8.          0.92202704]\t 0.6552140243198975\t 0.6524258272573389\t 0.43103420910527995\t 0.43103420910527995\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 0.8804917195016874\t 0.6524258272573389\t 0.4201517697749115\t 0.4201517697749115\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7119792503375972\t 0.6524258272573389\t 0.41995589899775015\t 0.41995589899775015\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 0.8840919924947371\t 0.6524258272573389\t 0.41952533382555696\t 0.41952533382555696\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.6539666670983036\t 0.6524258272573389\t 0.41999828085701\t 0.41999828085701\n",
            "24 \t [ 4.11986688  9.81320751 11.          0.98131964 17.          0.2975892 ]\t 0.81020927033387\t 0.6524258272573389\t 0.4234570817165474\t 0.4234570817165474\n",
            "25 \t [ 5.68455033  8.62564817 12.          0.86245924  3.          0.69313239]\t 0.6938168179254495\t 0.6524258272573389\t 0.42591171964890806\t 0.42591171964890806\n",
            "26 \t [ 9.76455747  9.71578983 14.          0.66293675 18.          0.1137209 ]\t 0.881723986870453\t 0.6524258272573389\t 0.4243348382551485\t 0.4243348382551485\n",
            "27 \t [0.73638155 5.44724197 9.         0.90159859 3.         0.84981348]\t 0.6619468807381774\t 0.6524258272573389\t 0.4216755834308921\t 0.4216755834308921\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 2.59065203  2.5376593  13.          0.84164115 13.          0.91116769]\u001b[0m\t \u001b[1m\u001b[92m0.6465810089582009\u001b[0m\t \u001b[1m\u001b[92m0.6465810089582009\u001b[0m\t \u001b[1m\u001b[92m0.41743529797539025\u001b[0m\t \u001b[1m\u001b[92m0.41743529797539025\u001b[0m\n",
            "29 \t [1.94133797 3.63491074 5.         0.73913035 7.         0.15758514]\t 0.8791449038323839\t 0.6465810089582009\t 0.4216936978467913\t 0.4216936978467913\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.81181886510441\t 0.6465810089582009\t 0.4271074447984931\t 0.4271074447984931\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51154.56984923246"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b1c4b1-6d3d-48e4-ada0-71a7c485a1b2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO_multi(surrogate_approx_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 0.3988356298884882\t 0.3988356298884882\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.39770645005489763\u001b[0m\t \u001b[1m\u001b[92m0.39770645005489763\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 0.3928867207707597\t 0.3928867207707597\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 0.9235319432135773\t 0.6577294425265764\t 0.3966024234200432\t 0.3966024234200432\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.7883201967902798\t 0.6577294425265764\t 0.41063660017783604\t 0.4106366001778257\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.6922630708519245\t 0.6577294425265764\t 0.41327282855155917\t 0.41327282855155917\n",
            "7  \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]\t 0.6892145672079726\t 0.6577294425265764\t 0.41034012971902867\t 0.4103401297187379\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.8743477887688297\t 0.6577294425265764\t 0.4080442456104972\t 0.4080442456104972\n",
            "9  \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]\t 0.6852941374864567\t 0.6577294425265764\t 0.4141247009494583\t 0.41412470093702813\n",
            "10 \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]\t 0.7098807101273504\t 0.6577294425265764\t 0.41171511022927637\t 0.41171511022927637\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.8864529961319944\t 0.6577294425265764\t 0.41037167560669585\t 0.41037167560669585\n",
            "12 \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]\t 0.9231023673501877\t 0.6577294425265764\t 0.41561200475715215\t 0.41561200475715215\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 0.9234149203761113\t 0.6577294425265764\t 0.4217094186010118\t 0.4217094186010118\n",
            "14 \t [ 0.62966465  6.1940162  12.          0.81741232 11.          0.49382371]\t 0.763330830255445\t 0.6577294425265764\t 0.4272052534710648\t 0.4272052534710648\n",
            "15 \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]\t 0.9297173774466645\t 0.6577294425265764\t 0.4268380958077674\t 0.4268380958077674\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7068100593711837\t 0.6577294425265764\t 0.4313894178697127\t 0.4313894178697127\n",
            "17 \t [ 8.04132914  5.28680001  8.          0.60118579 16.          0.65451176]\t 0.7024150837706379\t 0.6577294425265764\t 0.4295684011014716\t 0.4295684011014716\n",
            "18 \t [4.8061792  8.89898429 9.         0.78746867 6.         0.23513634]\t 0.9232996261586969\t 0.6577294425265764\t 0.43045913766157606\t 0.43045913766157606\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 0.9265282654642244\t 0.6577294425265764\t 0.43255846782493335\t 0.43255846782493335\n",
            "20 \t [0.56806539 7.69746805 6.         0.94796222 9.         0.37129588]\t 0.8772298745282174\t 0.6577294425265764\t 0.44104360527316966\t 0.44104360527316966\n",
            "21 \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]\t 0.7250537141107671\t 0.6577294425265764\t 0.44360431972910136\t 0.44360431972910136\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7286740032592812\t 0.6577294425265764\t 0.4398774944024606\t 0.4398774944024606\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7418835369809943\t 0.6577294425265764\t 0.4495493371898177\t 0.4495493371898177\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.8686347965869988\t 0.6577294425265764\t 0.439470581832038\t 0.439470581832038\n",
            "25 \t [8.78648556 8.67236761 7.         0.86300156 3.         0.51532161]\t 0.7380095705776981\t 0.6577294425265764\t 0.43534722843747037\t 0.43534722843747037\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.764405864026175\t 0.6577294425265764\t 0.44629462283169036\t 0.44629462283169036\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7332555811634872\t 0.6577294425265764\t 0.4376070913068284\t 0.4376070913068284\n",
            "28 \t [0.37569294 0.30864512 9.         0.6310655  7.         0.92576756]\t 0.6621924195468778\t 0.6577294425265764\t 0.4341974709717456\t 0.4341974709717456\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.6600116767225708\t 0.6577294425265764\t 0.4307617233844474\t 0.4307617233844474\n",
            "30 \t [4.8041921  4.06620309 5.         0.94317975 9.         0.20395595]\t 0.93061105311828\t 0.6577294425265764\t 0.43822031848595044\t 0.43822031848595044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52451.32960260449"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225c16c7-5f31-4731-f048-d1a61e89c32e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO_multi(surrogate_approx_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 0.43846609351717214\t 0.43846609351717214\n",
            "2  \t [ 3.78385301  2.21923666 12.          0.57141407  8.          0.55842631]\t 0.7285402508953416\t 0.7056203424268611\t 0.4341418056759192\t 0.4341418056759192\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 4.70630658  9.38750646 12.          0.7933865  10.          0.74968408]\u001b[0m\t \u001b[1m\u001b[92m0.6939932582164752\u001b[0m\t \u001b[1m\u001b[92m0.6939932582164752\u001b[0m\t \u001b[1m\u001b[92m0.4296526262539261\u001b[0m\t \u001b[1m\u001b[92m0.4296526262539261\u001b[0m\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.8009366885878899\t 0.6939932582164752\t 0.4240587511594447\t 0.4240587511594447\n",
            "5  \t [ 9.02656498  0.48984226 12.          0.66187047 14.          0.17842177]\t 0.9261950890540188\t 0.6939932582164752\t 0.4260411494713761\t 0.4260411494713761\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.7872412218199303\t 0.6939932582164752\t 0.4352413168378438\t 0.4352413168378438\n",
            "7  \t [ 9.92159613  3.53760601 14.          0.66495754  4.          0.92098158]\t 0.7037336633700015\t 0.6939932582164752\t 0.4351313008514887\t 0.4351313008514887\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.8017323350323444\t 0.6939932582164752\t 0.43139953521167457\t 0.43139953521167457\n",
            "9  \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]\t 0.7213506404912987\t 0.6939932582164752\t 0.4322264100217586\t 0.4322264100217586\n",
            "10 \t [ 2.00580329  2.31031601 14.          0.90401435 16.          0.44341936]\t 0.7698813922221472\t 0.6939932582164752\t 0.4298520573922025\t 0.4298520573922025\n",
            "11 \t [ 2.24226925  8.24518571  5.          0.69075261 11.          0.5179779 ]\t 0.7689331541513587\t 0.6939932582164752\t 0.42949644729379854\t 0.42949644729379854\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.7202487480474815\t 0.6939932582164752\t 0.42914447400644223\t 0.42914447400644223\n",
            "13 \t [ 5.97904546  9.54654633 12.          0.85402391 19.          0.25521119]\t 0.7891186169314436\t 0.6939932582164752\t 0.4273120947383547\t 0.4273120947383547\n",
            "14 \t [ 0.609825    8.87388875 14.          0.9069446   2.          0.82580346]\t 0.6998436682886817\t 0.6939932582164752\t 0.42776076418579284\t 0.42776076418579284\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9310123715662361\t 0.6939932582164752\t 0.4256694802348749\t 0.4256694802348749\n",
            "16 \t [ 9.50979811  3.16002382 14.          0.62948949 10.          0.39138316]\t 0.775390231089039\t 0.6939932582164752\t 0.43047468535467864\t 0.43047468535467864\n",
            "17 \t [ 2.38620183  1.03950496 13.          0.6257051   6.          0.34211692]\t 0.7949227225244432\t 0.6939932582164752\t 0.43036073827240395\t 0.43036073827240395\n",
            "18 \t [3.82043232 0.90149463 5.         0.93713205 2.         0.73959641]\t 0.7410345449107776\t 0.6939932582164752\t 0.43512553063392806\t 0.43512553063392806\n",
            "19 \t [9.51121457 1.16444035 9.         0.81792407 9.         0.70590587]\t 0.6983390620759949\t 0.6939932582164752\t 0.4315541985977182\t 0.4315541985977182\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.6939932582164752\t 0.4270609401436619\t 0.4270609401436619\n",
            "21 \t [ 0.60383814  6.44796032 11.          0.78951032 16.          0.75679881]\t 0.694356779546439\t 0.6939932582164752\t 0.4250661340660145\t 0.4250661340660145\n",
            "22 \t [ 4.22119996  7.99655483  5.          0.78307763 14.          0.79061697]\t 0.7405746569621561\t 0.6939932582164752\t 0.43578446667834625\t 0.43578446667834625\n",
            "23 \t [8.06269287 6.47637245 9.         0.81164321 8.         0.55442999]\t 0.7232813229370987\t 0.6939932582164752\t 0.4306534882281431\t 0.43065348434491546\n",
            "24 \t [ 3.54377146  1.55114788  9.          0.60325108 18.          0.58026864]\t 0.7288271346270945\t 0.6939932582164752\t 0.42215692357368007\t 0.42215692357368007\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9328823718301782\t 0.6939932582164752\t 0.43086722809881683\t 0.43086722809881683\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 1.0206155   0.50876351 11.          0.82996077 17.          0.80891943]\u001b[0m\t \u001b[1m\u001b[92m0.6931022492573785\u001b[0m\t \u001b[1m\u001b[92m0.6931022492573785\u001b[0m\t \u001b[1m\u001b[92m0.44008841114706193\u001b[0m\t \u001b[1m\u001b[92m0.44008841114706193\u001b[0m\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 8.81229045  3.85517324 10.78626807  0.5        20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6697546218287523\u001b[0m\t \u001b[1m\u001b[92m0.6697546218287523\u001b[0m\t \u001b[1m\u001b[92m0.4368908997465738\u001b[0m\t \u001b[1m\u001b[92m0.4368914027218416\u001b[0m\n",
            "28 \t [ 2.58558616  0.56131889 10.          0.88548273 13.          0.80616727]\t 0.6920038292043351\t 0.6697546218287523\t 0.43060911709262983\t 0.4306091170858011\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.7292686946198735\t 0.6697546218287523\t 0.4312512751169939\t 0.4312512751169939\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.9256181718283066\t 0.6697546218287523\t 0.4255601869794572\t 0.4255601869794572\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52552.180279492015"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ada833-19a5-4024-f732-c42c1c6d7a00"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO_multi(surrogate_approx_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 0.5072064891744983\t 0.5072064891744983\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.6734860180774931\t 0.6628876451121497\t 0.4906091691299594\t 0.4906091691299594\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.6628876451121497\t 0.4754030535780008\t 0.4754030535780008\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.6797825903178236\t 0.6628876451121497\t 0.4692323116995156\t 0.4692323116995156\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.0980632271289044\t 0.6628876451121497\t 0.45969722684220765\t 0.45969722684220765\n",
            "6  \t [ 7.68636788  7.27927184 12.          0.97932089  3.          0.87363673]\t 0.6657443951678294\t 0.6628876451121497\t 0.47627546664499215\t 0.47627546664499215\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8250792636501453\t 0.6628876451121497\t 0.46740276730718766\t 0.46740276730718766\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1062273028353988\t 0.6628876451121497\t 0.4663725186250071\t 0.4663725186250071\n",
            "9  \t [ 6.80309585  9.43423094  7.          0.8851539  14.          0.77731456]\t 0.6905350263714448\t 0.6628876451121497\t 0.4789424590153197\t 0.4789424590153197\n",
            "10 \t [ 6.60596124  8.35313787  6.          0.72167152 19.          0.94552853]\t 0.7025896131486131\t 0.6628876451121497\t 0.4726021281119921\t 0.4726021281119921\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7370906275446215\t 0.6628876451121497\t 0.467400624643589\t 0.46740062464358706\n",
            "12 \t [ 9.46545841  2.71414127  5.          0.83512297 13.          0.70984642]\t 0.7596192306405462\t 0.6628876451121497\t 0.46382630806150055\t 0.46382630806150055\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.9801878   7.62207926 11.          0.92097131  8.          0.96474414]\u001b[0m\t \u001b[1m\u001b[92m0.6582649380252287\u001b[0m\t \u001b[1m\u001b[92m0.6582649380252287\u001b[0m\t \u001b[1m\u001b[92m0.46129678769886007\u001b[0m\t \u001b[1m\u001b[92m0.46129678769886007\u001b[0m\n",
            "14 \t [ 6.64335896  4.21317694 13.          0.67704359  4.          0.77970128]\t 0.6746732785820976\t 0.6582649380252287\t 0.45639430204206394\t 0.45639430204206394\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.6582649380252287\t 0.45234610974524175\t 0.45234610974524175\n",
            "16 \t [9.66123717 1.6749164  7.         0.52601834 9.         0.78339475]\t 0.6982122839928836\t 0.6582649380252287\t 0.4485568201651828\t 0.4485568201651828\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.105080285400748\t 0.6582649380252287\t 0.4456171503797145\t 0.4456171503797145\n",
            "18 \t [9.81792293 8.02628625 6.         0.84581675 1.         0.43435016]\t 0.8324792319640995\t 0.6582649380252287\t 0.4525985491266424\t 0.4525985491266424\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.0995998424487943\t 0.6582649380252287\t 0.453633842976206\t 0.453633842976206\n",
            "20 \t [ 2.43733809  3.83718859 13.          0.87000869 16.          0.41452306]\t 0.8189050631597883\t 0.6582649380252287\t 0.46205945385690617\t 0.46205945385690617\n",
            "21 \t [4.36648808 8.42254188 6.         0.54886836 3.         0.62627434]\t 0.7390982861353472\t 0.6582649380252287\t 0.45962452883611715\t 0.45962452883611715\n",
            "22 \t [ 0.18137014  8.57899028  5.          0.96422639 17.          0.43096751]\t 0.8371589258211735\t 0.6582649380252287\t 0.4702817391593268\t 0.47028173846350924\n",
            "23 \t [3.55859061 5.61875163 8.         0.5882063  1.         0.57036163]\t 0.7346535405920693\t 0.6582649380252287\t 0.47124158310664\t 0.47124158310664\n",
            "24 \t [1.5938649  0.20757679 5.         0.94973168 4.         0.41254588]\t 0.8381523439146795\t 0.6582649380252287\t 0.46599722219735756\t 0.46599722219735756\n",
            "25 \t [9.92248648 8.73301847 7.         0.58578431 6.         0.64802898]\t 0.7258609233436316\t 0.6582649380252287\t 0.4606744903882952\t 0.4606744903882952\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.672888499874982\t 0.6582649380252287\t 0.4600774981787372\t 0.4600774981787372\n",
            "27 \t [ 7.74005531  8.73318352 14.          0.77422043 15.          0.27051553]\t 0.923046327058876\t 0.6582649380252287\t 0.4567271322122531\t 0.4567271322122531\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.768583852631927\t 0.6582649380252287\t 0.45440746791578757\t 0.45440746791578757\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9197610970890002\t 0.6582649380252287\t 0.4583565765931105\t 0.4583565765931105\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.9166993865744176\t 0.6582649380252287\t 0.45633290648778907\t 0.45633290648778907\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49331.664993400715"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfeebba-80bd-4209-aed4-9b1798e96e76"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO_multi(surrogate_approx_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 0.46598938625837255\t 0.46598938625837255\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.9571856949825378\t 0.6747866005380063\t 0.4826080329497747\t 0.4826080329497747\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6747866005380063\t 0.4893078002788662\t 0.4893078002788662\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6747866005380063\t 0.47899966820581485\t 0.47899966820581485\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9600990595782894\t 0.6747866005380063\t 0.4883428969249194\t 0.4883428969249194\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 1.0131910395518218\t 0.6747866005380063\t 0.4925954228765506\t 0.4925954228765506\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7242608483603965\t 0.6747866005380063\t 0.49895685483358193\t 0.49895685483358193\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 7.13077184  9.67534636 12.          0.53994085 17.          0.99732292]\u001b[0m\t \u001b[1m\u001b[92m0.6733183778157861\u001b[0m\t \u001b[1m\u001b[92m0.6733183778157861\u001b[0m\t \u001b[1m\u001b[92m0.4914250586286439\u001b[0m\t \u001b[1m\u001b[92m0.4914250586286439\u001b[0m\n",
            "9  \t [ 4.99777324  7.1255563   5.          0.87428718 19.          0.63814647]\t 0.7320174755578019\t 0.6733183778157861\t 0.4832412589977475\t 0.4832412589977475\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.697395180788185\t 0.6733183778157861\t 0.47799255957426845\t 0.47799255957426845\n",
            "11 \t [ 2.11261802  6.77105261 11.          0.82546435 17.          0.58049877]\t 0.7123976603724721\t 0.6733183778157861\t 0.47233479742974505\t 0.4723347951563555\n",
            "12 \t [ 1.87613733  0.3867672  10.          0.63542614  2.          0.41568093]\t 0.8195578782244798\t 0.6733183778157861\t 0.4677615806428442\t 0.4677615806428442\n",
            "13 \t [ 1.48556604  1.71732125 13.          0.7779625   9.          0.35101548]\t 0.9594313331116266\t 0.6733183778157861\t 0.46683899576990756\t 0.46683899576990756\n",
            "14 \t [4.48522578 6.54261798 5.         0.79314226 1.         0.29945677]\t 0.9752292115331169\t 0.6733183778157861\t 0.470500080300485\t 0.470500080300485\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 1.13909448  9.99750981 12.          0.83097832  8.          0.96211319]\u001b[0m\t \u001b[1m\u001b[92m0.6681753308209242\u001b[0m\t \u001b[1m\u001b[92m0.6681753308209242\u001b[0m\t \u001b[1m\u001b[92m0.47422237771696607\u001b[0m\t \u001b[1m\u001b[92m0.47422237771696607\u001b[0m\n",
            "16 \t [ 5.21920054  9.35580917 14.          0.81835368  4.          0.54800317]\t 0.7211586025861135\t 0.6681753308209242\t 0.46948663184454503\t 0.46948663184454503\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.7105097809499443\t 0.6681753308209242\t 0.4663201308250093\t 0.4663201308250093\n",
            "18 \t [ 9.40706915  0.91600736 13.          0.648599    7.          0.62885715]\t 0.6782712913254569\t 0.6681753308209242\t 0.4633646642867963\t 0.4633646642867963\n",
            "19 \t [ 3.46936711  8.05933995 13.          0.63796232  8.          0.58226276]\t 0.7204550280994024\t 0.6681753308209242\t 0.45712645581797745\t 0.45712645581797745\n",
            "20 \t [ 0.29432342  7.81815248  5.02042407  0.5        15.80418861  1.        ]\t 0.7172707008104678\t 0.6681753308209242\t 0.4618552846965648\t 0.46185528531007897\n",
            "21 \t [4.16561464 4.3151821  6.         0.76299318 2.         0.59049538]\t 0.7439602970032533\t 0.6681753308209242\t 0.46453380915313425\t 0.46453380915313425\n",
            "22 \t [4.66769699 4.74732773 9.         0.50018348 8.         0.67980328]\t 0.6864309955872094\t 0.6681753308209242\t 0.4593098509258054\t 0.4593098486692158\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 1.008805594135994\t 0.6681753308209242\t 0.4582559229152305\t 0.4582559229152305\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.6871807270632571\t 0.6681753308209242\t 0.45687301741516334\t 0.45687301741516334\n",
            "25 \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]\t 0.7109212151666767\t 0.6681753308209242\t 0.4627682680425078\t 0.46276826804248705\n",
            "26 \t [ 5.73005003  1.18628884 13.          0.88016467 12.          0.48547975]\t 0.8109689394932417\t 0.6681753308209242\t 0.4545020049578569\t 0.4545020049578569\n",
            "27 \t [8.60914739 9.54673859 7.         0.78963544 7.         0.48348756]\t 0.815291878276993\t 0.6681753308209242\t 0.45300183738269506\t 0.45300183738269506\n",
            "28 \t [ 9.70174036  9.71799099 14.          0.84593857  8.          0.66512595]\t 0.672972068481645\t 0.6681753308209242\t 0.44892038870524764\t 0.44892038870524764\n",
            "29 \t [2.80395637 9.03108704 7.         0.9539385  8.         0.45699153]\t 0.8136618853493587\t 0.6681753308209242\t 0.448909878065735\t 0.448909878065735\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.6762301508489591\t 0.6681753308209242\t 0.4592901119113852\t 0.4592901119113852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51987.64926819376"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c08ed96-8474-4c0d-cbb4-c34d59459c28"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO_multi(surrogate_approx_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 0.4554698726083567\t 0.4554698726083567\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 0.44176715623384244\t 0.44176715623384244\n",
            "3  \t [ 9.6900225   0.69761314 13.          0.54877119 16.          0.55532692]\t 0.676755395441882\t 0.6568473525973234\t 0.4464129488556526\t 0.4464129488556526\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.8615658015198442\t 0.6568473525973234\t 0.43792203423229276\t 0.43792203423229276\n",
            "5  \t [ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\t 0.730615339433918\t 0.6568473525973234\t 0.4421961340823954\t 0.4421961340823954\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.8514677232156771\t 0.6568473525973234\t 0.43841674012400966\t 0.43841674012400966\n",
            "7  \t [ 9.09795503  1.07150197  7.          0.98191679 19.          0.62951892]\t 0.6952220627574484\t 0.6568473525973234\t 0.4413173387860481\t 0.4413173387860481\n",
            "8  \t [ 8.63880631  5.06396165 13.          0.58410058  1.          0.41865338]\t 0.8085010839601445\t 0.6568473525973234\t 0.4367832392005582\t 0.4367832392005582\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.7097411329660293\t 0.6568473525973234\t 0.43746671268976245\t 0.43746671268976245\n",
            "10 \t [ 5.69601833  8.48205706 14.          0.99692553  7.          0.48051376]\t 0.7852120921824152\t 0.6568473525973234\t 0.4343355177492322\t 0.43433551774921153\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.6638601166418586\t 0.6568473525973234\t 0.4342510501299497\t 0.4342510501299497\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.7350998875793917\t 0.6568473525973234\t 0.43030358837423405\t 0.43030358837423405\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.6855937848974291\t 0.6568473525973234\t 0.4288079230708493\t 0.4288079230708493\n",
            "14 \t [ 7.74771021  6.65318771  6.          0.83647538 17.          0.81072392]\t 0.7061824016851268\t 0.6568473525973234\t 0.42641872072727094\t 0.4264187195516258\n",
            "15 \t [3.91240074 6.5849714  5.         0.97211484 8.         0.11185491]\t 0.9123340390900221\t 0.6568473525973234\t 0.4243198129828762\t 0.4243198129828762\n",
            "16 \t [ 4.45420258  7.59025354  7.          0.50662979 17.          0.94915127]\t 0.6865826919452938\t 0.6568473525973234\t 0.4286764705314829\t 0.4286764705314829\n",
            "17 \t [4.50435964 1.42883317 8.         0.76583339 3.         0.4306355 ]\t 0.7929882304105694\t 0.6568473525973234\t 0.42651096169451025\t 0.42651096169451025\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.6653785933459865\t 0.6568473525973234\t 0.42239344052235506\t 0.42239344052235506\n",
            "19 \t [ 9.64875283  9.32176949  8.          0.85263567 19.          0.33410227]\t 0.849585847576698\t 0.6568473525973234\t 0.4253545948437786\t 0.4253545948437786\n",
            "20 \t [ 2.11709245  0.98000239 11.          0.61895038  1.          0.33752532]\t 0.8642382867076359\t 0.6568473525973234\t 0.42977553225159304\t 0.42977553225159304\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 1.82194226  5.93834848 10.          0.79561221  7.          0.75536101]\u001b[0m\t \u001b[1m\u001b[92m0.6549358180712573\u001b[0m\t \u001b[1m\u001b[92m0.6549358180712573\u001b[0m\t \u001b[1m\u001b[92m0.4387577125455744\u001b[0m\t \u001b[1m\u001b[92m0.43875751863158596\u001b[0m\n",
            "22 \t [ 2.416926    0.61467071 10.          0.98937047 11.          0.16903402]\t 0.9081588920257427\t 0.6549358180712573\t 0.4287900577238678\t 0.4287899890067549\n",
            "23 \t [ 5.3880688   2.65297896 14.          0.90613057  4.          0.23404421]\t 0.9109113159973135\t 0.6549358180712573\t 0.43328430483315805\t 0.43328430483315805\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.756031776613528\t 0.6549358180712573\t 0.43706356034247773\t 0.43706356034247773\n",
            "25 \t [ 1.719002    1.73903169  5.          0.87805761 14.          0.46260902]\t 0.8248486263986295\t 0.6549358180712573\t 0.4448015342031821\t 0.4448015342031821\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.8070679905812153\t 0.6549358180712573\t 0.44221200234363484\t 0.44221200234363484\n",
            "27 \t [ 5.69364724  7.79816519 10.          0.68740709 11.          0.10985593]\t 0.9123880688424546\t 0.6549358180712573\t 0.4389903453499531\t 0.43899034532428244\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 0.17423277  9.28464895 11.          0.86455659  1.          0.87456687]\u001b[0m\t \u001b[1m\u001b[92m0.6518721676322569\u001b[0m\t \u001b[1m\u001b[92m0.6518721676322569\u001b[0m\t \u001b[1m\u001b[92m0.4368767707674535\u001b[0m\t \u001b[1m\u001b[92m0.4368767707674535\u001b[0m\n",
            "29 \t [ 5.67686965  7.12623397 10.          0.88124763  1.          0.44323716]\t 0.7900641733857128\t 0.6518721676322569\t 0.4336647552476474\t 0.4336647552476474\n",
            "30 \t [ 5.49283486  0.14349186 11.          0.52303405 19.          0.41411835]\t 0.7943810197692028\t 0.6518721676322569\t 0.4368653455393355\t 0.4368653455393355\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50084.0361637815"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341f0d98-1068-47f3-cdaf-e48efa41fe01"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO_multi(surrogate_approx_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.5185425487143045\u001b[0m\t \u001b[1m\u001b[92m0.5185425487143045\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 0.49803901694706165\t 0.49803901694706165\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 0.49583699075991516\t 0.49583699075991516\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 0.49321884966564666\t 0.49321884966564666\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 0.4966653172414641\t 0.4966653172414641\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 0.49472065129760195\t 0.49472065129760195\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 0.48708745956026017\t 0.48708745956026017\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.7620148611738933\t 0.6878693399983744\t 0.49084619270769453\t 0.49084619270769453\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.4857827996029166\u001b[0m\t \u001b[1m\u001b[92m0.4857827996029166\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7199718018091047\t 0.6730441336589406\t 0.47850118150980303\t 0.47850118150980303\n",
            "11 \t [ 3.92379693  5.26427008  7.          0.52294127 13.          0.66328071]\t 0.7482193144353987\t 0.6730441336589406\t 0.47349943871790756\t 0.47349943871790756\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 0.4699767009517688\t 0.4699767009517688\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.4657603445275102\u001b[0m\t \u001b[1m\u001b[92m0.46576034452563225\u001b[0m\n",
            "14 \t [ 5.41155711  5.82534705 10.          0.62444801 12.          0.48368067]\t 0.8667049733212127\t 0.6551680070961308\t 0.4606051194716897\t 0.4606051194716897\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 0.8854668121365705\t 0.6551680070961308\t 0.461546063760005\t 0.461546063760005\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6551680070961308\t 0.4628327527734923\t 0.4628327527734923\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 0.9718611347031094\t 0.6551680070961308\t 0.4615783407397181\t 0.4615783407397181\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 0.8703303423168164\t 0.6551680070961308\t 0.47233263738119496\t 0.47233263738119496\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 0.8664298555004347\t 0.6551680070961308\t 0.46455314052165825\t 0.46455314052165825\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.8073058384557079\t 0.6551680070961308\t 0.46890926575729697\t 0.46890926575729697\n",
            "21 \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]\t 0.9496880408110411\t 0.6551680070961308\t 0.4725530784287566\t 0.47255303250413405\n",
            "22 \t [ 9.03366199  7.80955039  7.          0.58807038 16.          0.37530235]\t 0.8718032531648561\t 0.6551680070961308\t 0.4647315032293349\t 0.4647315032293349\n",
            "23 \t [0.58596137 5.71336149 9.         0.70354751 9.         0.28160967]\t 0.9498200925027509\t 0.6551680070961308\t 0.46768128255381164\t 0.4676812756413025\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7113005276137964\t 0.6551680070961308\t 0.4730902599063367\t 0.4730902599063367\n",
            "25 \t [ 1.2601232   9.9585863  10.          0.70525992  2.          0.9880166 ]\t 0.6631852367566748\t 0.6551680070961308\t 0.4699220793517709\t 0.4699220793517709\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 0.8623919725421392\t 0.6551680070961308\t 0.4662509299225574\t 0.4662509299225574\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.7206151175283746\t 0.6551680070961308\t 0.47150216335665607\t 0.47150216335665607\n",
            "28 \t [1.37294589 2.61228134 9.         0.89667199 1.         0.42044841]\t 0.8676686566935652\t 0.6551680070961308\t 0.4608610431442882\t 0.4608610431442882\n",
            "29 \t [ 1.58467279  1.68272877 13.          0.86101343 12.          0.4100987 ]\t 0.8613126520852274\t 0.6551680070961308\t 0.4699794980068883\t 0.4699794980068883\n",
            "30 \t [ 4.7382252   5.19023599  9.84610503  1.         19.20425593  1.        ]\t 0.6568167057144723\t 0.6551680070961308\t 0.46890897510851187\t 0.4689084774278661\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50482.78878121671"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cf8ec3-543a-4533-b22f-8e84222565fd"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO_multi(surrogate_approx_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 0.45190987401032423\t 0.45190987401032423\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 0.4565532206639616\t 0.4565532206639616\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 0.45273320108093484\t 0.45273320108093484\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 0.4465389389754202\t 0.4465389389754202\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 0.4569907524819502\t 0.4569907524819502\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 0.45855958031516414\t 0.45855958031516414\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 0.4587595880923709\t 0.4587595880923709\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 0.45542615125174324\t 0.45542615125174324\n",
            "9  \t [9.85206608 0.28191822 5.         0.52457928 8.         0.84714334]\t 0.7819517369688569\t 0.7141038418197827\t 0.45828048676296895\t 0.45828048676296895\n",
            "10 \t [ 0.2191332   8.51773955  5.          0.60657578 15.          0.49735822]\t 0.8316281392969092\t 0.7141038418197827\t 0.45517266794214023\t 0.45517266794214023\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 0.4553902117386412\t 0.4553902117386412\n",
            "12 \t [0.95504342 7.30424524 8.         0.76682007 6.         0.21761275]\t 0.9667342747401506\t 0.7141038418197827\t 0.455846220428504\t 0.455846220428504\n",
            "13 \t [ 7.51514915  5.57821555 12.          0.8704045   9.          0.10769764]\t 0.9654026035949915\t 0.7141038418197827\t 0.46046613945784154\t 0.4604661228443509\n",
            "14 \t [5.79855217 7.64610678 9.         0.54644758 3.         0.68341681]\t 0.7349404110255493\t 0.7141038418197827\t 0.46412088065318496\t 0.46412088065318496\n",
            "15 \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]\t 0.8751160002928657\t 0.7141038418197827\t 0.46196835380073853\t 0.46196835380073853\n",
            "16 \t [ 5.22074709  0.74229772 13.          0.87455275  7.          0.44305495]\t 0.8053149455389029\t 0.7141038418197827\t 0.46309248891898824\t 0.46309248891898824\n",
            "17 \t [ 9.1928307   3.75120063 13.          0.61085648 16.          0.3130605 ]\t 0.8587285155589749\t 0.7141038418197827\t 0.4626340758400247\t 0.4626340758400247\n",
            "18 \t [ 0.17456981  4.44078349  6.          0.87411246 11.          0.7606398 ]\t 0.7575142025728411\t 0.7141038418197827\t 0.46424043909276774\t 0.46424043909276774\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]\u001b[0m\t \u001b[1m\u001b[92m0.7137199048529451\u001b[0m\t \u001b[1m\u001b[92m0.7137199048529451\u001b[0m\t \u001b[1m\u001b[92m0.47016938944376113\u001b[0m\t \u001b[1m\u001b[92m0.4701693894428761\u001b[0m\n",
            "20 \t [ 8.57333797  0.94219501 14.          0.51089969  3.          0.1953435 ]\t 0.9742874478076378\t 0.7137199048529451\t 0.4557681355617727\t 0.4557681355617727\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\u001b[0m\t \u001b[1m\u001b[92m0.6678102642866967\u001b[0m\t \u001b[1m\u001b[92m0.6678102642866967\u001b[0m\t \u001b[1m\u001b[92m0.47135158858141957\u001b[0m\t \u001b[1m\u001b[92m0.47135158858141957\u001b[0m\n",
            "22 \t [ 6.72796419  6.10053296 14.          0.56325639  2.          0.91580991]\t 0.672911524877989\t 0.6678102642866967\t 0.46349996557071926\t 0.4634999632205714\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.7660042630046296\t 0.6678102642866967\t 0.4640553031554766\t 0.4640553031554766\n",
            "24 \t [9.30371298 5.41042714 5.         0.80825473 7.         0.72790994]\t 0.775406840278715\t 0.6678102642866967\t 0.45143336895961733\t 0.45143336895961733\n",
            "25 \t [ 1.24596208  9.8539336  15.          1.         12.73396474  0.1       ]\t 0.9637613496472\t 0.6678102642866967\t 0.4564004844578589\t 0.45639984101936854\n",
            "26 \t [ 9.68199458  9.34620738 11.          0.57663541 14.          0.24521092]\t 0.9699971507331904\t 0.6678102642866967\t 0.46464341319934077\t 0.46464341319934077\n",
            "27 \t [ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]\t 0.7275389527778259\t 0.6678102642866967\t 0.46543523971062656\t 0.46543523971062656\n",
            "28 \t [ 4.55919043  8.6591134   6.          0.8884863  12.          0.96165246]\t 0.7009533648321409\t 0.6678102642866967\t 0.4580686509580385\t 0.4580686509580385\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.7646380284813412\t 0.6678102642866967\t 0.4621576013104022\t 0.4621576013104022\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.7247998938700702\t 0.6678102642866967\t 0.4512882131781887\t 0.4512882131781887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49715.57654450851"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f8696e-1692-448f-b90c-ae812fe41213"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO_multi(surrogate_approx_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.8853778201562241\t 0.6968179065224296\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.6968179065224296\t 0.6968179065224296\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.8778125354456613\t 0.6968179065224296\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7421252990295766\t 0.6968179065224296\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7041732589144625\t 0.6968179065224296\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.7694285284315747\t 0.6968179065224296\t 0.4320797464613799\t 0.4320797464613799\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m0.43077780638201757\u001b[0m\t \u001b[1m\u001b[92m0.43077780638201757\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.740342057576812\t 0.65697799905797\t 0.4216657227834396\t 0.4216657227834396\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.893321248053374\t 0.65697799905797\t 0.42000271732332517\t 0.42000271732332517\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.697182883066114\t 0.65697799905797\t 0.42928127134168415\t 0.42928127134168415\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 0.934413982456124\t 0.65697799905797\t 0.42444476049987095\t 0.42444476049987095\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 0.9339136409907385\t 0.65697799905797\t 0.433971706322362\t 0.433971706322362\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.7385292363411576\t 0.65697799905797\t 0.4408372431956188\t 0.4408372431956188\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.7318688282028918\t 0.65697799905797\t 0.4383153750341142\t 0.4383153727999961\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.6917610853596872\t 0.65697799905797\t 0.43594303462441797\t 0.43594302993092443\n",
            "11 \t [2.26673282 9.18109909 5.         0.89654818 1.         0.23064839]\t 0.9345922648183839\t 0.65697799905797\t 0.43288512297883586\t 0.43288512297883586\n",
            "12 \t [ 0.62191196  4.69754177  5.          0.72971917 15.          0.95903084]\t 0.7251980612547309\t 0.65697799905797\t 0.43815955597729106\t 0.43815955597729106\n",
            "13 \t [ 8.34050252  7.45495891 14.          0.58875591  8.          0.92669456]\t 0.6608570085316285\t 0.65697799905797\t 0.436289332042466\t 0.436289332042466\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.7718546540038929\t 0.65697799905797\t 0.43260583227044225\t 0.43260583227044225\n",
            "15 \t [0.73985165 0.58861565 5.         0.76246476 8.         0.22502929]\t 0.9355351230643232\t 0.65697799905797\t 0.4322691826021696\t 0.4322691826021696\n",
            "16 \t [ 2.74922981  6.93422037  7.          0.64536331 17.          0.3979189 ]\t 0.7829163073478957\t 0.65697799905797\t 0.43682276572164125\t 0.43682276572164125\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 5.01391374  9.05765577 13.          0.9768187   1.          0.92456281]\u001b[0m\t \u001b[1m\u001b[92m0.6564534467026883\u001b[0m\t \u001b[1m\u001b[92m0.6564534467026883\u001b[0m\t \u001b[1m\u001b[92m0.4365869062306952\u001b[0m\t \u001b[1m\u001b[92m0.4365869062306952\u001b[0m\n",
            "18 \t [ 7.49379106  4.28777418 12.          0.51562956  7.          0.83771026]\t 0.7078067412607201\t 0.6564534467026883\t 0.4378317360280869\t 0.4378317360280869\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 0.932289957585124\t 0.6564534467026883\t 0.44359704676050754\t 0.44359704676050754\n",
            "20 \t [2.46492428 5.43160937 5.         0.80464169 6.         0.16325382]\t 0.9347869126515154\t 0.6564534467026883\t 0.4496642811567652\t 0.4496642811567652\n",
            "21 \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]\t 0.7726367108722194\t 0.6564534467026883\t 0.4399797799326321\t 0.4399797799326321\n",
            "22 \t [ 0.03968768  0.41026974 12.07503683  0.5        15.14973459  0.1       ]\t 0.9267121582979587\t 0.6564534467026883\t 0.4413280008940542\t 0.44132800203942535\n",
            "23 \t [ 6.72349545  5.27194732 13.          0.74776676 17.          0.30949491]\t 0.8771141770175074\t 0.6564534467026883\t 0.4468195221543418\t 0.4468195221543418\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.6800999300330094\t 0.6564534467026883\t 0.44714829312095666\t 0.44714829312095666\n",
            "25 \t [ 3.75888009  4.48669956 11.          0.79480873  1.          0.40375096]\t 0.7782460025277567\t 0.6564534467026883\t 0.4525790067554291\t 0.4525790067554291\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.772806554469849\t 0.6564534467026883\t 0.4502403024401004\t 0.4502403024401004\n",
            "27 \t [ 0.24526093  9.9241919  13.          0.52652258 12.          0.43108972]\t 0.7744431314593644\t 0.6564534467026883\t 0.4423736174513268\t 0.4423736174513268\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 0.9252239486256577\t 0.6564534467026883\t 0.4396345077210127\t 0.4396345077210127\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.7153038490865153\t 0.6564534467026883\t 0.44128541869444154\t 0.44128541869444154\n",
            "30 \t [6.65163782 6.39807144 6.         0.64802115 8.         0.12708916]\t 0.9320996702572151\t 0.6564534467026883\t 0.44482514294272\t 0.44482514294272\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49565.10047471935"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc03553-a49b-4fa9-ea7f-a1951de1618e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO_multi(surrogate_approx_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.4411357329952958\u001b[0m\t \u001b[1m\u001b[92m0.4411357329952958\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 0.4305959003513451\t 0.4305959003513451\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 0.42464158863412116\t 0.42464158863412116\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 0.44419344427479884\t 0.44419344427479884\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 0.4399075477215166\t 0.4399075477215166\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.7059767781587389\t 0.6773838424850286\t 0.44360494719205135\t 0.44360494719205135\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.7065170119936448\t 0.6773838424850286\t 0.4389397446065172\t 0.4389397446065172\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.7317581740148223\t 0.6773838424850286\t 0.43503623052007645\t 0.43503623052007645\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.7857306346205829\t 0.6773838424850286\t 0.4326875763366868\t 0.4326875763366868\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 4.45643696  6.43761151 10.          0.59521711 15.          0.91320177]\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m0.43272248043960143\u001b[0m\t \u001b[1m\u001b[92m0.43272247386284607\u001b[0m\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.7333445147195274\t 0.6773536163008785\t 0.4289912046782187\t 0.4289912046782187\n",
            "12 \t [ 9.41792853  9.11293681  6.          0.87420995 11.          0.8007601 ]\t 0.7086968319816249\t 0.6773536163008785\t 0.4277771795145932\t 0.42777717726096354\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.0149681655113947\t 0.6773536163008785\t 0.4253988777203607\t 0.4253988777203607\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.7335321473751593\t 0.6773536163008785\t 0.4341443591609298\t 0.4341443591609298\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.767048132195449\t 0.6773536163008785\t 0.4326637265254995\t 0.4326637265254995\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.7391934581482711\t 0.6773536163008785\t 0.4322643433259289\t 0.43226434296914434\n",
            "17 \t [4.5467287  4.10200035 9.         0.56725941 2.         0.95321578]\t 0.6834809053345061\t 0.6773536163008785\t 0.43144770253933423\t 0.43144770253933423\n",
            "18 \t [ 7.9679648   6.50875696 12.          0.58580991 13.          0.19954847]\t 1.018322232391354\t 0.6773536163008785\t 0.4254930917706845\t 0.4254930917706845\n",
            "19 \t [ 2.76696568  4.32638207 10.          0.69065092 10.          0.32928339]\t 0.8606879483167145\t 0.6773536163008785\t 0.434497751095741\t 0.434497751095741\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.6776716071409558\t 0.6773536163008785\t 0.4377580879236106\t 0.4377580879236106\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.679119846341469\t 0.6773536163008785\t 0.4433648047106391\t 0.4433648047106391\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.7131407042423596\t 0.6773536163008785\t 0.43194035479483484\t 0.43194035479483484\n",
            "23 \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]\t 0.7458028061131368\t 0.6773536163008785\t 0.44681098973036387\t 0.44681098973036387\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 8.32281899  8.13330287 11.          0.96254932  9.          0.88712633]\u001b[0m\t \u001b[1m\u001b[92m0.667446549429236\u001b[0m\t \u001b[1m\u001b[92m0.667446549429236\u001b[0m\t \u001b[1m\u001b[92m0.4327404200409249\u001b[0m\t \u001b[1m\u001b[92m0.4327404200409249\u001b[0m\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.7487322203145116\t 0.667446549429236\t 0.42913599171591627\t 0.42913599171591627\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.7108432598487722\t 0.667446549429236\t 0.433740899942682\t 0.433740899942682\n",
            "27 \t [6.6672698  0.63840466 9.         0.87317079 8.         0.32475468]\t 0.8600427002690658\t 0.667446549429236\t 0.4235487867601396\t 0.4235487867601396\n",
            "28 \t [8.3735996  5.34104024 8.         0.56456303 7.         0.59553385]\t 0.7245806620781778\t 0.667446549429236\t 0.4299337035086814\t 0.4299337035086814\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.7131420295812025\t 0.667446549429236\t 0.4279237713380247\t 0.4279237713380247\n",
            "30 \t [9.30545715 2.21896205 9.         0.96965499 5.         0.61228081]\t 0.7128642744554409\t 0.667446549429236\t 0.4282112914511509\t 0.4282112914511509\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48534.64481811289"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10ac8d2-eea0-4a64-9307-7c0a9c452d29"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO_multi(surrogate_approx_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 0.4676225906533388\t 0.4676225906533388\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 0.4704189701850425\t 0.4704189701850425\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.7502219040814293\t 0.6597299542050263\t 0.4886722572440912\t 0.4886722572440912\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7367139517682284\t 0.6597299542050263\t 0.4799328924967524\t 0.4799328924967524\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8006234291185196\t 0.6597299542050263\t 0.47230642158175185\t 0.47230642158175185\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.058727127460609\t 0.6597299542050263\t 0.46930805750577625\t 0.46930805750551297\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.703165388931625\t 0.6597299542050263\t 0.4810578512695257\t 0.4810578512695257\n",
            "8  \t [ 2.63649501  9.62311075  7.          0.5192485  13.          0.19746315]\t 1.0640909980360433\t 0.6597299542050263\t 0.4737709996366581\t 0.47377099596665473\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0651952678837315\t 0.6597299542050263\t 0.48358065035839737\t 0.48358065035839737\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.8036859734991779\t 0.6597299542050263\t 0.4917132703036627\t 0.4917132703036627\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0624486911635314\t 0.6597299542050263\t 0.4885816052661991\t 0.4885816052661991\n",
            "12 \t [ 6.27900589  9.12764923  5.          0.84263312 18.          0.79256191]\t 0.730579912896863\t 0.6597299542050263\t 0.4952918805878062\t 0.4952918805878062\n",
            "13 \t [ 6.23595836  9.32810182 13.          0.66281123 18.          0.41679152]\t 0.8037682530168745\t 0.6597299542050263\t 0.4903149632218386\t 0.4903149632218386\n",
            "14 \t [ 2.08109501  0.31399789  8.          0.78263012 11.          0.87673239]\t 0.6735019021239127\t 0.6597299542050263\t 0.4879541985386348\t 0.4879541985386348\n",
            "15 \t [ 6.97560183  1.48211849  9.          0.80794429 10.          0.21839694]\t 1.0602103565189318\t 0.6597299542050263\t 0.4823562581155453\t 0.4823562581155453\n",
            "16 \t [ 0.3999032   2.66263318 14.          0.55784408  3.          0.95411688]\t 0.6765956478595294\t 0.6597299542050263\t 0.4879564669972688\t 0.4879564669972688\n",
            "17 \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]\t 0.7117644991570005\t 0.6597299542050263\t 0.48285173388674124\t 0.48285173388674124\n",
            "18 \t [ 1.21632555  2.44839139  8.          0.8927599  17.          0.25270381]\t 0.878121266134469\t 0.6597299542050263\t 0.4792326385275989\t 0.4792326385275989\n",
            "19 \t [4.83067255 2.19904639 7.         0.5680519  3.         0.59514532]\t 0.7720408244337518\t 0.6597299542050263\t 0.47878154190832256\t 0.47878154190832256\n",
            "20 \t [ 5.3866253   1.98558863 14.          0.93996594  6.          0.18524928]\t 1.0595101751758718\t 0.6597299542050263\t 0.47853035097685814\t 0.47853035097685814\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.8784158308955667\t 0.6597299542050263\t 0.4883826422801451\t 0.4883826422801451\n",
            "22 \t [ 2.87514576  3.13712267 13.          0.97475974 17.          0.73021265]\t 0.6835469609962976\t 0.6597299542050263\t 0.4881394728489941\t 0.4881394728489941\n",
            "23 \t [ 7.7259419   7.24070659 12.          0.78792483 13.          0.54558593]\t 0.7474521691759894\t 0.6597299542050263\t 0.47875667088781837\t 0.47875667088781837\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.6902699854328027\t 0.6597299542050263\t 0.47619553678861537\t 0.47619553678861537\n",
            "25 \t [ 0.83358887  9.71793838 12.          0.52075624 11.          0.67770945]\t 0.6983988113329787\t 0.6597299542050263\t 0.4803234491628842\t 0.4803234491628842\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.7422712401342008\t 0.6597299542050263\t 0.47753770429417747\t 0.47753770429417747\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 7.22618504  7.40431113 14.94284436  1.          3.70046767  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6428069043344805\u001b[0m\t \u001b[1m\u001b[92m0.6428069043344805\u001b[0m\t \u001b[1m\u001b[92m0.4813264252434234\u001b[0m\t \u001b[1m\u001b[92m0.4813260237953646\u001b[0m\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.0600568728235613\t 0.6428069043344805\t 0.47000603745012026\t 0.47000603745012026\n",
            "29 \t [ 0.39565672  8.50724472  5.          0.74462587 17.          0.73375146]\t 0.7368138593297264\t 0.6428069043344805\t 0.47793057483909024\t 0.47793057483909024\n",
            "30 \t [ 0.89195001  6.01604215 14.          0.84121292  7.          0.44798682]\t 0.8038070345544759\t 0.6428069043344805\t 0.4654069482923027\t 0.46540694153510465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51299.20252489755"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f81eb4-b167-41b5-a01c-bbcd38d2edce"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663859249.4950526"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd74a101-b12e-45e0-eeec-3aa21a923869"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 0.48592102208482957\t 0.48592102208482957\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 0.48451724411241526\t 0.48451724411241526\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 0.4999166707794104\t 0.4999166707794104\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8992034514090065\t 0.6536753952667645\t 0.4859024301703329\t 0.4859024301703329\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6504936383293095\u001b[0m\t \u001b[1m\u001b[92m0.6504936383293095\u001b[0m\t \u001b[1m\u001b[92m0.487006940745659\u001b[0m\t \u001b[1m\u001b[92m0.4870069404015714\u001b[0m\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.9004243658767852\t 0.6504936383293095\t 0.475730389508091\t 0.475730389508091\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6504936383293095\t 0.4776500820613691\t 0.4776500820613691\n",
            "8  \t [8.51945771 8.4424986  8.         0.90741371 1.         0.49942468]\t 0.8757522803338091\t 0.6504936383293095\t 0.4844399625448784\t 0.4844399625448784\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 1.0632523501795186\t 0.6504936383293095\t 0.48431490844855035\t 0.48431490844855035\n",
            "10 \t [ 5.33531967  8.54366774  8.          0.66341534 14.          0.29734112]\t 0.998213042419686\t 0.6504936383293095\t 0.49229373033516227\t 0.49229373033516227\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6504936383293095\t 0.49637502185980387\t 0.49637502185980387\n",
            "12 \t [0.15776536 8.02750992 5.         0.65248282 3.         0.71659731]\t 0.8032223773845614\t 0.6504936383293095\t 0.5024078731792305\t 0.5024078731792305\n",
            "13 \t [4.13690736 2.14715696 6.         0.52611104 1.         0.96671642]\t 0.7093885008364936\t 0.6504936383293095\t 0.4991061735571117\t 0.4991061735571117\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6504936383293095\t 0.4937417974175614\t 0.4937417974175614\n",
            "15 \t [ 9.20512342  1.60831322 11.          0.87041344  2.          0.50117029]\t 0.8186293003915115\t 0.6504936383293095\t 0.48982376331469357\t 0.48982376331469357\n",
            "16 \t [ 0.28990425  5.36117717 14.          0.57624837 11.          0.76620972]\t 0.684834878460344\t 0.6504936383293095\t 0.48802856970673897\t 0.48802856970673897\n",
            "17 \t [1.68476972 5.2908721  8.         0.92839616 1.         0.96471758]\t 0.670961172017669\t 0.6504936383293095\t 0.4833632766105733\t 0.4833632766105733\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8661734316276007\t 0.6504936383293095\t 0.4773180522162924\t 0.4773180522162924\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 1.0095429457834948\t 0.6504936383293095\t 0.482427411845864\t 0.482427411845864\n",
            "20 \t [ 5.68575652  2.73061603 14.          0.61811388 15.          0.91855302]\t 0.6649510133524581\t 0.6504936383293095\t 0.4820036536260416\t 0.4820036536260416\n",
            "21 \t [ 9.72376714  9.82517342 14.          0.96896704 10.          0.66715413]\t 0.7365987830832396\t 0.6504936383293095\t 0.47921804285575464\t 0.47921804285575464\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 1.060877500434967\t 0.6504936383293095\t 0.4849199994306177\t 0.4849199994306177\n",
            "23 \t [ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\t 0.6693366893520581\t 0.6504936383293095\t 0.48716236365963844\t 0.48716236365963844\n",
            "24 \t [9.91212104 3.52811735 6.         0.93018572 1.         0.49999318]\t 0.8890012000810771\t 0.6504936383293095\t 0.48116031643307133\t 0.48116031643307133\n",
            "25 \t [ 9.92106016  5.52981723 11.          0.80826141 13.          0.31322593]\t 1.000587889017468\t 0.6504936383293095\t 0.47856299069832026\t 0.47856299069832026\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.6562345271802523\t 0.6504936383293095\t 0.49138812926412634\t 0.49138812926412634\n",
            "27 \t [ 2.52136808  8.51741902 14.          0.89185963  6.          0.23066693]\t 1.0608073786807473\t 0.6504936383293095\t 0.47773104785110615\t 0.47773104785110615\n",
            "28 \t [0.72761348 1.82196215 5.         0.79281157 6.         0.99771556]\t 0.7301068319230399\t 0.6504936383293095\t 0.4845225521669528\t 0.4845225521669528\n",
            "29 \t [ 7.40845157  8.58336508  5.          0.8318041  19.          0.36434664]\t 1.0097984953249557\t 0.6504936383293095\t 0.486773656034581\t 0.486773656034581\n",
            "30 \t [ 1.2654566   9.68568733  5.          0.57664611 17.          0.70355107]\t 0.804917733132231\t 0.6504936383293095\t 0.47879067962061866\t 0.47879067962061866\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47321.8408099896"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03eafacc-2c51-4150-9f8e-f421c0c9ba7b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.4145735257624059\u001b[0m\t \u001b[1m\u001b[92m0.4145735257624059\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6807577751383148\t 0.4082936478724333\t 0.4082936478724333\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.7073935536898857\t 0.6807577751383148\t 0.40778991231330813\t 0.40778991231330813\n",
            "4  \t [ 5.03756278  5.01206033 13.          0.59912629 19.          0.46413865]\t 0.7900256550528338\t 0.6807577751383148\t 0.40583333175231867\t 0.40583333175231867\n",
            "5  \t [0.  0.  5.  0.5 1.  0.1]\t 0.8726019020039407\t 0.6807577751383148\t 0.40904622152568754\t 0.40904622152568487\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.4169862031251644\u001b[0m\t \u001b[1m\u001b[92m0.4169862031251644\u001b[0m\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.          9.51871594  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.654043934674785\u001b[0m\t \u001b[1m\u001b[92m0.654043934674785\u001b[0m\t \u001b[1m\u001b[92m0.4131352372326647\u001b[0m\t \u001b[1m\u001b[92m0.41313523723266454\u001b[0m\n",
            "8  \t [1.98662322 5.58086412 6.         0.94862422 3.         0.77339666]\t 0.7107162399424428\t 0.654043934674785\t 0.4090122021839652\t 0.4090122021839652\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.7397571279868462\t 0.654043934674785\t 0.40785711193941154\t 0.40785711193941154\n",
            "10 \t [ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\t 0.6684024492575475\t 0.654043934674785\t 0.40785632405191813\t 0.40785632405191813\n",
            "11 \t [ 5.44997493  9.23863618 12.          0.63531171 14.          0.3187171 ]\t 0.7973294184994432\t 0.654043934674785\t 0.40532668644457587\t 0.40532668644457587\n",
            "12 \t [ 0.29437191  1.54419592 13.          0.81915517  2.          0.27031264]\t 0.796661991187597\t 0.654043934674785\t 0.4075094105032476\t 0.4075094105032476\n",
            "13 \t [ 7.86086296  9.53235807  5.          0.78700181 16.          0.22516618]\t 0.8728710854388536\t 0.654043934674785\t 0.40944688650770955\t 0.40944688650770955\n",
            "14 \t [ 9.27473506  0.48916448  9.          0.9279608  19.          0.68123621]\t 0.6739448414977296\t 0.654043934674785\t 0.4138316593662114\t 0.4138316593662114\n",
            "15 \t [ 9.03841746 10.         13.36649945  1.         19.36649945  1.        ]\t 0.6547228859829877\t 0.654043934674785\t 0.4116735181088602\t 0.41167351806043606\n",
            "16 \t [ 3.79151097  4.0129324  10.          0.78656319  9.          0.57380624]\t 0.6970533395297733\t 0.654043934674785\t 0.40934331534325086\t 0.40934331534325086\n",
            "17 \t [ 1.94467794  1.47584396  5.          0.91953126 11.          0.49707889]\t 0.8258856905247922\t 0.654043934674785\t 0.4083943171359302\t 0.4083943171359302\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.6693925559674401\t 0.654043934674785\t 0.419938470489295\t 0.419938470489295\n",
            "19 \t [ 6.92673077  1.23845568 10.          0.63463476  8.          0.28240746]\t 0.7984787223028406\t 0.654043934674785\t 0.42237251892747646\t 0.42237251892747646\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.7918243780041875\t 0.654043934674785\t 0.4198781035504829\t 0.4198781035504829\n",
            "21 \t [7.13284983 1.18470919 5.         0.63977211 3.         0.12223048]\t 0.8717594731267366\t 0.654043934674785\t 0.4175972208157408\t 0.4175972208157408\n",
            "22 \t [ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\t 0.664392530003631\t 0.654043934674785\t 0.4157107141262562\t 0.4157107141262562\n",
            "23 \t [8.76774335 2.47727368 5.         0.77895852 8.         0.95970784]\t 0.7344723614600867\t 0.654043934674785\t 0.4213427207924945\t 0.4213427207924945\n",
            "24 \t [ 0.49801933  9.4005764  12.          0.91363804 18.          0.53716763]\t 0.6927907397975772\t 0.654043934674785\t 0.4299392284382654\t 0.4299392284382654\n",
            "25 \t [ 8.22593027  3.70832356  5.          0.80279417 18.          0.57200994]\t 0.768920640618771\t 0.654043934674785\t 0.41981093892811555\t 0.41981093892811555\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.6666799570614775\t 0.654043934674785\t 0.4134031667272264\t 0.4134031667272264\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.6817048020092698\t 0.654043934674785\t 0.41930415086176354\t 0.41930415086176354\n",
            "28 \t [ 4.9644812   1.12270948  6.          0.71065886 17.          0.26866166]\t 0.816338550997086\t 0.654043934674785\t 0.4220505806062556\t 0.4220505806062556\n",
            "29 \t [ 5.98509126  0.06989145 14.          0.5561472  16.          0.1874862 ]\t 0.8641573587264293\t 0.654043934674785\t 0.41776977082387123\t 0.41776977082387123\n",
            "30 \t [5.55301534 4.43776121 9.         0.77874612 6.         0.99491253]\t 0.6713718258462102\t 0.654043934674785\t 0.4168486000291605\t 0.4168486000291605\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49022.23069865059"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe05d296-1429-415c-9fd2-c995930198ce"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 0.5222485137409463\t 0.5222485137409463\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.46535469  7.06056184  5.          0.53518488 13.          0.98930148]\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.5100202695647403\u001b[0m\t \u001b[1m\u001b[92m0.5100202695647403\u001b[0m\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7347345488605661\t 0.4963890106933756\t 0.4963890106933756\n",
            "4  \t [ 6.69378835  1.1746468   5.          0.75549171 16.          0.73450657]\t 0.7722220514333056\t 0.7347345488605661\t 0.5054110759082608\t 0.5054110759082608\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[8.5662852  7.62282167 7.         0.57679587 9.         0.92751362]\u001b[0m\t \u001b[1m\u001b[92m0.7056354714684\u001b[0m\t \u001b[1m\u001b[92m0.7056354714684\u001b[0m\t \u001b[1m\u001b[92m0.49719051617280285\u001b[0m\t \u001b[1m\u001b[92m0.49719051617280285\u001b[0m\n",
            "6  \t [5.7225441  2.61495097 6.         0.67527106 6.         0.33729846]\t 0.983509408209931\t 0.7056354714684\t 0.48745617658492457\t 0.48745617658492457\n",
            "7  \t [ 6.56033613  1.17774647 12.          0.5376295  15.          0.81305603]\t 0.7061518218591949\t 0.7056354714684\t 0.49268792997537036\t 0.49268792997537036\n",
            "8  \t [3.50549632 8.04483305 8.         0.95341936 1.         0.79512535]\t 0.7104180654574984\t 0.7056354714684\t 0.4849163758758863\t 0.4849163758758863\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[ 8.89682762  0.79017134 14.          0.58366818  8.          0.97456627]\u001b[0m\t \u001b[1m\u001b[92m0.6882258735708705\u001b[0m\t \u001b[1m\u001b[92m0.6882258735708705\u001b[0m\t \u001b[1m\u001b[92m0.47838995133070605\u001b[0m\t \u001b[1m\u001b[92m0.47838995133070605\u001b[0m\n",
            "10 \t [3.28340726 7.81144764 9.         0.96528359 7.         0.1686463 ]\t 1.0208805187492747\t 0.6882258735708705\t 0.47201014343342423\t 0.47201014343342423\n",
            "11 \t [ 3.53262431  2.07514765  7.          0.93520802 15.          0.4184813 ]\t 0.8751855836959452\t 0.6882258735708705\t 0.4785998913424873\t 0.4785998913424873\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.6998375974069359\t 0.6882258735708705\t 0.478851573006493\t 0.478851573006493\n",
            "13 \t [ 3.26032277  7.80574265 14.          0.88329978  3.          0.24845127]\t 1.021317881731207\t 0.6882258735708705\t 0.4739289376229196\t 0.4739289376229196\n",
            "14 \t [ 9.85636221  3.89791593  9.          0.61925349 14.          0.90156475]\t 0.692118262463878\t 0.6882258735708705\t 0.4792654309536639\t 0.4792654309536639\n",
            "15 \t [0.         0.         5.         0.5        4.56991129 0.1       ]\t 1.02783969823506\t 0.6882258735708705\t 0.4746101921787451\t 0.47461018626591966\n",
            "\u001b[1m\u001b[92m16\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6548396524742095\u001b[0m\t \u001b[1m\u001b[92m0.6548396524742095\u001b[0m\t \u001b[1m\u001b[92m0.47968901428261634\u001b[0m\t \u001b[1m\u001b[92m0.47968900982525087\u001b[0m\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.6548396524742095\t 0.47465994666827455\t 0.47465994666827455\n",
            "18 \t [9.83745664 3.68679807 9.         0.98607907 6.         0.93173856]\t 0.685538272783727\t 0.6548396524742095\t 0.4711235268970124\t 0.4711235268970124\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8649856112240915\t 0.6548396524742095\t 0.47389032089310745\t 0.47389032089310745\n",
            "20 \t [ 3.58262831  2.79375979  9.          0.709183   11.          0.30931145]\t 0.9766713924391162\t 0.6548396524742095\t 0.4690209642267311\t 0.4690209642267311\n",
            "21 \t [ 9.83060339  5.43479292  5.          0.93965116 19.          0.81693736]\t 0.7430400763458248\t 0.6548396524742095\t 0.4710660605176085\t 0.4710660605176085\n",
            "22 \t [ 2.77110475  0.35980325 10.          0.77088835  9.          0.78161047]\t 0.702308760297458\t 0.6548396524742095\t 0.4679736360926874\t 0.4679736360926874\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8752416347792465\t 0.6548396524742095\t 0.4771815250144966\t 0.4771815250144966\n",
            "24 \t [ 1.81637107  2.43482354 12.          0.52164424 18.          0.82567571]\t 0.7068734002824963\t 0.6548396524742095\t 0.47393504122018065\t 0.47393504122018065\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7185577429000575\t 0.6548396524742095\t 0.47082143872609405\t 0.47082143872609405\n",
            "26 \t [ 2.54357797  2.17286037  5.          0.86076647 19.          0.34653218]\t 0.9894490705371982\t 0.6548396524742095\t 0.46586464376923503\t 0.46586464376923503\n",
            "27 \t [ 8.21944232  0.76315735 14.          0.70782001  3.          0.58640207]\t 0.771954843353409\t 0.6548396524742095\t 0.4660943170929997\t 0.4660943170929997\n",
            "28 \t [ 9.01763405  8.9342346  11.          0.78253186 14.          0.5899614 ]\t 0.7571328011102442\t 0.6548396524742095\t 0.4685748062875001\t 0.4685748062875001\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.0229660667953924\t 0.6548396524742095\t 0.4637139598499392\t 0.4637139598499392\n",
            "30 \t [ 0.56213381  4.41770035 10.          0.6803733   4.          0.67199979]\t 0.7355552741037803\t 0.6548396524742095\t 0.47177652372552314\t 0.47177652372552314\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46877.10407555545"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdDTsSEtNuf-",
        "outputId": "c2279645-401a-4bb7-c54a-b2d1ab21958a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 0.4306015759774582\t 0.4306015759774582\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 0.9436692731753087\t 0.6641721421409617\t 0.44684890128315974\t 0.44684890128315974\n",
            "3  \t [7.47521879 1.08446649 5.         0.82092246 1.         0.87686231]\t 0.7277791972054833\t 0.6641721421409617\t 0.4580590560201699\t 0.4580590560201699\n",
            "4  \t [ 1.21913591  5.39021078 12.          0.52306788  2.          0.57375676]\t 0.7297298564124828\t 0.6641721421409617\t 0.45134869888265366\t 0.45134869888265366\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         16.98989514  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6433372706341197\u001b[0m\t \u001b[1m\u001b[92m0.6433372706341197\u001b[0m\t \u001b[1m\u001b[92m0.44616731412304517\u001b[0m\t \u001b[1m\u001b[92m0.4461673140949871\u001b[0m\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6433372706341197\t 0.43788041739554173\t 0.43788041739554173\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.7531044966742895\t 0.6433372706341197\t 0.44573012244621735\t 0.44573012244621735\n",
            "8  \t [ 0.32236964  2.41893129 14.          0.88540422 15.          0.72064562]\t 0.6990250321451492\t 0.6433372706341197\t 0.4432670292561431\t 0.4432670292561431\n",
            "9  \t [ 3.69209917  2.68210714  5.          0.5        12.44903937  0.1       ]\t 0.9401495944049177\t 0.6433372706341197\t 0.43908638089443425\t 0.439086380826539\n",
            "10 \t [ 2.85681452  3.87276276 14.          0.7995451  19.          0.43455239]\t 0.7705863499687786\t 0.6433372706341197\t 0.445214136434853\t 0.445214136434853\n",
            "11 \t [ 1.21907942  7.91297486  9.          0.5539985  16.          0.24710819]\t 0.9403329304575425\t 0.6433372706341197\t 0.4438848436229598\t 0.4438848436229598\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.6923205913979871\t 0.6433372706341197\t 0.44890955036223296\t 0.44890955036223296\n",
            "13 \t [ 2.71889417  6.23637706 13.          0.68299595  7.          0.60398003]\t 0.7183753718380752\t 0.6433372706341197\t 0.4452280410955264\t 0.4452280410955264\n",
            "14 \t [8.19619365 4.83684524 9.         0.8298899  4.         0.33596065]\t 0.8217273448818323\t 0.6433372706341197\t 0.4426600921022505\t 0.4426600921022505\n",
            "15 \t [0.         2.41631774 5.         0.5        1.         0.1       ]\t 0.9408999252070572\t 0.6433372706341197\t 0.44320737550171474\t 0.4432073754436061\n",
            "16 \t [ 3.46388124  0.89729092 11.          0.85678068  8.          0.44423579]\t 0.7732877075402497\t 0.6433372706341197\t 0.4472513541444342\t 0.4472513541444342\n",
            "17 \t [ 7.11901622  5.30460878 11.21763161  0.5        16.21763161  0.1       ]\t 0.9433886080079537\t 0.6433372706341197\t 0.4463955910305278\t 0.44639559103051707\n",
            "18 \t [6.18461978 1.56321293 5.         0.63345598 8.         0.11755092]\t 0.9382571320102834\t 0.6433372706341197\t 0.45547183996693547\t 0.45547183996693547\n",
            "19 \t [ 7.0857374   0.50559932 11.          0.75013908 13.          0.89656104]\t 0.6645935641687042\t 0.6433372706341197\t 0.4543059072544723\t 0.4543059072544723\n",
            "20 \t [ 1.78217576  9.78210974  5.          0.8003284  12.          0.83416548]\t 0.7532223657335955\t 0.6433372706341197\t 0.44711358542560276\t 0.44711358542560276\n",
            "21 \t [ 8.89454243 10.          7.48110967  1.         19.48110967  1.        ]\t 0.6746924462866547\t 0.6433372706341197\t 0.44508001747939785\t 0.4450798812929719\n",
            "22 \t [ 1.84655537  0.92635666  9.          0.60237883 14.          0.70534193]\t 0.7101596489776973\t 0.6433372706341197\t 0.45272489448897096\t 0.45272489448897096\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.6433372706341197\t 0.44616895713981525\t 0.44616895713981525\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.724172646323414\t 0.6433372706341197\t 0.4510537305813251\t 0.4510537305813251\n",
            "25 \t [4.21410488 1.53847897 8.         0.72947689 4.         0.95835056]\t 0.6751026509280861\t 0.6433372706341197\t 0.4492919508127008\t 0.4492919508127008\n",
            "26 \t [ 7.01360923  0.03074572 13.          0.56476682  9.          0.19217174]\t 0.9417712124079543\t 0.6433372706341197\t 0.4500646087116186\t 0.4500646087116186\n",
            "27 \t [ 2.49277017  9.71877294 14.          0.64108163 15.          0.60597318]\t 0.7146840039689067\t 0.6433372706341197\t 0.44685527752937704\t 0.44685527752937704\n",
            "28 \t [ 5.66588054  7.91454523 11.          0.93003188 12.          0.45330688]\t 0.7712523815321525\t 0.6433372706341197\t 0.4459087228805495\t 0.4459087228805495\n",
            "29 \t [0.57836485 1.08971763 5.         0.5        6.32987311 0.1       ]\t 0.9404794612511042\t 0.6433372706341197\t 0.443638076969293\t 0.4436380743262478\n",
            "30 \t [ 1.40912589  1.93204629 14.          0.88642674  6.          0.63288273]\t 0.7035285706615795\t 0.6433372706341197\t 0.4472415488755471\t 0.4472415488755471\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49863.83231446011"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca2e52c-71a5-46e2-f237-a39c0b49c9b9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 0.4695191127095293\t 0.4695191127095293\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 0.47835373607547427\t 0.47835373607547427\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.48321868515709215\u001b[0m\t \u001b[1m\u001b[92m0.48321868515709215\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 0.4779515031151883\t 0.4779515031151883\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.4787077372660694\u001b[0m\t \u001b[1m\u001b[92m0.4787077372660694\u001b[0m\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.92565009216999\t 0.6989575443158274\t 0.47020734975294665\t 0.47020734975294665\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6989575443158274\t 0.47399587662265713\t 0.47399587662265713\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.47203575928901736\u001b[0m\t \u001b[1m\u001b[92m0.47203575928901736\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9277423136052668\t 0.6747588495441635\t 0.4651153130589337\t 0.4651153130589337\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.6796390241442563\t 0.6747588495441635\t 0.4685703623715472\t 0.4685703623715472\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6458620128690523\u001b[0m\t \u001b[1m\u001b[92m0.6458620128690523\u001b[0m\t \u001b[1m\u001b[92m0.4629128172431785\u001b[0m\t \u001b[1m\u001b[92m0.46291281473637724\u001b[0m\n",
            "12 \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]\t 0.7387384974169141\t 0.6458620128690523\t 0.45698186016414727\t 0.45698186016414727\n",
            "13 \t [ 0.44763689  4.50747029  9.11849709  0.5        17.11849709  0.1       ]\t 0.9296719516378518\t 0.6458620128690523\t 0.4541835507210962\t 0.45418352851775823\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.6833142835714986\t 0.6458620128690523\t 0.45772699792218263\t 0.45772699792218263\n",
            "15 \t [ 0.69381482  7.09764326  5.          0.79260103 13.          0.36148114]\t 0.9417860014577227\t 0.6458620128690523\t 0.45531511863671636\t 0.45531511863671636\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8392510578678525\t 0.6458620128690523\t 0.45840795511897797\t 0.45840795511897797\n",
            "17 \t [ 9.34484937  3.49003142 14.          0.90417251  7.          0.92435507]\t 0.6682628994459927\t 0.6458620128690523\t 0.4591559755508829\t 0.4591559755508829\n",
            "18 \t [ 5.89128049  7.40217342 14.          0.90594716 12.          0.81399699]\t 0.6832896781938512\t 0.6458620128690523\t 0.4705764166188532\t 0.4705764166188532\n",
            "19 \t [1.07658799 0.12945598 8.         0.90000966 1.         0.17336755]\t 0.9286510383873756\t 0.6458620128690523\t 0.4577094864004631\t 0.4577094864004631\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7616619440927369\t 0.6458620128690523\t 0.4646576367319426\t 0.4646576367319426\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7413460349644984\t 0.6458620128690523\t 0.4598706797254822\t 0.4598706797254822\n",
            "22 \t [4.07754006 0.11652617 9.         0.95821235 4.         0.97462432]\t 0.6727052649233233\t 0.6458620128690523\t 0.4535335398796293\t 0.4535335398796293\n",
            "23 \t [ 0.14337166  3.83051228 13.          0.67084469 13.          0.27589041]\t 0.9247196191844409\t 0.6458620128690523\t 0.4606636216058174\t 0.4606636216058174\n",
            "24 \t [0.         4.02974491 7.88862693 0.5        9.88862693 0.1       ]\t 0.9328370307054457\t 0.6458620128690523\t 0.44894146214587843\t 0.4489414507669528\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.6920167982810115\t 0.6458620128690523\t 0.45468286894855586\t 0.45468286894855586\n",
            "26 \t [ 4.17159166  1.29977694 14.          0.98338203 15.          0.31941672]\t 0.9223893560576031\t 0.6458620128690523\t 0.4526428029208453\t 0.4526428029208453\n",
            "27 \t [ 6.7869298   7.33423056  8.          0.62356625 11.          0.28561393]\t 0.9246183343310115\t 0.6458620128690523\t 0.45196519968616417\t 0.45196519968616417\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7099197558902939\t 0.6458620128690523\t 0.4651336910566798\t 0.4651336910566798\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7312561878518347\t 0.6458620128690523\t 0.4512791088936608\t 0.4512791088936608\n",
            "30 \t [ 3.24299685  5.0767909  11.          0.96497977  1.          0.60484337]\t 0.7411866605831333\t 0.6458620128690523\t 0.4634197671333257\t 0.4634197671333257\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49933.520017673625"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i707LrINxei",
        "outputId": "4d68b86f-7653-47b9-97e1-dc9237bb54c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 0.4739473024786077\t 0.4739473024786077\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 0.4897084845727703\t 0.4897084845727703\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0228902128409325\t 0.7312157182363477\t 0.5015333119984576\t 0.5015333119984576\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0595990180003476\t 0.7312157182363477\t 0.5097533674663782\t 0.5097533674663782\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.5185517235379828\u001b[0m\t \u001b[1m\u001b[92m0.5185517235379828\u001b[0m\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m0.5066007615848027\u001b[0m\t \u001b[1m\u001b[92m0.5066007615843957\u001b[0m\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.0610911324495744\t 0.6519505196682808\t 0.49514047973436587\t 0.49514047973436587\n",
            "8  \t [ 7.95338906  4.97443695  6.          0.96129183 19.          0.6207097 ]\t 0.8468653810155391\t 0.6519505196682808\t 0.5032549328797143\t 0.5032549328797143\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0250396556181756\t 0.6519505196682808\t 0.5005529012976107\t 0.5005529012976107\n",
            "10 \t [ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\t 0.6832941408312798\t 0.6519505196682808\t 0.5054411469362131\t 0.5054411469362131\n",
            "11 \t [ 6.40351874  0.13565515 11.          0.58564403 18.          0.80232868]\t 0.7351278242287741\t 0.6519505196682808\t 0.4978902732365362\t 0.4978902732365362\n",
            "12 \t [ 1.03080361  6.70895845  7.          0.73336025 19.          0.31104879]\t 1.016921838187168\t 0.6519505196682808\t 0.4925776085405073\t 0.4925776085405073\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0641944470930125\t 0.6519505196682808\t 0.49688440889405067\t 0.49688440889405067\n",
            "14 \t [9.89801174 9.77563967 9.         0.68555662 3.         0.83921118]\t 0.73813303625317\t 0.6519505196682808\t 0.5023247197958894\t 0.5023247197958894\n",
            "15 \t [ 0.50127522  1.94924928 11.          0.89270197 19.          0.91286914]\t 0.6768798166626013\t 0.6519505196682808\t 0.4977421019319112\t 0.4977421019319112\n",
            "16 \t [ 8.27965778  0.50999055  5.          0.77678861 11.          0.85564655]\t 0.7905013033543324\t 0.6519505196682808\t 0.49233352279445936\t 0.49233352279445936\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.9614697348345509\t 0.6519505196682808\t 0.4902673845061405\t 0.4902673845061405\n",
            "18 \t [ 4.48555971  3.69204095  9.          0.58646272 16.          0.41216867]\t 0.9310926555739572\t 0.6519505196682808\t 0.4899533524489971\t 0.4899533524489971\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6519505196682808\t 0.49066160835657163\t 0.49066160835657163\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9398497506465855\t 0.6519505196682808\t 0.5013953649099139\t 0.5013953649099139\n",
            "21 \t [ 9.93156192  7.7870595  10.          0.99771234 15.          0.55373941]\t 0.8201615943694559\t 0.6519505196682808\t 0.507478336289218\t 0.507478336289218\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.6833221374902283\t 0.6519505196682808\t 0.4929267293530256\t 0.4929267293530256\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9387634302639226\t 0.6519505196682808\t 0.49411629811975544\t 0.49411629811975544\n",
            "24 \t [ 9.55684885  4.02134483 11.          0.82079508  6.          0.83404351]\t 0.7299947122757273\t 0.6519505196682808\t 0.4910074879451954\t 0.4910074879451954\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.6893334668436607\t 0.6519505196682808\t 0.49859056856757555\t 0.49859056856757555\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.7458275930604825\t 0.6519505196682808\t 0.4844030567309962\t 0.4844030567309962\n",
            "27 \t [4.35202159 5.24316404 7.         0.80344711 8.         0.19668159]\t 1.0598689889242516\t 0.6519505196682808\t 0.4887762707581726\t 0.4887762707581726\n",
            "28 \t [2.67216807 9.69926207 9.         0.64694239 5.         0.78751691]\t 0.7418123175221034\t 0.6519505196682808\t 0.48876802630785976\t 0.48876802630785976\n",
            "29 \t [ 1.77214312  9.25420942  5.          0.67440912 15.          0.38002389]\t 0.9607222392225847\t 0.6519505196682808\t 0.4902689164451228\t 0.4902689164451228\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.786373065109467\t 0.6519505196682808\t 0.487200395812643\t 0.487200395812643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46832.22443034189"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh0IJf8zNy9E",
        "outputId": "0d8e055d-834b-49af-a97e-f0171910675f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [ 9.55468323  6.82913854  8.          0.82455943 12.          0.31160837]\t 0.8416584500129389\t 0.6529031062312245\t 0.3902505825570243\t 0.3902505825570243\n",
            "2  \t [4.37424807 0.         5.         0.5        7.59762639 0.1       ]\t 1.0010074936588798\t 0.6529031062312245\t 0.40348521161525486\t 0.4034852116152547\n",
            "3  \t [ 9.16018191  2.71212808 10.          0.9776402  19.          0.41742389]\t 0.7822778484971837\t 0.6529031062312245\t 0.4278482720421146\t 0.4278482720421146\n",
            "4  \t [ 1.32843216  2.19353037  6.          0.94261641 13.          0.5630397 ]\t 0.7345852348176267\t 0.6529031062312245\t 0.4282802630563596\t 0.4282802630563596\n",
            "5  \t [ 6.19812193  5.75755827  5.          0.80922676 17.          0.36934488]\t 0.8870271108470653\t 0.6529031062312245\t 0.4257561865299442\t 0.4257561865299442\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 0.43250200504240055\t 0.43250200504240055\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 0.42753306789335593\t 0.42753306789335593\n",
            "8  \t [2.59969694 6.06128167 7.         0.94107568 1.         0.29258808]\t 0.8525714213670698\t 0.6529031062312245\t 0.4312647479712632\t 0.4312647479712632\n",
            "9  \t [0.19352615 0.96857518 7.         0.99703217 1.         0.36778699]\t 0.8539978950304207\t 0.6529031062312245\t 0.4343703241785102\t 0.4343703241785102\n",
            "10 \t [ 3.23063104  1.13251329 14.          0.56093148  7.          0.35241226]\t 0.8450769378247118\t 0.6529031062312245\t 0.43707587427546624\t 0.43707587427546624\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[ 8.5803984 10.        15.         1.        20.         1.       ]\u001b[0m\t \u001b[1m\u001b[92m0.64157441567256\u001b[0m\t \u001b[1m\u001b[92m0.64157441567256\u001b[0m\t \u001b[1m\u001b[92m0.4390508177542148\u001b[0m\t \u001b[1m\u001b[92m0.4390508177540546\u001b[0m\n",
            "12 \t [ 8.73271627  9.30388015 13.          0.94065667  9.          0.80274839]\t 0.6799490868442287\t 0.64157441567256\t 0.43421528019015604\t 0.43421528019015604\n",
            "13 \t [ 1.09439533  3.2006585   9.          0.50381113 19.          0.472626  ]\t 0.7984289026782336\t 0.64157441567256\t 0.43094751867723435\t 0.43094751867723435\n",
            "14 \t [ 5.05369665  2.67147005  5.          0.51290284 10.          0.64085   ]\t 0.7504591409344632\t 0.64157441567256\t 0.43145951622376627\t 0.43145951622376627\n",
            "15 \t [ 5.68512904  1.06118229  8.          0.98280719 13.          0.69447233]\t 0.6947668291504472\t 0.64157441567256\t 0.4305784448249981\t 0.4305784448249981\n",
            "16 \t [7.89296158 8.07854158 9.         0.82581845 4.         0.89844069]\t 0.6591722803339997\t 0.64157441567256\t 0.42831215901074254\t 0.42831215901074254\n",
            "17 \t [9.91439686 1.1223406  9.         0.69987447 9.         0.50079002]\t 0.7024687257866902\t 0.64157441567256\t 0.4253012785992288\t 0.4253012785992288\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.6910349298616485\t 0.64157441567256\t 0.42494497207267834\t 0.42494497207267834\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 0.9937922112122403\t 0.64157441567256\t 0.42249122651832\t 0.42249122651832\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.8385022169449027\t 0.64157441567256\t 0.42953879746211493\t 0.42953879746211493\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7015179019308584\t 0.64157441567256\t 0.4411741500038878\t 0.4411741500038878\n",
            "22 \t [ 8.54638969  0.26613927 13.          0.51657274 13.          0.48506928]\t 0.791548114972684\t 0.64157441567256\t 0.42732561473756986\t 0.42732561473756986\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.8346586316188039\t 0.64157441567256\t 0.43009086340559755\t 0.43009086340559755\n",
            "24 \t [ 8.17909255  8.95640578 13.          0.94174624  1.          0.89014148]\t 0.6509486270988182\t 0.64157441567256\t 0.43388374748353087\t 0.43388374748353087\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7621762752757402\t 0.64157441567256\t 0.42537794381769717\t 0.42537794381769717\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 0.9921424184439918\t 0.64157441567256\t 0.4293168605899571\t 0.4293168605899571\n",
            "27 \t [ 0.          0.          9.37424568  0.5        10.37424568  0.1       ]\t 0.9947053939566501\t 0.64157441567256\t 0.4386113292265351\t 0.4386113289689612\n",
            "28 \t [ 2.61920828  0.74890646 14.          0.70116142 18.          0.54069228]\t 0.6934175200009414\t 0.64157441567256\t 0.43698302578950543\t 0.43698302578950543\n",
            "29 \t [5.13805575 8.46039335 5.         0.82814397 6.         0.39527277]\t 0.833602430515404\t 0.64157441567256\t 0.4293663430031144\t 0.4293663430031144\n",
            "30 \t [ 0.17868882  0.02563999  6.          0.70125149 17.          0.2280711 ]\t 0.9950218956004317\t 0.64157441567256\t 0.444732077315212\t 0.444732077315212\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49437.905311907154"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3826dde3-fcaa-4711-cbcf-0692070a0a12"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 0.4081058654691961\t 0.4081058654691961\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 0.40396857731543717\t 0.40396857731543717\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 0.41199225472552337\t 0.41199225472552337\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 0.41040141305178446\t 0.41040141305178446\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 0.41590307611908867\t 0.41590307611908867\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 0.4145702917516164\t 0.4145702917516164\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 0.41072878259820683\t 0.41072878259820683\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 0.4154103285836257\t 0.4154103285836257\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m0.4187217078156283\u001b[0m\t \u001b[1m\u001b[92m0.41872170737793746\u001b[0m\n",
            "10 \t [ 6.33546486  6.1965483  14.          0.77082014  7.          0.18999946]\t 0.9299324411052285\t 0.6454226853941064\t 0.41454704674230525\t 0.41454704674230525\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6454226853941064\t 0.4217943201746697\t 0.4217943201746697\n",
            "12 \t [ 0.20192989  7.58476143 13.          0.98270421 14.          0.40270035]\t 0.8039385291078224\t 0.6454226853941064\t 0.42451618496353694\t 0.42451618496353694\n",
            "13 \t [ 0.22888225  1.52219033  6.          0.51713456 14.          0.15753373]\t 0.9337269032683195\t 0.6454226853941064\t 0.4256475991495072\t 0.4256475991495072\n",
            "14 \t [ 5.98690224  8.81178262 10.          0.88479084 18.          0.87962399]\t 0.6615155897240605\t 0.6454226853941064\t 0.4311134459131422\t 0.4311134459131422\n",
            "15 \t [3.63587924 9.92644255 5.         0.74785877 1.         0.42737692]\t 0.8438702768074448\t 0.6454226853941064\t 0.42721642333249304\t 0.42721642333249304\n",
            "16 \t [3.43569941 0.11776396 7.         0.67769873 2.         0.85092179]\t 0.6970572728060835\t 0.6454226853941064\t 0.4302318819445837\t 0.4302318819445837\n",
            "17 \t [2.76407972 8.95502778 9.         0.67297573 5.         0.56560976]\t 0.7213199372798768\t 0.6454226853941064\t 0.4279390259342916\t 0.4279390259342916\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9301596203801468\t 0.6454226853941064\t 0.43627411042533587\t 0.43627411042533587\n",
            "19 \t [ 1.24817982  5.75156112 12.          0.56532786 19.          0.40494625]\t 0.8104031101648417\t 0.6454226853941064\t 0.44496184737938727\t 0.44496184737938727\n",
            "20 \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]\t 0.6778496323948628\t 0.6454226853941064\t 0.4282150190862761\t 0.4282150190862761\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.713587872750312\t 0.6454226853941064\t 0.4249154594410266\t 0.4249154594410266\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.8265101138776348\t 0.6454226853941064\t 0.43245638072491904\t 0.43245638072491904\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7048213880431081\t 0.6454226853941064\t 0.42665319364517146\t 0.42665319364517146\n",
            "24 \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\t 0.6652912380850803\t 0.6454226853941064\t 0.43558770487260007\t 0.43558770487260007\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8407613659642559\t 0.6454226853941064\t 0.4218896061129626\t 0.4218896061129626\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9338663333604857\t 0.6454226853941064\t 0.4259401775418615\t 0.4259401775418615\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8100270760776773\t 0.6454226853941064\t 0.4271866013224782\t 0.4271866013224782\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.675192856271044\t 0.6454226853941064\t 0.4355440240325037\t 0.4355440240325037\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.699572467500549\t 0.6454226853941064\t 0.43556661069251074\t 0.43556661069251074\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 0.930914842449664\t 0.6454226853941064\t 0.43076231503142465\t 0.43076231503142465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51081.55924427656"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4c0bc1-f789-474d-bba9-9e5413c740dc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 0.414364935239825\t 0.414364935239825\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 0.44621643652697535\t 0.44621643652697535\n",
            "3  \t [ 8.20707753  5.23681739  9.          0.99500664 19.          0.41686889]\t 0.7862089426832719\t 0.6448358819228919\t 0.4365672696915609\t 0.4365672696915609\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 0.43618002128327243\t 0.43618002128327243\n",
            "5  \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]\t 0.7377720407232845\t 0.6448358819228919\t 0.43311588901177367\t 0.43311588901177367\n",
            "6  \t [ 2.07399013  1.08547559 13.          0.90854674 16.          0.44415088]\t 0.7854445167823974\t 0.6448358819228919\t 0.4305524031931954\t 0.4305524031931954\n",
            "7  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0517934452387856\t 0.6448358819228919\t 0.4307791878525005\t 0.43077918785105745\n",
            "8  \t [ 0.56883492  2.21937218  6.          0.84490274 16.          0.30898926]\t 0.8417982153735359\t 0.6448358819228919\t 0.4451160059092334\t 0.4451160059092334\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.788150408197674\t 0.6448358819228919\t 0.446604208792868\t 0.446604208792868\n",
            "10 \t [ 0.67105095  0.94101024 14.          0.7967074   8.          0.63229074]\t 0.6948006463812106\t 0.6448358819228919\t 0.44575455548855364\t 0.44575455548855364\n",
            "11 \t [ 7.53441733  9.89426931 12.          0.67232682 16.          0.3377491 ]\t 0.8356708666812738\t 0.6448358819228919\t 0.4418507868978672\t 0.4418507868978672\n",
            "12 \t [ 4.47453193  7.16141346  8.          0.50393935 18.          0.6896195 ]\t 0.7226637411621276\t 0.6448358819228919\t 0.443052554754021\t 0.443052554754021\n",
            "13 \t [ 3.46207476  9.83623086 13.          0.59254174 15.          0.37573299]\t 0.7964686272194577\t 0.6448358819228919\t 0.44055434780771835\t 0.44055434780771835\n",
            "14 \t [ 8.88182279  1.21247755  8.          0.57194414 15.          0.58313863]\t 0.7551157627093398\t 0.6448358819228919\t 0.44049904593834066\t 0.44049904593834066\n",
            "15 \t [6.5099841  8.70472582 8.         0.63069736 4.         0.74098062]\t 0.7182841662032551\t 0.6448358819228919\t 0.43919651999357595\t 0.43919651999357595\n",
            "16 \t [1.12068613 5.38370759 5.         0.59812309 7.         0.55127392]\t 0.7957827851423114\t 0.6448358819228919\t 0.43723651263541513\t 0.43723651263541513\n",
            "17 \t [ 4.19189824  5.69856246 15.          1.         20.          1.        ]\t 0.6505668917473632\t 0.6448358819228919\t 0.437246372247671\t 0.43724637165471597\n",
            "18 \t [ 6.28900386  8.75764894 14.          0.6787757   5.          0.37393632]\t 0.8397681012018501\t 0.6448358819228919\t 0.4333161249103975\t 0.4333161249103975\n",
            "19 \t [3.71364107 1.34189013 8.         0.86771065 9.         0.8854455 ]\t 0.6658411506285626\t 0.6448358819228919\t 0.43391274706942456\t 0.43391274706942456\n",
            "20 \t [ 5.06569568  9.95512019 10.          0.79200421  8.          0.9497448 ]\t 0.6524837713585139\t 0.6448358819228919\t 0.4320939733326756\t 0.4320939733326756\n",
            "21 \t [ 4.2953213   0.27911896 10.          0.9783586  19.          0.46300401]\t 0.7860315206098012\t 0.6448358819228919\t 0.4368255246041143\t 0.4368255246041143\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.7865928825712862\t 0.6448358819228919\t 0.4308233023354134\t 0.4308233023354134\n",
            "23 \t [10. 10. 15.  1. 20.  1.]\t 0.6505488267879174\t 0.6448358819228919\t 0.4451764420762335\t 0.44517642662584717\n",
            "24 \t [ 2.42220116  6.1788397  13.          0.64865813 10.          0.13940747]\t 1.0466026780420001\t 0.6448358819228919\t 0.4356837343004227\t 0.4356837343004227\n",
            "25 \t [2.57515952 4.90843155 5.81121657 0.5        1.         0.1       ]\t 1.0517934852889312\t 0.6448358819228919\t 0.4382554249846853\t 0.438255424984685\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.6950503015339501\t 0.6448358819228919\t 0.4406440935909706\t 0.4406440935909706\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 0.4454032716374388\t 0.4454032716374388\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 0.8375129312365261\t 0.6448358819228919\t 0.44342858681523034\t 0.44342858681523034\n",
            "29 \t [2.42401477 8.78296692 9.         0.60498241 1.         0.43587645]\t 0.7989562518109162\t 0.6448358819228919\t 0.44156570543029733\t 0.44156570543029733\n",
            "30 \t [ 6.14078962  2.31372054 11.          0.9240952  13.          0.361681  ]\t 0.8314074749252223\t 0.6448358819228919\t 0.43806613030262603\t 0.43806613030262603\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e843fbc8-a899-4dd5-8606-9897229d5659"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 0.4252219050926418\t 0.4252219050926418\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 0.41701109438766176\t 0.41701109438766176\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 0.8792946548244501\t 0.6669292375133978\t 0.41587239172629975\t 0.41587239172629975\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 0.42509730508636695\t 0.42509730508636695\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6455928988859453\u001b[0m\t \u001b[1m\u001b[92m0.6455928988859453\u001b[0m\t \u001b[1m\u001b[92m0.4209611765717424\u001b[0m\t \u001b[1m\u001b[92m0.4209611765717424\u001b[0m\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 0.8210163484458256\t 0.6455928988859453\t 0.4149173727183459\t 0.4149173727183459\n",
            "7  \t [ 3.62490684  2.84275183 14.          0.74589397  2.          0.75096489]\t 0.6670230975290341\t 0.6455928988859453\t 0.41848821193287344\t 0.41848821193287344\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7069523757910561\t 0.6455928988859453\t 0.4144972496914829\t 0.4144972496914829\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.661096368919013\t 0.6455928988859453\t 0.41264745199170655\t 0.41264745199170655\n",
            "10 \t [ 3.30148079  9.88907038 12.          0.72868817  1.          0.65479477]\t 0.6997345104361262\t 0.6455928988859453\t 0.40939500296101317\t 0.40939500296101317\n",
            "11 \t [ 7.71064959  9.96207932 10.          0.59477685 12.          0.11554071]\t 0.8835980337648006\t 0.6455928988859453\t 0.4078638563609076\t 0.4078638563609076\n",
            "12 \t [2.09526391 0.         6.28082505 0.5        9.28082505 0.1       ]\t 0.8821767837924288\t 0.6455928988859453\t 0.4132649990992661\t 0.4132649990992661\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         13.73223735  1.          6.73223735  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6418479660754709\u001b[0m\t \u001b[1m\u001b[92m0.6418479660754709\u001b[0m\t \u001b[1m\u001b[92m0.4179114885333607\u001b[0m\t \u001b[1m\u001b[92m0.41791148583480553\u001b[0m\n",
            "14 \t [ 3.89768175  5.29572603  8.          0.92074245 11.          0.31486353]\t 0.8106110145898601\t 0.6418479660754709\t 0.41461518425553123\t 0.41461518425553123\n",
            "15 \t [ 0.07808224  6.49649777 13.          0.58750637 14.          0.83487235]\t 0.6660901372736843\t 0.6418479660754709\t 0.4164131357067501\t 0.4164131357067501\n",
            "16 \t [ 0.04708663  5.63008151  7.          0.89049451 16.          0.24468474]\t 0.8805243043062951\t 0.6418479660754709\t 0.41402262943291807\t 0.41402262943291807\n",
            "17 \t [0.54815519 9.09457687 7.         0.55756737 9.         0.32110491]\t 0.8160888137431301\t 0.6418479660754709\t 0.41738069059358407\t 0.41738069059358407\n",
            "18 \t [ 6.17394409  4.04114422 10.          0.65058545  1.          0.14583054]\t 0.884659950113891\t 0.6418479660754709\t 0.42793166506004804\t 0.42793166506004804\n",
            "19 \t [ 1.75909042  8.50460179 10.          0.61596511  8.          0.92202704]\t 0.6552140243198975\t 0.6418479660754709\t 0.43404435963755417\t 0.43404435963755417\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 0.8804917195016874\t 0.6418479660754709\t 0.4230979478579876\t 0.4230979478579876\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7119792503375972\t 0.6418479660754709\t 0.4240230195727318\t 0.4240230195727318\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 0.8840919924947371\t 0.6418479660754709\t 0.4222579871725613\t 0.4222579871725613\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.6539666670983036\t 0.6418479660754709\t 0.4226307347080368\t 0.4226307347080368\n",
            "24 \t [ 2.44191194  3.33063319 11.          0.65513922  6.          0.45905506]\t 0.7450791968566186\t 0.6418479660754709\t 0.42597839501071927\t 0.42597839501071927\n",
            "25 \t [ 9.03172065  9.67970196  7.          0.96197904 17.          0.43267247]\t 0.7430943297217871\t 0.6418479660754709\t 0.4271288326276404\t 0.4271288326276404\n",
            "26 \t [10.         10.         15.          1.         15.00990788  1.        ]\t 0.6443484935444447\t 0.6418479660754709\t 0.42633570644307106\t 0.4263356181232198\n",
            "27 \t [ 9.40854499  7.80841653 11.          0.95953726  2.          0.65169631]\t 0.6921338634127544\t 0.6418479660754709\t 0.4195481086253582\t 0.4195481086253582\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 0.8822650514974324\t 0.6418479660754709\t 0.41580395347205035\t 0.41580395347205035\n",
            "29 \t [ 7.25858886  0.05284455 11.          0.66498317  6.          0.51372905]\t 0.7081124510423997\t 0.6418479660754709\t 0.4239429221756629\t 0.4239429221756629\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.81181886510441\t 0.6418479660754709\t 0.42651041242387006\t 0.42651041242387006\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49767.57796170873"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd831b2-7498-446f-8c78-5550625864df"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 0.3988356298884882\t 0.3988356298884882\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.39770645005489763\u001b[0m\t \u001b[1m\u001b[92m0.39770645005489763\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 0.3928867207707597\t 0.3928867207707597\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 0.9235319432135773\t 0.6577294425265764\t 0.3966024234200432\t 0.3966024234200432\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 8.67505649  9.5012475  12.82893091  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6379572694545345\u001b[0m\t \u001b[1m\u001b[92m0.6379572694545345\u001b[0m\t \u001b[1m\u001b[92m0.41063660017783604\u001b[0m\t \u001b[1m\u001b[92m0.4106366001778257\u001b[0m\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.6922630708519245\t 0.6379572694545345\t 0.40530928870783073\t 0.40530928870783073\n",
            "7  \t [8.5599695  9.54840342 6.         0.73281277 1.         0.77796226]\t 0.7154523071123053\t 0.6379572694545345\t 0.4030539608747522\t 0.4030539608747522\n",
            "8  \t [0.50746251 9.37264814 7.         0.59739834 4.         0.27068294]\t 0.8761103353410163\t 0.6379572694545345\t 0.4024938418388631\t 0.4024938418388631\n",
            "9  \t [0.  0.  5.  0.5 1.  0.1]\t 0.9342890171193261\t 0.6379572694545345\t 0.40917657039221045\t 0.4091765703922019\n",
            "10 \t [ 1.06054513  2.23745512 13.          0.92745502  9.          0.16992758]\t 0.9226798533243917\t 0.6379572694545345\t 0.4177032305537556\t 0.4177032305537556\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.8864529961319944\t 0.6379572694545345\t 0.4243622322999283\t 0.4243622322999283\n",
            "12 \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]\t 0.9231023673501877\t 0.6379572694545345\t 0.42858165248310287\t 0.42858165248310287\n",
            "13 \t [ 9.1224192   0.14577581 10.          0.79058624  9.          0.93264556]\t 0.6536325607956057\t 0.6379572694545345\t 0.43381404510313565\t 0.43381404510313565\n",
            "14 \t [ 6.98012979  9.70420514 13.          0.5373863  14.          0.73047943]\t 0.7019688866391167\t 0.6379572694545345\t 0.43006192570863383\t 0.43006192570863383\n",
            "15 \t [ 2.15117289  9.9737351  13.          0.92054036 19.          0.17057887]\t 0.9220444895634238\t 0.6379572694545345\t 0.4275131462135653\t 0.4275131462135653\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7068100593711837\t 0.6379572694545345\t 0.4321950386349318\t 0.4321950386349318\n",
            "17 \t [6.84259942 4.32103035 5.         0.56696926 3.         0.18577896]\t 0.932783668551836\t 0.6379572694545345\t 0.4303576762283642\t 0.4303576762283642\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.698358780864823\t 0.6379572694545345\t 0.4342241174446522\t 0.4342241174446522\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 0.9265282654642244\t 0.6379572694545345\t 0.43309618340276484\t 0.43309618340276484\n",
            "20 \t [0.56806539 7.69746805 6.         0.94796222 9.         0.37129588]\t 0.8772298745282174\t 0.6379572694545345\t 0.44184685733422985\t 0.44184685733422985\n",
            "21 \t [ 3.32966927  6.72206515 14.          0.83912863 18.          0.84659432]\t 0.6883249973001357\t 0.6379572694545345\t 0.44437446751479986\t 0.44437446751479986\n",
            "22 \t [3.9771337  2.1194538  8.         0.99912274 6.         0.12579719]\t 0.9220848297716273\t 0.6379572694545345\t 0.43996174872879223\t 0.43996174872879223\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7418835369809943\t 0.6379572694545345\t 0.45346673966453643\t 0.45346673966453643\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.8686347965869988\t 0.6379572694545345\t 0.4433394723349813\t 0.4433394723349813\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 0.9247656684808231\t 0.6379572694545345\t 0.4391228244130939\t 0.4391228244130939\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.764405864026175\t 0.6379572694545345\t 0.45323161524321837\t 0.45323161524321837\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7332555811634872\t 0.6379572694545345\t 0.444460316384569\t 0.444460316384569\n",
            "28 \t [ 6.68138453  0.2955558   6.          0.96090271 10.          0.14408308]\t 0.9276546535784822\t 0.6379572694545345\t 0.4408905432000194\t 0.4408905432000194\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.6600116767225708\t 0.6379572694545345\t 0.4416034147435306\t 0.4416034147435306\n",
            "30 \t [ 8.69363194  5.58726529 10.          0.7161638  14.          0.98763741]\t 0.6573177381041478\t 0.6379572694545345\t 0.44858561064836816\t 0.44858561064836816\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50731.823425048555"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7d9ccb-68a7-4e69-b737-adfe452bd01a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 0.43846609351717214\t 0.43846609351717214\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10.          7.27377669 10.6363985   1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6540301941887037\u001b[0m\t \u001b[1m\u001b[92m0.6540301941887037\u001b[0m\t \u001b[1m\u001b[92m0.4341418056759192\u001b[0m\t \u001b[1m\u001b[92m0.4341418056759192\u001b[0m\n",
            "3  \t [ 7.48458025  0.82585105 14.          0.62666135 18.          0.34757206]\t 0.7923560070207463\t 0.6540301941887037\t 0.42441501673964754\t 0.42441501673964754\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.8009366885878899\t 0.6540301941887037\t 0.42598907801540764\t 0.42598907801540764\n",
            "5  \t [ 5.83217552  8.53843574 11.          0.58549752 18.          0.26781236]\t 0.7937241882253031\t 0.6540301941887037\t 0.4277494171637389\t 0.4277494171637389\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.7872412218199303\t 0.6540301941887037\t 0.4287450156469885\t 0.4287450156469885\n",
            "7  \t [ 9.92159613  3.53760601 14.          0.66495754  4.          0.92098158]\t 0.7037336633700015\t 0.6540301941887037\t 0.4292280255548008\t 0.4292280255548008\n",
            "8  \t [ 1.25868956  0.22795824 11.          0.81986474  9.          0.64717158]\t 0.695450831468692\t 0.6540301941887037\t 0.42594414048551604\t 0.42594414048551604\n",
            "9  \t [ 2.73067092  9.86029136  9.          0.98915314 11.          0.78920814]\t 0.693545230998452\t 0.6540301941887037\t 0.422825416168138\t 0.422825416168138\n",
            "10 \t [ 0.14475494  9.8292754  12.          0.60331385  2.          0.9622215 ]\t 0.7073584311311387\t 0.6540301941887037\t 0.4200640161808332\t 0.4200640161808332\n",
            "11 \t [ 1.81539004  3.97973122 11.          0.55780808 14.          0.86016605]\t 0.7041682587723528\t 0.6540301941887037\t 0.4181250092998395\t 0.4181250092998395\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.7202487480474815\t 0.6540301941887037\t 0.4163184673861381\t 0.4163184673861381\n",
            "13 \t [ 6.90129968  1.22715242 14.          0.66551675  8.          0.14885541]\t 0.9268098747337306\t 0.6540301941887037\t 0.4152167882484771\t 0.4152167882484771\n",
            "14 \t [8.72042964 1.18098427 6.         0.87093363 1.         0.1200865 ]\t 0.930151934795418\t 0.6540301941887037\t 0.4211366564478764\t 0.4211366564478764\n",
            "15 \t [ 8.84534507  8.61072725  6.          0.70366548 19.          0.12607791]\t 0.929431740491148\t 0.6540301941887037\t 0.4264281335052089\t 0.4264281335052089\n",
            "16 \t [0.         1.53887053 5.         0.5        1.         0.1       ]\t 0.9380339511614821\t 0.6540301941887037\t 0.4311229138742941\t 0.4311229112625779\n",
            "17 \t [ 2.38620183  1.03950496 13.          0.6257051   6.          0.34211692]\t 0.7949227225244432\t 0.6540301941887037\t 0.4357799197869588\t 0.4357799197869588\n",
            "18 \t [ 9.66419595  5.21985973  6.          0.59246694 13.          0.24342225]\t 0.9308052505637308\t 0.6540301941887037\t 0.43991456440073673\t 0.43991456440073673\n",
            "19 \t [ 4.82116392  7.94441114 13.          0.79896359 10.          0.94409065]\t 0.6965786487707983\t 0.6540301941887037\t 0.442913216946458\t 0.442913216946458\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.6540301941887037\t 0.4359634560163773\t 0.4359634560163773\n",
            "21 \t [ 1.31543985  7.56963465  9.          0.65553666 19.          0.70845471]\t 0.7028718248487947\t 0.6540301941887037\t 0.43366124097941644\t 0.43366124097941644\n",
            "22 \t [ 4.22119996  7.99655483  5.          0.78307763 14.          0.79061697]\t 0.7405746569621561\t 0.6540301941887037\t 0.4440152360946871\t 0.4440152360946871\n",
            "23 \t [ 9.39056075  5.8448496  10.          0.68658632  9.          0.39035966]\t 0.7745690312005094\t 0.6540301941887037\t 0.4387216927267245\t 0.4387216927267245\n",
            "24 \t [ 3.54377146  1.55114788  9.          0.60325108 18.          0.58026864]\t 0.7288271346270945\t 0.6540301941887037\t 0.4310031211764811\t 0.4310031211764811\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9328823718301782\t 0.6540301941887037\t 0.43925188276656507\t 0.43925188276656507\n",
            "26 \t [ 1.0206155   0.50876351 11.          0.82996077 17.          0.80891943]\t 0.6931022492573785\t 0.6540301941887037\t 0.44803807248691535\t 0.44803807248691535\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.650360917790661\u001b[0m\t \u001b[1m\u001b[92m0.650360917790661\u001b[0m\t \u001b[1m\u001b[92m0.4448119312345665\u001b[0m\t \u001b[1m\u001b[92m0.44481214614829656\u001b[0m\n",
            "28 \t [6.03395923 5.04528992 9.         0.51562369 6.         0.58948876]\t 0.7337956797757847\t 0.650360917790661\t 0.437973826055471\t 0.437973826055471\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.7292686946198735\t 0.650360917790661\t 0.43899752537002895\t 0.43899752537002895\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.9256181718283066\t 0.650360917790661\t 0.433185910457672\t 0.433185910457672\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49876.69652464331"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea94d5a-88e9-4948-e2ea-00cf55d06aae"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 0.5072064891744983\t 0.5072064891744983\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.6734860180774931\t 0.6628876451121497\t 0.4906091691299594\t 0.4906091691299594\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.6628876451121497\t 0.4754030535780008\t 0.4754030535780008\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.6797825903178236\t 0.6628876451121497\t 0.4692323116995156\t 0.4692323116995156\n",
            "5  \t [0.         0.         5.         0.5        7.86383038 0.1       ]\t 1.099828942687583\t 0.6628876451121497\t 0.45969722684220765\t 0.45969722684220765\n",
            "6  \t [ 7.68636788  7.27927184 12.          0.97932089  3.          0.87363673]\t 0.6657443951678294\t 0.6628876451121497\t 0.47639939794032954\t 0.47639939794032954\n",
            "7  \t [ 1.83205559  5.96122477  9.          0.60293091 14.          0.2543724 ]\t 0.9191321113264156\t 0.6628876451121497\t 0.46751729890480337\t 0.46751729890480337\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1062273028353988\t 0.6628876451121497\t 0.4709111009549569\t 0.4709111009549569\n",
            "9  \t [9.82022331 2.48941517 7.         0.64964742 8.         0.44060186]\t 0.8227498001206589\t 0.6628876451121497\t 0.48302492236582034\t 0.48302492236582034\n",
            "10 \t [ 6.60596124  8.35313787  6.          0.72167152 19.          0.94552853]\t 0.7025896131486131\t 0.6628876451121497\t 0.48098217843978924\t 0.48098217843978924\n",
            "11 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0998776154616823\t 0.6628876451121497\t 0.4753145348428307\t 0.47531453484283004\n",
            "12 \t [ 9.65518672  0.13040633  6.          0.63296628 18.          0.44133279]\t 0.8313881881531572\t 0.6628876451121497\t 0.48455641768592084\t 0.48455641768592084\n",
            "13 \t [ 7.77142802  6.85788776  8.          0.58776826 12.          0.54100185]\t 0.732296187069162\t 0.6628876451121497\t 0.48304256650902905\t 0.48304256650902905\n",
            "14 \t [ 6.64335896  4.21317694 13.          0.67704359  4.          0.77970128]\t 0.6746732785820976\t 0.6628876451121497\t 0.47896989283979086\t 0.47896989283979086\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.6628876451121497\t 0.47398261594167157\t 0.47398261594167157\n",
            "\u001b[1m\u001b[92m16\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         18.98268304  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6476667557756681\u001b[0m\t \u001b[1m\u001b[92m0.6476667557756681\u001b[0m\t \u001b[1m\u001b[92m0.46924232137071614\u001b[0m\t \u001b[1m\u001b[92m0.46924232137071614\u001b[0m\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.105080285400748\t 0.6476667557756681\t 0.4657193352870024\t 0.4657193352870024\n",
            "18 \t [2.57352577 0.33719112 9.         0.97251025 4.         0.51947396]\t 0.7203223434212329\t 0.6476667557756681\t 0.47310402536278484\t 0.47310402536278484\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.0995998424487943\t 0.6476667557756681\t 0.4691234011374783\t 0.4691234011374783\n",
            "20 \t [7.78054327e-03 3.05674801e+00 1.40000000e+01 9.86996551e-01\n",
            " 1.60000000e+01 3.30836599e-01]\t 0.9201059801130411\t 0.6476667557756681\t 0.47545101133877815\t 0.47545101133877815\n",
            "21 \t [4.43762845 4.57483662 7.         0.94265707 5.         0.33245902]\t 0.9143862631824987\t 0.6476667557756681\t 0.4741653762580332\t 0.4741653762580332\n",
            "22 \t [4.74151988e-03 7.73535708e+00 9.00000000e+00 8.10214170e-01\n",
            " 7.00000000e+00 8.51111303e-01]\t 0.6741140944144826\t 0.6476667557756681\t 0.4876188009087413\t 0.4876188009087413\n",
            "23 \t [3.55859061 5.61875163 8.         0.5882063  1.         0.57036163]\t 0.7346535405920693\t 0.6476667557756681\t 0.4851889220662602\t 0.4851889220662602\n",
            "24 \t [ 0.2594182   8.03698568 14.          0.55642831  5.          0.91542841]\t 0.6724111162410003\t 0.6476667557756681\t 0.47961739755660854\t 0.47961739755660854\n",
            "25 \t [9.92248648 8.73301847 7.         0.58578431 6.         0.64802898]\t 0.7258609233436316\t 0.6476667557756681\t 0.47131150423573426\t 0.47131150423573426\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.672888499874982\t 0.6476667557756681\t 0.4703883024965134\t 0.4703883024965134\n",
            "27 \t [ 5.85240254  2.29607078  6.          0.83156764 14.          0.75611542]\t 0.7093200501398801\t 0.6476667557756681\t 0.46679071559611196\t 0.46679071559611196\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.768583852631927\t 0.6476667557756681\t 0.46074398148397433\t 0.46074398148397433\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9197610970890002\t 0.6476667557756681\t 0.4644556662316001\t 0.4644556662316001\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.9166993865744176\t 0.6476667557756681\t 0.46228479008492396\t 0.46228479008492396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49047.4697426364"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3a94cc-7ffc-4aa9-b5d3-abb61eed949d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 0.46598938625837255\t 0.46598938625837255\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.9571856949825378\t 0.6747866005380063\t 0.4826080329497747\t 0.4826080329497747\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6747866005380063\t 0.4893078002788662\t 0.4893078002788662\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6747866005380063\t 0.47899966820581485\t 0.47899966820581485\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9600990595782894\t 0.6747866005380063\t 0.4883428969249194\t 0.4883428969249194\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 1.0131910395518218\t 0.6747866005380063\t 0.4925954228765506\t 0.4925954228765506\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7242608483603965\t 0.6747866005380063\t 0.49895685483358193\t 0.49895685483358193\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 7.13077184  9.67534636 12.          0.53994085 17.          0.99732292]\u001b[0m\t \u001b[1m\u001b[92m0.6733183778157861\u001b[0m\t \u001b[1m\u001b[92m0.6733183778157861\u001b[0m\t \u001b[1m\u001b[92m0.4914250586286439\u001b[0m\t \u001b[1m\u001b[92m0.4914250586286439\u001b[0m\n",
            "9  \t [ 4.99777324  7.1255563   5.          0.87428718 19.          0.63814647]\t 0.7320174755578019\t 0.6733183778157861\t 0.4832412589977475\t 0.4832412589977475\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.697395180788185\t 0.6733183778157861\t 0.47799255957426845\t 0.47799255957426845\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[ 2.67348935  9.63015736 15.          1.          3.27730534  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6494078889322195\u001b[0m\t \u001b[1m\u001b[92m0.6494078889322195\u001b[0m\t \u001b[1m\u001b[92m0.47233479742974505\u001b[0m\t \u001b[1m\u001b[92m0.4723347951563555\u001b[0m\n",
            "12 \t [ 1.87613733  0.3867672  10.          0.63542614  2.          0.41568093]\t 0.8195578782244798\t 0.6494078889322195\t 0.4660133739891588\t 0.4660133739891588\n",
            "13 \t [ 9.52967585  8.1936199  11.          0.55796294 10.          0.99729185]\t 0.6733311328695132\t 0.6494078889322195\t 0.4651926400130786\t 0.4651926400130786\n",
            "14 \t [ 0.14006525  1.03750573 13.          0.72168802 14.          0.72400369]\t 0.67689133219431\t 0.6494078889322195\t 0.46047462080974766\t 0.46047462080974766\n",
            "15 \t [ 4.60180761  5.86373927 12.          0.57860802 15.          0.61913601]\t 0.7198975715482087\t 0.6494078889322195\t 0.4563349429229514\t 0.4563349429229514\n",
            "16 \t [ 6.17398984  7.07288493 12.          0.63300963  8.          0.36188703]\t 0.9625825839575025\t 0.6494078889322195\t 0.45369629114729815\t 0.45369629114729815\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.7105097809499443\t 0.6494078889322195\t 0.45725854739672583\t 0.45725854739672583\n",
            "18 \t [1.97879228 8.99345507 8.         0.55562265 8.         0.49118331]\t 0.8134492450677617\t 0.6494078889322195\t 0.46182320004662863\t 0.46182320004662863\n",
            "19 \t [ 2.09007555  7.86113915 13.          0.73459776 19.          0.32750702]\t 0.9574373954877385\t 0.6494078889322195\t 0.4646888709793793\t 0.4646888709793793\n",
            "20 \t [ 1.65783574  0.06450124 14.          0.84574925  8.          0.63962887]\t 0.673073219622785\t 0.6494078889322195\t 0.4622709124630649\t 0.4622709124630649\n",
            "21 \t [4.16561464 4.3151821  6.         0.76299318 2.         0.59049538]\t 0.7439602970032533\t 0.6494078889322195\t 0.46416011896685117\t 0.46416011896685117\n",
            "22 \t [10. 10. 15.  1. 20.  1.]\t 0.6502979285238808\t 0.6494078889322195\t 0.4590128514808504\t 0.45901284923184044\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 1.008805594135994\t 0.6494078889322195\t 0.4573312776746671\t 0.4573312776746671\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.6871807270632571\t 0.6494078889322195\t 0.4559775801163185\t 0.4559775801163185\n",
            "25 \t [ 1.51961568  8.70421801  5.          0.99750159 15.          0.60985883]\t 0.7613941242589393\t 0.6494078889322195\t 0.4619145724698298\t 0.4619145724698298\n",
            "26 \t [ 5.73005003  1.18628884 13.          0.88016467 12.          0.48547975]\t 0.8109689394932417\t 0.6494078889322195\t 0.45448935316800804\t 0.45448935316800804\n",
            "27 \t [8.60914739 9.54673859 7.         0.78963544 7.         0.48348756]\t 0.815291878276993\t 0.6494078889322195\t 0.4529633637385563\t 0.4529633637385563\n",
            "28 \t [ 2.62398972  4.9810834  13.          0.9301268   3.          0.39611817]\t 0.8199554258125602\t 0.6494078889322195\t 0.44889656408702255\t 0.44889656408702255\n",
            "29 \t [ 7.16352089  0.19968156 11.          0.62318898  8.          0.21107406]\t 1.013079448285806\t 0.6494078889322195\t 0.451057007500837\t 0.451057007500837\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.6762301508489591\t 0.6494078889322195\t 0.46474178152233814\t 0.46474178152233814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52576.92115809613"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96f0cd3-0210-4bca-fdc4-1885a40da421"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 0.4554698726083567\t 0.4554698726083567\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 0.44176715623384244\t 0.44176715623384244\n",
            "3  \t [ 9.6900225   0.69761314 13.          0.54877119 16.          0.55532692]\t 0.676755395441882\t 0.6568473525973234\t 0.4464129488556526\t 0.4464129488556526\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.8615658015198442\t 0.6568473525973234\t 0.43792203423229276\t 0.43792203423229276\n",
            "5  \t [ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\t 0.730615339433918\t 0.6568473525973234\t 0.4421961340823954\t 0.4421961340823954\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.8514677232156771\t 0.6568473525973234\t 0.43841674012400966\t 0.43841674012400966\n",
            "7  \t [ 9.09795503  1.07150197  7.          0.98191679 19.          0.62951892]\t 0.6952220627574484\t 0.6568473525973234\t 0.4413173387860481\t 0.4413173387860481\n",
            "8  \t [ 8.63880631  5.06396165 13.          0.58410058  1.          0.41865338]\t 0.8085010839601445\t 0.6568473525973234\t 0.4367832392005582\t 0.4367832392005582\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.7097411329660293\t 0.6568473525973234\t 0.43746671268976245\t 0.43746671268976245\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         14.94793326  1.         11.94793326  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6463125386249665\u001b[0m\t \u001b[1m\u001b[92m0.6463125386249665\u001b[0m\t \u001b[1m\u001b[92m0.4343355177492322\u001b[0m\t \u001b[1m\u001b[92m0.43433551774921153\u001b[0m\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.6638601166418586\t 0.6463125386249665\t 0.4295833759350002\t 0.4295833759350002\n",
            "12 \t [ 9.64496659  9.57963322 10.          0.94492464 10.          0.37804844]\t 0.7837998757691783\t 0.6463125386249665\t 0.42589924344496144\t 0.42589924344496144\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.6855937848974291\t 0.6463125386249665\t 0.42618277904494356\t 0.42618277904494356\n",
            "14 \t [10. 10. 15.  1. 20.  1.]\t 0.6491916518522693\t 0.6463125386249665\t 0.42372126045316755\t 0.4237212594409628\n",
            "15 \t [ 0.16461509  2.47453913  6.          0.69159787 16.          0.61162096]\t 0.7243032673932515\t 0.6463125386249665\t 0.42050324054725485\t 0.42050324054725485\n",
            "16 \t [1.58135563 6.14676537 7.         0.58599454 7.         0.37032959]\t 0.8586845884175147\t 0.6463125386249665\t 0.41951834797102777\t 0.41951834797102777\n",
            "17 \t [4.50435964 1.42883317 8.         0.76583339 3.         0.4306355 ]\t 0.7929882304105694\t 0.6463125386249665\t 0.42267100990890555\t 0.42267100990890555\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.6653785933459865\t 0.6463125386249665\t 0.4194742798623318\t 0.4194742798623318\n",
            "19 \t [ 9.64875283  9.32176949  8.          0.85263567 19.          0.33410227]\t 0.849585847576698\t 0.6463125386249665\t 0.4208081711739737\t 0.4208081711739737\n",
            "20 \t [ 5.31037667  6.81676807  5.          0.53020463 18.          0.21260061]\t 0.9149718789671064\t 0.6463125386249665\t 0.4322830039207812\t 0.4322830039207812\n",
            "21 \t [10.          2.73232205 14.92186549  1.         19.92186549  1.        ]\t 0.6479723881006704\t 0.6463125386249665\t 0.43670724402547667\t 0.43670706159155753\n",
            "22 \t [ 4.90087649  7.40954674 11.          0.53028779  8.          0.43614982]\t 0.7965594035331703\t 0.6463125386249665\t 0.4266536347908174\t 0.4266536347908174\n",
            "23 \t [ 1.04966198  1.72140723 11.          0.68060657  8.          0.5044115 ]\t 0.671250212686766\t 0.6463125386249665\t 0.42883991207784095\t 0.42883991207784095\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.756031776613528\t 0.6463125386249665\t 0.4281948169554334\t 0.4281948169554334\n",
            "25 \t [ 1.719002    1.73903169  5.          0.87805761 14.          0.46260902]\t 0.8248486263986295\t 0.6463125386249665\t 0.4363831576993692\t 0.4363831576993692\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.8070679905812153\t 0.6463125386249665\t 0.4340191303329229\t 0.4340191303329229\n",
            "27 \t [ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]\t 0.659126679409869\t 0.6463125386249665\t 0.43098287002200636\t 0.43098287002200636\n",
            "28 \t [0.         0.70837277 5.         0.5        8.49071851 0.1       ]\t 0.9161068736690398\t 0.6463125386249665\t 0.4247792775109661\t 0.42477927170948515\n",
            "29 \t [ 2.27601751  8.37986432  6.          0.63312332 14.          0.21259169]\t 0.9131057510002976\t 0.6463125386249665\t 0.4235985747757001\t 0.4235985747757001\n",
            "30 \t [ 5.49283486  0.14349186 11.          0.52303405 19.          0.41411835]\t 0.7943810197692028\t 0.6463125386249665\t 0.4318037954207195\t 0.4318037954207195\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49563.56629739273"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10057f66-d00d-4ca4-e5fe-7a62c34a9b62"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.5185425487143045\u001b[0m\t \u001b[1m\u001b[92m0.5185425487143045\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 0.49803901694706165\t 0.49803901694706165\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 0.49583699075991516\t 0.49583699075991516\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 0.49321884966564666\t 0.49321884966564666\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 0.4966653172414641\t 0.4966653172414641\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 0.49472065129760195\t 0.49472065129760195\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 0.48708745956026017\t 0.48708745956026017\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.7620148611738933\t 0.6878693399983744\t 0.49084619270769453\t 0.49084619270769453\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.4857827996029166\u001b[0m\t \u001b[1m\u001b[92m0.4857827996029166\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7199718018091047\t 0.6730441336589406\t 0.47850118150980303\t 0.47850118150980303\n",
            "11 \t [ 3.92379693  5.26427008  7.          0.52294127 13.          0.66328071]\t 0.7482193144353987\t 0.6730441336589406\t 0.47349943871790756\t 0.47349943871790756\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 0.4699767009517688\t 0.4699767009517688\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9761208022264058\t 0.6730441336589406\t 0.4657603445275102\t 0.46576034452563225\n",
            "14 \t [ 5.41155711  5.82534705 10.          0.62444801 12.          0.48368067]\t 0.8667049733212127\t 0.6730441336589406\t 0.47011637582543836\t 0.47011637582543836\n",
            "15 \t [ 3.80611843  6.00578786 13.          0.99755611 17.          0.8390553 ]\t 0.674115404745782\t 0.6730441336589406\t 0.4705820589491322\t 0.4705820589491322\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6730441336589406\t 0.4661319958527451\t 0.4661319958527451\n",
            "17 \t [ 0.21149048  9.62450412 13.          0.59110309 11.          0.7784724 ]\t 0.6874818585611984\t 0.6730441336589406\t 0.46432528752467384\t 0.46432528752467384\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 0.8703303423168164\t 0.6730441336589406\t 0.4683999665266284\t 0.4683999665266284\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 0.8664298555004347\t 0.6730441336589406\t 0.4607319106835632\t 0.4607319106835632\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.8073058384557079\t 0.6730441336589406\t 0.4758473746685937\t 0.4758473746685937\n",
            "21 \t [ 9.56073795  5.10603834 10.          0.97339183  6.          0.73852605]\t 0.7185412612177071\t 0.6730441336589406\t 0.4690936128073762\t 0.4690936128073762\n",
            "22 \t [ 9.03366199  7.80955039  7.          0.58807038 16.          0.37530235]\t 0.8718032531648561\t 0.6730441336589406\t 0.4566237804514861\t 0.4566237804514861\n",
            "23 \t [ 1.30643471  9.21858448  9.          0.51787301 19.          0.17653473]\t 0.9732754583939892\t 0.6730441336589406\t 0.459912394456718\t 0.459912394456718\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 2.91558366  9.40302939 14.          0.60718476  6.          0.89915876]\u001b[0m\t \u001b[1m\u001b[92m0.6633813585457923\u001b[0m\t \u001b[1m\u001b[92m0.6633813585457923\u001b[0m\t \u001b[1m\u001b[92m0.46618908080870713\u001b[0m\t \u001b[1m\u001b[92m0.46618908080870713\u001b[0m\n",
            "\u001b[1m\u001b[92m25\u001b[0m\t \u001b[1m\u001b[92m[ 1.2601232   9.9585863  10.          0.70525992  2.          0.9880166 ]\u001b[0m\t \u001b[1m\u001b[92m0.6631852367566748\u001b[0m\t \u001b[1m\u001b[92m0.6631852367566748\u001b[0m\t \u001b[1m\u001b[92m0.4624859489480246\u001b[0m\t \u001b[1m\u001b[92m0.4624859489480246\u001b[0m\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 0.8623919725421392\t 0.6631852367566748\t 0.4589990154339881\t 0.4589990154339881\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.7206151175283746\t 0.6631852367566748\t 0.4645580037650783\t 0.4645580037650783\n",
            "28 \t [1.37294589 2.61228134 9.         0.89667199 1.         0.42044841]\t 0.8676686566935652\t 0.6631852367566748\t 0.45397106094825845\t 0.45397106094825845\n",
            "29 \t [ 1.58467279  1.68272877 13.          0.86101343 12.          0.4100987 ]\t 0.8613126520852274\t 0.6631852367566748\t 0.463425225029403\t 0.463425225029403\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6493784945243817\u001b[0m\t \u001b[1m\u001b[92m0.6493784945243817\u001b[0m\t \u001b[1m\u001b[92m0.4624746625024278\u001b[0m\t \u001b[1m\u001b[92m0.46247494455911214\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50307.652362955014"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0351747c-9dad-4283-a970-3a8142a6bbc1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 0.45190987401032423\t 0.45190987401032423\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 0.4565532206639616\t 0.4565532206639616\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 0.45273320108093484\t 0.45273320108093484\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 0.4465389389754202\t 0.4465389389754202\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 0.4569907524819502\t 0.4569907524819502\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 0.45855958031516414\t 0.45855958031516414\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 0.4587595880923709\t 0.4587595880923709\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 0.45542615125174324\t 0.45542615125174324\n",
            "9  \t [9.85206608 0.28191822 5.         0.52457928 8.         0.84714334]\t 0.7819517369688569\t 0.7141038418197827\t 0.45828048676296895\t 0.45828048676296895\n",
            "10 \t [ 0.2191332   8.51773955  5.          0.60657578 15.          0.49735822]\t 0.8316281392969092\t 0.7141038418197827\t 0.45517266794214023\t 0.45517266794214023\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 0.4553902117386412\t 0.4553902117386412\n",
            "12 \t [0.95504342 7.30424524 8.         0.76682007 6.         0.21761275]\t 0.9667342747401506\t 0.7141038418197827\t 0.455846220428504\t 0.455846220428504\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         17.20867128  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6462975059517682\u001b[0m\t \u001b[1m\u001b[92m0.6462975059517682\u001b[0m\t \u001b[1m\u001b[92m0.46046613945784154\u001b[0m\t \u001b[1m\u001b[92m0.4604661228443509\u001b[0m\n",
            "14 \t [ 7.35111323  4.42247898 14.          0.92954426  7.          0.31778445]\t 0.8561431043387969\t 0.6462975059517682\t 0.454464398501293\t 0.454464398501293\n",
            "15 \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]\t 0.8751160002928657\t 0.6462975059517682\t 0.45564510767790484\t 0.45564510767790484\n",
            "16 \t [ 5.22074709  0.74229772 13.          0.87455275  7.          0.44305495]\t 0.8053149455389029\t 0.6462975059517682\t 0.4578308616717999\t 0.4578308616717999\n",
            "17 \t [4.28909467 2.95396152 7.         0.61833417 1.         0.26051641]\t 0.8651717443623994\t 0.6462975059517682\t 0.4551574911791011\t 0.4551574911791011\n",
            "18 \t [ 4.89792246 10.          7.75863264  1.         17.75863264  1.        ]\t 0.675296473350069\t 0.6462975059517682\t 0.4541556103355207\t 0.45415561033439705\n",
            "19 \t [ 4.97292776  1.20431154 12.          0.66041686 13.          0.76932779]\t 0.7197765289730202\t 0.6462975059517682\t 0.46091524694315533\t 0.46091524694315533\n",
            "20 \t [ 8.57333797  0.94219501 14.          0.51089969  3.          0.1953435 ]\t 0.9742874478076378\t 0.6462975059517682\t 0.4501382352320586\t 0.4501382352320586\n",
            "21 \t [ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\t 0.6678102642866967\t 0.6462975059517682\t 0.46612050483774586\t 0.46612050483774586\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 6.07236319  9.81992716 15.          1.         10.76449502  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6451990768641908\u001b[0m\t \u001b[1m\u001b[92m0.6451990768641908\u001b[0m\t \u001b[1m\u001b[92m0.45837741479833616\u001b[0m\t \u001b[1m\u001b[92m0.45837741144293004\u001b[0m\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.7660042630046296\t 0.6451990768641908\t 0.458690605721284\t 0.458690605721284\n",
            "24 \t [9.30371298 5.41042714 5.         0.80825473 7.         0.72790994]\t 0.775406840278715\t 0.6451990768641908\t 0.44610820701503767\t 0.44610820701503767\n",
            "25 \t [ 0.13287937  9.19770254 14.          0.75778617 16.          0.92734937]\t 0.6527026234014134\t 0.6451990768641908\t 0.4513103397262674\t 0.4513103397262674\n",
            "26 \t [ 8.35560958  6.49504743 11.          0.90882708 12.          0.40676904]\t 0.8022669136645764\t 0.6451990768641908\t 0.4544139830343045\t 0.4544139830343045\n",
            "27 \t [ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]\t 0.7275389527778259\t 0.6451990768641908\t 0.45243636726517317\t 0.45243636726517317\n",
            "28 \t [ 4.55919043  8.6591134   6.          0.8884863  12.          0.96165246]\t 0.7009533648321409\t 0.6451990768641908\t 0.4452607625629826\t 0.4452607625629826\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.7646380284813412\t 0.6451990768641908\t 0.4498446325635014\t 0.4498446325635014\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.7247998938700702\t 0.6451990768641908\t 0.439035804829149\t 0.439035804829149\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48181.79061276722"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538e00be-39ec-4271-fe5c-18a810bcee5a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9953081887469889\t 0.7220763687473127\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.7220763687473127\t 0.7220763687473127\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9889075947558364\t 0.7220763687473127\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7606594495187335\t 0.7220763687473127\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7225304513182221\t 0.7220763687473127\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8181138208820815\t 0.7220763687473127\t 0.4660349686517125\t 0.4660349686517125\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10.          9.20775036 15.          1.         11.19712219  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6430021390685138\u001b[0m\t \u001b[1m\u001b[92m0.6430021390685138\u001b[0m\t \u001b[1m\u001b[92m0.4635710775532534\u001b[0m\t \u001b[1m\u001b[92m0.4635710775532534\u001b[0m\n",
            "3  \t [ 9.73276592  4.33279761 10.          0.71324    18.          0.20825635]\t 1.0032478680346943\t 0.6430021390685138\t 0.44961302561310007\t 0.44961302561310007\n",
            "4  \t [ 8.75973966  9.82329124  5.          0.53071358 10.          0.36963631]\t 0.9980169308427342\t 0.6430021390685138\t 0.4638162756497055\t 0.4638162756497055\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.7153197782842456\t 0.6430021390685138\t 0.4748379010551844\t 0.4748379010551844\n",
            "6  \t [ 6.79595692  7.93947545  5.          0.67208024 18.          0.4521055 ]\t 0.9008535104045862\t 0.6430021390685138\t 0.4668293916090344\t 0.4668293916090344\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 1.0120318552286456\t 0.6430021390685138\t 0.47015419103535977\t 0.47015419103535977\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.745004296865836\t 0.6430021390685138\t 0.47760657676674567\t 0.47760657676674567\n",
            "9  \t [ 2.23113902  0.01922131 12.          0.79543463 18.          0.19646488]\t 1.001968930279911\t 0.6430021390685138\t 0.47280032950554446\t 0.47280032950554446\n",
            "10 \t [ 1.39180663  0.94255352  5.          0.5        14.0831317   0.1       ]\t 1.016751521143701\t 0.6430021390685138\t 0.4790973291720253\t 0.4790971975299872\n",
            "11 \t [2.26673282 9.18109909 5.         0.89654818 1.         0.23064839]\t 1.0135085581422132\t 0.6430021390685138\t 0.48517675689858114\t 0.48517675689858114\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.7593781021734818\t 0.6430021390685138\t 0.4896834243735844\t 0.4896834243735844\n",
            "13 \t [10.         10.          8.96189557  1.         14.96189557  1.        ]\t 0.663377805190321\t 0.6430021390685138\t 0.4862058558510464\t 0.4862058558510208\n",
            "14 \t [ 9.17553299  1.41421886 11.          0.77317761 11.          0.82263086]\t 0.6736743474910011\t 0.6430021390685138\t 0.4803280761924484\t 0.4803280761924484\n",
            "15 \t [0.73985165 0.58861565 5.         0.76246476 8.         0.22502929]\t 1.011956540988281\t 0.6430021390685138\t 0.4752113519500841\t 0.4752113519500841\n",
            "16 \t [ 0.21200191  9.95034596  6.          0.77719285 19.          0.61346381]\t 0.7917438451600965\t 0.6430021390685138\t 0.4797381743632491\t 0.4797381743632491\n",
            "17 \t [9.98273363 0.40807687 5.         0.58049551 4.         0.30262691]\t 0.9970945517723454\t 0.6430021390685138\t 0.4769464718723687\t 0.4769464718723687\n",
            "18 \t [ 7.49379106  4.28777418 12.          0.51562956  7.          0.83771026]\t 0.6902334466391202\t 0.6430021390685138\t 0.4832437456373482\t 0.4832437456373482\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 1.0088210680321927\t 0.6430021390685138\t 0.48630979027821875\t 0.48630979027821875\n",
            "20 \t [ 2.76899542  3.95112357  8.          0.68989555 17.          0.45648964]\t 0.8469938115494976\t 0.6430021390685138\t 0.49207143793423785\t 0.49207143793423785\n",
            "21 \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]\t 0.8196793624782129\t 0.6430021390685138\t 0.4797423230799472\t 0.4797423230799472\n",
            "22 \t [ 4.52625472  6.1466137  15.          1.         20.          1.        ]\t 0.6430322328902018\t 0.6430021390685138\t 0.4804449922085321\t 0.4804449864673868\n",
            "23 \t [ 9.53885612  7.77476011 11.          0.72419664  1.          0.36894154]\t 0.9966950049469988\t 0.6430021390685138\t 0.4791513163880283\t 0.4791513163880283\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.6770117185241518\t 0.6430021390685138\t 0.4808286048220261\t 0.4808286048220261\n",
            "25 \t [ 0.58971199  1.10190062 11.          0.65725563 12.          0.9091195 ]\t 0.6564060234815495\t 0.6430021390685138\t 0.4847659174164521\t 0.4847659174164521\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.8194429585323096\t 0.6430021390685138\t 0.4797910188179898\t 0.4797910188179898\n",
            "27 \t [ 2.61804656  1.63569751 10.          0.63241032  1.          0.28443324]\t 0.9978409265559002\t 0.6430021390685138\t 0.4720653357100106\t 0.4720653357100106\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 1.003549466667358\t 0.6430021390685138\t 0.4726804381478328\t 0.4726804381478328\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.7575197707232916\t 0.6430021390685138\t 0.47470517526875555\t 0.47470517526875555\n",
            "30 \t [ 5.9265347   0.36590014 12.          0.80067771 15.          0.64080372]\t 0.7128216181811142\t 0.6430021390685138\t 0.4776472946341992\t 0.4776472946341992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47741.442886593046"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7b8974-ddfc-4f8b-e826-a95c07e769d1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.4411357329952958\u001b[0m\t \u001b[1m\u001b[92m0.4411357329952958\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 0.4305959003513451\t 0.4305959003513451\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 0.42464158863412116\t 0.42464158863412116\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 0.44419344427479884\t 0.44419344427479884\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 0.4399075477215166\t 0.4399075477215166\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.7059767781587389\t 0.6773838424850286\t 0.44360494719205135\t 0.44360494719205135\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.7065170119936448\t 0.6773838424850286\t 0.4389397446065172\t 0.4389397446065172\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.7317581740148223\t 0.6773838424850286\t 0.43503623052007645\t 0.43503623052007645\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.7857306346205829\t 0.6773838424850286\t 0.4326875763366868\t 0.4326875763366868\n",
            "10 \t [0.         2.9963083  5.         0.5        7.28612373 0.1       ]\t 1.0125393973803523\t 0.6773838424850286\t 0.43272248043960143\t 0.43272247386284607\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.7333445147195274\t 0.6773838424850286\t 0.442205120736961\t 0.442205120736961\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[10.          9.60926601  9.89068249  1.          6.89068249  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6599925512336002\u001b[0m\t \u001b[1m\u001b[92m0.6599925512336002\u001b[0m\t \u001b[1m\u001b[92m0.43986460983677966\u001b[0m\t \u001b[1m\u001b[92m0.4398646076737706\u001b[0m\n",
            "13 \t [ 4.84381248  4.87586967 12.          0.75612961  4.          0.36979417]\t 0.867035932761975\t 0.6599925512336002\t 0.43574476820070285\t 0.43574476820070285\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.7335321473751593\t 0.6599925512336002\t 0.4383989768272098\t 0.4383989768272098\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.767048132195449\t 0.6599925512336002\t 0.4361642600714929\t 0.4361642600714929\n",
            "16 \t [ 9.59735383  9.10351575  9.          0.67389645 14.          0.42791014]\t 0.7455236601760216\t 0.6599925512336002\t 0.43608776832699536\t 0.43608776832699536\n",
            "17 \t [ 4.34521215  5.28934175 10.          0.70701942 19.          0.12854445]\t 1.0162103828928835\t 0.6599925512336002\t 0.435336654215496\t 0.435336654215496\n",
            "18 \t [ 9.86546391  1.61531421  5.          0.70369851 10.          0.92790326]\t 0.7312350236326303\t 0.6599925512336002\t 0.4402314483191601\t 0.4402314483191601\n",
            "19 \t [ 2.76696568  4.32638207 10.          0.69065092 10.          0.32928339]\t 0.8606879483167145\t 0.6599925512336002\t 0.4387619877573248\t 0.4387619877573248\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.6776716071409558\t 0.6599925512336002\t 0.4414178322094868\t 0.4414178322094868\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.679119846341469\t 0.6599925512336002\t 0.44722443147670793\t 0.44722443147670793\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.7131407042423596\t 0.6599925512336002\t 0.4357550954251748\t 0.4357550954251748\n",
            "23 \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]\t 0.7458028061131368\t 0.6599925512336002\t 0.45036866865728026\t 0.45036866865728026\n",
            "24 \t [ 2.76287935  0.832992   10.          0.52421602  1.          0.77581255]\t 0.6811258108165148\t 0.6599925512336002\t 0.4362866330597522\t 0.4362866330597522\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.7487322203145116\t 0.6599925512336002\t 0.43280901233027974\t 0.43280901233027974\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.7108432598487722\t 0.6599925512336002\t 0.4372584852207475\t 0.4372584852207475\n",
            "27 \t [ 1.56204295  7.22226414  7.          0.60623869 14.          0.4680562 ]\t 0.7555703250463353\t 0.6599925512336002\t 0.42703877351966857\t 0.42703877351966857\n",
            "28 \t [8.3735996  5.34104024 8.         0.56456303 7.         0.59553385]\t 0.7245806620781778\t 0.6599925512336002\t 0.4314700674051971\t 0.4314700674051971\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.7131420295812025\t 0.6599925512336002\t 0.42942200609812653\t 0.42942200609812653\n",
            "30 \t [9.30545715 2.21896205 9.         0.96965499 5.         0.61228081]\t 0.7128642744554409\t 0.6599925512336002\t 0.42966581807444326\t 0.42966581807444326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49706.11896343179"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c171177-2f22-4942-b198-1ebfdb9efa62"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 0.4676225906533388\t 0.4676225906533388\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 0.4704189701850425\t 0.4704189701850425\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.7502219040814293\t 0.6597299542050263\t 0.4886722572440912\t 0.4886722572440912\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7367139517682284\t 0.6597299542050263\t 0.4799328924967524\t 0.4799328924967524\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8006234291185196\t 0.6597299542050263\t 0.47230642158175185\t 0.47230642158175185\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6408433430998837\u001b[0m\t \u001b[1m\u001b[92m0.6408433430998837\u001b[0m\t \u001b[1m\u001b[92m0.46930805750577625\u001b[0m\t \u001b[1m\u001b[92m0.46930805750551297\u001b[0m\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.703165388931625\t 0.6408433430998837\t 0.46020755641465577\t 0.46020755641465577\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         13.87817567  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6403650661465254\u001b[0m\t \u001b[1m\u001b[92m0.6403650661465254\u001b[0m\t \u001b[1m\u001b[92m0.45438813891817265\u001b[0m\t \u001b[1m\u001b[92m0.4543881412342027\u001b[0m\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0651952678837315\t 0.6403650661465254\t 0.44761221413496305\t 0.44761221413496305\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.8036859734991779\t 0.6403650661465254\t 0.45900040029909467\t 0.45900040029909467\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0624486911635314\t 0.6403650661465254\t 0.4579186817453662\t 0.4579186817453662\n",
            "12 \t [ 6.27900589  9.12764923  5.          0.84263312 18.          0.79256191]\t 0.730579912896863\t 0.6403650661465254\t 0.46699495964041393\t 0.46699495964041393\n",
            "13 \t [ 5.96615687  3.82181138 12.          0.64448426  8.          0.96178268]\t 0.6691597261782757\t 0.6403650661465254\t 0.4634413104774882\t 0.4634413104774882\n",
            "14 \t [ 0.30329279  8.44985963 11.          0.88949602 12.          0.98063814]\t 0.6581410006205839\t 0.6403650661465254\t 0.4587187131292377\t 0.4587187131292377\n",
            "15 \t [ 6.97560183  1.48211849  9.          0.80794429 10.          0.21839694]\t 1.0602103565189318\t 0.6403650661465254\t 0.4541816933055271\t 0.4541816933055271\n",
            "16 \t [ 0.3999032   2.66263318 14.          0.55784408  3.          0.95411688]\t 0.6765956478595294\t 0.6403650661465254\t 0.4615652732717896\t 0.4615652732717896\n",
            "17 \t [8.4112622  6.61129193 7.         0.60328014 5.         0.90260887]\t 0.6916923925215309\t 0.6403650661465254\t 0.4581484160264282\t 0.4581484160264282\n",
            "18 \t [0.05603826 5.95458494 6.         0.80513443 9.         0.58618251]\t 0.7819963212764711\t 0.6403650661465254\t 0.45474974653010897\t 0.45474974653010897\n",
            "19 \t [4.83067255 2.19904639 7.         0.5680519  3.         0.59514532]\t 0.7720408244337518\t 0.6403650661465254\t 0.4534460083568876\t 0.4534460083568876\n",
            "20 \t [ 0.02776244  1.53012881  8.          0.96273615 15.          0.27616872]\t 0.8778800869252311\t 0.6403650661465254\t 0.45453796546493586\t 0.45453796546493586\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.8784158308955667\t 0.6403650661465254\t 0.4614163986826116\t 0.4614163986826116\n",
            "22 \t [ 2.87514576  3.13712267 13.          0.97475974 17.          0.73021265]\t 0.6835469609962976\t 0.6403650661465254\t 0.46218637389364015\t 0.46218637389364015\n",
            "23 \t [10.          6.88191732 10.15407151  1.         14.15407151  1.        ]\t 0.6464923700219258\t 0.6403650661465254\t 0.453238995281899\t 0.45323884859430363\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.6902699854328027\t 0.6403650661465254\t 0.4498045805687069\t 0.4498045805687069\n",
            "25 \t [ 0.          1.01182241  5.          0.5        10.29540229  0.1       ]\t 1.0673802924142777\t 0.6403650661465254\t 0.45506971506050287\t 0.45506957208842586\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.7422712401342008\t 0.6403650661465254\t 0.45996674317374425\t 0.45996674317374425\n",
            "27 \t [ 2.03880167  9.16229686  8.          0.60402254 16.          0.20309055]\t 1.0619957315160622\t 0.6403650661465254\t 0.4644444259552982\t 0.4644444259552982\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.0600568728235613\t 0.6403650661465254\t 0.460449436483342\t 0.460449436483342\n",
            "29 \t [ 9.46105078  8.51558179 14.          0.6234267   1.          0.59075489]\t 0.7699575115200042\t 0.6403650661465254\t 0.4688694315388418\t 0.4688694315388418\n",
            "30 \t [0.         0.         6.23968388 0.5        1.23968388 0.1       ]\t 1.0665626114625386\t 0.6403650661465254\t 0.4568687784087288\t 0.45686877401592807\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48475.65686277387"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfad1378-e977-4466-bc56-a6ba64b3482f"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1558.2156555652618"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cab6f2-7f73-49ba-f94b-dffbe960e804"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50194.34015284295"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4adf02-6d01-4014-aad0-0aef450b59a8"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49221.09718295412"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f594bd24-011a-43e8-eaab-829312ba2cc6"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  48624.2920853472,\n",
              "  48624.2920853472,\n",
              "  48624.2920853472,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466,\n",
              "  47116.726055847466],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c773600-5bdd-4064-ceac-3204d549d4d8"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([47321.8408099896,\n",
              "  47321.8408099896,\n",
              "  46877.10407555545,\n",
              "  46877.10407555545,\n",
              "  46877.10407555545,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "53ab6fa4-dd81-4059-9f69-009d7a0d9f9d"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Green', label='RMSE: Approx STP ERM gradients', ls='--')\n",
        "plt.plot(min_rmse_exact, color = 'Blue', label='RMSE: Exact STP dERM gradients', ls='-')# r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualize!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa9aa33-8301-4b18-abd7-432352c3f607"
      },
      "source": [
        "time_approx, time_exact\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1606.4760434627533, 1558.2156555652618)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34934c1-e5f1-46c6-ed12-2351e22eaf54"
      },
      "source": [
        "min(min_rmse_exact), min(min_rmse_approx)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46832.22443034189, 47116.726055847466)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}