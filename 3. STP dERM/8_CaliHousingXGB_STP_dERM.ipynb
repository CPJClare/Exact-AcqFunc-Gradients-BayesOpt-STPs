{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59c6914-c34a-4fe4-f756-7157fb053530"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Collecting Theano-PyMC\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.1 MB/s \n",
            "\u001b[?25hCollecting pyMC3\n",
            "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
            "\u001b[K     |████████████████████████████████| 872 kB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Collecting deprecat\n",
            "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting semver>=2.13.0\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=a0f60f2964edc3b45b75687616ed9aa21a3c308a0c46e85df31942d8438d40c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529963 sha256=e87f00be53166feea8f132127f004228865083094bf287df0262cca480fe5843\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/af/8c/5dd7553522d74c52a7813806fc7ee1a9caa20a3f7c8fd850d5\n",
            "Successfully built pyGPGO Theano-PyMC\n",
            "Installing collected packages: Theano-PyMC, semver, deprecat, pyMC3, pyGPGO\n",
            "Successfully installed Theano-PyMC-1.1.2 deprecat-2.1.1 pyGPGO-0.5.1 pyMC3-3.11.5 semver-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import t\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "abe542eb-bd42-4284-ba5b-13212a4120f4"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-245d0a5b-8faf-4d3b-b77e-71b37ba2f0a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245d0a5b-8faf-4d3b-b77e-71b37ba2f0a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-245d0a5b-8faf-4d3b-b77e-71b37ba2f0a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-245d0a5b-8faf-4d3b-b77e-71b37ba2f0a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47ae1f6-4ba8-4bcb-af14-4c2dd81aadcc"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "f6f95bd8-853d-407f-8a31-c508b416f733"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5ddc37-6c03-4902-b697-ee17186584f9"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "21d517c8-0561-402c-d183-4f69a4e245d8"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c6cbf1a-3725-485c-a75f-2bf11ff7c31b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c6cbf1a-3725-485c-a75f-2bf11ff7c31b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c6cbf1a-3725-485c-a75f-2bf11ff7c31b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c6cbf1a-3725-485c-a75f-2bf11ff7c31b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1ae53ec9-37c3-447f-b2ad-3858aca7b77f"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53b2e965-1cfb-449c-a57c-993ff1430f7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53b2e965-1cfb-449c-a57c-993ff1430f7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53b2e965-1cfb-449c-a57c-993ff1430f7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53b2e965-1cfb-449c-a57c-993ff1430f7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util = 'ERM'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.90\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08\n",
        "\n",
        "df = 3\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 5"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "def kronDelta(X, Xstar):                     # Kronecker's Delta method\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "def se(X, Xstar, sigmaf, l, sigman):         # S.E. kernel method\n",
        "    return sigmaf * np.exp(-0.5 * cdist(X, Xstar) ** 2 / l ** 2) + sigman * kronDelta(X, Xstar)\n",
        "\n",
        "def delta(X, Xstar):                         # Distance between training X and test Xstar vectors\n",
        "    return (X - Xstar)\n",
        "   \n",
        "def der_covmat(X, Xstar, sigmaf, l, sigman): # Covariance matrix derivative terms (i.e. exact, first-order)\n",
        "    nx = len(X)\n",
        "    ny = len(Xstar)\n",
        "    return np.round(np.array([(delta(np.atleast_2d(i), np.atleast_2d(j))[0] * se(np.atleast_2d(i), np.atleast_2d(j), sigmaf, l, sigman)[0]).sum() for (i, j) in itertools.product(X, Xstar)]).reshape(nx, ny), 8)\n",
        "\n",
        "class dtStudentProcess(tStudentProcess):    # Via inheritance, also optimises hyperparameters when opt = TRUE\n",
        "    \n",
        "    def AcqGrad(self, Xstar):               # Method returning exact, first-order derivatives of the STP's posterior mean and standard deviation\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = self.covfunc.K(self.X, Xstar).T\n",
        "        dKstar = der_covmat(self.X, Xstar, self.covfunc.sigmaf, self.covfunc.l, self.covfunc.sigman).T\n",
        "        \n",
        "        smd_adj = (self.nu + self.beta1 - 2) / (self.nu + self.n1 - 2)\n",
        "\n",
        "        alpha = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), self.y)\n",
        "        alpha_Kstar = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), Kstar.T)      \n",
        "        \n",
        "        dm = np.dot(dKstar, alpha)\n",
        "        ds = -2 * smd_adj * np.dot(dKstar, alpha_Kstar)\n",
        "        \n",
        "        return dm, ds           \n",
        "        "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "class Acquisition_grad(Acquisition):    \n",
        "    def __init__(self, mode, eps=eps, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'ERM': self.ERM\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def ERM(self, tau, mean, std, ds, dm, nu=3.0):\n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - tau) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (gamma * t.cdf(gamma, df=nu) + (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma, df=nu))\n",
        "        df1 = f / (std + self.eps) * dsdx \n",
        "        df2 = (std + self.eps) * (t.cdf(gamma, df=nu) * dmdx + gamma * t.pdf(gamma, df=nu) \\\n",
        "            * (1 - (nu + gamma ** 2)/(nu - 1) + 2/(nu - 1) * dmdx))\n",
        "        df = (df1 + df2)[0]\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append(df)\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "        \n",
        "    def d_eval(self, tau, mean, std, ds, dm, nu=3.0):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, nu=3.0, **self.params)\n",
        "        "
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAK8N5bwfuJ7"
      },
      "source": [
        "## GPGO_multi: \n",
        "\n",
        "class GPGO_multi(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        " \n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "   \n",
        "    def _optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        \n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr        \n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_exact = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_exact = np.empty((n_start,))\n",
        "        opt_exact = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_exact = np.array([res.x for res in opt_exact])\n",
        "        f_best_exact = np.array([np.atleast_1d(res.fun)[0] for res in opt_exact])\n",
        "        f_best_min_exact = min(f_best_exact)\n",
        "\n",
        "        self.x_best_exact = x_best_exact\n",
        "        self.f_best_exact = f_best_exact\n",
        "        self.f_best_min_exact = f_best_min_exact\n",
        "        self.best_exact = x_best_exact[np.argmin(f_best_exact)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_exact)\n",
        "\n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_exact = str(inverse * self.f_best_min_exact)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_exact = BOLD + OKGREEN + max_acqfunc_exact + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc_exact, max_acqfunc))\n",
        "        \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self._optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "class dGPGO(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        "\n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_approx = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_approx = np.empty((n_start,))\n",
        "        opt_approx = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_approx = np.array([res.x for res in opt_approx])\n",
        "        f_best_approx = np.array([np.atleast_1d(res.fun)[0] for res in opt_approx])\n",
        "        f_best_min_approx = min(f_best_approx)\n",
        "\n",
        "        self.x_best_approx = x_best_approx\n",
        "        self.f_best_approx = f_best_approx\n",
        "        self.f_best_min_approx = f_best_min_approx\n",
        "        self.best_approx = x_best_approx[np.argmin(f_best_approx)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_approx)\n",
        "    \n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_approx = str(inverse * self.f_best_min_approx)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_approx = BOLD + OKGREEN + max_acqfunc_approx + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc, max_acqfunc_approx))\n",
        "\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d43dc2-e550-4e56-f2d3-61372180b411"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1662460066.0516078"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc07fdf-aaf0-4276-92d4-9b50725580cf"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO_multi(surrogate_approx_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 0.848101320876155\t 0.7386468688809501\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7469689781479785\t 0.7386468688809501\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8079963708366673\t 0.7386468688809501\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.7386468688809501\t 0.7386468688809501\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 0.937768916815817\t 0.7386468688809501\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8126185461054997\t 0.7386468688809501\t 0.45162596541557376\t 0.45162596541557376\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 0.9318704004009237\t 0.7386468688809501\t 0.45102699013998043\t 0.45102699013998043\n",
            "3  \t [7.35353694 6.03494644 5.         0.7919799  3.         0.96282991]\t 0.7646755003247829\t 0.7386468688809501\t 0.4605134818317217\t 0.4605134818317217\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8108923609041201\t 0.7386468688809501\t 0.4558295847084458\t 0.4558295847084458\n",
            "5  \t [ 3.76363217  9.95052322  8.          0.75835318 19.          0.10206715]\t 0.9302979891635867\t 0.7386468688809501\t 0.45486455657270725\t 0.45486455657270725\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.8121266607783616\t 0.7386468688809501\t 0.4609969843128662\t 0.4609969843128662\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 0.8530932869908747\t 0.7386468688809501\t 0.4598083559265772\t 0.4598083559265772\n",
            "8  \t [ 7.25642545  0.25925793 13.          0.51727017  4.          0.8962137 ]\t 0.7822187847645935\t 0.7386468688809501\t 0.46069473787687826\t 0.46069473779882564\n",
            "9  \t [0.75623385 3.14055399 6.         0.5417671  8.         0.78866556]\t 0.7758028719550957\t 0.7386468688809501\t 0.45849770102789145\t 0.4584976997880083\n",
            "10 \t [9.47161836 5.35231143 6.         0.51632193 6.         0.43288953]\t 0.8314092949686034\t 0.7386468688809501\t 0.4563685405952584\t 0.4563685405952584\n",
            "11 \t [ 0.75310873  4.25724412 13.          0.65895151  1.          0.82964911]\t 0.7771294155692965\t 0.7386468688809501\t 0.45650660234750634\t 0.45650660234750634\n",
            "12 \t [0.15776536 8.02750992 5.         0.65248282 3.         0.71659731]\t 0.7752392265192147\t 0.7386468688809501\t 0.45479706897280275\t 0.45479706897280275\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 9.31003194  2.78504172 14.          0.81837194 14.          0.87646711]\u001b[0m\t \u001b[1m\u001b[92m0.7355848546414411\u001b[0m\t \u001b[1m\u001b[92m0.7355848546414411\u001b[0m\t \u001b[1m\u001b[92m0.4532573304616179\u001b[0m\t \u001b[1m\u001b[92m0.4532573304616179\u001b[0m\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7644930642703252\t 0.7355848546414411\t 0.4507142056932403\t 0.4507142056932403\n",
            "15 \t [ 4.9586464   0.03452716 14.          0.97140399  9.          0.31674359]\t 0.8444570331313808\t 0.7355848546414411\t 0.44917767070596454\t 0.4491776706216754\n",
            "16 \t [ 3.45062645  9.8040474   6.          0.9453621  12.          0.8489149 ]\t 0.7535830619192916\t 0.7355848546414411\t 0.4500705297097958\t 0.4500705297097958\n",
            "17 \t [1.68476972 5.2908721  8.         0.92839616 1.         0.96471758]\t 0.7413177424377804\t 0.7355848546414411\t 0.4480546075851543\t 0.4480546075851543\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8088933131983232\t 0.7355848546414411\t 0.45272373794616666\t 0.45272373794616666\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 0.8343379491664138\t 0.7355848546414411\t 0.45210098827928186\t 0.45210098827928186\n",
            "20 \t [ 7.12741784  1.59648512  9.          0.96056513 11.          0.30752062]\t 0.8419713781829536\t 0.7355848546414411\t 0.450486695096266\t 0.450486695096266\n",
            "21 \t [ 9.72376714  9.82517342 14.          0.96896704 10.          0.66715413]\t 0.7442263922491208\t 0.7355848546414411\t 0.44910866912295316\t 0.44910866912295316\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 0.9354453567539931\t 0.7355848546414411\t 0.4576557842490529\t 0.4576557842490529\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\u001b[0m\t \u001b[1m\u001b[92m0.7341701271899448\u001b[0m\t \u001b[1m\u001b[92m0.7341701271899448\u001b[0m\t \u001b[1m\u001b[92m0.4580699188333076\u001b[0m\t \u001b[1m\u001b[92m0.4580699188333076\u001b[0m\n",
            "24 \t [4.92344511 0.59103391 8.         0.92756882 1.         0.71609051]\t 0.7449712611020661\t 0.7341701271899448\t 0.45378092938413117\t 0.45378092938413117\n",
            "25 \t [ 9.97471031  7.71725552  9.          0.75893438 14.          0.97108888]\t 0.7458665279787168\t 0.7341701271899448\t 0.4493253624985455\t 0.4493253624985455\n",
            "26 \t [ 0.50749748  8.96045258 11.          0.56036852 13.          0.50747166]\t 0.7932595093143926\t 0.7341701271899448\t 0.4591808495653347\t 0.4591808495653347\n",
            "27 \t [ 2.52136808  8.51741902 14.          0.89185963  6.          0.23066693]\t 0.9371270391052704\t 0.7341701271899448\t 0.44771536080298274\t 0.44771536080298274\n",
            "28 \t [8.68506658 0.40799141 5.         0.90040035 2.         0.17112852]\t 0.9332047623667679\t 0.7341701271899448\t 0.4533693915023173\t 0.4533693915023173\n",
            "29 \t [ 7.40845157  8.58336508  5.          0.8318041  19.          0.36434664]\t 0.8342471407090255\t 0.7341701271899448\t 0.46001981943073633\t 0.4600198194078096\n",
            "30 \t [ 9.84118082  4.29794399 10.          0.60638682  1.          0.22679444]\t 0.9488686566857412\t 0.7341701271899448\t 0.449248704219754\t 0.44924870421974783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60746.65105051846"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f5f581-847a-4da1-f8a9-c14a72ae5280"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO_multi(surrogate_approx_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.9157817005982263\t 0.8490988745111359\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.8517975125315337\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.8490988745111359\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.9839177202713774\t 0.8490988745111359\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.9688138526063573\t 0.8490988745111359\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m0.5043658072393779\u001b[0m\t \u001b[1m\u001b[92m0.5043658072393779\u001b[0m\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\u001b[0m\t \u001b[1m\u001b[92m0.7753470044170323\u001b[0m\t \u001b[1m\u001b[92m0.7753470044170323\u001b[0m\t \u001b[1m\u001b[92m0.49383764677544045\u001b[0m\t \u001b[1m\u001b[92m0.4938376467754177\u001b[0m\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.876401110742202\t 0.7753470044170323\t 0.4849131516549371\t 0.4849131516549371\n",
            "4  \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]\t 0.9658206597269258\t 0.7753470044170323\t 0.48469751762899516\t 0.48469751762899516\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.9313569330212417\t 0.7753470044170323\t 0.49023733190173946\t 0.49023733190173946\n",
            "6  \t [ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\t 0.8411431281498688\t 0.7753470044170323\t 0.49284015675883214\t 0.49284015675883214\n",
            "7  \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]\t 0.9164031394028719\t 0.7753470044170323\t 0.4900574851407011\t 0.4900574851400244\n",
            "8  \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]\t 1.0138871967237582\t 0.7753470044170323\t 0.4913405682110727\t 0.4913405682110727\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.8472224210855768\t 0.7753470044170323\t 0.4970469166418039\t 0.4970469166418039\n",
            "10 \t [ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\t 0.786526849407035\t 0.7753470044170323\t 0.4949658046918372\t 0.4949658046918372\n",
            "11 \t [4.59560507 9.66694693 5.         0.8652774  6.         0.90565092]\t 0.7793501597644426\t 0.7753470044170323\t 0.4910660588243099\t 0.4910660588243099\n",
            "12 \t [ 8.76507252  8.76898373 14.          0.51356786  6.          0.73624795]\t 0.8509923386963646\t 0.7753470044170323\t 0.4871313112608411\t 0.4871313112608411\n",
            "13 \t [ 6.62295179  6.77584978 14.          0.65936287 12.          0.50955919]\t 0.845219311359458\t 0.7753470044170323\t 0.48616127562849404\t 0.48616127562849404\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.8437383195985765\t 0.7753470044170323\t 0.48520481220355666\t 0.4852048118921145\n",
            "15 \t [ 9.80429676  9.59801315  7.          0.61168386 14.          0.66107461]\t 0.8362874386261758\t 0.7753470044170323\t 0.4845090114378358\t 0.4845090114378358\n",
            "16 \t [ 3.79151097  4.0129324  10.          0.78656319  9.          0.57380624]\t 0.8479506527275633\t 0.7753470044170323\t 0.48317785285195886\t 0.48317785285195886\n",
            "17 \t [6.53156572 9.72376072 9.         0.51610543 1.         0.4929146 ]\t 0.9514823488789619\t 0.7753470044170323\t 0.48172018999871874\t 0.48172018999871874\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.812855948594331\t 0.7753470044170323\t 0.4895772279865215\t 0.4895772279865215\n",
            "19 \t [ 6.92673077  1.23845568 10.          0.63463476  8.          0.28240746]\t 0.9737154587401665\t 0.7753470044170323\t 0.49288652223419144\t 0.49288652223419144\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.9759301877372604\t 0.7753470044170323\t 0.4908457331545114\t 0.4908457331545114\n",
            "21 \t [7.13284983 1.18470919 5.         0.63977211 3.         0.12223048]\t 1.0124277228121503\t 0.7753470044170323\t 0.49024316219896014\t 0.49024316219896014\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\u001b[0m\t \u001b[1m\u001b[92m0.7642724935254156\u001b[0m\t \u001b[1m\u001b[92m0.7642724935254156\u001b[0m\t \u001b[1m\u001b[92m0.48919070670965537\u001b[0m\t \u001b[1m\u001b[92m0.48919070670965537\u001b[0m\n",
            "23 \t [8.76774335 2.47727368 5.         0.77895852 8.         0.95970784]\t 0.7783672057784645\t 0.7642724935254156\t 0.49314926014312405\t 0.49314926014312405\n",
            "24 \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]\t 0.9941403780835223\t 0.7642724935254156\t 0.4989021021106522\t 0.4989021021106522\n",
            "25 \t [ 9.70148981  3.84860271 14.          0.8648022   1.          0.77351018]\t 0.8176855829782234\t 0.7642724935254156\t 0.49330874501799454\t 0.49330874501799454\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.7746854783898445\t 0.7642724935254156\t 0.4864238899240862\t 0.4864238899240862\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.8184668279349161\t 0.7642724935254156\t 0.49086395200841404\t 0.49086395200841404\n",
            "28 \t [ 4.9644812   1.12270948  6.          0.71065886 17.          0.26866166]\t 0.9667438219230509\t 0.7642724935254156\t 0.4931213348749455\t 0.4931213348749455\n",
            "29 \t [ 5.98509126  0.06989145 14.          0.5561472  16.          0.1874862 ]\t 1.0105701333726524\t 0.7642724935254156\t 0.4892559593094552\t 0.4892559593094552\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[5.55301534 4.43776121 9.         0.77874612 6.         0.99491253]\u001b[0m\t \u001b[1m\u001b[92m0.7585656248465545\u001b[0m\t \u001b[1m\u001b[92m0.7585656248465545\u001b[0m\t \u001b[1m\u001b[92m0.48969999580816176\u001b[0m\t \u001b[1m\u001b[92m0.48969999580816176\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62513.455753809474"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aca3e77-05c8-4a95-ccf6-9bd258786994"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO_multi(surrogate_approx_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.1001019572672721\t 0.8205570570239384\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.0968690738660336\t 0.8205570570239384\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.8205570570239384\t 0.8205570570239384\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0984076753833096\t 0.8205570570239384\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8540219347978375\t 0.8205570570239384\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8296591774144556\t 0.8205570570239384\t 0.552568679117548\t 0.552568679117548\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.46535469  7.06056184  5.          0.53518488 13.          0.98930148]\u001b[0m\t \u001b[1m\u001b[92m0.8159546965123093\u001b[0m\t \u001b[1m\u001b[92m0.8159546965123093\u001b[0m\t \u001b[1m\u001b[92m0.5378791801454976\u001b[0m\t \u001b[1m\u001b[92m0.5378791801454976\u001b[0m\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0951088390242933\t 0.8159546965123093\t 0.526207851627801\t 0.526207851627801\n",
            "4  \t [ 6.69378835  1.1746468   5.          0.75549171 16.          0.73450657]\t 0.8217725728652645\t 0.8159546965123093\t 0.5365159952942914\t 0.5365159952942914\n",
            "5  \t [ 0.24010242  9.80847714 13.          0.63702721  3.          0.56729929]\t 0.8241986609721416\t 0.8159546965123093\t 0.5278957093350293\t 0.5278957093350293\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[9.87422438 6.71772444 5.         0.63287091 5.         0.98483042]\u001b[0m\t \u001b[1m\u001b[92m0.8150350857143913\u001b[0m\t \u001b[1m\u001b[92m0.8150350857143913\u001b[0m\t \u001b[1m\u001b[92m0.5210133730012616\u001b[0m\t \u001b[1m\u001b[92m0.5210133730012616\u001b[0m\n",
            "7  \t [6.87752707 0.15955299 8.         0.55138154 9.         0.67263073]\t 0.8171526002553859\t 0.8150350857143913\t 0.5149108164080863\t 0.5149108164080863\n",
            "8  \t [2.6278521  1.48922274 6.         0.63082487 1.         0.15934029]\t 1.1015309912379583\t 0.8150350857143913\t 0.5098556094179575\t 0.5098556094179575\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[ 8.89682762  0.79017134 14.          0.58366818  8.          0.97456627]\u001b[0m\t \u001b[1m\u001b[92m0.7882233954631125\u001b[0m\t \u001b[1m\u001b[92m0.7882233954631125\u001b[0m\t \u001b[1m\u001b[92m0.5180035656022437\u001b[0m\t \u001b[1m\u001b[92m0.5180035656022437\u001b[0m\n",
            "10 \t [ 8.77606832  6.32160473  5.          0.71489692 18.          0.76442589]\t 0.8083681579816849\t 0.7882233954631125\t 0.5124941198904704\t 0.5124941198904704\n",
            "11 \t [ 3.53262431  2.07514765  7.          0.93520802 15.          0.4184813 ]\t 0.8494175289417161\t 0.7882233954631125\t 0.5083123349907168\t 0.5083123349907168\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.7986988788225304\t 0.7882233954631125\t 0.5059041530873615\t 0.5059041530873615\n",
            "13 \t [ 9.06298174  1.35559831 12.          0.65549633 16.          0.13675737]\t 1.0964679144435232\t 0.7882233954631125\t 0.5023077585630197\t 0.5023077585630197\n",
            "14 \t [ 9.85636221  3.89791593  9.          0.61925349 14.          0.90156475]\t 0.7917903727359957\t 0.7882233954631125\t 0.5085040030807803\t 0.5085040030807803\n",
            "15 \t [ 8.58495733  5.09928748 13.          0.89538108  1.          0.67774369]\t 0.8310233985591402\t 0.7882233954631125\t 0.5048857993127052\t 0.5048857993127052\n",
            "16 \t [ 4.66948753  0.78814602 10.          0.955043   17.          0.2188467 ]\t 1.0962260054583457\t 0.7882233954631125\t 0.5028034717020488\t 0.5028034717020488\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\u001b[0m\t \u001b[1m\u001b[92m0.7834162130060136\u001b[0m\t \u001b[1m\u001b[92m0.7834162130060136\u001b[0m\t \u001b[1m\u001b[92m0.5086109568878432\u001b[0m\t \u001b[1m\u001b[92m0.5086109568878432\u001b[0m\n",
            "18 \t [1.14934749 1.30310631 7.         0.60930428 6.         0.86412796]\t 0.7988635386480449\t 0.7834162130060136\t 0.5069596341246544\t 0.5069596341246544\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8394856040419147\t 0.7834162130060136\t 0.5068009436543399\t 0.5068009436543399\n",
            "20 \t [ 1.06084272  8.60821489 11.          0.60672694  9.          0.40602348]\t 0.858441552538079\t 0.7834162130060136\t 0.5005148064642521\t 0.5005148064642191\n",
            "21 \t [7.66786548 9.63378327 6.         0.67341055 1.         0.88994805]\t 0.8132267424569065\t 0.7834162130060136\t 0.49903881091661845\t 0.49903881091661845\n",
            "22 \t [ 0.02131996  1.10966908  5.          0.84030465 19.          0.36311324]\t 0.9481408908067073\t 0.7834162130060136\t 0.5017569587695591\t 0.5017569587695591\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8627583512307193\t 0.7834162130060136\t 0.5080647669778658\t 0.5080647669778658\n",
            "24 \t [ 0.04997226  0.57243486  5.          0.9748128  12.          0.24835402]\t 1.1002185993205575\t 0.7834162130060136\t 0.5037520932610159\t 0.5037520930194864\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7859921669897617\t 0.7834162130060136\t 0.507005044416505\t 0.507005044416505\n",
            "26 \t [ 5.07665331  4.6343883  14.          0.62511663 16.          0.73650486]\t 0.8117073016334935\t 0.7834162130060136\t 0.5022595435303754\t 0.5022595435303754\n",
            "27 \t [ 8.21944232  0.76315735 14.          0.70782001  3.          0.58640207]\t 0.8090375820501642\t 0.7834162130060136\t 0.49833385381798667\t 0.49833385381798667\n",
            "28 \t [ 9.01763405  8.9342346  11.          0.78253186 14.          0.5899614 ]\t 0.8008497075757127\t 0.7834162130060136\t 0.5002528255201196\t 0.5002528255201196\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.095967263497375\t 0.7834162130060136\t 0.49540632418842984\t 0.49540632418842984\n",
            "30 \t [ 0.56213381  4.41770035 10.          0.6803733   4.          0.67199979]\t 0.8046905628950565\t 0.7834162130060136\t 0.5034329525513134\t 0.5034329525513134\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59963.734606268496"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a12516d-8dc1-48c2-bb8f-b8b6c53e01d4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO_multi(surrogate_approx_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7650622398140196\t 0.7505823286451517\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7710732234684645\t 0.7505823286451517\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 1.127900018061083\t 0.7505823286451517\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.7505823286451517\t 0.7505823286451517\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.9579573664970923\t 0.7505823286451517\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 1.1269429525174437\t 0.7505823286451517\t 0.488981754778346\t 0.488981754778346\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 1.129364536434021\t 0.7505823286451517\t 0.5134117111763707\t 0.5134117111763707\n",
            "3  \t [ 1.20931261  6.80689034  9.          0.92011951 17.          0.30723956]\t 0.9481459007646673\t 0.7505823286451517\t 0.5303967786752228\t 0.5303967786752228\n",
            "4  \t [ 1.21913591  5.39021078 12.          0.52306788  2.          0.57375676]\t 0.8175628207948187\t 0.7505823286451517\t 0.5294458935409077\t 0.5294458935409077\n",
            "5  \t [5.20880295 1.88390627 9.         0.63189416 3.         0.18887718]\t 1.1294817157053765\t 0.7505823286451517\t 0.521288199019543\t 0.5212881986718053\n",
            "6  \t [ 9.06307728  4.86114267 13.          0.58554955 19.          0.71395167]\t 0.7663633049670207\t 0.7505823286451517\t 0.5323016381907185\t 0.5323016381907185\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.8044591218487582\t 0.7505823286451517\t 0.5232739795756151\t 0.5232739795756151\n",
            "8  \t [ 0.81680031  1.59198282 10.          0.96064429  2.          0.39459215]\t 0.8548861270630322\t 0.7505823286451517\t 0.5170978164637527\t 0.5170978164637527\n",
            "9  \t [ 5.44631958  4.09972266  5.          0.7031307  18.          0.59728817]\t 0.8117584664942734\t 0.7505823286451517\t 0.5137199055870381\t 0.5137199055870381\n",
            "10 \t [ 5.47785092  4.8461481  12.          0.74846659 14.          0.61206304]\t 0.7921662259989626\t 0.7505823286451517\t 0.5092777928192989\t 0.5092777928192989\n",
            "11 \t [ 9.26888317  0.34770884 13.          0.56989599  5.          0.4978041 ]\t 0.8698317056044329\t 0.7505823286451517\t 0.5047684892898222\t 0.5047684892898222\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.7753874640601797\t 0.7505823286451517\t 0.5032373128278962\t 0.5032373128278962\n",
            "13 \t [ 9.47516521  0.98411555  7.          0.63763494 14.          0.52093401]\t 0.7995428779273371\t 0.7505823286451517\t 0.4991335699037678\t 0.4991335699037678\n",
            "14 \t [ 3.22282465  1.05364145  6.          0.75774626 12.          0.92739587]\t 0.7669842156079565\t 0.7505823286451517\t 0.49606182776435626\t 0.49606182776435626\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.8233136201842758\t 0.7505823286451517\t 0.4924504540413901\t 0.4924504540413901\n",
            "16 \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]\t 0.9579981335802007\t 0.7505823286451517\t 0.4904101299726913\t 0.4904101299726913\n",
            "17 \t [ 4.21251381  9.34883611  7.          0.86607935 10.          0.51599279]\t 0.7903972753988527\t 0.7505823286451517\t 0.4926615674163842\t 0.4926615674163842\n",
            "18 \t [ 3.8330061   0.35722521 10.          0.9669447   8.          0.85083452]\t 0.7621276147698381\t 0.7505823286451517\t 0.49346200802442075\t 0.49346200802442075\n",
            "19 \t [ 2.28250676  8.57781075 10.          0.71780124 12.          0.3772521 ]\t 0.8627736627545619\t 0.7505823286451517\t 0.4892094581758687\t 0.4892094581758687\n",
            "20 \t [ 9.66721268  1.8443589  13.          0.69291942 15.          0.16614767]\t 1.1236074280369432\t 0.7505823286451517\t 0.4849599049814744\t 0.4849599048162587\n",
            "21 \t [ 3.90376452  0.27194016 14.          0.92188548 14.          0.42162751]\t 0.8519773428950567\t 0.7505823286451517\t 0.48800398386810734\t 0.48800395628714566\n",
            "22 \t [ 0.34343537  0.75830465 14.          0.57372847 18.          0.51234475]\t 0.7987111680789081\t 0.7505823286451517\t 0.4965664980311266\t 0.4965664980311266\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 1.1250394819981728\t 0.7505823286451517\t 0.4905601911010257\t 0.4905601911010257\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.7993682157943708\t 0.7505823286451517\t 0.49757175230594186\t 0.49757175230594186\n",
            "25 \t [9.14387233 8.82409497 7.         0.87227821 8.         0.52464991]\t 0.7895388146683674\t 0.7505823286451517\t 0.49566245540680126\t 0.49566245540680126\n",
            "26 \t [ 7.01360923  0.03074572 13.          0.56476682  9.          0.19217174]\t 1.1276865380590453\t 0.7505823286451517\t 0.4965945253025826\t 0.4965945253025826\n",
            "27 \t [ 5.3916587   9.41115446 14.          0.7428898  17.          0.24162874]\t 1.1217718597624515\t 0.7505823286451517\t 0.49599147744905336\t 0.49599147744905336\n",
            "28 \t [ 0.40130386  1.97007932 14.          0.94919936  9.          0.10604155]\t 1.124373317318908\t 0.7505823286451517\t 0.500642601506459\t 0.500642601506459\n",
            "29 \t [ 8.18178764  9.98869521 14.          0.83418368 10.          0.41151726]\t 0.8537499901780559\t 0.7505823286451517\t 0.5030755181231137\t 0.5030755181231137\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 7.07372144  7.12421793  9.          0.88361829 18.          0.94084728]\u001b[0m\t \u001b[1m\u001b[92m0.7429939712557221\u001b[0m\t \u001b[1m\u001b[92m0.7429939712557221\u001b[0m\t \u001b[1m\u001b[92m0.5033238451419932\u001b[0m\t \u001b[1m\u001b[92m0.5033238451419932\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60761.160061562216"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211f8763-950d-49ae-b300-29bc84f6bd03"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO_multi(surrogate_approx_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7978949387548113\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7689238087022429\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9009085979032214\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.9616956128686873\t 0.7689238087022429\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.8968042534595716\t 0.7689238087022429\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9141640599232991\t 0.7689238087022429\t 0.47284078090358667\t 0.47284078090358667\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9657302753232895\t 0.7689238087022429\t 0.4781759198212766\t 0.4781759198212766\n",
            "3  \t [ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\t 0.7975878945767783\t 0.7689238087022429\t 0.48629801488347657\t 0.48629801488347657\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.961106002845105\t 0.7689238087022429\t 0.48430368302376736\t 0.48430368302376736\n",
            "5  \t [ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\t 0.7812267618464406\t 0.7689238087022429\t 0.48643175857157517\t 0.48643175857157517\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.9035768104886805\t 0.7689238087022429\t 0.4811503143923679\t 0.4811503143923679\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8037187246418197\t 0.7689238087022429\t 0.48272221168783513\t 0.48272221168783513\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\u001b[0m\t \u001b[1m\u001b[92m0.7060994227407983\u001b[0m\t \u001b[1m\u001b[92m0.7060994227407983\u001b[0m\t \u001b[1m\u001b[92m0.4795464686752661\u001b[0m\t \u001b[1m\u001b[92m0.47954646867524114\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9684252162072007\t 0.7060994227407983\t 0.47321440645338203\t 0.47321440645338203\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.7212789829160808\t 0.7060994227407983\t 0.47780676391397225\t 0.47780676391397225\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[ 9.88162042  4.98501997  7.          0.71514689 11.          0.88825005]\u001b[0m\t \u001b[1m\u001b[92m0.7056574853508757\u001b[0m\t \u001b[1m\u001b[92m0.7056574853508757\u001b[0m\t \u001b[1m\u001b[92m0.4728867266102386\u001b[0m\t \u001b[1m\u001b[92m0.472886723950158\u001b[0m\n",
            "12 \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]\t 0.7645746008116381\t 0.7056574853508757\t 0.4680866807326038\t 0.4680866807326038\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7751802690627648\t 0.7056574853508757\t 0.4654295269948881\t 0.4654295126273876\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.7343751804493104\t 0.7056574853508757\t 0.46369860394574614\t 0.4636985680576408\n",
            "15 \t [ 0.58064821  4.71463583  6.          0.62063943 16.          0.34296764]\t 0.9094507882324498\t 0.7056574853508757\t 0.4621922041454448\t 0.4621922041454448\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8742114371455234\t 0.7056574853508757\t 0.4642834842371846\t 0.4642834842371846\n",
            "17 \t [ 3.45293281  1.16643478  9.          0.57140706 11.          0.20230511]\t 0.9702663325664342\t 0.7056574853508757\t 0.4644738743667021\t 0.4644738743667021\n",
            "18 \t [ 9.73541293  8.42044427 14.          0.53390677 16.          0.10576782]\t 0.9673248584076968\t 0.7056574853508757\t 0.48536021194407025\t 0.48536021194407025\n",
            "19 \t [ 7.38101511  7.5533833  14.          0.66040085  5.          0.11249251]\t 0.9703863182337837\t 0.7056574853508757\t 0.46925129070869287\t 0.46925129070868854\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7650562704693341\t 0.7056574853508757\t 0.4830779272490279\t 0.4830779272490279\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7875791905388638\t 0.7056574853508757\t 0.47783652556919365\t 0.47783652556919365\n",
            "22 \t [ 5.47781498  1.88597438 13.          0.63648698 17.          0.7577705 ]\t 0.7546482695497708\t 0.7056574853508757\t 0.47192292464996694\t 0.47192292464996694\n",
            "23 \t [ 0.14337166  3.83051228 13.          0.67084469 13.          0.27589041]\t 0.8967844079175256\t 0.7056574853508757\t 0.479442633185695\t 0.479442633185695\n",
            "24 \t [5.80891976 6.22815082 5.         0.60791835 2.         0.19304152]\t 0.9721486244102616\t 0.7056574853508757\t 0.466881261729246\t 0.466881261729246\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.7495093963493484\t 0.7056574853508757\t 0.4727382756857963\t 0.4727382756857963\n",
            "26 \t [ 0.65904826  3.00639193 10.          0.88267232 10.          0.15011078]\t 0.9700037688440479\t 0.7056574853508757\t 0.47106575498220216\t 0.47106575498220216\n",
            "27 \t [ 3.19568236  8.11750563 12.          0.61408734  2.          0.64741824]\t 0.7708972116226323\t 0.7056574853508757\t 0.47116835793389583\t 0.47116819810587607\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7558432662300643\t 0.7056574853508757\t 0.4803797059292572\t 0.4803797059292572\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7196023005131863\t 0.7056574853508757\t 0.4671680113128421\t 0.4671680113128421\n",
            "30 \t [9.84932726 0.01047441 9.         0.55060821 8.         0.4502745 ]\t 0.8779770054326832\t 0.7056574853508757\t 0.4783171317472656\t 0.4783171317472656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60866.87285515986"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309a421d-437d-43b1-ad12-f70b3817224a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO_multi(surrogate_approx_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8708842589582968\t 0.8009237324889021\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.868843701878103\t 0.8009237324889021\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.8009237324889021\t 0.8009237324889021\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.8412285708806564\t 0.8009237324889021\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0874405633037085\t 0.8009237324889021\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.077285755760575\t 0.8009237324889021\t 0.49558160894038694\t 0.49558160894038694\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.1030510584286708\t 0.8009237324889021\t 0.5132849915890133\t 0.5132849915890133\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0698458362482097\t 0.8009237324889021\t 0.5278809197758438\t 0.5278809197758438\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0952568725496277\t 0.8009237324889021\t 0.5360172867380244\t 0.5360172867380244\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m0.5439716969568772\u001b[0m\t \u001b[1m\u001b[92m0.5439716969568772\u001b[0m\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.8829825605031049\t 0.7880607112692197\t 0.5340338092816437\t 0.5340338092812108\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.1024724416092895\t 0.7880607112692197\t 0.5299155803277811\t 0.5299155803277811\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\u001b[0m\t \u001b[1m\u001b[92m0.7785043750594152\u001b[0m\t \u001b[1m\u001b[92m0.7785043750594152\u001b[0m\t \u001b[1m\u001b[92m0.5369576000026424\u001b[0m\t \u001b[1m\u001b[92m0.5369576000026424\u001b[0m\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0634397583136046\t 0.7785043750594152\t 0.5294499378677481\t 0.5294499378677481\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\u001b[0m\t \u001b[1m\u001b[92m0.7744953455912423\u001b[0m\t \u001b[1m\u001b[92m0.7744953455912423\u001b[0m\t \u001b[1m\u001b[92m0.5337118570011651\u001b[0m\t \u001b[1m\u001b[92m0.5337118570011651\u001b[0m\n",
            "11 \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]\t 0.7887884221082111\t 0.7744953455912423\t 0.527265761091979\t 0.527265761091979\n",
            "12 \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]\t 1.0699439848269314\t 0.7744953455912423\t 0.5219463032610703\t 0.5219463032610703\n",
            "13 \t [10.  10.   5.   0.5  1.   0.1]\t 1.0806859736708578\t 0.7744953455912423\t 0.5262113424870869\t 0.5262113424870873\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[ 1.35461816  3.68867636  7.          0.97358458 19.          0.99760691]\u001b[0m\t \u001b[1m\u001b[92m0.772679413351429\u001b[0m\t \u001b[1m\u001b[92m0.772679413351429\u001b[0m\t \u001b[1m\u001b[92m0.5303129795299463\u001b[0m\t \u001b[1m\u001b[92m0.5303129795296432\u001b[0m\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 0.19887638  4.80873048 13.          0.98258992 19.          0.95584094]\u001b[0m\t \u001b[1m\u001b[92m0.7622505819201761\u001b[0m\t \u001b[1m\u001b[92m0.7622505819201761\u001b[0m\t \u001b[1m\u001b[92m0.5254526547574602\u001b[0m\t \u001b[1m\u001b[92m0.5254526542390874\u001b[0m\n",
            "16 \t [ 4.8891514   9.63319929 13.          0.90452221  7.          0.96899492]\t 0.7651767009789585\t 0.7622505819201761\t 0.5207018423602836\t 0.5207018423602836\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.8987315752344891\t 0.7622505819201761\t 0.5163943080307212\t 0.5163943080307212\n",
            "18 \t [ 9.99036023  1.02904004 10.38693764  0.86129447  3.78171071  0.16759645]\t 1.09889265863578\t 0.7622505819201761\t 0.5183973118531626\t 0.5183973118643287\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.1009731307154418\t 0.7622505819201761\t 0.5167297067530009\t 0.5167297067530009\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9255377827812661\t 0.7622505819201761\t 0.5286539771274789\t 0.5286539771274789\n",
            "21 \t [ 0.47174379  1.61924333 14.          0.75160636 12.          0.46783122]\t 0.8990899098780416\t 0.7622505819201761\t 0.5315027292510588\t 0.5315027291767191\n",
            "22 \t [0.17851403 8.48161253 8.         0.92402557 4.         0.4823316 ]\t 0.9048140063822239\t 0.7622505819201761\t 0.5182119754838219\t 0.5182119754838219\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9004861276725805\t 0.7622505819201761\t 0.5221347582679791\t 0.5221347582679791\n",
            "24 \t [0.02966045 1.1870223  6.         0.92997678 6.         0.66621503]\t 0.83355468271605\t 0.7622505819201761\t 0.5175334008367587\t 0.5175334008367587\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.7882906269305859\t 0.7622505819201761\t 0.5254472030153006\t 0.5254472030153006\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.80192465196928\t 0.7622505819201761\t 0.5125384864913528\t 0.5125384864913528\n",
            "27 \t [4.35202159 5.24316404 7.         0.80344711 8.         0.19668159]\t 1.0985573147525929\t 0.7622505819201761\t 0.5166207957626728\t 0.5166207957532206\n",
            "28 \t [ 0.81732363  0.93646071 11.43178259  0.77230799  2.87766944  0.1       ]\t 1.1010834689454425\t 0.7622505819201761\t 0.517949267272671\t 0.5179496468575292\n",
            "29 \t [10.          2.38263275  5.          0.9462905   7.88281143  0.17614273]\t 1.0952759977679658\t 0.7622505819201761\t 0.5228093436467364\t 0.5228093895777698\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.8423134170816156\t 0.7622505819201761\t 0.5213826129234578\t 0.5213826129234578\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59260.747037503046"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d718ff33-adb2-4031-e318-5326264fe90d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO_multi(surrogate_approx_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.7260880637055529\t 0.7260880637055529\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.7424588384015385\t 0.7260880637055529\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.8412720456029797\t 0.7260880637055529\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7736412232573235\t 0.7260880637055529\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.7650415360356615\t 0.7260880637055529\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.9222990750260575\t 0.7260880637055529\t 0.42491666170098463\t 0.42491666170098463\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7908681556639724\t 0.7260880637055529\t 0.4399494027001377\t 0.4399494027001377\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.7532691574021181\t 0.7260880637055529\t 0.43939148494641733\t 0.43939148494641733\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7781432084155051\t 0.7260880637055529\t 0.436452655505105\t 0.436452655505105\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.8455317589117171\t 0.7260880637055529\t 0.4356322820094143\t 0.4356322820094143\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.7441046132441587\t 0.7260880637055529\t 0.4387812219399148\t 0.4387812219399148\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.938335419027365\t 0.7260880637055529\t 0.4362643355351837\t 0.4362643355351837\n",
            "8  \t [ 0.46626117  2.25760624  6.          0.85367342 17.          0.48531791]\t 0.8357006200561671\t 0.7260880637055529\t 0.44358629235634417\t 0.44358629235634417\n",
            "9  \t [2.13213943 0.33619788 8.         0.65805012 9.         0.21235962]\t 1.0382579820366014\t 0.7260880637055529\t 0.44492939715219604\t 0.44492939715219604\n",
            "10 \t [ 3.23063104  1.13251329 14.          0.56093148  7.          0.35241226]\t 0.9263052453028615\t 0.7260880637055529\t 0.45522182334911593\t 0.45522182334911593\n",
            "11 \t [9.32031429 7.90309325 6.         0.69040988 5.         0.24485333]\t 1.0379873808842273\t 0.7260880637055529\t 0.45912907356440186\t 0.45912907356440186\n",
            "12 \t [7.0602652  6.93790534 9.         0.99868525 6.         0.93828193]\t 0.7346015930490536\t 0.7260880637055529\t 0.4670038884167685\t 0.4670038884167685\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.8350939262618722\t 0.7260880637055529\t 0.4635339304025181\t 0.46353393038551366\n",
            "14 \t [ 6.2861962   7.16518546 10.          0.67477466  3.          0.33961227]\t 0.9218090224938408\t 0.7260880637055529\t 0.46342528611780415\t 0.46342528611780415\n",
            "15 \t [ 0.80466258  8.06348306  7.          0.77513285 17.          0.96959926]\t 0.7407859484199237\t 0.7260880637055529\t 0.4658967213906807\t 0.4658967213906807\n",
            "16 \t [7.5058071  0.77198166 5.         0.94542975 7.         0.89710815]\t 0.7549620723858046\t 0.7260880637055529\t 0.46319970040259884\t 0.46319970040259884\n",
            "17 \t [9.91439686 1.1223406  9.         0.69987447 9.         0.50079002]\t 0.7935395263864397\t 0.7260880637055529\t 0.4607592166981054\t 0.4607592166981054\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.7615889956561305\t 0.7260880637055529\t 0.462616985218997\t 0.462616985218997\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 1.0294400573352889\t 0.7260880637055529\t 0.4588581245544686\t 0.4588581245544686\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.9151572773679874\t 0.7260880637055529\t 0.46350097201780105\t 0.46350097201780105\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7851375921928307\t 0.7260880637055529\t 0.4746944413744206\t 0.4746944413744206\n",
            "22 \t [ 3.39029064  2.39709901 13.          0.66131557 19.          0.59343116]\t 0.7920132766777059\t 0.7260880637055529\t 0.462202088769556\t 0.462202088769556\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.9204040683754566\t 0.7260880637055529\t 0.46351154884795204\t 0.46351154884795204\n",
            "24 \t [0.70527907 5.59255728 5.         0.86863619 1.         0.35457337]\t 0.9131884722416652\t 0.7260880637055529\t 0.4676208878843028\t 0.4676208878843028\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7884946222204549\t 0.7260880637055529\t 0.4631425214686695\t 0.4631425214686695\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 1.026659800264627\t 0.7260880637055529\t 0.466031462970307\t 0.466031462970307\n",
            "27 \t [ 5.69797742  9.57419645  5.          0.83200529 19.          0.51994919]\t 0.7903346898520803\t 0.7260880637055529\t 0.4741926984488967\t 0.47419269844417145\n",
            "28 \t [ 7.27114604  3.7137488   9.          0.55194413 17.          0.65085645]\t 0.7913418219905086\t 0.7260880637055529\t 0.4680944494218658\t 0.4680944494218658\n",
            "29 \t [ 9.4564322   8.90732533 12.          0.76283199 19.          0.73059119]\t 0.7869676947248176\t 0.7260880637055529\t 0.4761763272070208\t 0.4761763268399026\n",
            "30 \t [ 0.41344076  0.53197741 10.          0.82623488 16.          0.71102663]\t 0.782525551781882\t 0.7260880637055529\t 0.4742797155389666\t 0.4742797155389666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61351.93418054509"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1684c221-6d36-485c-8974-7f3838ae7fc0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO_multi(surrogate_approx_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.802823873653181\t 0.7393694249818598\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.7439561063387327\t 0.7393694249818598\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8573744170126428\t 0.7393694249818598\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.7605799870908501\t 0.7393694249818598\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.7393694249818598\t 0.7393694249818598\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.4311826833537119\u001b[0m\t \u001b[1m\u001b[92m0.4311826833537119\u001b[0m\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8873087046852387\t 0.7341650428609557\t 0.42689350483825034\t 0.42689350483825034\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7481675054625107\t 0.7341650428609557\t 0.43633932398102926\t 0.43633932398102926\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8633824421289817\t 0.7341650428609557\t 0.4334294903010252\t 0.4334294903010252\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7484161632696045\t 0.7341650428609557\t 0.43836468396232153\t 0.43836468396232153\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.7356192440307244\t 0.7341650428609557\t 0.4358590208842028\t 0.4358590208842028\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8970855207140378\t 0.7341650428609557\t 0.4331927928661581\t 0.4331927928661581\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8688237885855482\t 0.7341650428609557\t 0.43863762634414055\t 0.43863762634414055\n",
            "9  \t [ 0.45485069  5.92046568 13.          0.54575641 15.          0.3753516 ]\t 0.8113677562605297\t 0.7341650428609557\t 0.4418738481424463\t 0.44187384765604026\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.7505018736047322\t 0.7341650428609557\t 0.4422657890850334\t 0.4422657890850334\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8673094941420189\t 0.7341650428609557\t 0.4404237035704483\t 0.4404237035704483\n",
            "12 \t [3.47378168 0.90493309 7.         0.70332668 6.         0.717685  ]\t 0.7495116962078379\t 0.7341650428609557\t 0.44287550024615757\t 0.44287550024615757\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 1.0006633800011113\t 0.7341650428609557\t 0.4411723443416545\t 0.4411723443416545\n",
            "14 \t [ 2.60485405  0.1122727  14.          0.63362696 19.          0.53965358]\t 0.7741744043730975\t 0.7341650428609557\t 0.4480463342956306\t 0.4480463342956306\n",
            "15 \t [3.63587924 9.92644255 5.         0.74785877 1.         0.42737692]\t 0.7942979577990048\t 0.7341650428609557\t 0.4469505649350101\t 0.4469505649350101\n",
            "16 \t [ 6.35979139  1.00897047 10.          0.55338934  9.          0.8992107 ]\t 0.7582154255415187\t 0.7341650428609557\t 0.4465977221865257\t 0.4465977221865257\n",
            "17 \t [ 2.12586208  4.01516793 14.          0.99753944  1.          0.59182746]\t 0.7780815499248835\t 0.7341650428609557\t 0.445547224589944\t 0.445547224589944\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9980631943644411\t 0.7341650428609557\t 0.44065019061409866\t 0.44065019061409866\n",
            "19 \t [ 1.24817982  5.75156112 12.          0.56532786 19.          0.40494625]\t 0.8074218603040494\t 0.7341650428609557\t 0.45944728293429216\t 0.45944728293429216\n",
            "20 \t [ 6.84951512  0.65690232  5.          0.51903401 13.          0.510251  ]\t 0.8038460886877121\t 0.7341650428609557\t 0.44580186215333845\t 0.44580186215333845\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.7443970340307106\t 0.7341650428609557\t 0.44442489787490624\t 0.44442489787490624\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.869979050273399\t 0.7341650428609557\t 0.45150459369463214\t 0.45150459369463214\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7442995610019533\t 0.7341650428609557\t 0.4510894972095651\t 0.4510894972095651\n",
            "24 \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\t 0.7403513737505086\t 0.7341650428609557\t 0.4547371843796273\t 0.4547371843796273\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8853726892659874\t 0.7341650428609557\t 0.4421999313809186\t 0.4421999313809186\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9897503949395169\t 0.7341650428609557\t 0.4462778325381797\t 0.4462778325381797\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8013428795907425\t 0.7341650428609557\t 0.4479888889463857\t 0.4479888889463857\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.7439831766925111\t 0.7341650428609557\t 0.4552182649844142\t 0.4552182649844142\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.7400612177024872\t 0.7341650428609557\t 0.4556321803743495\t 0.4556321803743495\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 1.0026563027674915\t 0.7341650428609557\t 0.4510364487254888\t 0.4510364487254888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60822.98185938519"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6028c7c6-aadc-479a-c112-f8c5b64b6975"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO_multi(surrogate_approx_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 1.1242573295906948\t 0.7785306461595496\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 1.1029639839305116\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.7785306461595496\t 0.7785306461595496\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.8502721808074817\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.8007936005920335\t 0.7785306461595496\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.1406566629866908\t 0.7785306461595496\t 0.520170981176189\t 0.520170981176189\n",
            "2  \t [ 8.16285902  8.43489929  9.          0.96605421 10.          0.79940153]\t 0.8233816089104812\t 0.7785306461595496\t 0.5398110058888215\t 0.5398110058888215\n",
            "3  \t [ 8.20707753  5.23681739  9.          0.99500664 19.          0.41686889]\t 0.9191507511732485\t 0.7785306461595496\t 0.5284030919203756\t 0.5284030919203756\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.8430600265636745\t 0.7785306461595496\t 0.5257428510733637\t 0.5257428510733637\n",
            "5  \t [ 1.54349431  7.96191852 12.          0.85734974 19.          0.2533894 ]\t 1.0672478448781664\t 0.7785306461595496\t 0.519325014868042\t 0.519325014868042\n",
            "6  \t [ 2.07399013  1.08547559 13.          0.90854674 16.          0.44415088]\t 0.9190933334870838\t 0.7785306461595496\t 0.5266407816232543\t 0.5266407816232543\n",
            "7  \t [ 1.89765372  4.25355821 10.          0.70664475 12.          0.87029284]\t 0.8473962745999538\t 0.7785306461595496\t 0.5248613454810166\t 0.5248613451121057\n",
            "8  \t [3.82480828 0.40103086 7.         0.99159013 8.         0.13885831]\t 1.1340370849711392\t 0.7785306461595496\t 0.520298808947906\t 0.520298808947906\n",
            "9  \t [ 1.49007135  2.48971353  7.          0.51783762 18.          0.72303345]\t 0.8773511871300128\t 0.7785306461595496\t 0.5291124117218284\t 0.5291124117218284\n",
            "10 \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]\t 0.9694253204437654\t 0.7785306461595496\t 0.5259987945434801\t 0.5259987945434801\n",
            "11 \t [ 7.53441733  9.89426931 12.          0.67232682 16.          0.3377491 ]\t 1.0829115765764628\t 0.7785306461595496\t 0.5265691240054423\t 0.5265691240054423\n",
            "12 \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]\t 1.0885131872740894\t 0.7785306461595496\t 0.531244303304599\t 0.531244303304599\n",
            "13 \t [ 3.46207476  9.83623086 13.          0.59254174 15.          0.37573299]\t 0.939883084954905\t 0.7785306461595496\t 0.5355498353943675\t 0.5355498353943675\n",
            "14 \t [ 8.88182279  1.21247755  8.          0.57194414 15.          0.58313863]\t 0.8769535406326074\t 0.7785306461595496\t 0.5345102804811221\t 0.5345102804811221\n",
            "15 \t [6.5099841  8.70472582 8.         0.63069736 4.         0.74098062]\t 0.8618854059109389\t 0.7785306461595496\t 0.5320300128866529\t 0.5320300128866529\n",
            "16 \t [1.12068613 5.38370759 5.         0.59812309 7.         0.55127392]\t 0.8917201352912059\t 0.7785306461595496\t 0.5291905944589985\t 0.5291905944589985\n",
            "17 \t [ 9.02776142  2.32861068 14.          0.70363074 17.          0.39080307]\t 0.9345712186418395\t 0.7785306461595496\t 0.5269506696929556\t 0.5269506696929556\n",
            "18 \t [2.32449242 8.80135208 8.         0.99642073 4.         0.14576968]\t 1.1331068048862545\t 0.7785306461595496\t 0.5287289499894894\t 0.5287289499894894\n",
            "19 \t [ 1.05981518  6.9935573   5.          0.61952114 12.          0.47639086]\t 0.9397945627343445\t 0.7785306461595496\t 0.5318020934655502\t 0.5318020934655502\n",
            "20 \t [ 9.27124123  1.79885495 11.          0.60820867  4.          0.48344805]\t 0.9618304471443053\t 0.7785306461595496\t 0.5302265390274746\t 0.5302265390274746\n",
            "21 \t [ 2.60018347  8.33426121 13.          0.92542949  6.          0.59638435]\t 0.8377766603609096\t 0.7785306461595496\t 0.5331328589861412\t 0.5331328589861412\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.9210006183994057\t 0.7785306461595496\t 0.525841244468277\t 0.525841244468277\n",
            "23 \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]\t 1.082295397988777\t 0.7785306461595496\t 0.5369606274221487\t 0.5369606273185005\n",
            "24 \t [1.76701563 1.7346788  7.         0.94361827 2.         0.93288306]\t 0.7877982540472509\t 0.7785306461595496\t 0.5335719298091598\t 0.5335719298091598\n",
            "25 \t [8.2007632  5.80436627 6.         0.76635233 7.         0.49444634]\t 0.9337877394134475\t 0.7785306461595496\t 0.5281795631105756\t 0.5281795631105756\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.8414357962829216\t 0.7785306461595496\t 0.5253305268886107\t 0.5253305268886107\n",
            "27 \t [ 4.17165897  0.93091347 13.          0.9339569  11.          0.80302369]\t 0.8238203838374375\t 0.7785306461595496\t 0.5289320296478117\t 0.5289320296478117\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 1.0854101197025208\t 0.7785306461595496\t 0.5252149281385666\t 0.5252149281385666\n",
            "29 \t [ 4.3882931   7.21586896  9.          0.93421279 16.          0.9902477 ]\t 0.7872624666282382\t 0.7785306461595496\t 0.5285708206848122\t 0.5285708206848122\n",
            "30 \t [ 0.01153499  2.29531024 11.          0.50673714  7.          0.13750522]\t 1.154363103664814\t 0.7785306461595496\t 0.52552460535511\t 0.52552460535511\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60590.73520973802"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9aad80-1ce8-42de-b973-1daeb83e9cf8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO_multi(surrogate_approx_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 1.0639310256047103\t 0.7797034870948047\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.79580179662759\t 0.7797034870948047\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7797034870948047\t 0.7797034870948047\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7990514117028104\t 0.7797034870948047\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 1.0587036817796267\t 0.7797034870948047\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m0.5012258261522557\u001b[0m\t \u001b[1m\u001b[92m0.5012258261522557\u001b[0m\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.8572799307158145\t 0.7741723447560037\t 0.4896112477525228\t 0.4896112477525228\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 1.0670266318570725\t 0.7741723447560037\t 0.4872234187338283\t 0.4872234187338283\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.5009718372933486\u001b[0m\t \u001b[1m\u001b[92m0.5009718372933486\u001b[0m\n",
            "5  \t [ 2.36407072  4.99081503 14.          0.6287111   1.          0.46714602]\t 0.8729171360227909\t 0.7701333999187374\t 0.49307035449797953\t 0.49307035449797953\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 1.013338643136875\t 0.7701333999187374\t 0.49190256113188124\t 0.49190256113188124\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 9.67314628  9.09427799  9.          0.82851167 16.          0.96267251]\u001b[0m\t \u001b[1m\u001b[92m0.7578726678207005\u001b[0m\t \u001b[1m\u001b[92m0.7578726678207005\u001b[0m\t \u001b[1m\u001b[92m0.4983443478664686\u001b[0m\t \u001b[1m\u001b[92m0.4983443478663527\u001b[0m\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7966957629406074\t 0.7578726678207005\t 0.49213806658726816\t 0.49213806658726816\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.7659210449096093\t 0.7578726678207005\t 0.48827246477919595\t 0.48827246477919595\n",
            "10 \t [ 9.68988111  3.14723756  5.          0.57337272 11.          0.12853019]\t 1.0708271865508894\t 0.7578726678207005\t 0.4838578367087731\t 0.4838578367087731\n",
            "11 \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]\t 0.7767785796277231\t 0.7578726678207005\t 0.4916772092039396\t 0.4916772092039396\n",
            "12 \t [ 2.40528406  7.71427622 14.          0.55203588 14.          0.3470708 ]\t 0.9922782988108612\t 0.7578726678207005\t 0.487965342790202\t 0.487965342790202\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.9748541191382067\t 0.7578726678207005\t 0.4916381774636022\t 0.49163817444635916\n",
            "14 \t [ 3.89768175  5.29572603  8.          0.92074245 11.          0.31486353]\t 0.9676224176737994\t 0.7578726678207005\t 0.4942720246088886\t 0.4942720246088886\n",
            "15 \t [ 9.86913094  2.54287696 14.          0.86051843  2.          0.74044264]\t 0.7772670831926136\t 0.7578726678207005\t 0.496405617795817\t 0.496405617795817\n",
            "16 \t [ 3.32064678  9.82322091 10.          0.61729748  2.          0.52189899]\t 0.7905976657577247\t 0.7578726678207005\t 0.49325352696743124\t 0.49325351369109743\n",
            "17 \t [0.54815519 9.09457687 7.         0.55756737 9.         0.32110491]\t 0.9905916044645892\t 0.7578726678207005\t 0.4902555903892631\t 0.4902555903892631\n",
            "18 \t [ 6.17394409  4.04114422 10.          0.65058545  1.          0.14583054]\t 1.0756148882202339\t 0.7578726678207005\t 0.49777993993183667\t 0.49777993993183667\n",
            "19 \t [ 0.46054358  2.23255    12.          0.55707085  4.          0.75408551]\t 0.7971512804306983\t 0.7578726678207005\t 0.505432202944913\t 0.505432202944913\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 1.0497516119782428\t 0.7578726678207005\t 0.4956272729264365\t 0.4956272729264365\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7979220004395456\t 0.7578726678207005\t 0.49935511081633005\t 0.49935511081633005\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 1.0727233913162242\t 0.7578726678207005\t 0.49503116598953395\t 0.49503116598953395\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.7738741181601402\t 0.7578726678207005\t 0.496984693203298\t 0.496984693203298\n",
            "24 \t [ 4.11986688  9.81320751 11.          0.98131964 17.          0.2975892 ]\t 0.9690486153881398\t 0.7578726678207005\t 0.4992709721592379\t 0.4992709721592379\n",
            "25 \t [ 8.21404851  8.60074735  5.          0.79731226 10.          0.34633832]\t 0.9747124656772961\t 0.7578726678207005\t 0.5020001375792599\t 0.5020000989663193\n",
            "26 \t [ 9.76455747  9.71578983 14.          0.66293675 18.          0.1137209 ]\t 1.0681711815285222\t 0.7578726678207005\t 0.5029255287832173\t 0.5029255272719095\n",
            "27 \t [ 7.88167693  7.97515501  6.          0.78950848 17.          0.19131965]\t 1.0553390354056282\t 0.7578726678207005\t 0.5035564706286055\t 0.5035564706286055\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 1.0555070855921338\t 0.7578726678207005\t 0.5083358489901317\t 0.5083358489901317\n",
            "29 \t [ 6.08927292  8.16912912 14.          0.79690706  3.          0.68863564]\t 0.7850181441090629\t 0.7578726678207005\t 0.509659427703898\t 0.509659427703898\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.9718991207487232\t 0.7578726678207005\t 0.5105070327167173\t 0.5105070327167173\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60744.35614633767"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facb1646-61d0-4c68-db69-c83071ce6b6d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO_multi(surrogate_approx_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.8177825188141039\t 0.7287337628426743\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.7419480115539112\t 0.7287337628426743\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.7287337628426743\t 0.7287337628426743\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7335645848611818\t 0.7287337628426743\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7441537376931249\t 0.7287337628426743\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.7482694480200888\t 0.7287337628426743\t 0.4153049507789871\t 0.4153049507789871\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.4148458324214286\u001b[0m\t \u001b[1m\u001b[92m0.4148458324214286\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7598608339614092\t 0.7070648622170269\t 0.4113646533320737\t 0.4113646533320737\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 1.0312511769390245\t 0.7070648622170269\t 0.4123183275376377\t 0.4123183275376377\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.821741520088635\t 0.7070648622170269\t 0.4324748021213038\t 0.4324748021212923\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.7209540253636189\t 0.7070648622170269\t 0.4347519586514114\t 0.4347519586514114\n",
            "7  \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]\t 0.7248028462146275\t 0.7070648622170269\t 0.43133572949057597\t 0.43133572949026816\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.9107534784629161\t 0.7070648622170269\t 0.4289301505698846\t 0.4289301505698846\n",
            "9  \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]\t 0.725647375042158\t 0.7070648622170269\t 0.4348617308756367\t 0.4348617308548471\n",
            "10 \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]\t 0.7416396014125557\t 0.7070648622170269\t 0.43259725168540925\t 0.43259725168540925\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.9287138963597805\t 0.7070648622170269\t 0.4310745537194634\t 0.4310745537194634\n",
            "12 \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]\t 1.0220817994568854\t 0.7070648622170269\t 0.4366119109271939\t 0.4366119109271939\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 1.0261353862133127\t 0.7070648622170269\t 0.4450090803896767\t 0.4450090803896767\n",
            "14 \t [ 0.62966465  6.1940162  12.          0.81741232 11.          0.49382371]\t 0.8182502230736013\t 0.7070648622170269\t 0.4525737557954073\t 0.4525737557954073\n",
            "15 \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]\t 1.0235667739127183\t 0.7070648622170269\t 0.45246748200282827\t 0.45246748200282827\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7623000424638748\t 0.7070648622170269\t 0.459026963980302\t 0.459026963980302\n",
            "17 \t [0.08327566 8.61614883 7.         0.71686897 9.         0.2323488 ]\t 1.0162942984816756\t 0.7070648622170269\t 0.4568872148416611\t 0.4568872148416611\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.7459513240013139\t 0.7070648622170269\t 0.4625176616464336\t 0.4625176616464336\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 1.0352571936435033\t 0.7070648622170269\t 0.4666578976097861\t 0.4666578976097861\n",
            "20 \t [9.22875209 9.1986098  9.         0.90439491 3.         0.27523226]\t 0.9230186077285822\t 0.7070648622170269\t 0.46955279912427694\t 0.46955279912427694\n",
            "21 \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]\t 0.7362063940289248\t 0.7070648622170269\t 0.4719333772918283\t 0.4719333772918283\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7433881169429852\t 0.7070648622170269\t 0.4676017488140482\t 0.4676017488140482\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7547149277921693\t 0.7070648622170269\t 0.4760151133718124\t 0.4760151133718124\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.9114560559082703\t 0.7070648622170269\t 0.4658183902029185\t 0.4658183902029185\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 1.0248025279634128\t 0.7070648622170269\t 0.4619056597232173\t 0.4619056597232173\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.8261521259015148\t 0.7070648622170269\t 0.4766518620583243\t 0.4766518620583243\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7532872744350481\t 0.7070648622170269\t 0.4685887327697333\t 0.4685887327697333\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[0.37569294 0.30864512 9.         0.6310655  7.         0.92576756]\u001b[0m\t \u001b[1m\u001b[92m0.6982328571669815\u001b[0m\t \u001b[1m\u001b[92m0.6982328571669815\u001b[0m\t \u001b[1m\u001b[92m0.4647900963223496\u001b[0m\t \u001b[1m\u001b[92m0.4647900963223496\u001b[0m\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.7123414924113913\t 0.6982328571669815\t 0.4611811556499922\t 0.4611811556499922\n",
            "30 \t [4.8041921  4.06620309 5.         0.94317975 9.         0.20395595]\t 1.0168771290789498\t 0.6982328571669815\t 0.46798958323264556\t 0.46798958323264556\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62004.49800279091"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c9ecfc-ebed-44c1-b8ea-eac73d0999d3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO_multi(surrogate_approx_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.992708970032886\t 0.7896346786115067\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.9050380263035862\t 0.7896346786115067\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.8362986807103934\t 0.7896346786115067\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7896346786115067\t 0.7896346786115067\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.9186387829358221\t 0.7896346786115067\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.8115376813007883\t 0.7896346786115067\t 0.4913562726526995\t 0.4913562726526995\n",
            "2  \t [ 3.78385301  2.21923666 12.          0.57141407  8.          0.55842631]\t 0.8600045769145973\t 0.7896346786115067\t 0.48431108469755246\t 0.48431108469755246\n",
            "3  \t [ 7.48458025  0.82585105 14.          0.62666135 18.          0.34757206]\t 0.9136369680693782\t 0.7896346786115067\t 0.4828719383489006\t 0.4828719383489006\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.9144290525005069\t 0.7896346786115067\t 0.48552619305930167\t 0.48552619305930167\n",
            "5  \t [ 5.83217552  8.53843574 11.          0.58549752 18.          0.26781236]\t 0.9216214538529052\t 0.7896346786115067\t 0.48763076625169877\t 0.48763076625169877\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.9442383814615898\t 0.7896346786115067\t 0.48971793651770185\t 0.48971793651770185\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 6.10107735  0.03652674 11.          0.56244485 13.          0.89741329]\u001b[0m\t \u001b[1m\u001b[92m0.7783701142125483\u001b[0m\t \u001b[1m\u001b[92m0.7783701142125483\u001b[0m\t \u001b[1m\u001b[92m0.49260402346081167\u001b[0m\t \u001b[1m\u001b[92m0.49260402346081167\u001b[0m\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.9239433760752476\t 0.7783701142125483\t 0.48763101020244726\t 0.48763101020244726\n",
            "9  \t [ 2.73067092  9.86029136  9.          0.98915314 11.          0.78920814]\t 0.7815140040967317\t 0.7783701142125483\t 0.4893410014242414\t 0.4893410014242414\n",
            "10 \t [ 0.14475494  9.8292754  12.          0.60331385  2.          0.9622215 ]\t 0.7880902159034013\t 0.7783701142125483\t 0.48539790321301335\t 0.48539790321301335\n",
            "11 \t [ 1.81539004  3.97973122 11.          0.55780808 14.          0.86016605]\t 0.8021824021652308\t 0.7783701142125483\t 0.48217253510636576\t 0.48217253510636576\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.786862562407444\t 0.7783701142125483\t 0.47977935939236355\t 0.47977935939236355\n",
            "13 \t [ 8.71378379  5.91732489 10.          0.67395488  5.          0.37191233]\t 0.9140896924023043\t 0.7783701142125483\t 0.4771935071759855\t 0.4771935071759855\n",
            "14 \t [8.72042964 1.18098427 6.         0.87093363 1.         0.1200865 ]\t 0.978708815138663\t 0.7783701142125483\t 0.4786842921118453\t 0.4786842921118453\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9970201710934681\t 0.7783701142125483\t 0.48210737128988546\t 0.48210737128988546\n",
            "16 \t [ 9.50979811  3.16002382 14.          0.62948949 10.          0.39138316]\t 0.9147194483561627\t 0.7783701142125483\t 0.4856862437623393\t 0.48568623998331817\n",
            "17 \t [ 2.38620183  1.03950496 13.          0.6257051   6.          0.34211692]\t 0.9194161634890323\t 0.7783701142125483\t 0.48632722289773217\t 0.48632722289773217\n",
            "18 \t [3.82043232 0.90149463 5.         0.93713205 2.         0.73959641]\t 0.7986205174407796\t 0.7783701142125483\t 0.49745414120834613\t 0.49745414120834613\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 4.82116392  7.94441114 13.          0.79896359 10.          0.94409065]\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.4869673926462366\u001b[0m\t \u001b[1m\u001b[92m0.4869673926462366\u001b[0m\n",
            "20 \t [4.88722703 1.05307859 6.         0.84108367 7.         0.32451309]\t 0.9150062445310105\t 0.7656138946809342\t 0.4845175550443762\t 0.4845175550443762\n",
            "21 \t [ 4.73215091  0.85301789  5.          0.940584   18.          0.80546064]\t 0.7987217033287252\t 0.7656138946809342\t 0.47986897580998333\t 0.47986897580998333\n",
            "22 \t [ 4.22119996  7.99655483  5.          0.78307763 14.          0.79061697]\t 0.7946617241328867\t 0.7656138946809342\t 0.48930420289922794\t 0.48930420289922794\n",
            "23 \t [7.12967992 8.154614   8.         0.5156473  9.         0.21177212]\t 0.9924239421587664\t 0.7656138946809342\t 0.48383401652557473\t 0.48383401652557473\n",
            "24 \t [ 1.47973338  1.45058818 11.          0.74181509 19.          0.60410465]\t 0.8329180373498172\t 0.7656138946809342\t 0.4857322323313142\t 0.4857322323313142\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9785605674881227\t 0.7656138946809342\t 0.4872095742303796\t 0.4872095742303796\n",
            "26 \t [ 4.24823418  9.49681173 13.          0.6150292   7.          0.81414675]\t 0.7903152027969078\t 0.7656138946809342\t 0.4945623536011042\t 0.4945623536011042\n",
            "27 \t [ 9.48577803  3.67088742  8.          0.57966698 12.          0.6677145 ]\t 0.7926582622847888\t 0.7656138946809342\t 0.49127212585910573\t 0.4912717895044598\n",
            "28 \t [ 3.68821786  5.6786616   8.          0.65862302 12.          0.189801  ]\t 0.9845598727954463\t 0.7656138946809342\t 0.48604119423699116\t 0.48604119423699116\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.8456632041648999\t 0.7656138946809342\t 0.48957171148239836\t 0.48957171148239836\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.979555746560927\t 0.7656138946809342\t 0.4846255488613736\t 0.4846255488613736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60877.04939096347"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db28470-dd79-47d3-a136-401d00f6513e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO_multi(surrogate_approx_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.7315012035187541\t 0.7315012035187541\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1319770010327717\t 0.7315012035187541\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.9318565354152348\t 0.7315012035187541\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.7799608780638936\t 0.7315012035187541\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1305934464937346\t 0.7315012035187541\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7922048089873084\t 0.7315012035187541\t 0.5271464231493893\t 0.5271464231493893\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.7364009364353266\t 0.7315012035187541\t 0.513189448758987\t 0.513189448758987\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7884892526498699\t 0.7315012035187541\t 0.4992874624139297\t 0.4992874624139297\n",
            "4  \t [ 4.39024044  6.42906019 12.          0.96666124  5.          0.79403332]\t 0.7332036085962248\t 0.7315012035187541\t 0.49169578315733137\t 0.49169578315733137\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.1341345349522627\t 0.7315012035187541\t 0.4827614203685143\t 0.4827614203685143\n",
            "6  \t [ 1.86840748  0.75206083 14.          0.81141351 17.          0.47108772]\t 0.8233179447887817\t 0.7315012035187541\t 0.49884767182112244\t 0.4988476718187545\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8347085780850761\t 0.7315012035187541\t 0.4949327525281908\t 0.4949327525281908\n",
            "8  \t [ 9.44002225  4.67426365 14.          0.69806573  1.          0.72511221]\t 0.7758064515807063\t 0.7315012035187541\t 0.49213228291380684\t 0.49213228291380684\n",
            "9  \t [ 6.80309585  9.43423094  7.          0.8851539  14.          0.77731456]\t 0.7410022072170401\t 0.7315012035187541\t 0.4874806733527709\t 0.4874806733527709\n",
            "10 \t [ 9.90790911  3.6691837   7.          0.58814302 10.          0.64733993]\t 0.761278126308538\t 0.7315012035187541\t 0.4822698376636171\t 0.4822698376636171\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7577952901048656\t 0.7315012035187541\t 0.4783513382163841\t 0.4783513382163841\n",
            "12 \t [ 8.67074354  1.64396694 14.          0.83039094  7.          0.18845957]\t 1.133362308446904\t 0.7315012035187541\t 0.47479003612813486\t 0.47479003612813486\n",
            "13 \t [ 1.3504194   1.49735602 14.          0.92508696  4.          0.69758236]\t 0.7478948066146335\t 0.7315012035187541\t 0.48492320069234546\t 0.4849232006605799\n",
            "14 \t [ 6.64335896  4.21317694 13.          0.67704359  4.          0.77970128]\t 0.7492274689494482\t 0.7315012035187541\t 0.48118942795466313\t 0.48118942795466313\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.7438065116890006\t 0.7315012035187541\t 0.47789958729891463\t 0.47789958729891463\n",
            "16 \t [ 2.06284179  6.9068961   5.          0.9448545  18.          0.13792391]\t 1.1296197909572616\t 0.7315012035187541\t 0.4746552876479734\t 0.4746552876479734\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.1355955958989596\t 0.7315012035187541\t 0.48308930301121994\t 0.48308930301121994\n",
            "18 \t [2.57352577 0.33719112 9.         0.97251025 4.         0.51947396]\t 0.78517596210852\t 0.7315012035187541\t 0.49239246827597904\t 0.49239246827597904\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.1349556164442796\t 0.7315012035187541\t 0.48818587873191294\t 0.48818587873191294\n",
            "20 \t [ 9.35280568  2.44132886  8.          0.87489385 18.          0.92170626]\t 0.733467050872053\t 0.7315012035187541\t 0.49431419238494795\t 0.49431419238494795\n",
            "21 \t [ 1.23850137  5.96524691 14.          0.65167204 16.          0.56763255]\t 0.7987790499738011\t 0.7315012035187541\t 0.49653851378673497\t 0.49653851378673497\n",
            "22 \t [8.1634571  7.58766207 7.         0.64490867 1.         0.97002079]\t 0.7514301027178281\t 0.7315012035187541\t 0.498252551252552\t 0.498252551252552\n",
            "23 \t [3.55859061 5.61875163 8.         0.5882063  1.         0.57036163]\t 0.8119275659738049\t 0.7315012035187541\t 0.49670257170102555\t 0.49670257170102555\n",
            "24 \t [9.58119431 4.08928042 5.         0.53767664 4.         0.31130369]\t 0.922946959484098\t 0.7315012035187541\t 0.49213923261309567\t 0.49213923261309567\n",
            "25 \t [9.92248648 8.73301847 7.         0.58578431 6.         0.64802898]\t 0.7597086493735234\t 0.7315012035187541\t 0.4877978471767644\t 0.4877978471763878\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.7463927243485514\t 0.7315012035187541\t 0.48688833448823016\t 0.48688833448823016\n",
            "27 \t [ 5.85240254  2.29607078  6.          0.83156764 14.          0.75611542]\t 0.7463626746911727\t 0.7315012035187541\t 0.4839278256397118\t 0.4839278256131134\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.7956673392227565\t 0.7315012035187541\t 0.4781008626050998\t 0.4781008626050998\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9305364532791108\t 0.7315012035187541\t 0.4826995348728309\t 0.4826995348728309\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.932353773777384\t 0.7315012035187541\t 0.4791790477797005\t 0.4791790477797005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59500.46682850479"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad34917-791d-4ad9-91ca-d4e8f058ff5c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO_multi(surrogate_approx_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.886516450243748\t 0.7696523735238344\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.8159404842786963\t 0.7696523735238344\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.9077084280320982\t 0.7696523735238344\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.7696523735238344\t 0.7696523735238344\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 0.9767143382937844\t 0.7696523735238344\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 0.9945462140035275\t 0.7696523735238344\t 0.4820184704180913\t 0.4820184704180913\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.8956717295899809\t 0.7696523735238344\t 0.4936914785628743\t 0.4936914785628743\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7896752580111073\t 0.7696523735238344\t 0.4937086211876093\t 0.4937086211876093\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 0.9788770650266176\t 0.7696523735238344\t 0.48679866303969827\t 0.48679866303969827\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9068912188410501\t 0.7696523735238344\t 0.4929547046977047\t 0.4929547046977047\n",
            "6  \t [ 1.2948927   7.78786103 11.          0.50236456  2.          0.82308036]\t 0.7981960996164814\t 0.7696523735238344\t 0.4936635688292529\t 0.4936635688292529\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7844376116756365\t 0.7696523735238344\t 0.48903397850681196\t 0.48903397850681196\n",
            "8  \t [ 7.13077184  9.67534636 12.          0.53994085 17.          0.99732292]\t 0.7788814985676316\t 0.7696523735238344\t 0.48457360015140916\t 0.48457360015140916\n",
            "9  \t [ 4.99777324  7.1255563   5.          0.87428718 19.          0.63814647]\t 0.8365647355641779\t 0.7696523735238344\t 0.48055581884687226\t 0.48055581884687226\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.8262334140046084\t 0.7696523735238344\t 0.4792001686054196\t 0.4792001686054196\n",
            "11 \t [ 2.11261802  6.77105261 11.          0.82546435 17.          0.58049877]\t 0.8420672525155452\t 0.7696523735238344\t 0.4776617972225349\t 0.4776617972225349\n",
            "12 \t [ 1.50285169  4.17593259 14.          0.69234646  6.          0.74044842]\t 0.8279918365760726\t 0.7696523735238344\t 0.4768452431876819\t 0.4768452431876819\n",
            "13 \t [ 9.52967585  8.1936199  11.          0.55796294 10.          0.99729185]\t 0.7763977773208957\t 0.7696523735238344\t 0.4756565153071133\t 0.4756565153071133\n",
            "14 \t [ 0.14006525  1.03750573 13.          0.72168802 14.          0.72400369]\t 0.815597828474959\t 0.7696523735238344\t 0.47315198068686964\t 0.47315198068686964\n",
            "15 \t [ 4.60180761  5.86373927 12.          0.57860802 15.          0.61913601]\t 0.8488880266059902\t 0.7696523735238344\t 0.4720203039036109\t 0.4720203039036109\n",
            "16 \t [ 0.37071497  8.67648538  5.          0.98055998 16.          0.65274603]\t 0.8335023218287553\t 0.7696523735238344\t 0.4716458366363288\t 0.4716458366363288\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.778866435123053\t 0.7696523735238344\t 0.4708866835191585\t 0.4708866835191585\n",
            "18 \t [1.97879228 8.99345507 8.         0.55562265 8.         0.49118331]\t 0.8951491505335811\t 0.7696523735238344\t 0.46618458045860245\t 0.46618458045860245\n",
            "19 \t [ 3.46936711  8.05933995 13.          0.63796232  8.          0.58226276]\t 0.8566066993171872\t 0.7696523735238344\t 0.4655478289411396\t 0.4655478289411396\n",
            "20 \t [2.03544962 0.82234782 9.         0.75192666 8.         0.57674562]\t 0.8454913145347565\t 0.7696523735238344\t 0.46772011367009586\t 0.46772011367009586\n",
            "21 \t [4.16561464 4.3151821  6.         0.76299318 2.         0.59049538]\t 0.8474357581098328\t 0.7696523735238344\t 0.47901111922627965\t 0.47901111922627965\n",
            "22 \t [4.66769699 4.74732773 9.         0.50018348 8.         0.67980328]\t 0.8402846678230176\t 0.7696523735238344\t 0.4754346456751802\t 0.475434619222342\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 0.9821896458721675\t 0.7696523735238344\t 0.4764665183411231\t 0.4764665183411231\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.7800900414685491\t 0.7696523735238344\t 0.4739329147891463\t 0.4739329147891463\n",
            "25 \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]\t 0.7754504257026212\t 0.7696523735238344\t 0.48050662809281836\t 0.48050662809279865\n",
            "26 \t [ 5.73005003  1.18628884 13.          0.88016467 12.          0.48547975]\t 0.8868749954853754\t 0.7696523735238344\t 0.4730007029856388\t 0.4730007029856388\n",
            "27 \t [8.60914739 9.54673859 7.         0.78963544 7.         0.48348756]\t 0.8811833469490125\t 0.7696523735238344\t 0.47226224334174427\t 0.47226224334174427\n",
            "28 \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]\t 0.8621381926118351\t 0.7696523735238344\t 0.46888497131113654\t 0.46888497131113654\n",
            "29 \t [ 7.16352089  0.19968156 11.          0.62318898  8.          0.21107406]\t 0.9776297559990524\t 0.7696523735238344\t 0.4710537878415819\t 0.4710537878415819\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.8347983363393409\t 0.7696523735238344\t 0.4829952274044756\t 0.4829952274044756\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60169.1345471105"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd272a4-1128-4af9-f743-8b830861b4fa"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO_multi(surrogate_approx_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.7846478010899064\t 0.7846478010899064\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 1.0448868808294456\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 1.0327067294213346\t 0.7846478010899064\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.8536879526704689\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 1.0323325469581077\t 0.7846478010899064\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.810550884613735\t 0.7846478010899064\t 0.5269987735641259\t 0.5269987735641259\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.9535088265263543\t 0.7846478010899064\t 0.5145127550710321\t 0.5145127550710321\n",
            "3  \t [ 1.91126037  0.99517267  5.          0.54111286 13.          0.82351196]\t 0.8272848096167836\t 0.7846478010899064\t 0.5161253424648982\t 0.5161253424648982\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 9.65016643  9.36315476  6.          0.59817648 12.          0.93115055]\u001b[0m\t \u001b[1m\u001b[92m0.7808363478466259\u001b[0m\t \u001b[1m\u001b[92m0.7808363478466259\u001b[0m\t \u001b[1m\u001b[92m0.5090100218559563\u001b[0m\t \u001b[1m\u001b[92m0.5090100218559563\u001b[0m\n",
            "5  \t [ 7.92634325  7.5869497  10.          0.81214373  5.          0.71583728]\t 0.8214564758537112\t 0.7808363478466259\t 0.5008945306693038\t 0.5008945306693038\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.9316923990976885\t 0.7808363478466259\t 0.49630339324200334\t 0.49630339324200334\n",
            "7  \t [ 1.16848639  8.05538533  5.          0.78038294 17.          0.39890654]\t 0.9239694196020342\t 0.7808363478466259\t 0.4979070399426127\t 0.4979070399426127\n",
            "8  \t [ 2.92030295  6.55213539  7.          0.85743112 11.          0.10721562]\t 1.0321654101154336\t 0.7808363478466259\t 0.4988759516397813\t 0.4988759516397813\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.8467944167491783\t 0.7808363478466259\t 0.5046185545776022\t 0.5046185544113658\n",
            "10 \t [ 7.63220266  0.71776488 13.          0.94235703 19.          0.50312607]\t 0.8163942466098536\t 0.7808363478466259\t 0.5020180538864178\t 0.5020180535723013\n",
            "11 \t [7.86329715 0.45193827 6.         0.68312899 1.         0.69810196]\t 0.8331518961036075\t 0.7808363478466259\t 0.4987263964345921\t 0.4987263964345921\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.8291023984963773\t 0.7808363478466259\t 0.4963564023489633\t 0.4963564023489633\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.7817258295570644\t 0.7808363478466259\t 0.494130492258536\t 0.49413049224790706\n",
            "14 \t [ 7.74771021  6.65318771  6.          0.83647538 17.          0.81072392]\t 0.8146793231457089\t 0.7808363478466259\t 0.4908577974346868\t 0.49085779519582745\n",
            "15 \t [ 0.16461509  2.47453913  6.          0.69159787 16.          0.61162096]\t 0.8390246298076309\t 0.7808363478466259\t 0.4886934814955458\t 0.4886934814955458\n",
            "16 \t [ 1.01000548  1.96777104 12.          0.51504561  8.          0.68970296]\t 0.8363440079633978\t 0.7808363478466259\t 0.48757906760561065\t 0.48757906760561065\n",
            "17 \t [4.50435964 1.42883317 8.         0.76583339 3.         0.4306355 ]\t 0.9350949568458088\t 0.7808363478466259\t 0.48669802315936517\t 0.48669802315936517\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.8184266869335748\t 0.7808363478466259\t 0.48951728789783044\t 0.48951728789783044\n",
            "19 \t [7.35570048 8.26460229 5.         0.55162663 8.         0.77748758]\t 0.8355742875991361\t 0.7808363478466259\t 0.4864061336285283\t 0.4864061336285283\n",
            "20 \t [ 5.31037667  6.81676807  5.          0.53020463 18.          0.21260061]\t 1.0437596156191435\t 0.7808363478466259\t 0.4865422908331984\t 0.4865422908331984\n",
            "21 \t [8.81149616 6.28323965 6.         0.50689458 2.         0.19421846]\t 1.0506048051001848\t 0.7808363478466259\t 0.4957970941396225\t 0.49579707600890965\n",
            "22 \t [ 9.31305405  2.68340802  7.          0.59348541 12.          0.97471219]\t 0.7821514519763622\t 0.7808363478466259\t 0.492508689056863\t 0.49250858032964806\n",
            "23 \t [ 6.04262604  3.49698263 14.          0.62988823  3.          0.21136394]\t 1.0525057130171327\t 0.7808363478466259\t 0.4922410625186827\t 0.4922410625186827\n",
            "24 \t [ 6.65527361  8.38369074 14.          0.9282554  10.          0.38464501]\t 0.9220170566192639\t 0.7808363478466259\t 0.49659845019188437\t 0.49659845019188437\n",
            "25 \t [6.6803176  5.16849036 5.         0.60605786 3.         0.85637409]\t 0.8471085133591287\t 0.7808363478466259\t 0.5044133126057403\t 0.5044133126057403\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.9727332413478633\t 0.7808363478466259\t 0.5006750103454806\t 0.5006750103454806\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 7.09078553  0.20539715  7.          0.8316483  19.          0.9376529 ]\u001b[0m\t \u001b[1m\u001b[92m0.7579786747536188\u001b[0m\t \u001b[1m\u001b[92m0.7579786747536188\u001b[0m\t \u001b[1m\u001b[92m0.49893719179465373\u001b[0m\t \u001b[1m\u001b[92m0.4989371917946014\u001b[0m\n",
            "28 \t [ 0.17423277  9.28464895 11.          0.86455659  1.          0.87456687]\t 0.8297316707491886\t 0.7579786747536188\t 0.4929576530367478\t 0.49295761742960614\n",
            "29 \t [ 5.67686965  7.12623397 10.          0.88124763  1.          0.44323716]\t 0.94769082817622\t 0.7579786747536188\t 0.4909290156909584\t 0.4909290156909584\n",
            "30 \t [ 9.40435768  7.598465   10.          0.97457018 15.          0.31309738]\t 0.9314234944354094\t 0.7579786747536188\t 0.49463502713928365\t 0.49463502713928365\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62175.74619527894"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107daf69-05aa-4ac6-8d8d-c772b9246792"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO_multi(surrogate_approx_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 1.0442882316794924\t 0.9988899440522335\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 1.034592364984854\t 0.9988899440522335\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.9988899440522335\t 0.9988899440522335\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 1.0616382201607613\t 0.9988899440522335\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 1.0586655163441985\t 0.9988899440522335\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m0.5732753340025499\u001b[0m\t \u001b[1m\u001b[92m0.5732753340025499\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 1.0357720753154218\t 0.7588724777099193\t 0.5504955772989466\t 0.5504955772989466\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.9957364873565091\t 0.7588724777099193\t 0.5534995725159004\t 0.5534995725159004\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 1.0230792313624693\t 0.7588724777099193\t 0.5529182807269342\t 0.5529182807269342\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.9990381912537636\t 0.7588724777099193\t 0.5541804786488659\t 0.5541804786488659\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.857846290397769\t 0.7588724777099193\t 0.553845723683855\t 0.553845723683855\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 1.0693894233525565\t 0.7588724777099193\t 0.5469871225744853\t 0.5469871225744853\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.8611559732831295\t 0.7588724777099193\t 0.5506483751807187\t 0.5506483751807187\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m0.5452010991335544\u001b[0m\t \u001b[1m\u001b[92m0.5452010991335544\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7415155405776647\t 0.7219532506859043\t 0.5360309419327026\t 0.5360309419327026\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 1.1107767409489193\t 0.7219532506859043\t 0.5285107869768771\t 0.5285107869768771\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.857182327987213\t 0.7219532506859043\t 0.534132070118328\t 0.534132070118328\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.5306938187862427\u001b[0m\t \u001b[1m\u001b[92m0.5306938187862427\u001b[0m\n",
            "14 \t [ 5.41155711  5.82534705 10.          0.62444801 12.          0.48368067]\t 1.011456246332149\t 0.7195558119979323\t 0.5241752858782721\t 0.5241752858782721\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 1.0073272814467533\t 0.7195558119979323\t 0.5259747075886434\t 0.5259747075886434\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.894093323976883\t 0.7195558119979323\t 0.527411244028548\t 0.527411244028548\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 1.096518529758772\t 0.7195558119979323\t 0.5264463338138571\t 0.5264463338138571\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 1.0333946700789831\t 0.7195558119979323\t 0.5335870354756929\t 0.5335870354756929\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 1.0221431969128547\t 0.7195558119979323\t 0.5280042130547761\t 0.5280042130547761\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.9054977129617926\t 0.7195558119979323\t 0.5345159457567574\t 0.5345159457567574\n",
            "21 \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]\t 1.0357266754545873\t 0.7195558119979323\t 0.5355764483794454\t 0.5355764483794454\n",
            "22 \t [ 6.72271828  8.33075498 14.          0.78841734 10.          0.48431777]\t 0.9963666823715333\t 0.7195558119979323\t 0.5399300178287247\t 0.539929998531757\n",
            "23 \t [0.58596137 5.71336149 9.         0.70354751 9.         0.28160967]\t 1.0385062021776466\t 0.7195558119979323\t 0.5342311655541561\t 0.5342311647814583\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7761448350601515\t 0.7195558119979323\t 0.5355869859818089\t 0.5355869859818089\n",
            "25 \t [ 9.01141716  1.23452325  9.          0.70620993 16.          0.46074297]\t 1.0029978093526934\t 0.7195558119979323\t 0.5317346633461975\t 0.5317346633461973\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 1.0050223847057222\t 0.7195558119979323\t 0.531845194806736\t 0.531845194806736\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.8647657423877456\t 0.7195558119979323\t 0.5369057420403361\t 0.5369057420403361\n",
            "28 \t [ 1.9619463   0.16028995 10.          0.50330845  2.          0.6207421 ]\t 0.9390116776172818\t 0.7195558119979323\t 0.5335067467436458\t 0.5335067467436458\n",
            "29 \t [ 0.07133277  0.91368388 13.          0.65353856  5.          0.96196496]\t 0.7348336825290495\t 0.7195558119979323\t 0.5349299377157503\t 0.5349299377157503\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 2.1041119   4.17114039 15.          1.         15.29465763  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7025933028233607\u001b[0m\t \u001b[1m\u001b[92m0.7025933028233607\u001b[0m\t \u001b[1m\u001b[92m0.5306178653704626\u001b[0m\t \u001b[1m\u001b[92m0.5306166154551178\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59422.4387633967"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94167554-a757-42b3-c139-acbee4cd12fb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO_multi(surrogate_approx_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.8160193762021096\t 0.8160193762021096\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.9345750435828236\t 0.8160193762021096\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.8609997448649105\t 0.8160193762021096\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9816665199899536\t 0.8160193762021096\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.9568167510294832\t 0.8160193762021096\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.9860041719301801\t 0.8160193762021096\t 0.4988128185398431\t 0.4988128185398431\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.8418838401878418\t 0.8160193762021096\t 0.5065546590736558\t 0.5065546590736558\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m0.5007174162276283\u001b[0m\t \u001b[1m\u001b[92m0.5007174162276283\u001b[0m\n",
            "4  \t [ 8.39316326 10.         12.89249739  0.90661512  3.58549177  0.49967351]\t 0.9484701070811592\t 0.7805118546901472\t 0.4924682513816366\t 0.4924682513816449\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.955892785185136\t 0.7805118546901472\t 0.49594400176380216\t 0.49594400176380216\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.9781132546552117\t 0.7805118546901472\t 0.5011730356288049\t 0.5011730356288049\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.8404775189371637\t 0.7805118546901472\t 0.5029175224291738\t 0.5029175224291738\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.9731655942341536\t 0.7805118546901472\t 0.49974236716689235\t 0.49974236716689235\n",
            "9  \t [ 1.2716555   3.78378689  5.          0.57556817 17.          0.18163876]\t 0.9895289390337443\t 0.7805118546901472\t 0.5026692463243102\t 0.5026692463243102\n",
            "10 \t [1.38490793 6.87002541 5.         0.73931504 9.         0.41767138]\t 0.9451941333061711\t 0.7805118546901472\t 0.5058471256394012\t 0.5058471256394012\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.9443317250470002\t 0.7805118546901472\t 0.5068850546561199\t 0.5068850546561199\n",
            "12 \t [ 9.99251025  3.68443024 14.          0.88286102  6.          0.35061034]\t 0.9638650175020833\t 0.7805118546901472\t 0.5076020345794063\t 0.5076020345794063\n",
            "13 \t [ 9.01951661  7.6268332  12.          0.5811273  10.          0.17713152]\t 0.9894164696060692\t 0.7805118546901472\t 0.5100340425541252\t 0.5100340425541252\n",
            "14 \t [ 4.06523875  9.81698466  6.          0.66300775 13.          0.37229542]\t 0.9562258995537348\t 0.7805118546901472\t 0.5112084519731483\t 0.5112084519731483\n",
            "15 \t [ 5.83497175  4.45174574 10.          0.74501078  6.          0.19360692]\t 0.9815194490355662\t 0.7805118546901472\t 0.5116918642620347\t 0.5116918365324131\n",
            "16 \t [ 5.22074709  0.74229772 13.          0.87455275  7.          0.44305495]\t 0.9475819018040168\t 0.7805118546901472\t 0.5147168283488202\t 0.5147168283488202\n",
            "17 \t [ 9.1928307   3.75120063 13.          0.61085648 16.          0.3130605 ]\t 0.9631882478680399\t 0.7805118546901472\t 0.5146450598993175\t 0.5146450598993175\n",
            "18 \t [ 1.83368891  8.1756677   8.          0.96471075 17.          0.14868642]\t 0.9694018750179361\t 0.7805118546901472\t 0.5149447506856191\t 0.5149447506856191\n",
            "19 \t [ 1.32113565  9.62738611 14.          0.55066636 15.          0.36069244]\t 0.9688180161670505\t 0.7805118546901472\t 0.5226764235038132\t 0.5226764234740302\n",
            "20 \t [ 6.88175573  0.68997438  9.          0.55006192 19.          0.74555899]\t 0.8711954678288816\t 0.7805118546901472\t 0.5127324121123988\t 0.5127324121123988\n",
            "21 \t [ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\t 0.7847481688271192\t 0.7805118546901472\t 0.5226192896733985\t 0.5226192896733985\n",
            "22 \t [6.17562703 5.62140054 5.         0.97946506 3.         0.20857904]\t 0.9722212560084632\t 0.7805118546901472\t 0.5155411964400494\t 0.5155411963491348\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.8589132192206685\t 0.7805118546901472\t 0.5194761325261175\t 0.5194761325261175\n",
            "24 \t [9.30371298 5.41042714 5.         0.80825473 7.         0.72790994]\t 0.8552977982452606\t 0.7805118546901472\t 0.5079399667048353\t 0.5079399667048353\n",
            "25 \t [9.66959108 0.03423869 5.         0.63791788 7.         0.65549808]\t 0.8637733602298097\t 0.7805118546901472\t 0.5117499200479613\t 0.5117498489631003\n",
            "26 \t [ 3.61406382  9.87735751 10.          0.70199599  8.          0.85082246]\t 0.8238784103397794\t 0.7805118546901472\t 0.5158240328559424\t 0.5158240328559424\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]\u001b[0m\t \u001b[1m\u001b[92m0.7787515875060036\u001b[0m\t \u001b[1m\u001b[92m0.7787515875060036\u001b[0m\t \u001b[1m\u001b[92m0.5126114880293305\u001b[0m\t \u001b[1m\u001b[92m0.5126114880293305\u001b[0m\n",
            "28 \t [ 3.3191017   1.36482014 13.          0.77172143  1.          0.73147858]\t 0.8632014318852118\t 0.7787515875060036\t 0.5052302560853976\t 0.5052302558597724\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.860674338231938\t 0.7787515875060036\t 0.5098769962304497\t 0.5098769962304497\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.8118933760299614\t 0.7787515875060036\t 0.5000762473623855\t 0.5000762473623855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64394.74610430705"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a7639e-8bf9-4eeb-8f3d-2f927b0b3b6b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO_multi(surrogate_approx_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9945504564494708\t 0.8040972705253946\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.8040972705253946\t 0.8040972705253946\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9800705737387579\t 0.8040972705253946\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.8208145553024886\t 0.8040972705253946\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.8099770295888573\t 0.8040972705253946\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8290526771960891\t 0.8040972705253946\t 0.48733305944788174\t 0.48733305944788174\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.7717526578038573\u001b[0m\t \u001b[1m\u001b[92m0.7717526578038573\u001b[0m\t \u001b[1m\u001b[92m0.48242276146304053\u001b[0m\t \u001b[1m\u001b[92m0.48242276146304053\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.8267998563487631\t 0.7717526578038573\t 0.4747076814587022\t 0.4747076814587022\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.9720368320825408\t 0.7717526578038573\t 0.47239028280551765\t 0.47239028280551765\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.7939440774877953\t 0.7717526578038573\t 0.4805468950796057\t 0.4805468950796057\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 1.0766617046782607\t 0.7717526578038573\t 0.47581770837726484\t 0.47581770837726484\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 1.0814569137184114\t 0.7717526578038573\t 0.4882504522566366\t 0.4882504522566366\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.8167106174903189\t 0.7717526578038573\t 0.4976513186282556\t 0.4976513186282556\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.8216445533109903\t 0.7717526578038573\t 0.49416785493157966\t 0.4941678531452638\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.7908825942180885\t 0.7717526578038573\t 0.4913401826960045\t 0.4913401774571407\n",
            "11 \t [ 0.2637722   4.11659493  5.          0.61604637 11.          0.22374653]\t 1.0699354655820383\t 0.7717526578038573\t 0.48785031302516635\t 0.48785031302516635\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.8390111546541604\t 0.7717526578038573\t 0.4947753368082254\t 0.49477533672354657\n",
            "13 \t [ 8.34050252  7.45495891 14.          0.58875591  8.          0.92669456]\t 0.7757542421516687\t 0.7717526578038573\t 0.4933597398780021\t 0.4933597398780021\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.9054011377721235\t 0.7717526578038573\t 0.4901884350912323\t 0.4901884350912323\n",
            "15 \t [3.36125149 0.38066674 7.         0.83604387 7.         0.55591318]\t 0.8269535778079307\t 0.7717526578038573\t 0.49002950042113247\t 0.49002950042113247\n",
            "16 \t [ 0.71491502  0.67997826 10.          0.84656193 16.          0.26877596]\t 0.9802989527959\t 0.7717526578038573\t 0.4887845332978477\t 0.4887845332978477\n",
            "17 \t [0.80116063 4.55633099 5.         0.79763457 4.         0.36850753]\t 0.9816472859446954\t 0.7717526578038573\t 0.49165641138124005\t 0.49165641138124005\n",
            "18 \t [ 4.48360078  7.855369   10.          0.64837174 18.          0.21997892]\t 1.069621582520547\t 0.7717526578038573\t 0.5007496857589627\t 0.5007496857589627\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 1.0659804815531757\t 0.7717526578038573\t 0.50611022712456\t 0.50611022712456\n",
            "20 \t [ 9.84526946  7.66546924  9.          0.85160345 12.          0.57041046]\t 0.8143407207554997\t 0.7717526578038573\t 0.5122895381313463\t 0.5122895381313463\n",
            "21 \t [ 9.23733929  4.4641986  14.          0.5618978  13.          0.67359608]\t 0.8084765247236222\t 0.7717526578038573\t 0.4990422006554251\t 0.4990422006554251\n",
            "22 \t [ 3.44634229  0.73068286  6.          0.98116529 13.          0.55221155]\t 0.8186382898037643\t 0.7717526578038573\t 0.4988098558548874\t 0.4988098558548874\n",
            "23 \t [ 9.53885612  7.77476011 11.          0.72419664  1.          0.36894154]\t 0.9940856467171486\t 0.7717526578038573\t 0.4997160459383104\t 0.4997160459383104\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.7803443878774855\t 0.7717526578038573\t 0.5005773658996064\t 0.5005773658996064\n",
            "25 \t [1.70698239 9.19985282 6.         0.50661833 7.         0.29378886]\t 0.9933904701114727\t 0.7717526578038573\t 0.505231921667218\t 0.505231921667218\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.8237860321712347\t 0.7717526578038573\t 0.5052310873279522\t 0.5052310873279522\n",
            "27 \t [ 2.49960443  6.35739516  5.          0.82569718 16.          0.24708903]\t 1.0804872789733682\t 0.7717526578038573\t 0.4973447284282047\t 0.4973447284282047\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 1.0695374663391362\t 0.7717526578038573\t 0.49861305145409374\t 0.49861305145409374\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.8216721197517609\t 0.7717526578038573\t 0.5010143203706626\t 0.5010143203706626\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 6.37097579  5.69315713 13.          0.83848815 18.          0.96944598]\u001b[0m\t \u001b[1m\u001b[92m0.7607071092665223\u001b[0m\t \u001b[1m\u001b[92m0.7607071092665223\u001b[0m\t \u001b[1m\u001b[92m0.5039480944458551\u001b[0m\t \u001b[1m\u001b[92m0.5039480944458551\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61392.39752730621"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd952bd-7f55-4ec4-fd0d-baa43e7df503"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO_multi(surrogate_approx_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.9238143360620997\t 0.824729580989813\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.9119597092034326\t 0.824729580989813\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.1280473533716002\t 0.824729580989813\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.885331313733569\t 0.824729580989813\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.824729580989813\t 0.824729580989813\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m0.5163049872859979\u001b[0m\t \u001b[1m\u001b[92m0.5163049872859979\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.8875735409405836\t 0.79346025102973\t 0.5040210556114599\t 0.5040210556114599\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.1322726135322738\t 0.79346025102973\t 0.5019507575494121\t 0.5019507575494121\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.9633601355550562\t 0.79346025102973\t 0.5188177561290613\t 0.5188177561290613\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.9736613453341365\t 0.79346025102973\t 0.5202000175160089\t 0.5202000175160089\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.8962334110364653\t 0.79346025102973\t 0.521885101587873\t 0.521885101587873\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.8910080545620651\t 0.79346025102973\t 0.5194219148223846\t 0.5194219148223846\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.8893037640708062\t 0.79346025102973\t 0.5171320131078915\t 0.5171320131078915\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.9338815902432167\t 0.79346025102973\t 0.5151170716394711\t 0.5151170716394711\n",
            "10 \t [ 4.45643696  6.43761151 10.          0.59521711 15.          0.91320177]\t 0.8255704645290564\t 0.79346025102973\t 0.5151009303091465\t 0.5151009236174313\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.8287447527880435\t 0.79346025102973\t 0.5113229882677627\t 0.5113229882677627\n",
            "12 \t [ 9.41792853  9.11293681  6.          0.87420995 11.          0.8007601 ]\t 0.8060510151077646\t 0.79346025102973\t 0.5080989821694329\t 0.5080989793750821\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.1276065677179288\t 0.79346025102973\t 0.5045462397342553\t 0.5045462397342553\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.8195075556875523\t 0.79346025102973\t 0.512436594426852\t 0.512436594426852\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.9367777767954987\t 0.79346025102973\t 0.5087904801300007\t 0.5087904801300007\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.9192069504605914\t 0.79346025102973\t 0.5097069875325584\t 0.5097069875325584\n",
            "17 \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]\t 0.8744339215870263\t 0.79346025102973\t 0.5092905680011871\t 0.5092905680011871\n",
            "18 \t [ 7.9679648   6.50875696 12.          0.58580991 13.          0.19954847]\t 1.1274997047398325\t 0.79346025102973\t 0.5142973581884243\t 0.5142973581884243\n",
            "19 \t [ 9.97958622  9.03409533 12.          0.51772082  4.          0.45869101]\t 0.9473572626155049\t 0.79346025102973\t 0.5163639971460867\t 0.5163639971460867\n",
            "20 \t [ 3.55165538  9.78370062 13.          0.78750167  1.          0.7976462 ]\t 0.832291165091001\t 0.79346025102973\t 0.5150521119714832\t 0.5150521119714832\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.8200285178970692\t 0.79346025102973\t 0.5165621211108048\t 0.5165621211108048\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.9223651097826323\t 0.79346025102973\t 0.5065691723793483\t 0.5065691723793483\n",
            "23 \t [ 4.81184079  0.03027405 11.          0.96437956 10.          0.97759806]\t 0.7947258239649384\t 0.79346025102973\t 0.5208223397557745\t 0.5208223397557745\n",
            "24 \t [ 6.30542676  7.71202743  5.          0.69290865 17.          0.68185665]\t 0.9062144692012971\t 0.79346025102973\t 0.507597435404606\t 0.507597435404606\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.9381315214046673\t 0.79346025102973\t 0.5052042428289597\t 0.5052042428289597\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.8895644243531041\t 0.79346025102973\t 0.50994587336669\t 0.50994587336669\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 9.95218976  0.50408771 11.99840824  1.         18.56802146  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7706287397273098\u001b[0m\t \u001b[1m\u001b[92m0.7706287397273098\u001b[0m\t \u001b[1m\u001b[92m0.5130842151979632\u001b[0m\t \u001b[1m\u001b[92m0.513084206033171\u001b[0m\n",
            "28 \t [8.3735996  5.34104024 8.         0.56456303 7.         0.59553385]\t 0.9329548781688652\t 0.7706287397273098\t 0.50367630916528\t 0.50367630916528\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.8158422349857315\t 0.7706287397273098\t 0.5030193437892173\t 0.5030193437892173\n",
            "30 \t [9.30545715 2.21896205 9.         0.96965499 5.         0.61228081]\t 0.8966551531404072\t 0.7706287397273098\t 0.5026339863309227\t 0.5026339863309227\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60904.5354943106"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab1000e-a248-4aee-b368-dc6f1ef38c96"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO_multi(surrogate_approx_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.7520109919120059\t 0.7520109919120059\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.7843437690505969\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0380897569172567\t 0.7520109919120059\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.9185289289653313\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.9180724641961298\t 0.7520109919120059\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.9254670555638643\t 0.7520109919120059\t 0.4897153177896012\t 0.4897153177896012\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0314631424665905\t 0.7520109919120059\t 0.49275690098418806\t 0.49275690098418806\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.8949898491028812\t 0.7520109919120059\t 0.5043026263601241\t 0.5043026263601241\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7944418105894601\t 0.7520109919120059\t 0.5029568212895166\t 0.5029568212895166\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8997545663056927\t 0.7520109919120059\t 0.49615944084144575\t 0.49615944084144575\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.0239998235141596\t 0.7520109919120059\t 0.49614971225005466\t 0.49614971224975896\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.8480209770499222\t 0.7520109919120059\t 0.5029883712410318\t 0.5029883712410318\n",
            "8  \t [ 2.63649501  9.62311075  7.          0.5192485  13.          0.19746315]\t 1.0350432385289277\t 0.7520109919120059\t 0.4999143586050333\t 0.49991435476389806\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0363798049215616\t 0.7520109919120059\t 0.5059023092890091\t 0.5059023092890091\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.865997699883801\t 0.7520109919120059\t 0.5108590412526302\t 0.5108590412526302\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0228429225587468\t 0.7520109919120059\t 0.508644978498921\t 0.508644978498921\n",
            "12 \t [ 6.27900589  9.12764923  5.          0.84263312 18.          0.79256191]\t 0.7735262251857813\t 0.7520109919120059\t 0.5120913743077036\t 0.5120913716118765\n",
            "13 \t [6.3101326  8.61804899 7.         0.66826014 6.         0.89905701]\t 0.778060148609183\t 0.7520109919120059\t 0.507687326762666\t 0.507687326762666\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[ 2.08109501  0.31399789  8.          0.78263012 11.          0.87673239]\u001b[0m\t \u001b[1m\u001b[92m0.7493527307804453\u001b[0m\t \u001b[1m\u001b[92m0.7493527307804453\u001b[0m\t \u001b[1m\u001b[92m0.5036917054941993\u001b[0m\t \u001b[1m\u001b[92m0.5036917054941993\u001b[0m\n",
            "15 \t [ 6.97560183  1.48211849  9.          0.80794429 10.          0.21839694]\t 1.0237787601826196\t 0.7493527307804453\t 0.49925881142023837\t 0.49925881142023837\n",
            "16 \t [ 1.47808653  5.79832114 12.          0.95992435  9.          0.71524706]\t 0.8162777104474938\t 0.7493527307804453\t 0.5023706653216596\t 0.5023706653216596\n",
            "17 \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]\t 0.8155570453490526\t 0.7493527307804453\t 0.5001677576331168\t 0.5001677576331168\n",
            "18 \t [ 1.21632555  2.44839139  8.          0.8927599  17.          0.25270381]\t 0.9237148678212173\t 0.7493527307804453\t 0.4972139786183106\t 0.4972139786183106\n",
            "19 \t [4.83067255 2.19904639 7.         0.5680519  3.         0.59514532]\t 0.8957701072181361\t 0.7493527307804453\t 0.49709000950250737\t 0.49709000950250737\n",
            "20 \t [ 6.62295384  9.17069374  8.          0.91336715 18.          0.33402165]\t 0.9207932652757735\t 0.7493527307804453\t 0.5056780641678753\t 0.5056780641678753\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.9203913838650098\t 0.7493527307804453\t 0.5041933617759563\t 0.5041933617759563\n",
            "22 \t [ 3.78905605  1.09144745 12.          0.97395259  5.          0.57197592]\t 0.8694290931926432\t 0.7493527307804453\t 0.5042244432843384\t 0.5042244432843384\n",
            "23 \t [ 5.86852957  9.2552543  14.          0.74343957 14.          0.26209686]\t 0.9228195832204917\t 0.7493527307804453\t 0.49766360786635044\t 0.49766360786635044\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.7797715795229998\t 0.7493527307804453\t 0.4977141212776813\t 0.4977141212776813\n",
            "25 \t [ 9.4251418   2.62898513  5.          0.90450266 19.          0.92733176]\t 0.7703406847213696\t 0.7493527307804453\t 0.5021957078791573\t 0.5021949856892215\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.8602984001975387\t 0.7493527307804453\t 0.4999734948910736\t 0.4999734948910736\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 6.99502412  7.44127161 14.8642596   1.          3.57923648  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7461918907845432\u001b[0m\t \u001b[1m\u001b[92m0.7461918907845432\u001b[0m\t \u001b[1m\u001b[92m0.504576193355954\u001b[0m\t \u001b[1m\u001b[92m0.5045748664862267\u001b[0m\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.021708916478741\t 0.7461918907845432\t 0.49454291695173525\t 0.49454291695173525\n",
            "29 \t [ 2.05797056  3.5679443  14.          0.67286552 19.          0.3168445 ]\t 0.9202198906523096\t 0.7461918907845432\t 0.500461363500629\t 0.500461363500629\n",
            "30 \t [8.73201359 2.51653751 5.         1.         1.         1.        ]\t 0.7542686397136368\t 0.7461918907845432\t 0.49049409977604985\t 0.4904938152611027\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61387.94829835231"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f80095-0700-4af6-9601-22914b87189a"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1662461278.501974"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cb3e03-9378-450e-e17b-7aab897b0d46"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 0.848101320876155\t 0.7386468688809501\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7469689781479785\t 0.7386468688809501\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8079963708366673\t 0.7386468688809501\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.7386468688809501\t 0.7386468688809501\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 0.937768916815817\t 0.7386468688809501\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8126185461054997\t 0.7386468688809501\t 0.45162596541557376\t 0.45162596541557376\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 0.9318704004009237\t 0.7386468688809501\t 0.45102699013998043\t 0.45102699013998043\n",
            "3  \t [7.35353694 6.03494644 5.         0.7919799  3.         0.96282991]\t 0.7646755003247829\t 0.7386468688809501\t 0.4605134818317217\t 0.4605134818317217\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8108923609041201\t 0.7386468688809501\t 0.4558295847084458\t 0.4558295847084458\n",
            "5  \t [ 3.76363217  9.95052322  8.          0.75835318 19.          0.10206715]\t 0.9302979891635867\t 0.7386468688809501\t 0.45486455657270725\t 0.45486455657270725\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.8121266607783616\t 0.7386468688809501\t 0.4609969843128662\t 0.4609969843128662\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 0.8530932869908747\t 0.7386468688809501\t 0.4598083559265772\t 0.4598083559265772\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7169134935137329\u001b[0m\t \u001b[1m\u001b[92m0.7169134935137329\u001b[0m\t \u001b[1m\u001b[92m0.46069473787687826\u001b[0m\t \u001b[1m\u001b[92m0.46069473779882564\u001b[0m\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 0.9452829494695465\t 0.7169134935137329\t 0.45599460689676286\t 0.45599460689676286\n",
            "10 \t [9.47161836 5.35231143 6.         0.51632193 6.         0.43288953]\t 0.8314092949686034\t 0.7169134935137329\t 0.460955596721301\t 0.460955596721301\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 0.9369155032359574\t 0.7169134935137329\t 0.46078295983473566\t 0.46078295983473566\n",
            "12 \t [0.15776536 8.02750992 5.         0.65248282 3.         0.71659731]\t 0.7752392265192147\t 0.7169134935137329\t 0.46446435019753446\t 0.46446435019753446\n",
            "13 \t [ 9.31003194  2.78504172 14.          0.81837194 14.          0.87646711]\t 0.7355848546414411\t 0.7169134935137329\t 0.4623854748944192\t 0.4623854748944192\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7644930642703252\t 0.7169134935137329\t 0.4593954403559022\t 0.4593954403559022\n",
            "15 \t [ 9.20512342  1.60831322 11.          0.87041344  2.          0.50117029]\t 0.7810258661361746\t 0.7169134935137329\t 0.4574752097829836\t 0.4574752097829836\n",
            "16 \t [ 0.21685405  7.71152333 13.          0.94772928  9.          0.78016857]\t 0.745641428580208\t 0.7169134935137329\t 0.4561920465888929\t 0.4561920465888929\n",
            "17 \t [ 9.05451551  8.43196135 13.          0.88399349 12.          0.71276317]\t 0.7411130987479616\t 0.7169134935137329\t 0.4542757102277309\t 0.4542757102277309\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8088933131983232\t 0.7169134935137329\t 0.45185353264162664\t 0.45185353264162664\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 0.8343379491664138\t 0.7169134935137329\t 0.4570097445033593\t 0.4570097445033593\n",
            "20 \t [ 7.12741784  1.59648512  9.          0.96056513 11.          0.30752062]\t 0.8419713781829536\t 0.7169134935137329\t 0.45396952567655613\t 0.45396952567655613\n",
            "21 \t [ 0.83654934  7.44741776 11.          0.74011057 19.          0.46950988]\t 0.8107211682139951\t 0.7169134935137329\t 0.45490898036961014\t 0.45490898036961014\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 0.9354453567539931\t 0.7169134935137329\t 0.46322737121226853\t 0.46322737121226853\n",
            "23 \t [ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\t 0.7341701271899448\t 0.7169134935137329\t 0.4634388729485928\t 0.4634388729485928\n",
            "24 \t [0.         0.         5.         0.5        9.85612287 0.1       ]\t 0.9400967798045234\t 0.7169134935137329\t 0.45901532331330613\t 0.45901532331327377\n",
            "25 \t [ 8.11423763  9.45656887  5.          0.66260898 13.          0.53125757]\t 0.7864262400566092\t 0.7169134935137329\t 0.4580865583057944\t 0.4580865583057944\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.7500814347067293\t 0.7169134935137329\t 0.4681337002628109\t 0.4681337002628109\n",
            "27 \t [4.30702998 1.603885   6.         0.67957661 1.         0.65896812]\t 0.7722507414442762\t 0.7169134935137329\t 0.4559218628577538\t 0.4559218628577538\n",
            "28 \t [ 0.42024221  1.80970657 14.          0.62730009  9.          0.87538064]\t 0.7568866482811789\t 0.7169134935137329\t 0.4584155879548366\t 0.4584155879548366\n",
            "29 \t [0.3891804  3.01968332 7.         0.98615129 4.         0.45509305]\t 0.8059617596863097\t 0.7169134935137329\t 0.4619647025417245\t 0.4619647025417245\n",
            "30 \t [10.          5.50504048  9.49037728  1.         17.49037728  1.        ]\t 0.7205185134532861\t 0.7169134935137329\t 0.45073433501341786\t 0.45073433501308574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59912.05597064799"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290251e3-cdd4-401a-f312-abbe48fde1aa"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.9157817005982263\t 0.8490988745111359\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.8517975125315337\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.8490988745111359\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.9839177202713774\t 0.8490988745111359\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.9688138526063573\t 0.8490988745111359\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m0.5043658072393779\u001b[0m\t \u001b[1m\u001b[92m0.5043658072393779\u001b[0m\n",
            "2  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0080537575046533\t 0.7933779577878181\t 0.49383764677544045\t 0.4938376467754177\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 9.58514067  5.7670966   7.          0.86943542 19.          0.83320355]\u001b[0m\t \u001b[1m\u001b[92m0.781886335686165\u001b[0m\t \u001b[1m\u001b[92m0.781886335686165\u001b[0m\t \u001b[1m\u001b[92m0.5031521440019752\u001b[0m\t \u001b[1m\u001b[92m0.5031521440019752\u001b[0m\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 0.60781829  7.94471276 14.          0.95131596 14.          0.78401217]\u001b[0m\t \u001b[1m\u001b[92m0.7787563738340587\u001b[0m\t \u001b[1m\u001b[92m0.7787563738340587\u001b[0m\t \u001b[1m\u001b[92m0.4947171015748157\u001b[0m\t \u001b[1m\u001b[92m0.4947171015748157\u001b[0m\n",
            "5  \t [1.25559631 9.8394609  9.         0.52015567 2.         0.32958416]\t 0.9931478086626242\t 0.7787563738340587\t 0.48788687159458655\t 0.48788687159458655\n",
            "6  \t [ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\t 0.8411431281498688\t 0.7787563738340587\t 0.4944055909252163\t 0.4944055909252163\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.          9.39863146  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7453132812712437\u001b[0m\t \u001b[1m\u001b[92m0.7453132812712437\u001b[0m\t \u001b[1m\u001b[92m0.4914889531538889\u001b[0m\t \u001b[1m\u001b[92m0.4914889531536198\u001b[0m\n",
            "8  \t [0.         0.         5.         0.5        8.24878358 0.1       ]\t 1.0045109156965843\t 0.7453132812712437\t 0.48527407108384896\t 0.4852740642637625\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.8472224210855768\t 0.7453132812712437\t 0.49107494192037987\t 0.49107494192037987\n",
            "10 \t [ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\t 0.786526849407035\t 0.7453132812712437\t 0.4894019239027774\t 0.4894019239027774\n",
            "11 \t [ 0.10472305  8.04212015  6.          0.60521977 17.          0.5035541 ]\t 0.8662205350111943\t 0.7453132812712437\t 0.48586429735380643\t 0.48586429735380643\n",
            "12 \t [ 6.63689231  7.93880524 13.          0.98296315 18.          0.62117466]\t 0.8373508055060113\t 0.7453132812712437\t 0.4851018192386767\t 0.4851018192386767\n",
            "13 \t [ 5.82610312  7.72983875 14.          0.69621099  4.          0.32496788]\t 0.9806464940304703\t 0.7453132812712437\t 0.4838978943226352\t 0.4838978943226352\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.8437383195985765\t 0.7453132812712437\t 0.48730470638483075\t 0.48730470638483075\n",
            "15 \t [ 8.6950785   0.99410218 13.          0.66782851 17.          0.9323419 ]\t 0.7718203736909484\t 0.7453132812712437\t 0.4863812930561015\t 0.4863812930561015\n",
            "16 \t [ 3.79151097  4.0129324  10.          0.78656319  9.          0.57380624]\t 0.8479506527275633\t 0.7453132812712437\t 0.4833446720100166\t 0.4833446720100166\n",
            "17 \t [ 9.61885664  9.78589131 14.          0.8903706   1.          0.14094172]\t 1.0146384496628387\t 0.7453132812712437\t 0.4829755938431134\t 0.4829755938431134\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.812855948594331\t 0.7453132812712437\t 0.48741628604253423\t 0.48741628604253423\n",
            "19 \t [4.19450476 6.06514239 6.         0.74664809 4.         0.92780068]\t 0.7698099099042158\t 0.7453132812712437\t 0.5003906660757163\t 0.5003906660757163\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.9759301877372604\t 0.7453132812712437\t 0.48811083740939304\t 0.48811083740939304\n",
            "21 \t [7.13284983 1.18470919 5.         0.63977211 3.         0.12223048]\t 1.0124277228121503\t 0.7453132812712437\t 0.48761048871400137\t 0.48761048871400137\n",
            "22 \t [ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\t 0.7642724935254156\t 0.7453132812712437\t 0.48665031096382233\t 0.48665031096382233\n",
            "23 \t [2.36161323 4.19936331 9.         0.73250204 1.         0.79018905]\t 0.8150370035678787\t 0.7453132812712437\t 0.490719580740236\t 0.490719580740236\n",
            "24 \t [ 9.15676145  8.43306528  8.          0.95045438 14.          0.80351475]\t 0.7751523232069589\t 0.7453132812712437\t 0.497192207651391\t 0.497192207651391\n",
            "25 \t [ 9.70148981  3.84860271 14.          0.8648022   1.          0.77351018]\t 0.8176855829782234\t 0.7453132812712437\t 0.48763581294987407\t 0.48763581294987407\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.7746854783898445\t 0.7453132812712437\t 0.4808564022169086\t 0.4808564022169086\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.8184668279349161\t 0.7453132812712437\t 0.48552074057797245\t 0.48552074057797245\n",
            "28 \t [ 4.9644812   1.12270948  6.          0.71065886 17.          0.26866166]\t 0.9667438219230509\t 0.7453132812712437\t 0.4879648684819147\t 0.4879648684819147\n",
            "29 \t [ 2.5418393   4.40583972 14.          0.62206199 11.          0.11330702]\t 1.0095838821089207\t 0.7453132812712437\t 0.4842119850002191\t 0.4842119850002191\n",
            "30 \t [5.55301534 4.43776121 9.         0.77874612 6.         0.99491253]\t 0.7585656248465545\t 0.7453132812712437\t 0.4847875069222575\t 0.4847875069222575\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61693.3583787739"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e961b3f5-502d-4114-8e56-89cb00f1bc14"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.1001019572672721\t 0.8205570570239384\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.0968690738660336\t 0.8205570570239384\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.8205570570239384\t 0.8205570570239384\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0984076753833096\t 0.8205570570239384\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8540219347978375\t 0.8205570570239384\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8296591774144556\t 0.8205570570239384\t 0.552568679117548\t 0.552568679117548\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.46535469  7.06056184  5.          0.53518488 13.          0.98930148]\u001b[0m\t \u001b[1m\u001b[92m0.8159546965123093\u001b[0m\t \u001b[1m\u001b[92m0.8159546965123093\u001b[0m\t \u001b[1m\u001b[92m0.5378791801454976\u001b[0m\t \u001b[1m\u001b[92m0.5378791801454976\u001b[0m\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0951088390242933\t 0.8159546965123093\t 0.526207851627801\t 0.526207851627801\n",
            "4  \t [ 6.69378835  1.1746468   5.          0.75549171 16.          0.73450657]\t 0.8217725728652645\t 0.8159546965123093\t 0.5365159952942914\t 0.5365159952942914\n",
            "5  \t [ 0.24010242  9.80847714 13.          0.63702721  3.          0.56729929]\t 0.8241986609721416\t 0.8159546965123093\t 0.5278957093350293\t 0.5278957093350293\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[9.87422438 6.71772444 5.         0.63287091 5.         0.98483042]\u001b[0m\t \u001b[1m\u001b[92m0.8150350857143913\u001b[0m\t \u001b[1m\u001b[92m0.8150350857143913\u001b[0m\t \u001b[1m\u001b[92m0.5210133730012616\u001b[0m\t \u001b[1m\u001b[92m0.5210133730012616\u001b[0m\n",
            "7  \t [6.87752707 0.15955299 8.         0.55138154 9.         0.67263073]\t 0.8171526002553859\t 0.8150350857143913\t 0.5149108164080863\t 0.5149108164080863\n",
            "8  \t [2.6278521  1.48922274 6.         0.63082487 1.         0.15934029]\t 1.1015309912379583\t 0.8150350857143913\t 0.5098556094179575\t 0.5098556094179575\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[ 8.89682762  0.79017134 14.          0.58366818  8.          0.97456627]\u001b[0m\t \u001b[1m\u001b[92m0.7882233954631125\u001b[0m\t \u001b[1m\u001b[92m0.7882233954631125\u001b[0m\t \u001b[1m\u001b[92m0.5180035656022437\u001b[0m\t \u001b[1m\u001b[92m0.5180035656022437\u001b[0m\n",
            "10 \t [ 8.77606832  6.32160473  5.          0.71489692 18.          0.76442589]\t 0.8083681579816849\t 0.7882233954631125\t 0.5124941198904704\t 0.5124941198904704\n",
            "11 \t [ 3.53262431  2.07514765  7.          0.93520802 15.          0.4184813 ]\t 0.8494175289417161\t 0.7882233954631125\t 0.5083123349907168\t 0.5083123349907168\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.7986988788225304\t 0.7882233954631125\t 0.5059041530873615\t 0.5059041530873615\n",
            "13 \t [ 9.06298174  1.35559831 12.          0.65549633 16.          0.13675737]\t 1.0964679144435232\t 0.7882233954631125\t 0.5023077585630197\t 0.5023077585630197\n",
            "14 \t [ 9.85636221  3.89791593  9.          0.61925349 14.          0.90156475]\t 0.7917903727359957\t 0.7882233954631125\t 0.5085040030807803\t 0.5085040030807803\n",
            "15 \t [ 8.58495733  5.09928748 13.          0.89538108  1.          0.67774369]\t 0.8310233985591402\t 0.7882233954631125\t 0.5048857993127052\t 0.5048857993127052\n",
            "16 \t [ 4.66948753  0.78814602 10.          0.955043   17.          0.2188467 ]\t 1.0962260054583457\t 0.7882233954631125\t 0.5028034717020488\t 0.5028034717020488\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\u001b[0m\t \u001b[1m\u001b[92m0.7834162130060136\u001b[0m\t \u001b[1m\u001b[92m0.7834162130060136\u001b[0m\t \u001b[1m\u001b[92m0.5086109568878432\u001b[0m\t \u001b[1m\u001b[92m0.5086109568878432\u001b[0m\n",
            "18 \t [1.14934749 1.30310631 7.         0.60930428 6.         0.86412796]\t 0.7988635386480449\t 0.7834162130060136\t 0.5069596341246544\t 0.5069596341246544\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8394856040419147\t 0.7834162130060136\t 0.5068009436543399\t 0.5068009436543399\n",
            "\u001b[1m\u001b[92m20\u001b[0m\t \u001b[1m\u001b[92m[ 9.63523032  7.98334562 15.          1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7606786672220577\u001b[0m\t \u001b[1m\u001b[92m0.7606786672220577\u001b[0m\t \u001b[1m\u001b[92m0.5005148064642521\u001b[0m\t \u001b[1m\u001b[92m0.5005148064642191\u001b[0m\n",
            "21 \t [7.66786548 9.63378327 6.         0.67341055 1.         0.88994805]\t 0.8132267424569065\t 0.7606786672220577\t 0.49713442800195823\t 0.49713442800195823\n",
            "22 \t [ 2.77110475  0.35980325 10.          0.77088835  9.          0.78161047]\t 0.7823446501963255\t 0.7606786672220577\t 0.492718818597591\t 0.492718818597591\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8627583512307193\t 0.7606786672220577\t 0.5032860123180396\t 0.5032860123180396\n",
            "24 \t [ 0.04997226  0.57243486  5.          0.9748128  12.          0.24835402]\t 1.1002185993205575\t 0.7606786672220577\t 0.49909901573306636\t 0.49909901573306636\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7859921669897617\t 0.7606786672220577\t 0.5025368818615341\t 0.5025368818615341\n",
            "26 \t [ 5.07665331  4.6343883  14.          0.62511663 16.          0.73650486]\t 0.8117073016334935\t 0.7606786672220577\t 0.49789492990914547\t 0.49789492990914547\n",
            "27 \t [ 8.21944232  0.76315735 14.          0.70782001  3.          0.58640207]\t 0.8090375820501642\t 0.7606786672220577\t 0.4940726234754213\t 0.4940726234754213\n",
            "28 \t [ 9.01763405  8.9342346  11.          0.78253186 14.          0.5899614 ]\t 0.8008497075757127\t 0.7606786672220577\t 0.4961372436151295\t 0.4961372436151295\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.095967263497375\t 0.7606786672220577\t 0.4913728835253649\t 0.4913728835253649\n",
            "30 \t [ 0.56213381  4.41770035 10.          0.6803733   4.          0.67199979]\t 0.8046905628950565\t 0.7606786672220577\t 0.49957816196775007\t 0.49957816196775007\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58928.58624943123"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdDTsSEtNuf-",
        "outputId": "3bd6a39f-cc42-484b-df5f-c56a73917fcd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7650622398140196\t 0.7505823286451517\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7710732234684645\t 0.7505823286451517\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 1.127900018061083\t 0.7505823286451517\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.7505823286451517\t 0.7505823286451517\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.9579573664970923\t 0.7505823286451517\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 1.1269429525174437\t 0.7505823286451517\t 0.488981754778346\t 0.488981754778346\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 1.129364536434021\t 0.7505823286451517\t 0.5134117111763707\t 0.5134117111763707\n",
            "3  \t [ 1.20931261  6.80689034  9.          0.92011951 17.          0.30723956]\t 0.9481459007646673\t 0.7505823286451517\t 0.5303967786752228\t 0.5303967786752228\n",
            "4  \t [ 1.21913591  5.39021078 12.          0.52306788  2.          0.57375676]\t 0.8175628207948187\t 0.7505823286451517\t 0.5294458935409077\t 0.5294458935409077\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[10.          9.10775381 15.          1.         14.91580774  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7368050324811986\u001b[0m\t \u001b[1m\u001b[92m0.7368050324811986\u001b[0m\t \u001b[1m\u001b[92m0.521288199019543\u001b[0m\t \u001b[1m\u001b[92m0.5212881986718053\u001b[0m\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 1.1223174585019604\t 0.7368050324811986\t 0.5109490066275666\t 0.5109490066275666\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.8044591218487582\t 0.7368050324811986\t 0.5216724990308521\t 0.5216724990308521\n",
            "8  \t [ 0.81680031  1.59198282 10.          0.96064429  2.          0.39459215]\t 0.8548861270630322\t 0.7368050324811986\t 0.5156123128032228\t 0.5156123128032228\n",
            "9  \t [ 4.92366693 10.          7.01743405  1.          6.01743405  1.        ]\t 0.7369300976319006\t 0.7368050324811986\t 0.512340129945633\t 0.5123401243403903\n",
            "10 \t [ 5.47785092  4.8461481  12.          0.74846659 14.          0.61206304]\t 0.7921662259989626\t 0.7368050324811986\t 0.5055033956267255\t 0.5055033956267255\n",
            "11 \t [ 5.06567259  4.87282999  5.          0.59003814 19.          0.62670426]\t 0.7888998363236649\t 0.7368050324811986\t 0.5012149368537614\t 0.5012149368537614\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.7753874640601797\t 0.7368050324811986\t 0.4973292598236679\t 0.4973292598236679\n",
            "13 \t [0.69118951 0.05924245 6.         0.53870729 9.         0.9249957 ]\t 0.7741345186712877\t 0.7368050324811986\t 0.4934957614593891\t 0.4934957614593891\n",
            "14 \t [ 0.23672537  2.2738828  13.          0.94943774 16.          0.1212694 ]\t 1.1226108036121656\t 0.7368050324811986\t 0.4900582911099631\t 0.4900582911099631\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.8233136201842758\t 0.7368050324811986\t 0.4976381966923536\t 0.4976381966923536\n",
            "16 \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]\t 0.9579981335802007\t 0.7368050324811986\t 0.49541944470974897\t 0.49541944470974897\n",
            "17 \t [ 9.90138461  8.08697717 14.          0.93960585 19.          0.16950739]\t 1.1231089443447917\t 0.7368050324811986\t 0.49714669475216267\t 0.49714669475216267\n",
            "18 \t [6.43477222 1.74780507 6.         0.96140344 5.         0.37385841]\t 0.9482197445555848\t 0.7368050324811986\t 0.5061274221491429\t 0.5061274221491429\n",
            "19 \t [ 2.28250676  8.57781075 10.          0.71780124 12.          0.3772521 ]\t 0.8627736627545619\t 0.7368050324811986\t 0.5054598535285281\t 0.5054598535285281\n",
            "20 \t [ 7.39797184  8.7826296  13.          0.53377308 19.          0.69293054]\t 0.7675713222438754\t 0.7368050324811986\t 0.5047442664810381\t 0.5047442664810381\n",
            "21 \t [ 2.94885486  0.8707386  12.          0.78283452  7.          0.76869321]\t 0.762680257769994\t 0.7368050324811986\t 0.49506274024340385\t 0.49506274024340385\n",
            "22 \t [ 1.84655537  0.92635666  9.          0.60237883 14.          0.70534193]\t 0.7664822097519275\t 0.7368050324811986\t 0.5017395936605507\t 0.5017395936605507\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 1.1250394819981728\t 0.7368050324811986\t 0.4950571288519926\t 0.4950571288519926\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.7993682157943708\t 0.7368050324811986\t 0.501853635918175\t 0.501853635918175\n",
            "25 \t [9.14387233 8.82409497 7.         0.87227821 8.         0.52464991]\t 0.7895388146683674\t 0.7368050324811986\t 0.4998180123312697\t 0.4998180123312697\n",
            "26 \t [3.60524491 1.19236957 9.         0.73012056 6.         0.89243922]\t 0.7693194850407705\t 0.7368050324811986\t 0.5006090829511463\t 0.5006090829511463\n",
            "27 \t [0.         0.         5.         0.5        1.29709594 0.1       ]\t 1.1271740942238118\t 0.7368050324811986\t 0.49330011600799\t 0.4933001171823485\n",
            "28 \t [ 9.328728    0.19822705 12.          0.75281018 11.          0.88551078]\t 0.753178217146275\t 0.7368050324811986\t 0.4982505757202278\t 0.4982505757202278\n",
            "29 \t [ 8.18178764  9.98869521 14.          0.83418368 10.          0.41151726]\t 0.8537499901780559\t 0.7368050324811986\t 0.49445131669243236\t 0.49445131669243236\n",
            "30 \t [ 9.17303226  5.74079031 12.          0.94675996 18.          0.70963979]\t 0.7558697441758776\t 0.7368050324811986\t 0.49500452813212936\t 0.49500452813212936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60270.483116079085"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc19df1a-1fe4-44f0-c7c5-d20e0080ba80"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7978949387548113\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7689238087022429\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9009085979032214\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.9616956128686873\t 0.7689238087022429\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.8968042534595716\t 0.7689238087022429\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9141640599232991\t 0.7689238087022429\t 0.47284078090358667\t 0.47284078090358667\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9657302753232895\t 0.7689238087022429\t 0.4781759198212766\t 0.4781759198212766\n",
            "3  \t [ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\t 0.7975878945767783\t 0.7689238087022429\t 0.48629801488347657\t 0.48629801488347657\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.961106002845105\t 0.7689238087022429\t 0.48430368302376736\t 0.48430368302376736\n",
            "5  \t [ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\t 0.7812267618464406\t 0.7689238087022429\t 0.48643175857157517\t 0.48643175857157517\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.9035768104886805\t 0.7689238087022429\t 0.4811503143923679\t 0.4811503143923679\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8037187246418197\t 0.7689238087022429\t 0.48272221168783513\t 0.48272221168783513\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         12.98976633  1.         17.98976633  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6957422621425818\u001b[0m\t \u001b[1m\u001b[92m0.6957422621425818\u001b[0m\t \u001b[1m\u001b[92m0.4795464686752661\u001b[0m\t \u001b[1m\u001b[92m0.47954646867524114\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9684252162072007\t 0.6957422621425818\t 0.4728575915572111\t 0.4728575915572111\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.7212789829160808\t 0.6957422621425818\t 0.4774789995321774\t 0.4774789995321774\n",
            "11 \t [ 0.89740814  7.68177756 10.          0.50899891 18.          0.1637852 ]\t 0.9741185037091096\t 0.6957422621425818\t 0.4725753702529214\t 0.4725753702529214\n",
            "12 \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]\t 0.7645746008116381\t 0.6957422621425818\t 0.47684189959143264\t 0.47684189959143264\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7751802690627648\t 0.6957422621425818\t 0.47372020766689504\t 0.47372020766689504\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.7343751804493104\t 0.6957422621425818\t 0.4713343303216731\t 0.4713343303216731\n",
            "15 \t [ 0.58064821  4.71463583  6.          0.62063943 16.          0.34296764]\t 0.9094507882324498\t 0.6957422621425818\t 0.46969766489462195\t 0.46969766489462195\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8742114371455234\t 0.6957422621425818\t 0.47147383050283265\t 0.47147383050283265\n",
            "17 \t [3.35483601 6.04519575 9.         0.66543363 5.         0.97731627]\t 0.7137833679191798\t 0.6957422621425818\t 0.4729109494189036\t 0.4729109494189036\n",
            "18 \t [ 9.73905766  7.12200775  5.          0.85875901 11.          0.99496281]\t 0.71823877936225\t 0.6957422621425818\t 0.4766758639744671\t 0.4766758639744671\n",
            "19 \t [ 2.91927839  7.3392069   6.          0.85847684 14.          0.50487035]\t 0.7952024688472059\t 0.6957422621425818\t 0.4654497360985705\t 0.4654497360985705\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7650562704693341\t 0.6957422621425818\t 0.47387089476957545\t 0.47387089476957545\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7875791905388638\t 0.6957422621425818\t 0.46888799862186664\t 0.46888799862186664\n",
            "22 \t [ 3.12623913  1.70372165 14.          0.65033852 15.          0.68304577]\t 0.7562554967310947\t 0.6957422621425818\t 0.4631986191418137\t 0.4631986191418137\n",
            "23 \t [ 0.19302552  7.40732602 14.          0.96196983 15.          0.6651316 ]\t 0.7564571907366251\t 0.6957422621425818\t 0.47121482530994574\t 0.47121482530994574\n",
            "24 \t [ 4.58273638  9.08734041 15.          1.         20.          1.        ]\t 0.6983879848958736\t 0.6957422621425818\t 0.45613704447485326\t 0.456136825151876\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.7495093963493484\t 0.6957422621425818\t 0.4573615332678058\t 0.4573615332678058\n",
            "26 \t [ 0.65904826  3.00639193 10.          0.88267232 10.          0.15011078]\t 0.9700037688440479\t 0.6957422621425818\t 0.45613856678839787\t 0.45613856678839787\n",
            "27 \t [ 6.72997514  0.60780575 14.          0.89835235 18.          0.97859978]\t 0.6974052019541508\t 0.6957422621425818\t 0.45680302072310114\t 0.45680302072310114\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7558432662300643\t 0.6957422621425818\t 0.46558456045131275\t 0.46558456045131275\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7196023005131863\t 0.6957422621425818\t 0.45239574431172497\t 0.45239574431172497\n",
            "30 \t [2.95141826 5.73718821 5.         0.67688433 2.         0.54293886]\t 0.8205208874191854\t 0.6957422621425818\t 0.4643181592022554\t 0.4643181592022554\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59989.37417909926"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i707LrINxei",
        "outputId": "a1c40a42-21bf-4076-9a78-567c79b4ecc4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8708842589582968\t 0.8009237324889021\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.868843701878103\t 0.8009237324889021\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.8009237324889021\t 0.8009237324889021\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.8412285708806564\t 0.8009237324889021\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0874405633037085\t 0.8009237324889021\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.077285755760575\t 0.8009237324889021\t 0.49558160894038694\t 0.49558160894038694\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.1030510584286708\t 0.8009237324889021\t 0.5132849915890133\t 0.5132849915890133\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0698458362482097\t 0.8009237324889021\t 0.5278809197758438\t 0.5278809197758438\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0952568725496277\t 0.8009237324889021\t 0.5360172867380244\t 0.5360172867380244\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m0.5439716969568772\u001b[0m\t \u001b[1m\u001b[92m0.5439716969568772\u001b[0m\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7670753779942304\u001b[0m\t \u001b[1m\u001b[92m0.7670753779942304\u001b[0m\t \u001b[1m\u001b[92m0.5340338092816437\u001b[0m\t \u001b[1m\u001b[92m0.5340338092812108\u001b[0m\n",
            "7  \t [ 9.63031278  5.84246315  5.          0.67198611 19.          0.39028114]\t 0.9003400458685011\t 0.7670753779942304\t 0.5249046992827111\t 0.5249046992827111\n",
            "8  \t [ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\t 0.7785043750594152\t 0.7670753779942304\t 0.5227093666845452\t 0.5227093666845452\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0634397583136046\t 0.7670753779942304\t 0.5161217984603335\t 0.5161217984603335\n",
            "10 \t [ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\t 0.7744953455912423\t 0.7670753779942304\t 0.5214453710438661\t 0.5214453710438661\n",
            "11 \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]\t 0.7887884221082111\t 0.7670753779942304\t 0.5156782814688003\t 0.5156782814688003\n",
            "12 \t [ 4.67804043  9.96860077  5.          0.57375399 17.          0.57638976]\t 0.877249535726319\t 0.7670753779942304\t 0.5109854504683018\t 0.5109854504683018\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0806850045968446\t 0.7670753779942304\t 0.5094411099857901\t 0.5094411099857901\n",
            "14 \t [ 1.35461816  3.68867636  7.          0.97358458 19.          0.99760691]\t 0.772679413351429\t 0.7670753779942304\t 0.5145889406680146\t 0.5145889406680146\n",
            "15 \t [ 0.81201206  8.38911567 10.          0.69531918  2.          0.65392368]\t 0.8472189531903409\t 0.7670753779942304\t 0.5104392459167789\t 0.5104392459167789\n",
            "16 \t [6.55109905 2.29203942 6.         0.7269974  8.         0.87997636]\t 0.7880946868581832\t 0.7670753779942304\t 0.508265206540276\t 0.508265206540276\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.8987315752344891\t 0.7670753779942304\t 0.5024858347329271\t 0.5024858347329271\n",
            "18 \t [ 4.48555971  3.69204095  9.          0.58646272 16.          0.41216867]\t 0.897577978282801\t 0.7670753779942304\t 0.5023906258609402\t 0.5023906258609402\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.1009731307154418\t 0.7670753779942304\t 0.5047542098857241\t 0.5047542098857241\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9255377827812661\t 0.7670753779942304\t 0.506031069151723\t 0.506031069151723\n",
            "21 \t [ 9.93156192  7.7870595  10.          0.99771234 15.          0.55373941]\t 0.8520346696455514\t 0.7670753779942304\t 0.518127294600884\t 0.518127294600884\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.7871483295077344\t 0.7670753779942304\t 0.5040800790797679\t 0.5040800790797679\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9004861276725805\t 0.7670753779942304\t 0.5064903726383929\t 0.5064903726383929\n",
            "24 \t [ 3.2089954   7.98885441 11.          0.74347413  7.          0.34430429]\t 1.0900551917284997\t 0.7670753779942304\t 0.5022982345414692\t 0.5022982345414692\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.7882906269305859\t 0.7670753779942304\t 0.5158242200463773\t 0.5158242200463773\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.80192465196928\t 0.7670753779942304\t 0.5029898540398225\t 0.5029898540398225\n",
            "27 \t [ 0.39288966  2.38137383 14.          0.84416271 18.          0.55228203]\t 0.8529352499033671\t 0.7670753779942304\t 0.5074515008382122\t 0.5074515008382122\n",
            "28 \t [ 3.86031457  2.79254313 11.          0.81134713  7.          0.51906134]\t 0.8669435791539841\t 0.7670753779942304\t 0.5032773443921699\t 0.5032773448935196\n",
            "29 \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]\t 0.7946263770809028\t 0.7670753779942304\t 0.5061323635232331\t 0.506132424258067\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.8423134170816156\t 0.7670753779942304\t 0.5001518638229618\t 0.5001518638229618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58709.31750678993"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh0IJf8zNy9E",
        "outputId": "ba76fb1e-4ad3-4f0f-f591-eb28d7c8d956"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.7260880637055529\t 0.7260880637055529\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.7424588384015385\t 0.7260880637055529\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.8412720456029797\t 0.7260880637055529\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7736412232573235\t 0.7260880637055529\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.7650415360356615\t 0.7260880637055529\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.9222990750260575\t 0.7260880637055529\t 0.42491666170098463\t 0.42491666170098463\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7908681556639724\t 0.7260880637055529\t 0.4399494027001377\t 0.4399494027001377\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.7532691574021181\t 0.7260880637055529\t 0.43939148494641733\t 0.43939148494641733\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7781432084155051\t 0.7260880637055529\t 0.436452655505105\t 0.436452655505105\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.8455317589117171\t 0.7260880637055529\t 0.4356322820094143\t 0.4356322820094143\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.7441046132441587\t 0.7260880637055529\t 0.4387812219399148\t 0.4387812219399148\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.938335419027365\t 0.7260880637055529\t 0.4362643355351837\t 0.4362643355351837\n",
            "8  \t [ 0.46626117  2.25760624  6.          0.85367342 17.          0.48531791]\t 0.8357006200561671\t 0.7260880637055529\t 0.44358629235634417\t 0.44358629235634417\n",
            "9  \t [2.13213943 0.33619788 8.         0.65805012 9.         0.21235962]\t 1.0382579820366014\t 0.7260880637055529\t 0.44492939715219604\t 0.44492939715219604\n",
            "10 \t [ 3.23063104  1.13251329 14.          0.56093148  7.          0.35241226]\t 0.9263052453028615\t 0.7260880637055529\t 0.45522182334911593\t 0.45522182334911593\n",
            "11 \t [9.32031429 7.90309325 6.         0.69040988 5.         0.24485333]\t 1.0379873808842273\t 0.7260880637055529\t 0.45912907356440186\t 0.45912907356440186\n",
            "12 \t [7.0602652  6.93790534 9.         0.99868525 6.         0.93828193]\t 0.7346015930490536\t 0.7260880637055529\t 0.4670038884167685\t 0.4670038884167685\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7226488301147809\u001b[0m\t \u001b[1m\u001b[92m0.7226488301147809\u001b[0m\t \u001b[1m\u001b[92m0.4635339304025181\u001b[0m\t \u001b[1m\u001b[92m0.46353393038551366\u001b[0m\n",
            "14 \t [ 2.03397746  9.6248515   8.          0.66158474 19.          0.33227831]\t 0.9092511979833319\t 0.7226488301147809\t 0.46021071094807864\t 0.46021071094807864\n",
            "15 \t [ 7.27698082  9.82692974 11.          0.6446349   1.          0.67673022]\t 0.8164551789412968\t 0.7226488301147809\t 0.46252964076403263\t 0.46252964076403263\n",
            "16 \t [ 9.7240858   1.02502031 13.          0.74856182  8.          0.72377846]\t 0.7929964167748693\t 0.7226488301147809\t 0.46185830690143903\t 0.46185830690143903\n",
            "17 \t [6.33756741 5.05898037 6.         0.8569361  9.         0.25342856]\t 0.9137833655193568\t 0.7226488301147809\t 0.46136188114554477\t 0.46136188114554477\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.7615889956561305\t 0.7226488301147809\t 0.462224654159218\t 0.462224654159218\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 1.0294400573352889\t 0.7226488301147809\t 0.4615123746788686\t 0.4615123746788686\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.9151572773679874\t 0.7226488301147809\t 0.4669657382929734\t 0.4669657382929734\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7851375921928307\t 0.7226488301147809\t 0.4769530374435019\t 0.4769530374435019\n",
            "22 \t [ 3.39029064  2.39709901 13.          0.66131557 19.          0.59343116]\t 0.7920132766777059\t 0.7226488301147809\t 0.4644451771933377\t 0.4644451771933377\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.9204040683754566\t 0.7226488301147809\t 0.465659548929506\t 0.465659548929506\n",
            "24 \t [0.70527907 5.59255728 5.         0.86863619 1.         0.35457337]\t 0.9131884722416652\t 0.7226488301147809\t 0.46967704806884836\t 0.46967704806884836\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7884946222204549\t 0.7226488301147809\t 0.46514922065925157\t 0.46514922065925157\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 1.026659800264627\t 0.7226488301147809\t 0.4679615757403718\t 0.4679615757403718\n",
            "27 \t [9.91546913 0.35662679 7.         0.87706909 8.         0.31009443]\t 0.9081190657516668\t 0.7226488301147809\t 0.47603220220123477\t 0.47603220220123477\n",
            "28 \t [ 7.27114604  3.7137488   9.          0.55194413 17.          0.65085645]\t 0.7913418219905086\t 0.7226488301147809\t 0.4718564890031567\t 0.4718564890031567\n",
            "29 \t [10.          8.79603694  9.31595177  1.         17.31595177  1.        ]\t 0.7251779046522723\t 0.7226488301147809\t 0.47986187573740546\t 0.4798616661364501\n",
            "30 \t [ 0.41344076  0.53197741 10.          0.82623488 16.          0.71102663]\t 0.782525551781882\t 0.7226488301147809\t 0.4769317170105562\t 0.4769317170105562\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59954.44736483102"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b12526e-ee84-4bf3-9453-88c78c06098b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.802823873653181\t 0.7393694249818598\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.7439561063387327\t 0.7393694249818598\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8573744170126428\t 0.7393694249818598\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.7605799870908501\t 0.7393694249818598\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.7393694249818598\t 0.7393694249818598\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.4311826833537119\u001b[0m\t \u001b[1m\u001b[92m0.4311826833537119\u001b[0m\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8873087046852387\t 0.7341650428609557\t 0.42689350483825034\t 0.42689350483825034\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7481675054625107\t 0.7341650428609557\t 0.43633932398102926\t 0.43633932398102926\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8633824421289817\t 0.7341650428609557\t 0.4334294903010252\t 0.4334294903010252\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7484161632696045\t 0.7341650428609557\t 0.43836468396232153\t 0.43836468396232153\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.7356192440307244\t 0.7341650428609557\t 0.4358590208842028\t 0.4358590208842028\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8970855207140378\t 0.7341650428609557\t 0.4331927928661581\t 0.4331927928661581\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8688237885855482\t 0.7341650428609557\t 0.43863762634414055\t 0.43863762634414055\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7231837694267848\u001b[0m\t \u001b[1m\u001b[92m0.7231837694267848\u001b[0m\t \u001b[1m\u001b[92m0.4418738481424463\u001b[0m\t \u001b[1m\u001b[92m0.44187384765604026\u001b[0m\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.7505018736047322\t 0.7231837694267848\t 0.43893232613430055\t 0.43893232613430055\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8673094941420189\t 0.7231837694267848\t 0.4372990990949049\t 0.4372990990949049\n",
            "12 \t [ 0.20192989  7.58476143 13.          0.98270421 14.          0.40270035]\t 0.7890765046464809\t 0.7231837694267848\t 0.43996692959302736\t 0.43996692959302736\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 1.0006633800011113\t 0.7231837694267848\t 0.43967463774442134\t 0.43967463774442134\n",
            "14 \t [ 2.60485405  0.1122727  14.          0.63362696 19.          0.53965358]\t 0.7741744043730975\t 0.7231837694267848\t 0.44662325856586516\t 0.44662325856586516\n",
            "15 \t [3.63587924 9.92644255 5.         0.74785877 1.         0.42737692]\t 0.7942979577990048\t 0.7231837694267848\t 0.4456248436965247\t 0.4456248436965247\n",
            "16 \t [0.05861183 0.85510206 7.         0.55669041 9.         0.24118856]\t 1.0069691016446431\t 0.7231837694267848\t 0.4454261416862342\t 0.4454261416862342\n",
            "17 \t [2.76407972 8.95502778 9.         0.67297573 5.         0.56560976]\t 0.7769146956967419\t 0.7231837694267848\t 0.4515312203600138\t 0.4515312203600138\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9980631943644411\t 0.7231837694267848\t 0.44934590425476595\t 0.44934590425476595\n",
            "19 \t [ 4.10272358  0.68972827 14.          0.96902802  1.          0.19814279]\t 0.9980269756487967\t 0.7231837694267848\t 0.46251023924471313\t 0.46251023924471313\n",
            "20 \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]\t 0.7668011264232973\t 0.7231837694267848\t 0.46019479855061274\t 0.46019479855061274\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.7443970340307106\t 0.7231837694267848\t 0.45287776354950776\t 0.45287776354950776\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.869979050273399\t 0.7231837694267848\t 0.4595217723437228\t 0.4595217723437228\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7442995610019533\t 0.7231837694267848\t 0.45882976434479267\t 0.45882976434479267\n",
            "24 \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\t 0.7403513737505086\t 0.7231837694267848\t 0.4621537119086249\t 0.4621537119086249\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8853726892659874\t 0.7231837694267848\t 0.4495711893915739\t 0.4495711893915739\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9897503949395169\t 0.7231837694267848\t 0.4533490170402511\t 0.4533490170402511\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8013428795907425\t 0.7231837694267848\t 0.45481499255014846\t 0.45481499255014846\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.7439831766925111\t 0.7231837694267848\t 0.4617353735148815\t 0.4617353735148815\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.7400612177024872\t 0.7231837694267848\t 0.4619532539208733\t 0.4619532539208733\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 1.0026563027674915\t 0.7231837694267848\t 0.45723985525846433\t 0.45723985525846433\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59493.46322622606"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff95b75-a433-4d23-b62c-77672282064f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 1.1242573295906948\t 0.7785306461595496\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 1.1029639839305116\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.7785306461595496\t 0.7785306461595496\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.8502721808074817\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.8007936005920335\t 0.7785306461595496\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.1406566629866908\t 0.7785306461595496\t 0.520170981176189\t 0.520170981176189\n",
            "2  \t [ 8.16285902  8.43489929  9.          0.96605421 10.          0.79940153]\t 0.8233816089104812\t 0.7785306461595496\t 0.5398110058888215\t 0.5398110058888215\n",
            "3  \t [ 8.20707753  5.23681739  9.          0.99500664 19.          0.41686889]\t 0.9191507511732485\t 0.7785306461595496\t 0.5284030919203756\t 0.5284030919203756\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.8430600265636745\t 0.7785306461595496\t 0.5257428510733637\t 0.5257428510733637\n",
            "5  \t [ 1.54349431  7.96191852 12.          0.85734974 19.          0.2533894 ]\t 1.0672478448781664\t 0.7785306461595496\t 0.519325014868042\t 0.519325014868042\n",
            "6  \t [ 2.07399013  1.08547559 13.          0.90854674 16.          0.44415088]\t 0.9190933334870838\t 0.7785306461595496\t 0.5266407816232543\t 0.5266407816232543\n",
            "7  \t [ 1.76049512  0.          5.          0.5        11.87857539  0.1       ]\t 1.1446572209275678\t 0.7785306461595496\t 0.5248613454810166\t 0.5248613451121057\n",
            "8  \t [ 2.46434908  1.6440678  12.          0.75989697  8.          0.17542689]\t 1.1423979994591345\t 0.7785306461595496\t 0.5345055315943595\t 0.5345055315943595\n",
            "9  \t [ 1.49007135  2.48971353  7.          0.51783762 18.          0.72303345]\t 0.8773511871300128\t 0.7785306461595496\t 0.5424472372467469\t 0.5424472372467469\n",
            "10 \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]\t 0.9694253204437654\t 0.7785306461595496\t 0.5384552431612136\t 0.5384552431612136\n",
            "11 \t [ 7.53441733  9.89426931 12.          0.67232682 16.          0.3377491 ]\t 1.0829115765764628\t 0.7785306461595496\t 0.5381996758458223\t 0.5381996758458223\n",
            "12 \t [ 4.47453193  7.16141346  8.          0.50393935 18.          0.6896195 ]\t 0.8808956649060647\t 0.7785306461595496\t 0.5420679281014387\t 0.5420679281014387\n",
            "13 \t [1.75561603 6.13376087 5.         0.74047005 6.         0.77032586]\t 0.861448932686572\t 0.7785306461595496\t 0.5389072386595815\t 0.5389072386595815\n",
            "14 \t [ 8.08392893  1.91862949 14.          0.6384648  17.          0.1890016 ]\t 1.1397191606937405\t 0.7785306461595496\t 0.5355704983182398\t 0.5355704983182398\n",
            "15 \t [6.5099841  8.70472582 8.         0.63069736 4.         0.74098062]\t 0.8618854059109389\t 0.7785306461595496\t 0.5408090473292558\t 0.5408090473292558\n",
            "16 \t [ 3.66353781  7.3371628  13.          0.91928424 11.          0.42437688]\t 0.9250856549171413\t 0.7785306461595496\t 0.5377770525375766\t 0.5377770525375766\n",
            "17 \t [ 7.41269892  0.83478465  6.          0.6889712  10.          0.57219815]\t 0.8643194478477276\t 0.7785306461595496\t 0.5354400464489958\t 0.5354400464489958\n",
            "18 \t [2.32449242 8.80135208 8.         0.99642073 4.         0.14576968]\t 1.1331068048862545\t 0.7785306461595496\t 0.5352522432993597\t 0.5352522432993597\n",
            "19 \t [ 9.61301835  0.71568939  7.          0.99060765 16.          0.12483015]\t 1.1364313239920083\t 0.7785306461595496\t 0.5380194539614874\t 0.5380194539614874\n",
            "20 \t [9.74269591 0.84941648 5.         0.73002428 5.         0.75624172]\t 0.8648365568864038\t 0.7785306461595496\t 0.5403332166822595\t 0.5403332166822595\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7758231675240183\u001b[0m\t \u001b[1m\u001b[92m0.7758231675240183\u001b[0m\t \u001b[1m\u001b[92m0.5413611649083809\u001b[0m\t \u001b[1m\u001b[92m0.5413611587440393\u001b[0m\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.9210006183994057\t 0.7758231675240183\t 0.5328203736904296\t 0.5328203736904296\n",
            "23 \t [ 8.84354923  0.30921958 13.          0.61293397  5.          0.55740225]\t 0.870674006678524\t 0.7758231675240183\t 0.5435545264791194\t 0.5435545264791194\n",
            "24 \t [1.76701563 1.7346788  7.         0.94361827 2.         0.93288306]\t 0.7877982540472509\t 0.7758231675240183\t 0.5359534365209251\t 0.5359534365209251\n",
            "25 \t [2.23847616 1.05481765 6.         0.88971719 7.         0.87464495]\t 0.8430587581911103\t 0.7758231675240183\t 0.530505258465027\t 0.530505258465027\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.8414357962829216\t 0.7758231675240183\t 0.5260933308687133\t 0.5260933308687133\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.9682092632615712\t 0.7758231675240183\t 0.5296659880661232\t 0.5296659880661232\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 1.0854101197025208\t 0.7758231675240183\t 0.528192659843858\t 0.528192659843858\n",
            "29 \t [ 9.89680111  6.16985579 13.          0.58428363 17.          0.77251451]\t 0.8594533098064951\t 0.7758231675240183\t 0.5314429511427176\t 0.5314429511427176\n",
            "30 \t [ 0.01153499  2.29531024 11.          0.50673714  7.          0.13750522]\t 1.154363103664814\t 0.7758231675240183\t 0.5293071387135955\t 0.5293071387135955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58909.59940760899"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1204889-c56d-485b-c95b-76c4eeb21350"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 1.0639310256047103\t 0.7797034870948047\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.79580179662759\t 0.7797034870948047\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7797034870948047\t 0.7797034870948047\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7990514117028104\t 0.7797034870948047\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 1.0587036817796267\t 0.7797034870948047\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m0.5012258261522557\u001b[0m\t \u001b[1m\u001b[92m0.5012258261522557\u001b[0m\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.8572799307158145\t 0.7741723447560037\t 0.4896112477525228\t 0.4896112477525228\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 1.0670266318570725\t 0.7741723447560037\t 0.4872234187338283\t 0.4872234187338283\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.5009718372933486\u001b[0m\t \u001b[1m\u001b[92m0.5009718372933486\u001b[0m\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7439381718569423\u001b[0m\t \u001b[1m\u001b[92m0.7439381718569423\u001b[0m\t \u001b[1m\u001b[92m0.49307035449797953\u001b[0m\t \u001b[1m\u001b[92m0.49307035449797953\u001b[0m\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 1.013338643136875\t 0.7439381718569423\t 0.4854165357290964\t 0.4854165357290964\n",
            "7  \t [ 3.62490684  2.84275183 14.          0.74589397  2.          0.75096489]\t 0.7820038747184979\t 0.7439381718569423\t 0.4925277061078459\t 0.4925277061078459\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7966957629406074\t 0.7439381718569423\t 0.4877073460814936\t 0.4877073460814936\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.7659210449096093\t 0.7439381718569423\t 0.4841515267187075\t 0.4841515267187075\n",
            "10 \t [ 3.30148079  9.88907038 12.          0.72868817  1.          0.65479477]\t 0.8045524062849576\t 0.7439381718569423\t 0.47998494662098473\t 0.47998494662098473\n",
            "11 \t [ 7.71064959  9.96207932 10.          0.59477685 12.          0.11554071]\t 1.0724043815350996\t 0.7439381718569423\t 0.4776527272484565\t 0.4776527272484565\n",
            "12 \t [ 2.40528406  7.71427622 14.          0.55203588 14.          0.3470708 ]\t 0.9922782988108612\t 0.7439381718569423\t 0.48554509442239685\t 0.48554509442239685\n",
            "13 \t [ 0.          3.50610813  5.45529607  0.5        12.45529607  0.1       ]\t 1.075642212356992\t 0.7439381718569423\t 0.489354827569276\t 0.4893548245611001\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.9834501292605996\t 0.7439381718569423\t 0.4956554180952475\t 0.4956554180952475\n",
            "15 \t [ 0.15128266  5.75290365 10.          0.52450544 13.          0.50574484]\t 0.7994065495894672\t 0.7439381718569423\t 0.4982473486250826\t 0.4982473486250826\n",
            "16 \t [ 0.04708663  5.63008151  7.          0.89049451 16.          0.24468474]\t 1.0507401712471502\t 0.7439381718569423\t 0.49566105486671186\t 0.49566105486671186\n",
            "17 \t [0.54815519 9.09457687 7.         0.55756737 9.         0.32110491]\t 0.9905916044645892\t 0.7439381718569423\t 0.5026998258870479\t 0.5026998258870479\n",
            "18 \t [ 6.17394409  4.04114422 10.          0.65058545  1.          0.14583054]\t 1.0756148882202339\t 0.7439381718569423\t 0.5060397523707608\t 0.5060397523707608\n",
            "19 \t [ 9.33248639  6.49046641  7.          0.64248044 18.          0.96487849]\t 0.7695866348898367\t 0.7439381718569423\t 0.5094889572754803\t 0.5094889572754803\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 1.0497516119782428\t 0.7439381718569423\t 0.5026520731521307\t 0.5026520731521307\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7979220004395456\t 0.7439381718569423\t 0.5061474909841248\t 0.5061474909841248\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 1.0727233913162242\t 0.7439381718569423\t 0.501630020185932\t 0.501630020185932\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.7738741181601402\t 0.7439381718569423\t 0.5033246672223236\t 0.5033246672223236\n",
            "24 \t [ 2.44191194  3.33063319 11.          0.65513922  6.          0.45905506]\t 0.8557072760427349\t 0.7439381718569423\t 0.5053659580614267\t 0.5053659580614267\n",
            "25 \t [0.         3.31497581 5.         0.5        6.37863805 0.1       ]\t 1.072508460372464\t 0.7439381718569423\t 0.505785787925142\t 0.5057857842653565\n",
            "26 \t [10.         10.         15.          1.         15.27030767  1.        ]\t 0.7485052187841178\t 0.7439381718569423\t 0.5085211066784989\t 0.5085206903148127\n",
            "27 \t [ 7.88167693  7.97515501  6.          0.78950848 17.          0.19131965]\t 1.0553390354056282\t 0.7439381718569423\t 0.5035268142600722\t 0.5035268142600722\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 1.0555070855921338\t 0.7439381718569423\t 0.5083073608167212\t 0.5083073608167212\n",
            "29 \t [ 7.25858886  0.05284455 11.          0.66498317  6.          0.51372905]\t 0.789614662217095\t 0.7439381718569423\t 0.5096101188398421\t 0.5096101188398421\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.9718991207487232\t 0.7439381718569423\t 0.5105418515367746\t 0.5105418515367746\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60178.06298836527"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c793c3e7-8af2-409b-99fd-577f0a68005a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.8177825188141039\t 0.7287337628426743\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.7419480115539112\t 0.7287337628426743\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.7287337628426743\t 0.7287337628426743\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7335645848611818\t 0.7287337628426743\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7441537376931249\t 0.7287337628426743\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.7482694480200888\t 0.7287337628426743\t 0.4153049507789871\t 0.4153049507789871\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.4148458324214286\u001b[0m\t \u001b[1m\u001b[92m0.4148458324214286\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7598608339614092\t 0.7070648622170269\t 0.4113646533320737\t 0.4113646533320737\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 1.0312511769390245\t 0.7070648622170269\t 0.4123183275376377\t 0.4123183275376377\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 8.69064367  9.51683468 12.8445181   1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.680057675243759\u001b[0m\t \u001b[1m\u001b[92m0.680057675243759\u001b[0m\t \u001b[1m\u001b[92m0.4324748021213038\u001b[0m\t \u001b[1m\u001b[92m0.4324748021212923\u001b[0m\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.7209540253636189\t 0.680057675243759\t 0.4272483826602861\t 0.4272483826602861\n",
            "7  \t [8.5599695  9.54840342 6.         0.73281277 1.         0.77796226]\t 0.7453826611938918\t 0.680057675243759\t 0.4244565009894473\t 0.4244565009894473\n",
            "8  \t [0.50746251 9.37264814 7.         0.59739834 4.         0.27068294]\t 0.9257657979703049\t 0.680057675243759\t 0.42350625927746727\t 0.42350625927746727\n",
            "9  \t [ 7.64065289  8.8630116  14.          0.9254486   9.          0.47351621]\t 0.8201426455204416\t 0.680057675243759\t 0.43072877627482203\t 0.43072877627482203\n",
            "10 \t [ 1.06054513  2.23745512 13.          0.92745502  9.          0.16992758]\t 1.0149395859817427\t 0.680057675243759\t 0.4323737697758014\t 0.4323737697758014\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.9287138963597805\t 0.680057675243759\t 0.4419911371790841\t 0.4419911371790841\n",
            "12 \t [5.85899015 0.18045227 8.         0.62804619 6.         0.14553575]\t 1.0282447300474362\t 0.680057675243759\t 0.44658284596375575\t 0.44658284596375575\n",
            "13 \t [1.37264123 4.42539257 5.         0.50284853 7.         0.43970984]\t 0.8266513707453879\t 0.680057675243759\t 0.45460897498584396\t 0.45460897498584396\n",
            "14 \t [ 8.71522337  2.64896453  8.          0.8880663  13.          0.19932467]\t 1.0170728687846124\t 0.680057675243759\t 0.45467975574051456\t 0.45467975574051456\n",
            "15 \t [ 2.15117289  9.9737351  13.          0.92054036 19.          0.17057887]\t 1.0131449589068056\t 0.680057675243759\t 0.46110752584105136\t 0.46110752584105136\n",
            "16 \t [0.         0.         5.55563212 0.5        1.         0.1       ]\t 1.0356192288020616\t 0.680057675243759\t 0.4660418889214552\t 0.4660418884629509\n",
            "17 \t [ 6.62081816  5.83340811 11.          0.78433061  5.          0.88937204]\t 0.6974656413257093\t 0.680057675243759\t 0.4717273011793475\t 0.4717273011793475\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.7459513240013139\t 0.680057675243759\t 0.464161706820282\t 0.464161706820282\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 1.0352571936435033\t 0.680057675243759\t 0.47209376444756934\t 0.47209376444756934\n",
            "20 \t [10.         10.         11.07984689  1.         14.07984689  1.        ]\t 0.6856685300245562\t 0.680057675243759\t 0.4747370187912098\t 0.47473701775152394\n",
            "21 \t [ 3.32966927  6.72206515 14.          0.83912863 18.          0.84659432]\t 0.7279340274982999\t 0.680057675243759\t 0.4721945179795657\t 0.4721945179795657\n",
            "22 \t [8.67104465 4.35878698 7.         0.95502342 3.         0.77505171]\t 0.7278290457912009\t 0.680057675243759\t 0.467709802562474\t 0.467709802562474\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7547149277921693\t 0.680057675243759\t 0.47585643225467655\t 0.47585643225467655\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.9114560559082703\t 0.680057675243759\t 0.46566182689392266\t 0.46566182689392266\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 1.0248025279634128\t 0.680057675243759\t 0.46175303360857534\t 0.46175303360857534\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.8261521259015148\t 0.680057675243759\t 0.47650873100985447\t 0.47650873100985447\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7532872744350481\t 0.680057675243759\t 0.4684476885881082\t 0.4684476885881082\n",
            "28 \t [ 1.9144183   6.0983121   9.          0.90157057 18.          0.30859982]\t 0.9139631546370381\t 0.680057675243759\t 0.4646011842030953\t 0.4646011842030953\n",
            "29 \t [ 8.55410258  0.21556026 13.          0.58321534  8.          0.98283741]\t 0.7093927693796672\t 0.680057675243759\t 0.4644021955354362\t 0.4644021955354362\n",
            "30 \t [ 8.90038024  6.84704721 14.          0.51883719 15.          0.17155821]\t 1.0329356662488842\t 0.680057675243759\t 0.47103868910655916\t 0.47103868910655916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60589.21573009441"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f01567-4d81-41c0-865d-7ca8dd61f0a0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.992708970032886\t 0.7896346786115067\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.9050380263035862\t 0.7896346786115067\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.8362986807103934\t 0.7896346786115067\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7896346786115067\t 0.7896346786115067\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.9186387829358221\t 0.7896346786115067\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.8115376813007883\t 0.7896346786115067\t 0.4913562726526995\t 0.4913562726526995\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7706848965834242\u001b[0m\t \u001b[1m\u001b[92m0.7706848965834242\u001b[0m\t \u001b[1m\u001b[92m0.48431108469755246\u001b[0m\t \u001b[1m\u001b[92m0.48431108469755246\u001b[0m\n",
            "3  \t [ 4.70630658  9.38750646 12.          0.7933865  10.          0.74968408]\t 0.7740271259823363\t 0.7706848965834242\t 0.47627784299686343\t 0.47627784299686343\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.9144290525005069\t 0.7706848965834242\t 0.47037142395507703\t 0.47037142395507703\n",
            "5  \t [ 9.02656498  0.48984226 12.          0.66187047 14.          0.17842177]\t 0.9872730085293098\t 0.7706848965834242\t 0.4742435520352774\t 0.4742435520352774\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.9442383814615898\t 0.7706848965834242\t 0.4817092136328473\t 0.4817092136328473\n",
            "7  \t [ 9.92159613  3.53760601 14.          0.66495754  4.          0.92098158]\t 0.7787508246094917\t 0.7706848965834242\t 0.4853723068020261\t 0.4853723068020261\n",
            "8  \t [ 1.25868956  0.22795824 11.          0.81986474  9.          0.64717158]\t 0.782386570492398\t 0.7706848965834242\t 0.48095304046169085\t 0.48095304046169085\n",
            "9  \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]\t 0.7968946617431405\t 0.7706848965834242\t 0.4773212090891248\t 0.4773212090891248\n",
            "10 \t [ 2.00580329  2.31031601 14.          0.90401435 16.          0.44341936]\t 0.898339395813403\t 0.7706848965834242\t 0.4747099992270391\t 0.4747099992270391\n",
            "11 \t [ 2.24226925  8.24518571  5.          0.69075261 11.          0.5179779 ]\t 0.8635668878874545\t 0.7706848965834242\t 0.47611440994437426\t 0.47611440994437426\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.786862562407444\t 0.7706848965834242\t 0.47611170375896694\t 0.47611170375896694\n",
            "13 \t [ 0.33448533  6.02991322 12.          0.82752699  5.          0.97662755]\t 0.780316207694459\t 0.7706848965834242\t 0.473712231830841\t 0.473712231830841\n",
            "14 \t [ 2.5148909   0.65089504 12.          0.58484221  7.          0.60627853]\t 0.8554164422603889\t 0.7706848965834242\t 0.47139362586846506\t 0.47139362586846506\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9970201710934681\t 0.7706848965834242\t 0.47165292474596626\t 0.47165292474596626\n",
            "16 \t [0.        1.0998848 5.        0.5       1.        0.1      ]\t 1.0013095349981458\t 0.7706848965834242\t 0.47529856460958003\t 0.4752985626715852\n",
            "17 \t [6.02563339 8.022786   5.         0.85676853 1.         0.25300442]\t 0.9124161582646213\t 0.7706848965834242\t 0.480420046308631\t 0.480420046308631\n",
            "18 \t [ 9.66419595  5.21985973  6.          0.59246694 13.          0.24342225]\t 0.9886523402397586\t 0.7706848965834242\t 0.4901840747709361\t 0.4901840747709361\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 4.82116392  7.94441114 13.          0.79896359 10.          0.94409065]\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.48508446803178645\u001b[0m\t \u001b[1m\u001b[92m0.48508446803178645\u001b[0m\n",
            "20 \t [ 9.5610791   6.78651029 10.          0.7149365   3.          0.88779274]\t 0.7734370920531868\t 0.7656138946809342\t 0.4819654715373572\t 0.4819654715373572\n",
            "21 \t [ 0.60383814  6.44796032 11.          0.78951032 16.          0.75679881]\t 0.7747911103421761\t 0.7656138946809342\t 0.4754705211107477\t 0.4754705211107477\n",
            "22 \t [ 9.56245     5.31730445 14.          0.64647905 16.          0.99119841]\t 0.7771121471364839\t 0.7656138946809342\t 0.4753654329921882\t 0.4753654329921882\n",
            "23 \t [ 9.39056075  5.8448496  10.          0.68658632  9.          0.39035966]\t 0.918146540973386\t 0.7656138946809342\t 0.4778059603833562\t 0.4778059603833562\n",
            "24 \t [ 7.15884466  1.55713353 12.          0.64543033 19.          0.44284943]\t 0.9151351770158846\t 0.7656138946809342\t 0.4781927352100289\t 0.4781927352100289\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9785605674881227\t 0.7656138946809342\t 0.48253946961811733\t 0.48253946961811733\n",
            "26 \t [ 1.0206155   0.50876351 11.          0.82996077 17.          0.80891943]\t 0.7759755947443205\t 0.7656138946809342\t 0.4901113948322271\t 0.4901113948322271\n",
            "27 \t [ 2.97926615  5.44675549 13.62430416  1.         20.          1.        ]\t 0.7706834787388439\t 0.7656138946809342\t 0.48503201614406966\t 0.48503241274607983\n",
            "28 \t [ 7.43506744 10.          8.9939185   1.         13.9939185   1.        ]\t 0.7695944697252395\t 0.7656138946809342\t 0.4811688361335707\t 0.48116883612828765\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.8456632041648999\t 0.7656138946809342\t 0.48146168472244766\t 0.48146168472244766\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.979555746560927\t 0.7656138946809342\t 0.4766674090320292\t 0.4766674090320292\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60877.04939096347"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeaa91dc-9c04-40b5-a4b9-f8dbbcbb40fc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.7315012035187541\t 0.7315012035187541\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1319770010327717\t 0.7315012035187541\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.9318565354152348\t 0.7315012035187541\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.7799608780638936\t 0.7315012035187541\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1305934464937346\t 0.7315012035187541\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7922048089873084\t 0.7315012035187541\t 0.5271464231493893\t 0.5271464231493893\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.7364009364353266\t 0.7315012035187541\t 0.513189448758987\t 0.513189448758987\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7884892526498699\t 0.7315012035187541\t 0.4992874624139297\t 0.4992874624139297\n",
            "4  \t [ 4.39024044  6.42906019 12.          0.96666124  5.          0.79403332]\t 0.7332036085962248\t 0.7315012035187541\t 0.49169578315733137\t 0.49169578315733137\n",
            "5  \t [0.         0.         5.         0.5        8.13167322 0.1       ]\t 1.1308504443814063\t 0.7315012035187541\t 0.4827614203685143\t 0.4827614203685143\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10.          9.85284964 14.5735778   1.          5.5735778   1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7252776296603194\u001b[0m\t \u001b[1m\u001b[92m0.7252776296603194\u001b[0m\t \u001b[1m\u001b[92m0.4986209854645209\u001b[0m\t \u001b[1m\u001b[92m0.49862098546429084\u001b[0m\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8347085780850761\t 0.7252776296603194\t 0.49046665326454925\t 0.49046665326454925\n",
            "8  \t [10. 10. 15.  1. 20.  1.]\t 0.7284779445464229\t 0.7252776296603194\t 0.48801634325658017\t 0.48801634325658017\n",
            "9  \t [9.82022331 2.48941517 7.         0.64964742 8.         0.44060186]\t 0.8297121923849406\t 0.7252776296603194\t 0.48192022930149336\t 0.48192022930149336\n",
            "10 \t [ 6.60596124  8.35313787  6.          0.72167152 19.          0.94552853]\t 0.7474061753992649\t 0.7252776296603194\t 0.48021382068753393\t 0.48021382068753393\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7577952901048656\t 0.7252776296603194\t 0.475971751058491\t 0.475971751058491\n",
            "12 \t [ 8.67074354  1.64396694 14.          0.83039094  7.          0.18845957]\t 1.133362308446904\t 0.7252776296603194\t 0.4725496240641936\t 0.4725496240641936\n",
            "13 \t [ 1.3504194   1.49735602 14.          0.92508696  4.          0.69758236]\t 0.7478948066146335\t 0.7252776296603194\t 0.482843689673942\t 0.482843689673942\n",
            "14 \t [ 6.69835565  4.8962604   7.          0.82340135 14.          0.10862074]\t 1.1277267187584699\t 0.7252776296603194\t 0.47918861300944987\t 0.47918861300944987\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.7438065116890006\t 0.7252776296603194\t 0.4877733436316755\t 0.4877733436316755\n",
            "16 \t [ 2.06284179  6.9068961   5.          0.9448545  18.          0.13792391]\t 1.1296197909572616\t 0.7252776296603194\t 0.48427908556313237\t 0.48427908556313237\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.1355955958989596\t 0.7252776296603194\t 0.4915717249793197\t 0.4915717249793197\n",
            "18 \t [2.57352577 0.33719112 9.         0.97251025 4.         0.51947396]\t 0.78517596210852\t 0.7252776296603194\t 0.5003669930518507\t 0.5003669930518507\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.1349556164442796\t 0.7252776296603194\t 0.495887122272503\t 0.495887122272503\n",
            "20 \t [ 2.43733809  3.83718859 13.          0.87000869 16.          0.41452306]\t 0.8238705938885991\t 0.7252776296603194\t 0.5029951012723388\t 0.5029951012723388\n",
            "21 \t [4.43762845 4.57483662 7.         0.94265707 5.         0.33245902]\t 0.9392529725176331\t 0.7252776296603194\t 0.5031262143089754\t 0.5031262143089754\n",
            "22 \t [8.1634571  7.58766207 7.         0.64490867 1.         0.97002079]\t 0.7514301027178281\t 0.7252776296603194\t 0.509240398865801\t 0.509240398865801\n",
            "23 \t [3.55859061 5.61875163 8.         0.5882063  1.         0.57036163]\t 0.8119275659738049\t 0.7252776296603194\t 0.5073343490955521\t 0.5073343490955521\n",
            "24 \t [ 0.2594182   8.03698568 14.          0.55642831  5.          0.91542841]\t 0.755553743320279\t 0.7252776296603194\t 0.5025014170613932\t 0.5025014170613932\n",
            "25 \t [9.92248648 8.73301847 7.         0.58578431 6.         0.64802898]\t 0.7597086493735234\t 0.7252776296603194\t 0.4950383777323853\t 0.4950383777323853\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.7463927243485514\t 0.7252776296603194\t 0.49390983728339183\t 0.49390983728339183\n",
            "27 \t [ 4.30271104  7.67529814 14.          0.73770848  1.          0.87787505]\t 0.756228394612864\t 0.7252776296603194\t 0.49077250064247935\t 0.49077250064247935\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.7956673392227565\t 0.7252776296603194\t 0.4849600839079677\t 0.4849600839079677\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9305364532791108\t 0.7252776296603194\t 0.4881859447288128\t 0.4881859447288128\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.932353773777384\t 0.7252776296603194\t 0.4856345652376904\t 0.4856345652376904\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60840.84881134633"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4b3f04-a913-46cf-fe9e-e8250c54cbfb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.886516450243748\t 0.7696523735238344\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.8159404842786963\t 0.7696523735238344\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.9077084280320982\t 0.7696523735238344\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.7696523735238344\t 0.7696523735238344\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 0.9767143382937844\t 0.7696523735238344\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 0.9945462140035275\t 0.7696523735238344\t 0.4820184704180913\t 0.4820184704180913\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.8956717295899809\t 0.7696523735238344\t 0.4936914785628743\t 0.4936914785628743\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7896752580111073\t 0.7696523735238344\t 0.4937086211876093\t 0.4937086211876093\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 0.9788770650266176\t 0.7696523735238344\t 0.48679866303969827\t 0.48679866303969827\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9068912188410501\t 0.7696523735238344\t 0.4929547046977047\t 0.4929547046977047\n",
            "6  \t [ 1.2948927   7.78786103 11.          0.50236456  2.          0.82308036]\t 0.7981960996164814\t 0.7696523735238344\t 0.4936635688292529\t 0.4936635688292529\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7844376116756365\t 0.7696523735238344\t 0.48903397850681196\t 0.48903397850681196\n",
            "8  \t [ 7.13077184  9.67534636 12.          0.53994085 17.          0.99732292]\t 0.7788814985676316\t 0.7696523735238344\t 0.48457360015140916\t 0.48457360015140916\n",
            "9  \t [ 4.99777324  7.1255563   5.          0.87428718 19.          0.63814647]\t 0.8365647355641779\t 0.7696523735238344\t 0.48055581884687226\t 0.48055581884687226\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.8262334140046084\t 0.7696523735238344\t 0.4792001686054196\t 0.4792001686054196\n",
            "11 \t [ 2.11261802  6.77105261 11.          0.82546435 17.          0.58049877]\t 0.8420672525155452\t 0.7696523735238344\t 0.4776617972225349\t 0.4776617972225349\n",
            "12 \t [ 1.50285169  4.17593259 14.          0.69234646  6.          0.74044842]\t 0.8279918365760726\t 0.7696523735238344\t 0.4768452431876819\t 0.4768452431876819\n",
            "13 \t [ 9.52967585  8.1936199  11.          0.55796294 10.          0.99729185]\t 0.7763977773208957\t 0.7696523735238344\t 0.4756565153071133\t 0.4756565153071133\n",
            "14 \t [ 0.14006525  1.03750573 13.          0.72168802 14.          0.72400369]\t 0.815597828474959\t 0.7696523735238344\t 0.47315198068686964\t 0.47315198068686964\n",
            "15 \t [ 4.60180761  5.86373927 12.          0.57860802 15.          0.61913601]\t 0.8488880266059902\t 0.7696523735238344\t 0.4720203039036109\t 0.4720203039036109\n",
            "16 \t [ 0.37071497  8.67648538  5.          0.98055998 16.          0.65274603]\t 0.8335023218287553\t 0.7696523735238344\t 0.4716458366363288\t 0.4716458366363288\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.778866435123053\t 0.7696523735238344\t 0.4708866835191585\t 0.4708866835191585\n",
            "18 \t [1.97879228 8.99345507 8.         0.55562265 8.         0.49118331]\t 0.8951491505335811\t 0.7696523735238344\t 0.46618458045860245\t 0.46618458045860245\n",
            "19 \t [ 3.46936711  8.05933995 13.          0.63796232  8.          0.58226276]\t 0.8566066993171872\t 0.7696523735238344\t 0.4655478289411396\t 0.4655478289411396\n",
            "20 \t [2.03544962 0.82234782 9.         0.75192666 8.         0.57674562]\t 0.8454913145347565\t 0.7696523735238344\t 0.46772011367009586\t 0.46772011367009586\n",
            "21 \t [4.16561464 4.3151821  6.         0.76299318 2.         0.59049538]\t 0.8474357581098328\t 0.7696523735238344\t 0.47901111922627965\t 0.47901111922627965\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.754288614897578\u001b[0m\t \u001b[1m\u001b[92m0.754288614897578\u001b[0m\t \u001b[1m\u001b[92m0.4754346456751802\u001b[0m\t \u001b[1m\u001b[92m0.475434619222342\u001b[0m\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 0.9821896458721675\t 0.754288614897578\t 0.4749017941469785\t 0.4749017941469785\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.7800900414685491\t 0.754288614897578\t 0.47241413054593623\t 0.47241413054593623\n",
            "25 \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]\t 0.7754504257026212\t 0.754288614897578\t 0.47905869439041876\t 0.47905869439041876\n",
            "26 \t [ 5.73005003  1.18628884 13.          0.88016467 12.          0.48547975]\t 0.8868749954853754\t 0.754288614897578\t 0.4715772861658862\t 0.4715772861658862\n",
            "27 \t [8.60914739 9.54673859 7.         0.78963544 7.         0.48348756]\t 0.8811833469490125\t 0.754288614897578\t 0.4708811698266518\t 0.4708811698266518\n",
            "28 \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]\t 0.8621381926118351\t 0.754288614897578\t 0.46753622504680487\t 0.46753622504680487\n",
            "29 \t [ 7.16352089  0.19968156 11.          0.62318898  8.          0.21107406]\t 0.9776297559990524\t 0.754288614897578\t 0.46975072331121887\t 0.46975072331121887\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.8347983363393409\t 0.754288614897578\t 0.48176081874997345\t 0.48176081874997345\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60569.20712257925"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec6e2ad-211c-4d5c-9dd6-6ad0915c592f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.7846478010899064\t 0.7846478010899064\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 1.0448868808294456\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 1.0327067294213346\t 0.7846478010899064\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.8536879526704689\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 1.0323325469581077\t 0.7846478010899064\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.810550884613735\t 0.7846478010899064\t 0.5269987735641259\t 0.5269987735641259\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.9535088265263543\t 0.7846478010899064\t 0.5145127550710321\t 0.5145127550710321\n",
            "3  \t [ 1.91126037  0.99517267  5.          0.54111286 13.          0.82351196]\t 0.8272848096167836\t 0.7846478010899064\t 0.5161253424648982\t 0.5161253424648982\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 9.65016643  9.36315476  6.          0.59817648 12.          0.93115055]\u001b[0m\t \u001b[1m\u001b[92m0.7808363478466259\u001b[0m\t \u001b[1m\u001b[92m0.7808363478466259\u001b[0m\t \u001b[1m\u001b[92m0.5090100218559563\u001b[0m\t \u001b[1m\u001b[92m0.5090100218559563\u001b[0m\n",
            "5  \t [ 7.92634325  7.5869497  10.          0.81214373  5.          0.71583728]\t 0.8214564758537112\t 0.7808363478466259\t 0.5008945306693038\t 0.5008945306693038\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.9316923990976885\t 0.7808363478466259\t 0.49630339324200334\t 0.49630339324200334\n",
            "7  \t [ 1.16848639  8.05538533  5.          0.78038294 17.          0.39890654]\t 0.9239694196020342\t 0.7808363478466259\t 0.4979070399426127\t 0.4979070399426127\n",
            "8  \t [ 2.92030295  6.55213539  7.          0.85743112 11.          0.10721562]\t 1.0321654101154336\t 0.7808363478466259\t 0.4988759516397813\t 0.4988759516397813\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7500277749997387\u001b[0m\t \u001b[1m\u001b[92m0.7500277749997387\u001b[0m\t \u001b[1m\u001b[92m0.5046185545776022\u001b[0m\t \u001b[1m\u001b[92m0.5046185544113658\u001b[0m\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 9.99662448  8.82459197 12.9268054   1.         10.60398441  0.75696092]\u001b[0m\t \u001b[1m\u001b[92m0.7398122141852611\u001b[0m\t \u001b[1m\u001b[92m0.7398122141852611\u001b[0m\t \u001b[1m\u001b[92m0.49866418485253117\u001b[0m\t \u001b[1m\u001b[92m0.4986641845365138\u001b[0m\n",
            "11 \t [7.86329715 0.45193827 6.         0.68312899 1.         0.69810196]\t 0.8331518961036075\t 0.7398122141852611\t 0.4931348630753658\t 0.4931348630753658\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.8291023984963773\t 0.7398122141852611\t 0.49108948466032143\t 0.49108948466032143\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.7817258295570644\t 0.7398122141852611\t 0.4891487116844778\t 0.4891487116844778\n",
            "14 \t [ 8.99181419  1.29592358  9.          0.86284928 19.          0.2606215 ]\t 0.9289186496912898\t 0.7398122141852611\t 0.48614065214204066\t 0.48614065214204066\n",
            "15 \t [ 0.16461509  2.47453913  6.          0.69159787 16.          0.61162096]\t 0.8390246298076309\t 0.7398122141852611\t 0.4875097783734496\t 0.4875097783734496\n",
            "16 \t [ 1.01000548  1.96777104 12.          0.51504561  8.          0.68970296]\t 0.8363440079633978\t 0.7398122141852611\t 0.4865219728618046\t 0.4865219728618046\n",
            "17 \t [4.50435964 1.42883317 8.         0.76583339 3.         0.4306355 ]\t 0.9350949568458088\t 0.7398122141852611\t 0.484350222380646\t 0.484350222380646\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.8184266869335748\t 0.7398122141852611\t 0.48565320490335545\t 0.48565320490335545\n",
            "19 \t [ 9.64875283  9.32176949  8.          0.85263567 19.          0.33410227]\t 0.9264535302583298\t 0.7398122141852611\t 0.48541320328956006\t 0.48541320328956006\n",
            "20 \t [ 5.31037667  6.81676807  5.          0.53020463 18.          0.21260061]\t 1.0437596156191435\t 0.7398122141852611\t 0.48815763338644924\t 0.48815763338644924\n",
            "21 \t [8.81149616 6.28323965 6.         0.50689458 2.         0.19421846]\t 1.0506048051001848\t 0.7398122141852611\t 0.4968463796393356\t 0.4968463956882489\n",
            "22 \t [ 9.31305405  2.68340802  7.          0.59348541 12.          0.97471219]\t 0.7821514519763622\t 0.7398122141852611\t 0.4936441096888359\t 0.4936441096888359\n",
            "23 \t [ 6.04262604  3.49698263 14.          0.62988823  3.          0.21136394]\t 1.0525057130171327\t 0.7398122141852611\t 0.4931908670891102\t 0.4931908670891102\n",
            "24 \t [ 2.81158295  0.14163964 12.          0.70854558 13.          0.79112734]\t 0.8291584327833194\t 0.7398122141852611\t 0.4975145913412242\t 0.4975145913412242\n",
            "25 \t [6.6803176  5.16849036 5.         0.60605786 3.         0.85637409]\t 0.8471085133591287\t 0.7398122141852611\t 0.5036394813451851\t 0.5036394813451851\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.9727332413478633\t 0.7398122141852611\t 0.4999205602244901\t 0.4999205602244901\n",
            "27 \t [ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]\t 0.7412282900611625\t 0.7398122141852611\t 0.4982161432614978\t 0.4982161432614978\n",
            "28 \t [ 5.01445613  7.60723079 13.          0.87242918 11.          0.16027469]\t 1.0329468934773758\t 0.7398122141852611\t 0.4920181540411313\t 0.4920181556572487\n",
            "29 \t [6.82981437 4.74493883 7.         0.89715965 7.         0.43907022]\t 0.9192091769762591\t 0.7398122141852611\t 0.4934395111613375\t 0.4934395111613375\n",
            "30 \t [ 9.40435768  7.598465   10.          0.97457018 15.          0.31309738]\t 0.9314234944354094\t 0.7398122141852611\t 0.4965910669699694\t 0.4965910669699694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61058.74866479826"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802c788b-e649-4f57-bd8e-f8c5e7085303"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 1.0442882316794924\t 0.9988899440522335\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 1.034592364984854\t 0.9988899440522335\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.9988899440522335\t 0.9988899440522335\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 1.0616382201607613\t 0.9988899440522335\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 1.0586655163441985\t 0.9988899440522335\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m0.5732753340025499\u001b[0m\t \u001b[1m\u001b[92m0.5732753340025499\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 1.0357720753154218\t 0.7588724777099193\t 0.5504955772989466\t 0.5504955772989466\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.9957364873565091\t 0.7588724777099193\t 0.5534995725159004\t 0.5534995725159004\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 1.0230792313624693\t 0.7588724777099193\t 0.5529182807269342\t 0.5529182807269342\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.9990381912537636\t 0.7588724777099193\t 0.5541804786488659\t 0.5541804786488659\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.857846290397769\t 0.7588724777099193\t 0.553845723683855\t 0.553845723683855\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 1.0693894233525565\t 0.7588724777099193\t 0.5469871225744853\t 0.5469871225744853\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.8611559732831295\t 0.7588724777099193\t 0.5506483751807187\t 0.5506483751807187\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m0.5452010991335544\u001b[0m\t \u001b[1m\u001b[92m0.5452010991335544\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7415155405776647\t 0.7219532506859043\t 0.5360309419327026\t 0.5360309419327026\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 1.1107767409489193\t 0.7219532506859043\t 0.5285107869768771\t 0.5285107869768771\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.857182327987213\t 0.7219532506859043\t 0.534132070118328\t 0.534132070118328\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.5306938187862427\u001b[0m\t \u001b[1m\u001b[92m0.5306938187862427\u001b[0m\n",
            "14 \t [ 5.41155711  5.82534705 10.          0.62444801 12.          0.48368067]\t 1.011456246332149\t 0.7195558119979323\t 0.5241752858782721\t 0.5241752858782721\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 1.0073272814467533\t 0.7195558119979323\t 0.5259747075886434\t 0.5259747075886434\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.894093323976883\t 0.7195558119979323\t 0.527411244028548\t 0.527411244028548\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 1.096518529758772\t 0.7195558119979323\t 0.5264463338138571\t 0.5264463338138571\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 1.0333946700789831\t 0.7195558119979323\t 0.5335870354756929\t 0.5335870354756929\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 1.0221431969128547\t 0.7195558119979323\t 0.5280042130547761\t 0.5280042130547761\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.9054977129617926\t 0.7195558119979323\t 0.5345159457567574\t 0.5345159457567574\n",
            "21 \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]\t 1.0357266754545873\t 0.7195558119979323\t 0.5355764483794454\t 0.5355764483794454\n",
            "22 \t [0.        0.        5.        0.5       2.8912697 0.1      ]\t 1.1109036399234546\t 0.7195558119979323\t 0.5399300178287247\t 0.539929998531757\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         13.08822639  1.          8.08822639  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6996450552202096\u001b[0m\t \u001b[1m\u001b[92m0.6996450552202096\u001b[0m\t \u001b[1m\u001b[92m0.5366778435469598\u001b[0m\t \u001b[1m\u001b[92m0.5366778428236086\u001b[0m\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7761448350601515\t 0.6996450552202096\t 0.5321745186993814\t 0.5321745186993814\n",
            "25 \t [ 9.01141716  1.23452325  9.          0.70620993 16.          0.46074297]\t 1.0029978093526934\t 0.6996450552202096\t 0.5284122516656681\t 0.5284122516656681\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 1.0050223847057222\t 0.6996450552202096\t 0.528630955899876\t 0.528630955899876\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.8647657423877456\t 0.6996450552202096\t 0.5338217601627415\t 0.5338217601627415\n",
            "28 \t [ 1.9619463   0.16028995 10.          0.50330845  2.          0.6207421 ]\t 0.9390116776172818\t 0.6996450552202096\t 0.5305005738467523\t 0.5305005738467523\n",
            "29 \t [ 1.58467279  1.68272877 13.          0.86101343 12.          0.4100987 ]\t 1.004998254560435\t 0.6996450552202096\t 0.5320170819402343\t 0.5320170819402343\n",
            "30 \t [10. 10. 15.  1. 20.  1.]\t 0.7037087316880686\t 0.6996450552202096\t 0.5315910801271992\t 0.5315906795206008\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60163.444219797144"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e195e5-88e8-433b-e076-4959eab17c6b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.8160193762021096\t 0.8160193762021096\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.9345750435828236\t 0.8160193762021096\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.8609997448649105\t 0.8160193762021096\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9816665199899536\t 0.8160193762021096\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.9568167510294832\t 0.8160193762021096\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.9860041719301801\t 0.8160193762021096\t 0.4988128185398431\t 0.4988128185398431\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.8418838401878418\t 0.8160193762021096\t 0.5065546590736558\t 0.5065546590736558\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m0.5007174162276283\u001b[0m\t \u001b[1m\u001b[92m0.5007174162276283\u001b[0m\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9840979999934294\t 0.7805118546901472\t 0.4924682513816366\t 0.4924682513816449\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.955892785185136\t 0.7805118546901472\t 0.4982829310688627\t 0.4982829310688627\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.9781132546552117\t 0.7805118546901472\t 0.5032566333936962\t 0.5032566333936962\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.8404775189371637\t 0.7805118546901472\t 0.5048056504947198\t 0.5048056504947198\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.9731655942341536\t 0.7805118546901472\t 0.5014840996229991\t 0.5014840996229991\n",
            "9  \t [9.85206608 0.28191822 5.         0.52457928 8.         0.84714334]\t 0.8508120667734606\t 0.7805118546901472\t 0.5058121452565497\t 0.5058121452565497\n",
            "10 \t [ 0.2191332   8.51773955  5.          0.60657578 15.          0.49735822]\t 0.9550900145970594\t 0.7805118546901472\t 0.5018354326644088\t 0.5018354326644088\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.9443317250470002\t 0.7805118546901472\t 0.5035194729576216\t 0.5035194729576216\n",
            "12 \t [0.95504342 7.30424524 8.         0.76682007 6.         0.21761275]\t 0.9795870115119684\t 0.7805118546901472\t 0.5058674873386116\t 0.5058674873386116\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         16.27820591  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7433704411297064\u001b[0m\t \u001b[1m\u001b[92m0.7433704411297064\u001b[0m\t \u001b[1m\u001b[92m0.5075940388817218\u001b[0m\t \u001b[1m\u001b[92m0.507594015487308\u001b[0m\n",
            "14 \t [ 7.35111323  4.42247898 14.          0.92954426  7.          0.31778445]\t 0.959605938976237\t 0.7433704411297064\t 0.50175405928991\t 0.50175405928991\n",
            "15 \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]\t 0.9759678380966751\t 0.7433704411297064\t 0.503629351094893\t 0.503629351094893\n",
            "16 \t [ 5.22074709  0.74229772 13.          0.87455275  7.          0.44305495]\t 0.9475819018040168\t 0.7433704411297064\t 0.5062359475138509\t 0.5062359475138509\n",
            "17 \t [ 9.1928307   3.75120063 13.          0.61085648 16.          0.3130605 ]\t 0.9631882478680399\t 0.7433704411297064\t 0.507314631281999\t 0.507314631281999\n",
            "18 \t [ 0.17456981  4.44078349  6.          0.87411246 11.          0.7606398 ]\t 0.8208688087690457\t 0.7433704411297064\t 0.5080701409270552\t 0.5080701409270552\n",
            "19 \t [ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]\t 0.8425830184404466\t 0.7433704411297064\t 0.5124757384096794\t 0.5124757384096794\n",
            "20 \t [ 3.14178862 10.         14.95674028  1.         12.95674028  1.        ]\t 0.7453730897157174\t 0.7433704411297064\t 0.49997702367843977\t 0.49997701604061007\n",
            "21 \t [ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\t 0.7847481688271192\t 0.7433704411297064\t 0.5082644304002926\t 0.5082644304002926\n",
            "22 \t [6.17562703 5.62140054 5.         0.97946506 3.         0.20857904]\t 0.9722212560084632\t 0.7433704411297064\t 0.5015302235855003\t 0.5015302235855003\n",
            "23 \t [ 7.72813057  7.72686892  6.          0.51801644 18.          0.89565947]\t 0.7981272981530259\t 0.7433704411297064\t 0.5060773340960465\t 0.5060773340960465\n",
            "24 \t [9.30371298 5.41042714 5.         0.80825473 7.         0.72790994]\t 0.8552977982452606\t 0.7433704411297064\t 0.4936394565430013\t 0.4936394565430013\n",
            "25 \t [0.         0.63380141 5.         0.5        1.         0.1       ]\t 0.9987994924328458\t 0.7433704411297064\t 0.49803524374821356\t 0.49803511880396684\n",
            "26 \t [ 8.35560958  6.49504743 11.          0.90882708 12.          0.40676904]\t 0.9390064468970415\t 0.7433704411297064\t 0.5051150446259229\t 0.5051150446259229\n",
            "27 \t [ 5.62137526  0.50742571 12.          0.60891749  1.          0.89299215]\t 0.8009030532950018\t 0.7433704411297064\t 0.5040902912068065\t 0.5040902912068065\n",
            "28 \t [ 4.55919043  8.6591134   6.          0.8884863  12.          0.96165246]\t 0.768672041990598\t 0.7433704411297064\t 0.4971708462974917\t 0.4971708462974917\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.860674338231938\t 0.7433704411297064\t 0.5007538142645271\t 0.5007538142645271\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.8118933760299614\t 0.7433704411297064\t 0.4910392222472623\t 0.4910392222472623\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60331.76147017974"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7010cbdf-1f65-4757-cc96-39877997e045"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9747807501509798\t 0.8413213471093884\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.8434056917425027\t 0.8413213471093884\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9720565145525129\t 0.8413213471093884\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.8568115101817837\t 0.8413213471093884\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.8413213471093884\t 0.8413213471093884\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8631585877624761\t 0.8413213471093884\t 0.4948766793870714\t 0.4948766793870714\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.7571977630434763\u001b[0m\t \u001b[1m\u001b[92m0.7571977630434763\u001b[0m\t \u001b[1m\u001b[92m0.49176223157296606\u001b[0m\t \u001b[1m\u001b[92m0.49176223157296606\u001b[0m\n",
            "3  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0836382758107443\t 0.7571977630434763\t 0.4818502375857933\t 0.48185023757736295\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.9891420999894684\t 0.7571977630434763\t 0.49776924572047226\t 0.49776924572047226\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.8235970122668114\t 0.7571977630434763\t 0.5039439146921241\t 0.5039439146921241\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 1.0897095171845277\t 0.7571977630434763\t 0.49857540729711\t 0.49857540729711\n",
            "7  \t [9.62350533 1.2688885  9.         0.94775659 1.         0.72317258]\t 0.8324419101287693\t 0.7571977630434763\t 0.5092463932567312\t 0.5092463932567312\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.8576035440570304\t 0.7571977630434763\t 0.504757204606292\t 0.504757204606292\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.8440073802229666\t 0.7571977630434763\t 0.5023723114811925\t 0.5023723114811925\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         12.21433251  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7455938399114179\u001b[0m\t \u001b[1m\u001b[92m0.7455938399114179\u001b[0m\t \u001b[1m\u001b[92m0.4997840459888871\u001b[0m\t \u001b[1m\u001b[92m0.49978404079854666\u001b[0m\n",
            "11 \t [2.26673282 9.18109909 5.         0.89654818 1.         0.23064839]\t 1.0833498845487965\t 0.7455938399114179\t 0.49479992439339127\t 0.49479992439339127\n",
            "12 \t [ 0.62191196  4.69754177  5.          0.72971917 15.          0.95903084]\t 0.7754264864839603\t 0.7455938399114179\t 0.5013628836007922\t 0.5013628836007922\n",
            "13 \t [ 5.48459978  3.46428764  6.          0.68559202 11.          0.97835551]\t 0.7658226206636108\t 0.7455938399114179\t 0.4977314107152464\t 0.4977314107152464\n",
            "14 \t [ 9.17553299  1.41421886 11.          0.77317761 11.          0.82263086]\t 0.7842845189628849\t 0.7455938399114179\t 0.4937986655690644\t 0.4937986655690644\n",
            "15 \t [0.73985165 0.58861565 5.         0.76246476 8.         0.22502929]\t 1.0860534715086827\t 0.7455938399114179\t 0.4904703750309264\t 0.4904703750309264\n",
            "16 \t [ 2.74922981  6.93422037  7.          0.64536331 17.          0.3979189 ]\t 0.9079405182192885\t 0.7455938399114179\t 0.4967444758219949\t 0.4967444758219949\n",
            "17 \t [ 5.01391374  9.05765577 13.          0.9768187   1.          0.92456281]\t 0.7679138124413849\t 0.7455938399114179\t 0.49637266833214044\t 0.49637266833214044\n",
            "18 \t [ 7.49379106  4.28777418 12.          0.51562956  7.          0.83771026]\t 0.8108696725518876\t 0.7455938399114179\t 0.4953167032445465\t 0.4953167032445465\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 1.0782261571143834\t 0.7455938399114179\t 0.5001007930395741\t 0.5001007930395741\n",
            "20 \t [ 1.66783825  3.86062767 10.          0.57131975 19.          0.50542835]\t 0.8581182648794368\t 0.7455938399114179\t 0.5069072225025527\t 0.5069072225025527\n",
            "21 \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]\t 0.8643544554338216\t 0.7455938399114179\t 0.4950603982364495\t 0.4950603982364495\n",
            "22 \t [ 9.53583471  8.78338896 12.          0.84585772  7.          0.92915609]\t 0.7556591173733462\t 0.7455938399114179\t 0.4955884131055544\t 0.4955884131055544\n",
            "23 \t [ 6.72349545  5.27194732 13.          0.74776676 17.          0.30949491]\t 0.960458435595567\t 0.7455938399114179\t 0.495531498408145\t 0.495531498408145\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.7689475410076321\t 0.7455938399114179\t 0.4958505236930959\t 0.4958505236930959\n",
            "25 \t [ 3.75888009  4.48669956 11.          0.79480873  1.          0.40375096]\t 0.9307562637157332\t 0.7455938399114179\t 0.5005271515682995\t 0.5005271515682995\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.874691617323094\t 0.7455938399114179\t 0.4994972711184829\t 0.4994972711184829\n",
            "27 \t [ 2.38281778  0.41819082 12.          0.85009716 13.          0.76896773]\t 0.7778157345003668\t 0.7455938399114179\t 0.49254950347626736\t 0.49254950347626736\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 1.0750435829982965\t 0.7455938399114179\t 0.4886909155075555\t 0.4886909155075555\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.8437734790413737\t 0.7455938399114179\t 0.49154132589968375\t 0.49154132589968375\n",
            "30 \t [6.65163782 6.39807144 6.         0.64802115 8.         0.12708916]\t 1.0861773102884364\t 0.7455938399114179\t 0.4951257624246039\t 0.4951257624246039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60695.25132467432"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1131f9dd-aff3-4272-bebd-e492742cb9f4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.9238143360620997\t 0.824729580989813\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.9119597092034326\t 0.824729580989813\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.1280473533716002\t 0.824729580989813\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.885331313733569\t 0.824729580989813\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.824729580989813\t 0.824729580989813\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m0.5163049872859979\u001b[0m\t \u001b[1m\u001b[92m0.5163049872859979\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.8875735409405836\t 0.79346025102973\t 0.5040210556114599\t 0.5040210556114599\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.1322726135322738\t 0.79346025102973\t 0.5019507575494121\t 0.5019507575494121\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.9633601355550562\t 0.79346025102973\t 0.5188177561290613\t 0.5188177561290613\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.9736613453341365\t 0.79346025102973\t 0.5202000175160089\t 0.5202000175160089\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.8962334110364653\t 0.79346025102973\t 0.521885101587873\t 0.521885101587873\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.8910080545620651\t 0.79346025102973\t 0.5194219148223846\t 0.5194219148223846\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.8893037640708062\t 0.79346025102973\t 0.5171320131078915\t 0.5171320131078915\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.9338815902432167\t 0.79346025102973\t 0.5151170716394711\t 0.5151170716394711\n",
            "10 \t [0.         3.03221242 5.         0.5        7.32202785 0.1       ]\t 1.1257248683238774\t 0.79346025102973\t 0.5151009303091465\t 0.5151009236174313\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.8287447527880435\t 0.79346025102973\t 0.5227952985088214\t 0.5227952985088214\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[10.          9.60381957  9.88523604  1.          6.88523604  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7687925551485486\u001b[0m\t \u001b[1m\u001b[92m0.7687925551485486\u001b[0m\t \u001b[1m\u001b[92m0.5189277067977218\u001b[0m\t \u001b[1m\u001b[92m0.5189277040799145\u001b[0m\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 9.3589356  10.         12.77357173  1.         11.77357173  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7632310115509527\u001b[0m\t \u001b[1m\u001b[92m0.7632310115509527\u001b[0m\t \u001b[1m\u001b[92m0.5139189764673464\u001b[0m\t \u001b[1m\u001b[92m0.5139187492533251\u001b[0m\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.8195075556875523\t 0.7632310115509527\t 0.5098004752519646\t 0.5098004752519646\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.9367777767954987\t 0.7632310115509527\t 0.5060579143814297\t 0.5060579143814297\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.9192069504605914\t 0.7632310115509527\t 0.5078907660792906\t 0.5078907660792906\n",
            "17 \t [0.  0.  5.  0.5 1.  0.1]\t 1.1259237710065677\t 0.7632310115509527\t 0.5070888872352045\t 0.5070888872352044\n",
            "18 \t [ 7.9679648   6.50875696 12.          0.58580991 13.          0.19954847]\t 1.1274997047398325\t 0.7632310115509527\t 0.5183024309220694\t 0.5183024309220694\n",
            "19 \t [ 1.10650842  9.77537077 14.          0.83431584  1.          0.5884296 ]\t 0.9332627646187607\t 0.7632310115509527\t 0.5205304632862163\t 0.5205304632862163\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.8410770258615529\t 0.7632310115509527\t 0.5187558011772218\t 0.5187558011772218\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.8200285178970692\t 0.7632310115509527\t 0.520275201874254\t 0.520275201874254\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.9223651097826323\t 0.7632310115509527\t 0.5102152483902678\t 0.5102152483902678\n",
            "23 \t [ 4.81184079  0.03027405 11.          0.96437956 10.          0.97759806]\t 0.7947258239649384\t 0.7632310115509527\t 0.5242427667034354\t 0.5242427667034354\n",
            "24 \t [ 6.30542676  7.71202743  5.          0.69290865 17.          0.68185665]\t 0.9062144692012971\t 0.7632310115509527\t 0.5109860621333299\t 0.5109860621333299\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.9381315214046673\t 0.7632310115509527\t 0.5084956960769216\t 0.5084956960769216\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.8895644243531041\t 0.7632310115509527\t 0.5131020456062664\t 0.5131020456062664\n",
            "27 \t [ 1.31282769  0.42578122 10.55702392  0.5        15.55702392  0.1       ]\t 1.1220813445167845\t 0.7632310115509527\t 0.5162744346162973\t 0.5162736961297746\n",
            "28 \t [8.3735996  5.34104024 8.         0.56456303 7.         0.59553385]\t 0.9329548781688652\t 0.7632310115509527\t 0.5126891815625199\t 0.5126891815625199\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.8158422349857315\t 0.7632310115509527\t 0.5117806268044547\t 0.5117806268044547\n",
            "30 \t [9.30545715 2.21896205 9.         0.96965499 5.         0.61228081]\t 0.8966551531404072\t 0.7632310115509527\t 0.5111534474358382\t 0.5111534474358382\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61600.81947010827"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397be4d3-a5a4-4c35-bc86-aad2006e8e4f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.7520109919120059\t 0.7520109919120059\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.7843437690505969\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0380897569172567\t 0.7520109919120059\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.9185289289653313\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.9180724641961298\t 0.7520109919120059\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.9254670555638643\t 0.7520109919120059\t 0.4897153177896012\t 0.4897153177896012\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0314631424665905\t 0.7520109919120059\t 0.49275690098418806\t 0.49275690098418806\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.8949898491028812\t 0.7520109919120059\t 0.5043026263601241\t 0.5043026263601241\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7944418105894601\t 0.7520109919120059\t 0.5029568212895166\t 0.5029568212895166\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8997545663056927\t 0.7520109919120059\t 0.49615944084144575\t 0.49615944084144575\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.7385083163165579\u001b[0m\t \u001b[1m\u001b[92m0.7385083163165579\u001b[0m\t \u001b[1m\u001b[92m0.49614971225005466\u001b[0m\t \u001b[1m\u001b[92m0.49614971224975896\u001b[0m\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.8480209770499222\t 0.7385083163165579\t 0.4889706935223331\t 0.4889706935223331\n",
            "8  \t [ 2.63649501  9.62311075  7.          0.5192485  13.          0.19746315]\t 1.0350432385289277\t 0.7385083163165579\t 0.48699891616118224\t 0.48699891996729333\n",
            "9  \t [ 8.00974414  4.59126341 14.          0.56460775 14.          0.49726491]\t 0.9191471833457289\t 0.7385083163165579\t 0.49413475396750445\t 0.49413475396750445\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.865997699883801\t 0.7385083163165579\t 0.49504931262518226\t 0.49504931262518226\n",
            "11 \t [ 1.427592    3.43787632  6.          0.91643951 11.          0.75231375]\t 0.7733806230390429\t 0.7385083163165579\t 0.49385078938218935\t 0.49385078938218935\n",
            "12 \t [0.  0.  5.  0.5 1.  0.1]\t 1.036464786400082\t 0.7385083163165579\t 0.4898905700158851\t 0.4898905677067741\n",
            "13 \t [6.3101326  8.61804899 7.         0.66826014 6.         0.89905701]\t 0.778060148609183\t 0.7385083163165579\t 0.49511989928128564\t 0.49511989928128564\n",
            "14 \t [ 2.50279974  6.16628292 14.          0.6198066   3.          0.6709793 ]\t 0.838302678262029\t 0.7385083163165579\t 0.49156056523000335\t 0.49156056523000335\n",
            "15 \t [ 9.90619221  7.05528672  5.          0.91932487 18.          0.63366006]\t 0.8278793279285719\t 0.7385083163165579\t 0.49024161473431654\t 0.49024161473431654\n",
            "16 \t [ 6.88800877  3.63955803 13.          0.83311434 19.          0.41364953]\t 0.9002158192779633\t 0.7385083163165579\t 0.4885780801733389\t 0.4885780801733389\n",
            "17 \t [ 9.25482431  3.58711584  5.          0.51735796 12.          0.26939009]\t 0.9387530110213307\t 0.7385083163165579\t 0.4888879077355022\t 0.4888879077355022\n",
            "18 \t [ 1.21632555  2.44839139  8.          0.8927599  17.          0.25270381]\t 0.9237148678212173\t 0.7385083163165579\t 0.48963522205728327\t 0.48963522205728327\n",
            "19 \t [4.83067255 2.19904639 7.         0.5680519  3.         0.59514532]\t 0.8957701072181361\t 0.7385083163165579\t 0.4908377911626718\t 0.4908377911626718\n",
            "20 \t [ 5.3866253   1.98558863 14.          0.93996594  6.          0.18524928]\t 1.0227232234344175\t 0.7385083163165579\t 0.491716792794518\t 0.491716792794518\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.9203913838650098\t 0.7385083163165579\t 0.49991081846289165\t 0.49991081846289165\n",
            "22 \t [ 4.7769101   1.74272694 10.          0.723119   12.          0.83210351]\t 0.7688444098214806\t 0.7385083163165579\t 0.5001014235392667\t 0.5001014235392667\n",
            "23 \t [ 5.86852957  9.2552543  14.          0.74343957 14.          0.26209686]\t 0.9228195832204917\t 0.7385083163165579\t 0.4918895515079967\t 0.4918896769055872\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.7797715795229998\t 0.7385083163165579\t 0.49207404955796324\t 0.49207404955796324\n",
            "25 \t [ 0.83358887  9.71793838 12.          0.52075624 11.          0.67770945]\t 0.8336166108724059\t 0.7385083163165579\t 0.4971631867769846\t 0.4971631867769846\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.8602984001975387\t 0.7385083163165579\t 0.49572808574355076\t 0.49572808574355076\n",
            "27 \t [10.        10.        15.         1.        11.4221574  1.       ]\t 0.7399112109301184\t 0.7385083163165579\t 0.5008756121373292\t 0.5008752442917199\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.021708916478741\t 0.7385083163165579\t 0.49042405573644515\t 0.49042405573644515\n",
            "29 \t [ 9.46105078  8.51558179 14.          0.6234267   1.          0.59075489]\t 0.8992359830115891\t 0.7385083163165579\t 0.49666488400221187\t 0.49666488400221187\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[10.        10.         9.2453942  1.        13.2453942  1.       ]\u001b[0m\t \u001b[1m\u001b[92m0.7365473814354433\u001b[0m\t \u001b[1m\u001b[92m0.7365473814354433\u001b[0m\t \u001b[1m\u001b[92m0.4864575505072885\u001b[0m\t \u001b[1m\u001b[92m0.4864577466451317\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59486.93429653909"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b272bbf-8f81-4009-9556-7b45091e0388"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1147.365149974823"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1486fad0-3dc5-4da8-d221-37de5c8da43c"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60992.57949565745"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25b12df-9ee3-4c6a-fdc0-de18e8c86820"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60212.60144444664"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf41ab68-987e-4c5f-c751-66b428e5f050"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([60746.65105051846,\n",
              "  60746.65105051846,\n",
              "  59963.734606268496,\n",
              "  59963.734606268496,\n",
              "  59963.734606268496,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4151b2d8-5b21-4820-b19e-61963ea965d1"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([59912.05597064799,\n",
              "  59912.05597064799,\n",
              "  58928.58624943123,\n",
              "  58928.58624943123,\n",
              "  58928.58624943123,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993,\n",
              "  58709.31750678993],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "1c05926b-f389-499c-8f96-5002a60ab72d"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Green', label='RMSE: Approx STP ERM gradients', ls='--')\n",
        "plt.plot(min_rmse_exact, color = 'Blue', label='RMSE: Exact STP dERM gradients', ls='-')# r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualize!\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cb9a30-648a-45db-af7f-e32a443b0d12"
      },
      "source": [
        "time_approx, time_exact\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212.4502692222595, 1147.365149974823)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5757e4f-1cd3-4969-e001-5ffbd8a483e8"
      },
      "source": [
        "min(min_rmse_exact), min(min_rmse_approx)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58709.31750678993, 59260.747037503046)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": 69,
      "outputs": []
    }
  ]
}