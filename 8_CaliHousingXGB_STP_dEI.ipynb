{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc94e272-0e95-4ddd-a53c-322bb1559b3d"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Collecting Theano-PyMC\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting pyMC3\n",
            "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
            "\u001b[K     |████████████████████████████████| 872 kB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Collecting semver>=2.13.0\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Collecting deprecat\n",
            "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=40b4796327c81b510ac02ac2115ae2ef11e2fc4296a9af106db182b5ac2b0acf\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529963 sha256=94c6f777c2d68ceaddcf593e9ad09081cffd3249717cca9d7cc9d6dcc331c222\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/af/8c/5dd7553522d74c52a7813806fc7ee1a9caa20a3f7c8fd850d5\n",
            "Successfully built pyGPGO Theano-PyMC\n",
            "Installing collected packages: Theano-PyMC, semver, deprecat, pyMC3, pyGPGO\n",
            "Successfully installed Theano-PyMC-1.1.2 deprecat-2.1.1 pyGPGO-0.5.1 pyMC3-3.11.5 semver-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import t\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "cdd8dc8a-6250-448a-ef63-301aa75938dc"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60410d9d-9769-4925-81e0-177553718d23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60410d9d-9769-4925-81e0-177553718d23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60410d9d-9769-4925-81e0-177553718d23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60410d9d-9769-4925-81e0-177553718d23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601640dd-1178-4764-ce6d-3d3c595991c4"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "048691ba-41eb-4cc3-a702-ca8ffd60e3dc"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c735e5b0-e035-4f84-c5d9-2683b7673515"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "e6e45181-9248-41cb-baac-9c69bf39abd8"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3457707e-1b71-4dd5-9ff6-bbe7f344baf5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3457707e-1b71-4dd5-9ff6-bbe7f344baf5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3457707e-1b71-4dd5-9ff6-bbe7f344baf5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3457707e-1b71-4dd5-9ff6-bbe7f344baf5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1d952662-6f89-4fbf-f2f5-c4ee1766126c"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74ab683c-3609-470a-b0ad-67acde4abbb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74ab683c-3609-470a-b0ad-67acde4abbb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74ab683c-3609-470a-b0ad-67acde4abbb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74ab683c-3609-470a-b0ad-67acde4abbb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util = 'EI'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.90\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08\n",
        "\n",
        "df = 3\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 5"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "def kronDelta(X, Xstar):                     # Kronecker's Delta method\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "def se(X, Xstar, sigmaf, l, sigman):         # S.E. kernel method\n",
        "    return sigmaf * np.exp(-0.5 * cdist(X, Xstar) ** 2 / l ** 2) + sigman * kronDelta(X, Xstar)\n",
        "\n",
        "def delta(X, Xstar):                         # Distance between training X and test Xstar vectors\n",
        "    return (X - Xstar)\n",
        "   \n",
        "def der_covmat(X, Xstar, sigmaf, l, sigman): # Covariance matrix derivative terms (i.e. exact, first-order)\n",
        "    nx = len(X)\n",
        "    ny = len(Xstar)\n",
        "    return np.round(np.array([(delta(np.atleast_2d(i), np.atleast_2d(j))[0] * se(np.atleast_2d(i), np.atleast_2d(j), sigmaf, l, sigman)[0]).sum() for (i, j) in itertools.product(X, Xstar)]).reshape(nx, ny), 8)\n",
        "\n",
        "class dtStudentProcess(tStudentProcess):    # Via inheritance, also optimises hyperparameters when opt = TRUE\n",
        "    \n",
        "    def AcqGrad(self, Xstar):               # Method returning exact, first-order derivatives of the STP's posterior mean and standard deviation\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = self.covfunc.K(self.X, Xstar).T\n",
        "        dKstar = der_covmat(self.X, Xstar, self.covfunc.sigmaf, self.covfunc.l, self.covfunc.sigman).T\n",
        "        \n",
        "        smd_adj = (self.nu + self.beta1 - 2) / (self.nu + self.n1 - 2)\n",
        "\n",
        "        alpha = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), self.y)\n",
        "        alpha_Kstar = np.dot(np.linalg.inv(self.K11 + (self.covfunc.sigman**2) * np.eye(len(self.X))), Kstar.T)      \n",
        "        \n",
        "        dm = np.dot(dKstar, alpha)\n",
        "        ds = -2 * smd_adj * np.dot(dKstar, alpha_Kstar)\n",
        "        \n",
        "        return dm, ds           \n",
        "        "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "class Acquisition_grad(Acquisition):    \n",
        "    def __init__(self, mode, eps=eps, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'EI': self.EI\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def EI(self, tau, mean, std, ds, dm, nu=3.0):\n",
        "        gamma = (mean - tau - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - tau) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (gamma * t.cdf(gamma, df=nu) + (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma, df=nu))\n",
        "        df1 = f / (std + self.eps) * dsdx \n",
        "        df2 = (std + self.eps) * (t.cdf(gamma, df=nu) * dmdx + gamma * t.pdf(gamma, df=nu) \\\n",
        "            * (1 - (nu + gamma ** 2)/(nu - 1) + 2/(nu - 1) * dmdx))\n",
        "        df = (df1 + df2)[0]\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append(df)\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "        \n",
        "    def d_eval(self, tau, mean, std, ds, dm, nu=3.0):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, nu=3.0, **self.params)\n",
        "        "
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAK8N5bwfuJ7"
      },
      "source": [
        "## GPGO_multi: \n",
        "\n",
        "class GPGO_multi(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        " \n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "   \n",
        "    def _optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        \n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr        \n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_exact = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_exact = np.empty((n_start,))\n",
        "        opt_exact = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_exact = np.array([res.x for res in opt_exact])\n",
        "        f_best_exact = np.array([np.atleast_1d(res.fun)[0] for res in opt_exact])\n",
        "        f_best_min_exact = min(f_best_exact)\n",
        "\n",
        "        self.x_best_exact = x_best_exact\n",
        "        self.f_best_exact = f_best_exact\n",
        "        self.f_best_min_exact = f_best_min_exact\n",
        "        self.best_exact = x_best_exact[np.argmin(f_best_exact)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_exact)\n",
        "\n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_exact = str(inverse * self.f_best_min_exact)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_exact = BOLD + OKGREEN + max_acqfunc_exact + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc_exact, max_acqfunc))\n",
        "        \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self._optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "class dGPGO(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        "\n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, nu=3.0)\n",
        "\n",
        "        return -f\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_approx = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_approx = np.empty((n_start,))\n",
        "        opt_approx = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_approx = np.array([res.x for res in opt_approx])\n",
        "        f_best_approx = np.array([np.atleast_1d(res.fun)[0] for res in opt_approx])\n",
        "        f_best_min_approx = min(f_best_approx)\n",
        "\n",
        "        self.x_best_approx = x_best_approx\n",
        "        self.f_best_approx = f_best_approx\n",
        "        self.f_best_min_approx = f_best_min_approx\n",
        "        self.best_approx = x_best_approx[np.argmin(f_best_approx)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_approx)\n",
        "    \n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_approx = str(inverse * self.f_best_min_approx)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_approx = BOLD + OKGREEN + max_acqfunc_approx + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc, max_acqfunc_approx))\n",
        "\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38de90fa-ad0d-4581-dc8d-b8a278b45347"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1662388682.474637"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f7601f-f758-4822-bffa-4a2d0d75202f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO_multi(surrogate_approx_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 0.848101320876155\t 0.7386468688809501\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7469689781479785\t 0.7386468688809501\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8079963708366673\t 0.7386468688809501\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.7386468688809501\t 0.7386468688809501\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 0.937768916815817\t 0.7386468688809501\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8126185461054997\t 0.7386468688809501\t 0.9338051879731153\t 0.9338051879731153\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 0.9318704004009237\t 0.7386468688809501\t 0.933334069213192\t 0.933334069213192\n",
            "3  \t [7.35353694 6.03494644 5.         0.7919799  3.         0.96282991]\t 0.7646755003247829\t 0.7386468688809501\t 0.9408264992321298\t 0.9408264992321298\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8108923609041201\t 0.7386468688809501\t 0.9371189647314604\t 0.9371189647314604\n",
            "5  \t [ 3.76363217  9.95052322  8.          0.75835318 19.          0.10206715]\t 0.9302979891635867\t 0.7386468688809501\t 0.9363570710472993\t 0.9363570710472923\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.8121266607783616\t 0.7386468688809501\t 0.9412101109465099\t 0.9412101109452539\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 0.8530932869908747\t 0.7386468688809501\t 0.9402673497197832\t 0.9402673497197832\n",
            "8  \t [ 7.25642545  0.25925793 13.          0.51727017  4.          0.8962137 ]\t 0.7822187847645935\t 0.7386468688809501\t 0.9409702886037354\t 0.9409702884821197\n",
            "9  \t [0.75623385 3.14055399 6.         0.5417671  8.         0.78866556]\t 0.7758028719550957\t 0.7386468688809501\t 0.9392289719569729\t 0.9392289719569729\n",
            "10 \t [9.47161836 5.35231143 6.         0.51632193 6.         0.43288953]\t 0.8314092949686034\t 0.7386468688809501\t 0.9375447679817556\t 0.9375447679817556\n",
            "11 \t [ 0.75310873  4.25724412 13.          0.65895151  1.          0.82964911]\t 0.7771294155692965\t 0.7386468688809501\t 0.9376538779347083\t 0.9376538779347083\n",
            "12 \t [0.15776536 8.02750992 5.         0.65248282 3.         0.71659731]\t 0.7752392265192147\t 0.7386468688809501\t 0.9363038147633268\t 0.9363038147633268\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 9.31003194  2.78504172 14.          0.81837194 14.          0.87646711]\u001b[0m\t \u001b[1m\u001b[92m0.7355848546414411\u001b[0m\t \u001b[1m\u001b[92m0.7355848546414411\u001b[0m\t \u001b[1m\u001b[92m0.9350896732653754\u001b[0m\t \u001b[1m\u001b[92m0.9350896732653754\u001b[0m\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7644930642703252\t 0.7355848546414411\t 0.9306901303529723\t 0.9306901303529723\n",
            "15 \t [ 4.9586464   0.03452716 14.          0.97140399  9.          0.31674359]\t 0.8444570331313808\t 0.7355848546414411\t 0.9294810202324345\t 0.9294810202324345\n",
            "16 \t [ 3.45062645  9.8040474   6.          0.9453621  12.          0.8489149 ]\t 0.7535830619192916\t 0.7355848546414411\t 0.9301834031388015\t 0.9301834031388015\n",
            "17 \t [1.68476972 5.2908721  8.         0.92839616 1.         0.96471758]\t 0.7413177424377804\t 0.7355848546414411\t 0.9285983907478422\t 0.9285983907478422\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8088933131983232\t 0.7355848546414411\t 0.9322740891353986\t 0.9322740891353986\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 0.8343379491664138\t 0.7355848546414411\t 0.9317829048127504\t 0.9317829048127504\n",
            "20 \t [ 7.12741784  1.59648512  9.          0.96056513 11.          0.30752062]\t 0.8419713781829536\t 0.7355848546414411\t 0.9305109897996047\t 0.9305109897996047\n",
            "21 \t [ 9.72376714  9.82517342 14.          0.96896704 10.          0.66715413]\t 0.7442263922491208\t 0.7355848546414411\t 0.9294267638844106\t 0.9294267638844106\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 0.9354453567539931\t 0.7355848546414411\t 0.9361741728721827\t 0.9361741728721827\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\u001b[0m\t \u001b[1m\u001b[92m0.7341701271899448\u001b[0m\t \u001b[1m\u001b[92m0.7341701271899448\u001b[0m\t \u001b[1m\u001b[92m0.9365024566372856\u001b[0m\t \u001b[1m\u001b[92m0.9365024566372856\u001b[0m\n",
            "24 \t [4.92344511 0.59103391 8.         0.92756882 1.         0.71609051]\t 0.7449712611020661\t 0.7341701271899448\t 0.9320034852709776\t 0.9320034852709776\n",
            "25 \t [ 9.97471031  7.71725552  9.          0.75893438 14.          0.97108888]\t 0.7458665279787168\t 0.7341701271899448\t 0.9284892016018441\t 0.9284892016018441\n",
            "26 \t [ 7.19657131  8.86746012 11.          0.87977872  6.          0.9517893 ]\t 0.7370129010584308\t 0.7341701271899448\t 0.9362820208562515\t 0.9362820208562515\n",
            "27 \t [ 2.52136808  8.51741902 14.          0.89185963  6.          0.23066693]\t 0.9371270391052704\t 0.7341701271899448\t 0.9265049737747258\t 0.9265049734814749\n",
            "28 \t [8.68506658 0.40799141 5.         0.90040035 2.         0.17112852]\t 0.9332047623667679\t 0.7341701271899448\t 0.9309870825812616\t 0.930987081861784\n",
            "29 \t [ 7.40845157  8.58336508  5.          0.8318041  19.          0.36434664]\t 0.8342471407090255\t 0.7341701271899448\t 0.9362834770981147\t 0.9362834770981147\n",
            "30 \t [ 9.84118082  4.29794399 10.          0.60638682  1.          0.22679444]\t 0.9488686566857412\t 0.7341701271899448\t 0.9277737398685393\t 0.9277737398685393\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60746.65105051846"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2b2f50-e659-43c8-c190-158871b6f16a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO_multi(surrogate_approx_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.9157817005982263\t 0.8490988745111359\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.8517975125315337\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.8490988745111359\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.9839177202713774\t 0.8490988745111359\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.9688138526063573\t 0.8490988745111359\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m1.0618732927207701\u001b[0m\t \u001b[1m\u001b[92m1.0618732927207701\u001b[0m\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\u001b[0m\t \u001b[1m\u001b[92m0.7753470044170323\u001b[0m\t \u001b[1m\u001b[92m0.7753470044170323\u001b[0m\t \u001b[1m\u001b[92m1.0099054026731076\u001b[0m\t \u001b[1m\u001b[92m1.009905402673072\u001b[0m\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.876401110742202\t 0.7753470044170323\t 0.9887775693607928\t 0.9887775693607928\n",
            "4  \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]\t 0.9658206597269258\t 0.7753470044170323\t 0.9886063162428974\t 0.9886063162428974\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.9313569330212417\t 0.7753470044170323\t 0.993015812915613\t 0.993015812915613\n",
            "6  \t [ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\t 0.8411431281498688\t 0.7753470044170323\t 0.9950945743701993\t 0.9950945743701993\n",
            "7  \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]\t 0.9164031394028719\t 0.7753470044170323\t 0.9928723413190496\t 0.9928723413190496\n",
            "8  \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]\t 1.0138871967237582\t 0.7753470044170323\t 0.9938963777243702\t 0.9938963777243702\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.8472224210855768\t 0.7753470044170323\t 0.998463623250438\t 0.998463623250438\n",
            "10 \t [ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\t 0.786526849407035\t 0.7753470044170323\t 0.9967955071212135\t 0.9967955071212135\n",
            "11 \t [4.59560507 9.66694693 5.         0.8652774  6.         0.90565092]\t 0.7793501597644426\t 0.7753470044170323\t 0.9936771992481529\t 0.9936771992481529\n",
            "12 \t [ 8.76507252  8.76898373 14.          0.51356786  6.          0.73624795]\t 0.8509923386963646\t 0.7753470044170323\t 0.9905410101242672\t 0.9905410101242672\n",
            "13 \t [ 6.62295179  6.77584978 14.          0.65936287 12.          0.50955919]\t 0.845219311359458\t 0.7753470044170323\t 0.9897694235702919\t 0.9897694235702919\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.8437383195985765\t 0.7753470044170323\t 0.989009250893371\t 0.989009250893371\n",
            "15 \t [ 9.80429676  9.59801315  7.          0.61168386 14.          0.66107461]\t 0.8362874386261758\t 0.7753470044170323\t 0.9884566333166022\t 0.9884566333166022\n",
            "16 \t [ 3.79151097  4.0129324  10.          0.78656319  9.          0.57380624]\t 0.8479506527275633\t 0.7753470044170323\t 0.9874003138968172\t 0.9874003138968172\n",
            "17 \t [6.53156572 9.72376072 9.         0.51610543 1.         0.4929146 ]\t 0.9514823488789619\t 0.7753470044170323\t 0.986244989980747\t 0.986244989980747\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.812855948594331\t 0.7753470044170323\t 0.9924893237144939\t 0.9924893237144939\n",
            "19 \t [ 6.92673077  1.23845568 10.          0.63463476  8.          0.28240746]\t 0.9737154587401665\t 0.7753470044170323\t 0.9951316445342518\t 0.9951316445342518\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.9759301877372604\t 0.7753470044170323\t 0.9935013188003713\t 0.9935013188003713\n",
            "21 \t [ 1.08921876  3.80688097  6.          0.69924764 10.          0.35621973]\t 0.97076281846746\t 0.7753470044170323\t 0.9930204643539853\t 0.9930204643539853\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\u001b[0m\t \u001b[1m\u001b[92m0.7642724935254156\u001b[0m\t \u001b[1m\u001b[92m0.7642724935254156\u001b[0m\t \u001b[1m\u001b[92m0.9914228493195514\u001b[0m\t \u001b[1m\u001b[92m0.9914228493195514\u001b[0m\n",
            "23 \t [8.76774335 2.47727368 5.         0.77895852 8.         0.95970784]\t 0.7783672057784645\t 0.7642724935254156\t 0.9860422446651219\t 0.9860422446651219\n",
            "24 \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]\t 0.9941403780835223\t 0.7642724935254156\t 0.9907097738412121\t 0.9907097738412121\n",
            "25 \t [ 9.70148981  3.84860271 14.          0.8648022   1.          0.77351018]\t 0.8176855829782234\t 0.7642724935254156\t 0.9862194745723147\t 0.9862194745723147\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.7746854783898445\t 0.7642724935254156\t 0.9807131292796001\t 0.9807131292796001\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.8184668279349161\t 0.7642724935254156\t 0.9842956198819361\t 0.9842956198819361\n",
            "28 \t [3.43433026 6.08655828 9.         0.81139776 7.         0.47049625]\t 0.9212193667670269\t 0.7642724935254156\t 0.9861307073635992\t 0.9861307073635992\n",
            "29 \t [ 5.98509126  0.06989145 14.          0.5561472  16.          0.1874862 ]\t 1.0105701333726524\t 0.7642724935254156\t 0.9824116172701082\t 0.9824116172701082\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[5.55301534 4.43776121 9.         0.77874612 6.         0.99491253]\u001b[0m\t \u001b[1m\u001b[92m0.7585656248465545\u001b[0m\t \u001b[1m\u001b[92m0.7585656248465545\u001b[0m\t \u001b[1m\u001b[92m0.982803729236249\u001b[0m\t \u001b[1m\u001b[92m0.982803729236249\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62513.455753809474"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838632d4-1e0e-42b3-e294-811816e29d7c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO_multi(surrogate_approx_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.1001019572672721\t 0.8205570570239384\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.0968690738660336\t 0.8205570570239384\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.8205570570239384\t 0.8205570570239384\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0984076753833096\t 0.8205570570239384\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8540219347978375\t 0.8205570570239384\t    \t    \n",
            "1  \t [4.88873245 9.27936348 6.         0.94344906 8.         0.25949204]\t 0.9493824618206954\t 0.8205570570239384\t 1.0781785092241796\t 1.0781785092241796\n",
            "2  \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]\t 1.1006737709479968\t 0.8205570570239384\t 1.0743020477741974\t 1.0743020477741974\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0951088390242933\t 0.8205570570239384\t 1.0815045845173918\t 1.0815045845173918\n",
            "4  \t [2.8109707  8.5584448  5.         0.58095261 1.         0.63920091]\t 0.8313480595740355\t 0.8205570570239384\t 1.086519856497887\t 1.086519856497887\n",
            "5  \t [ 0.24010242  9.80847714 13.          0.63702721  3.          0.56729929]\t 0.8241986609721416\t 0.8205570570239384\t 1.077809013054612\t 1.077809013054612\n",
            "6  \t [ 9.64653748  6.72353381  8.          0.90513452 12.          0.37287596]\t 0.9460821806843785\t 0.8205570570239384\t 1.0704933893644744\t 1.0704933893644744\n",
            "7  \t [8.71334312 0.05751618 6.         0.96160691 6.         0.14416297]\t 1.099780473093716\t 0.8205570570239384\t 1.06893325043495\t 1.06893325043495\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[3.50549632 8.04483305 8.         0.95341936 1.         0.79512535]\u001b[0m\t \u001b[1m\u001b[92m0.792713810458564\u001b[0m\t \u001b[1m\u001b[92m0.792713810458564\u001b[0m\t \u001b[1m\u001b[92m1.0735846937105449\u001b[0m\t \u001b[1m\u001b[92m1.0735846937105449\u001b[0m\n",
            "9  \t [9.68641233 7.7212035  5.         0.60078619 2.         0.57796031]\t 0.8398283365570345\t 0.792713810458564\t 1.046044520959063\t 1.046044520959063\n",
            "10 \t [ 2.71723833  2.08347502  5.          0.57784675 10.          0.79058878]\t 0.8140934540169763\t 0.792713810458564\t 1.0418724250907514\t 1.0418724250907514\n",
            "11 \t [ 1.21954001  0.36323278  6.          0.64916715 17.          0.72126664]\t 0.8123620808973413\t 0.792713810458564\t 1.0375727449634233\t 1.0375727449634233\n",
            "12 \t [ 5.67921195  1.58981244  6.          0.99670248 17.          0.64188212]\t 0.8102319292582132\t 0.792713810458564\t 1.0337852283367588\t 1.0337852283367588\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 4.62595246  0.8232495  14.          0.57883859 18.          0.96402221]\u001b[0m\t \u001b[1m\u001b[92m0.7902358770996643\u001b[0m\t \u001b[1m\u001b[92m0.7902358770996643\u001b[0m\t \u001b[1m\u001b[92m1.0303395560657573\u001b[0m\t \u001b[1m\u001b[92m1.0303395560657573\u001b[0m\n",
            "14 \t [ 9.85636221  3.89791593  9.          0.61925349 14.          0.90156475]\t 0.7917903727359957\t 0.7902358770996643\t 1.0249247781711304\t 1.0249247781711304\n",
            "15 \t [ 9.51708919  0.58391709 12.          0.88753946  6.          0.24646931]\t 1.099594508712044\t 0.7902358770996643\t 1.0215710492623824\t 1.021571044317421\n",
            "16 \t [5.16820535 1.73655339 5.         0.50842306 1.         0.74078179]\t 0.8441707783682706\t 0.7902358770996643\t 1.0257783147273214\t 1.0257783146952084\n",
            "17 \t [ 5.75362119  0.784353    6.          0.7236751  10.          0.30231616]\t 0.9456992053676885\t 0.7902358770996643\t 1.023961743406431\t 1.023961743406431\n",
            "\u001b[1m\u001b[92m18\u001b[0m\t \u001b[1m\u001b[92m[ 2.89376156  6.80811522  8.          0.97973048 13.          0.9848274 ]\u001b[0m\t \u001b[1m\u001b[92m0.7781164494864524\u001b[0m\t \u001b[1m\u001b[92m0.7781164494864524\u001b[0m\t \u001b[1m\u001b[92m1.0328093229652595\u001b[0m\t \u001b[1m\u001b[92m1.0328093229652595\u001b[0m\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8394856040419147\t 0.7781164494864524\t 1.0155929727511839\t 1.0155929727511839\n",
            "20 \t [ 1.06084272  8.60821489 11.          0.60672694  9.          0.40602348]\t 0.858441552538079\t 0.7781164494864524\t 1.010602251079381\t 1.0106022432567312\n",
            "21 \t [ 9.83060339  5.43479292  5.          0.93965116 19.          0.81693736]\t 0.8142206129403362\t 0.7781164494864524\t 1.0088064026513621\t 1.0088064026513621\n",
            "22 \t [ 8.78137031  9.07562973 14.          0.81240153 17.          0.56901188]\t 0.8048755929054721\t 0.7781164494864524\t 1.0107911451985803\t 1.0107911451985803\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8627583512307193\t 0.7781164494864524\t 1.0134509232892683\t 1.0134509232892683\n",
            "24 \t [7.31522244 5.66276563 8.         0.72233105 6.         0.34066511]\t 0.9488616299798448\t 0.7781164494864524\t 1.009851971577658\t 1.0098519710649463\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7859921669897617\t 0.7781164494864524\t 1.0098425800779613\t 1.0098425800779613\n",
            "26 \t [0.33454906 4.8293531  6.         0.75998498 5.         0.78354586]\t 0.7929069464417273\t 0.7781164494864524\t 1.0059856519676573\t 1.0059856519676573\n",
            "27 \t [ 3.62152889  0.3004606  14.          0.95110801 10.          0.65627919]\t 0.8077328639449257\t 0.7781164494864524\t 1.002570783161174\t 1.002570783161174\n",
            "28 \t [ 9.01763405  8.9342346  11.          0.78253186 14.          0.5899614 ]\t 0.8008497075757127\t 0.7781164494864524\t 1.0040648426198067\t 1.0040648426198067\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.095967263497375\t 0.7781164494864524\t 1.000158982118483\t 1.000158982118483\n",
            "30 \t [ 1.46510837  0.05503823 10.          0.63653968  6.          0.52877878]\t 0.8171707426653917\t 0.7781164494864524\t 1.0065684106995614\t 1.0065684106995614\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60027.427603108896"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3479750-0a5c-490e-e102-b42d4e8c2841"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO_multi(surrogate_approx_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7650622398140196\t 0.7505823286451517\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7710732234684645\t 0.7505823286451517\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 1.127900018061083\t 0.7505823286451517\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.7505823286451517\t 0.7505823286451517\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.9579573664970923\t 0.7505823286451517\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 1.1269429525174437\t 0.7505823286451517\t 0.9728582294431205\t 0.9728582294431205\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 1.129364536434021\t 0.7505823286451517\t 0.992763038272654\t 0.992763038272654\n",
            "3  \t [7.47521879 1.08446649 5.         0.82092246 1.         0.87686231]\t 0.7774252651714006\t 0.7505823286451517\t 1.0068048565962269\t 1.0068048565962269\n",
            "4  \t [ 1.21913591  5.39021078 12.          0.52306788  2.          0.57375676]\t 0.8175628207948187\t 0.7505823286451517\t 0.9971736203804549\t 0.9971736203804549\n",
            "5  \t [ 3.69739657  6.8572859  10.          0.91202097 18.          0.74080664]\t 0.7570718466030688\t 0.7505823286451517\t 0.9913208939481808\t 0.9913208938391448\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 1.1223174585019604\t 0.7505823286451517\t 0.9842569995661041\t 0.9842569995661041\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.8044591218487582\t 0.7505823286451517\t 0.9937600512178829\t 0.9937600512178829\n",
            "8  \t [ 0.32236964  2.41893129 14.          0.88540422 15.          0.72064562]\t 0.7523577235368768\t 0.7505823286451517\t 0.9892065192880365\t 0.9892065192880295\n",
            "9  \t [ 1.11038107  0.47615514 11.          0.89886404  7.          0.4182336 ]\t 0.856011038154356\t 0.7505823286451517\t 0.9837907722713874\t 0.9837907722713874\n",
            "10 \t [ 6.832625    9.87635293 14.          0.84450885 19.          0.20389666]\t 1.124482329888969\t 0.7505823286451517\t 0.9820657641722699\t 0.9820657641722699\n",
            "11 \t [ 9.26888317  0.34770884 13.          0.56989599  5.          0.4978041 ]\t 0.8698317056044329\t 0.7505823286451517\t 0.9892959696908479\t 0.9892959696908479\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.7753874640601797\t 0.7505823286451517\t 0.9878206651846065\t 0.9878206651846065\n",
            "13 \t [ 0.4387066   6.89707822  5.          0.5042882  15.          0.2274319 ]\t 1.1244646432198542\t 0.7505823286451517\t 0.984274927599568\t 0.984274927599568\n",
            "14 \t [ 3.22282465  1.05364145  6.          0.75774626 12.          0.92739587]\t 0.7669842156079565\t 0.7505823286451517\t 0.9902503182338792\t 0.9902503182338792\n",
            "15 \t [ 0.50761856  5.44188216 11.          0.71311926 13.          0.48848091]\t 0.8633097085470659\t 0.7505823286451517\t 0.9866451327993488\t 0.9866451327993488\n",
            "16 \t [0.18736012 2.87894429 5.         0.99715153 3.         0.38605574]\t 0.8628338913380814\t 0.7505823286451517\t 0.9852747103194369\t 0.9852747103194369\n",
            "17 \t [3.55913665 1.752351   8.         0.70851016 3.         0.2473213 ]\t 1.1312533914126544\t 0.7505823286451517\t 0.9843924301818023\t 0.9843924301818023\n",
            "18 \t [ 5.7913209   0.66562836 12.          0.88967575 12.          0.45276187]\t 0.8489279760422116\t 0.7505823286451517\t 0.9914439755838751\t 0.9914439755838751\n",
            "19 \t [ 2.28250676  8.57781075 10.          0.71780124 12.          0.3772521 ]\t 0.8627736627545619\t 0.7505823286451517\t 0.9888918671014966\t 0.9888918671014966\n",
            "20 \t [ 7.39797184  8.7826296  13.          0.53377308 19.          0.69293054]\t 0.7675713222438754\t 0.7505823286451517\t 0.9882037162537614\t 0.9882037162537614\n",
            "21 \t [ 9.42045232  0.07633595 10.          0.83414481 16.          0.95927957]\t 0.7631908978724775\t 0.7505823286451517\t 0.9785067874974688\t 0.9785067874974688\n",
            "22 \t [4.27741976 7.36210099 8.         0.57766463 4.         0.8825576 ]\t 0.7784880372200202\t 0.7505823286451517\t 0.9855504502953875\t 0.9855504502953875\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 1.1250394819981728\t 0.7505823286451517\t 0.9802448835317324\t 0.9802448835317324\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.7993682157943708\t 0.7505823286451517\t 0.9856663554409413\t 0.9856663554409413\n",
            "25 \t [ 2.60920445  5.00088016 13.          0.88308408 19.          0.6912904 ]\t 0.7571627381692319\t 0.7505823286451517\t 0.9839348845456388\t 0.9839348845456388\n",
            "26 \t [3.60524491 1.19236957 9.         0.73012056 6.         0.89243922]\t 0.7693194850407705\t 0.7505823286451517\t 0.9841051255612531\t 0.9841051255612531\n",
            "27 \t [7.33593218 0.5994764  5.         0.5        7.29546381 0.1       ]\t 1.1249722410925382\t 0.7505823286451517\t 0.9764492039974803\t 0.9764491877418124\n",
            "28 \t [8.0273803  9.87833752 7.         0.89111617 6.         0.4918673 ]\t 0.852075900769383\t 0.7505823286451517\t 0.9818200229188805\t 0.9818200229188805\n",
            "29 \t [ 8.18178764  9.98869521 14.          0.83418368 10.          0.41151726]\t 0.8537499901780559\t 0.7505823286451517\t 0.9785304902375485\t 0.9785304902375485\n",
            "30 \t [ 9.17303226  5.74079031 12.          0.94675996 18.          0.70963979]\t 0.7558697441758776\t 0.7505823286451517\t 0.9804437070806707\t 0.9804437070806707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61055.818606721616"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8a7e20-1501-4ff3-d563-40041e1906cd"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO_multi(surrogate_approx_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7978949387548113\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7689238087022429\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9009085979032214\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.9616956128686873\t 0.7689238087022429\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.8968042534595716\t 0.7689238087022429\t    \t    \n",
            "1  \t [0.12369412 8.59706887 7.         0.73916952 1.         0.56326417]\t 0.8174537431547186\t 0.7689238087022429\t 0.9742106670178746\t 0.9742106670178746\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9657302753232895\t 0.7689238087022429\t 0.9713604364644681\t 0.9713604364644681\n",
            "3  \t [ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\t 0.7975878945767783\t 0.7689238087022429\t 0.978893533356427\t 0.9788935333564263\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.961106002845105\t 0.7689238087022429\t 0.9780428784405885\t 0.9780428784405885\n",
            "5  \t [0.49485077 0.4059675  7.         0.94681222 2.         0.56569072]\t 0.8077874821141874\t 0.7689238087022429\t 0.9803375971450823\t 0.9803375971450823\n",
            "6  \t [ 9.03237982  2.68514855 14.          0.80239179  6.          0.21136054]\t 0.9710681128360521\t 0.7689238087022429\t 0.9776373995523662\t 0.9776373995520055\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[1.49233247 5.3896593  5.         0.87066105 8.         0.92211931]\u001b[0m\t \u001b[1m\u001b[92m0.7228358148769818\u001b[0m\t \u001b[1m\u001b[92m0.7228358148769818\u001b[0m\t \u001b[1m\u001b[92m0.9820665701421751\u001b[0m\t \u001b[1m\u001b[92m0.9820665701421751\u001b[0m\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\u001b[0m\t \u001b[1m\u001b[92m0.7060994227407983\u001b[0m\t \u001b[1m\u001b[92m0.7060994227407983\u001b[0m\t \u001b[1m\u001b[92m0.9422554968890772\u001b[0m\t \u001b[1m\u001b[92m0.9422554968890772\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9684252162072007\t 0.7060994227407983\t 0.9234585531239217\t 0.9234585531239217\n",
            "10 \t [ 8.77721948  3.14448267  5.          0.802911   12.          0.8948902 ]\t 0.7191090782230875\t 0.7060994227407983\t 0.9274024065202184\t 0.9274024065202184\n",
            "11 \t [6.22509123 2.58001899 5.         0.88395827 2.         0.12704608]\t 0.9721917237916324\t 0.7060994227407983\t 0.9234625280087354\t 0.9234625280087354\n",
            "12 \t [ 4.29965043  0.06336037 10.          0.52701362  6.          0.19046378]\t 0.9732504007064431\t 0.7060994227407983\t 0.9270312653423894\t 0.9270312653423894\n",
            "13 \t [ 0.28589596  9.30929679 13.          0.77474     3.          0.28028958]\t 0.9091073616035648\t 0.7060994227407983\t 0.9301984578353241\t 0.9301984578353241\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.7343751804493104\t 0.7060994227407983\t 0.9312492652051297\t 0.9312492641355281\n",
            "15 \t [5.75921757 4.77039092 7.         0.67384078 6.         0.14098647]\t 0.9658181016693262\t 0.7060994227407983\t 0.9294418176621496\t 0.9294418176621496\n",
            "16 \t [ 2.13721796  1.76523659  5.          1.         13.32873846  1.        ]\t 0.713673743103653\t 0.7060994227407983\t 0.9324393798481269\t 0.9324394027831482\n",
            "17 \t [ 1.11081165  8.62779853  7.          0.59553888 14.          0.69059047]\t 0.7623637251493264\t 0.7060994227407983\t 0.928764357661966\t 0.928764357661966\n",
            "18 \t [ 9.61107295  5.55116741 14.          0.66649379 19.          0.19472771]\t 0.9620126628286488\t 0.7060994227407983\t 0.9332437205138518\t 0.9332437205138518\n",
            "19 \t [ 4.91947961  2.35436537  8.          0.70617966 10.          0.39101974]\t 0.8609501137107196\t 0.7060994227407983\t 0.9325212760722925\t 0.9325212760722925\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7650562704693341\t 0.7060994227407983\t 0.9359664424471514\t 0.9359664424471514\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7875791905388638\t 0.7060994227407983\t 0.9316039787715005\t 0.9316039787715005\n",
            "22 \t [ 5.47781498  1.88597438 13.          0.63648698 17.          0.7577705 ]\t 0.7546482695497708\t 0.7060994227407983\t 0.9267167465696876\t 0.9267167465696876\n",
            "23 \t [8.3612328  9.24550833 6.         0.53087691 9.         0.45372486]\t 0.8866600898758945\t 0.7060994227407983\t 0.9327965958949326\t 0.9327965958949326\n",
            "24 \t [ 0.45147375  4.90831239 10.47290642  0.95819939 17.00140423  0.1       ]\t 0.9659842117009841\t 0.7060994227407983\t 0.9224147891100923\t 0.9224134499923298\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.7495093963493484\t 0.7060994227407983\t 0.926934089762438\t 0.926934089762438\n",
            "26 \t [ 0.65904826  3.00639193 10.          0.88267232 10.          0.15011078]\t 0.9700037688440479\t 0.7060994227407983\t 0.9255288294327976\t 0.9255288294327976\n",
            "27 \t [ 6.70018478  3.42462631 12.          0.80351569  2.          0.90139434]\t 0.713276468153104\t 0.7060994227407983\t 0.9255226004753413\t 0.9255226004753413\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7558432662300643\t 0.7060994227407983\t 0.9323736867697849\t 0.9323736867697849\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7196023005131863\t 0.7060994227407983\t 0.9215823031595867\t 0.9215823031595867\n",
            "30 \t [9.10249652 0.61043488 7.         0.88501359 7.         0.22982019]\t 0.9655196012991603\t 0.7060994227407983\t 0.9306509275312992\t 0.9306509275312992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61045.18796367246"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2453488e-61c4-4f5d-d141-ae7f9201c7fe"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO_multi(surrogate_approx_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8708842589582968\t 0.8009237324889021\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.868843701878103\t 0.8009237324889021\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.8009237324889021\t 0.8009237324889021\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.8412285708806564\t 0.8009237324889021\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0874405633037085\t 0.8009237324889021\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.077285755760575\t 0.8009237324889021\t 1.0171726820382654\t 1.0171726820382654\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.1030510584286708\t 0.8009237324889021\t 1.0312734667229346\t 1.0312734667229346\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0698458362482097\t 0.8009237324889021\t 1.0430456627740696\t 1.0430456627740696\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0952568725496277\t 0.8009237324889021\t 1.0496622076939837\t 1.0496622076939837\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m1.0561667225936209\u001b[0m\t \u001b[1m\u001b[92m1.0561667225936209\u001b[0m\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.8829825605031049\t 0.7880607112692197\t 1.0382196572049611\t 1.0382196572049611\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.1024724416092895\t 0.7880607112692197\t 1.034850557046576\t 1.034850557046576\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\u001b[0m\t \u001b[1m\u001b[92m0.7785043750594152\u001b[0m\t \u001b[1m\u001b[92m0.7785043750594152\u001b[0m\t \u001b[1m\u001b[92m1.040617313229862\u001b[0m\t \u001b[1m\u001b[92m1.040617313229862\u001b[0m\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0634397583136046\t 0.7785043750594152\t 1.027180832442952\t 1.027180832442952\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\u001b[0m\t \u001b[1m\u001b[92m0.7744953455912423\u001b[0m\t \u001b[1m\u001b[92m0.7744953455912423\u001b[0m\t \u001b[1m\u001b[92m1.0306819151361863\u001b[0m\t \u001b[1m\u001b[92m1.0306819151361863\u001b[0m\n",
            "11 \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]\t 0.7887884221082111\t 0.7744953455912423\t 1.022336142919654\t 1.022336142919654\n",
            "12 \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]\t 1.0699439848269314\t 0.7744953455912423\t 1.01797893531881\t 1.01797893531881\n",
            "13 \t [10.  10.   5.   0.5  1.   0.1]\t 1.0806859736708578\t 0.7744953455912423\t 1.0214711935384015\t 1.0214711935384015\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[ 1.35461816  3.68867636  7.          0.97358458 19.          0.99760691]\u001b[0m\t \u001b[1m\u001b[92m0.772679413351429\u001b[0m\t \u001b[1m\u001b[92m0.772679413351429\u001b[0m\t \u001b[1m\u001b[92m1.024839284156298\u001b[0m\t \u001b[1m\u001b[92m1.024839284156298\u001b[0m\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 0.19887638  4.80873048 13.          0.98258992 19.          0.95584094]\u001b[0m\t \u001b[1m\u001b[92m0.7622505819201761\u001b[0m\t \u001b[1m\u001b[92m0.7622505819201761\u001b[0m\t \u001b[1m\u001b[92m1.0194658382703945\u001b[0m\t \u001b[1m\u001b[92m1.0194658382703945\u001b[0m\n",
            "16 \t [ 4.8891514   9.63319929 13.          0.90452221  7.          0.96899492]\t 0.7651767009789585\t 0.7622505819201761\t 1.0076281389941277\t 1.0076281389941277\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.8987315752344891\t 0.7622505819201761\t 1.0040943002761542\t 1.0040943002761542\n",
            "18 \t [1.60888905 0.63523365 5.         0.67675773 1.         0.79159537]\t 0.8183001641510987\t 0.7622505819201761\t 1.005736223575687\t 1.005736223575687\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.1009731307154418\t 0.7622505819201761\t 0.99894523682231\t 0.99894523682231\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9255377827812661\t 0.7622505819201761\t 1.0090498147130444\t 1.0090498147130444\n",
            "21 \t [ 0.47174379  1.61924333 14.          0.75160636 12.          0.46783122]\t 0.8990899098780416\t 0.7622505819201761\t 1.011620512996047\t 1.011620512996047\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.7871483295077344\t 0.7622505819201761\t 1.0007740882288787\t 1.0007740882288787\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9004861276725805\t 0.7622505819201761\t 1.0024746744056547\t 1.0024746744056547\n",
            "24 \t [0.02966045 1.1870223  6.         0.92997678 6.         0.66621503]\t 0.83355468271605\t 0.7622505819201761\t 0.9988806492657134\t 0.9988806492657134\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.7882906269305859\t 0.7622505819201761\t 1.005650180938255\t 1.005650180938255\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.80192465196928\t 0.7622505819201761\t 0.9951553926047192\t 0.9951553926047192\n",
            "27 \t [4.35202159 5.24316404 7.         0.80344711 8.         0.19668159]\t 1.0985573147525929\t 0.7622505819201761\t 0.9987051241225412\t 0.9987051241225412\n",
            "28 \t [2.67216807 9.69926207 9.         0.64694239 5.         0.78751691]\t 0.805850678380253\t 0.7622505819201761\t 0.9999727310948312\t 0.9999727310948312\n",
            "29 \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]\t 0.7946263770809028\t 0.7622505819201761\t 1.000151450474292\t 1.000151450474292\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.8423134170816156\t 0.7622505819201761\t 0.9952728072343445\t 0.9952728072343445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59260.747037503046"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c54820-3ae1-4c51-ff5e-23ca942521be"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO_multi(surrogate_approx_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.7260880637055529\t 0.7260880637055529\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.7424588384015385\t 0.7260880637055529\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.8412720456029797\t 0.7260880637055529\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7736412232573235\t 0.7260880637055529\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.7650415360356615\t 0.7260880637055529\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.9222990750260575\t 0.7260880637055529\t 0.9030968322036044\t 0.9030968322036044\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7908681556639724\t 0.7260880637055529\t 0.9147889551710234\t 0.9147889551710234\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.7532691574021181\t 0.7260880637055529\t 0.9143518278113293\t 0.9143518278113293\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7781432084155051\t 0.7260880637055529\t 0.9120532467112259\t 0.9120532467112259\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.8455317589117171\t 0.7260880637055529\t 0.9114128028141715\t 0.9114128028141715\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.7441046132441587\t 0.7260880637055529\t 0.9138739634974152\t 0.9138739634974152\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.938335419027365\t 0.7260880637055529\t 0.9119061835675228\t 0.9119061835675228\n",
            "8  \t [ 0.46626117  2.25760624  6.          0.85367342 17.          0.48531791]\t 0.8357006200561671\t 0.7260880637055529\t 0.9176442992365856\t 0.9176442992365856\n",
            "9  \t [2.13213943 0.33619788 8.         0.65805012 9.         0.21235962]\t 1.0382579820366014\t 0.7260880637055529\t 0.9187013204006689\t 0.9187013204006689\n",
            "10 \t [ 3.23063104  1.13251329 14.          0.56093148  7.          0.35241226]\t 0.9263052453028615\t 0.7260880637055529\t 0.9268458441772504\t 0.9268458441772504\n",
            "11 \t [9.32031429 7.90309325 6.         0.69040988 5.         0.24485333]\t 1.0379873808842273\t 0.7260880637055529\t 0.9299577645436146\t 0.9299577645436146\n",
            "12 \t [7.0602652  6.93790534 9.         0.99868525 6.         0.93828193]\t 0.7346015930490536\t 0.7260880637055529\t 0.9362620355634323\t 0.9362620355634323\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.8350939262618722\t 0.7260880637055529\t 0.9334788556880398\t 0.9334788556880398\n",
            "14 \t [ 6.2861962   7.16518546 10.          0.67477466  3.          0.33961227]\t 0.9218090224938408\t 0.7260880637055529\t 0.9333918474779522\t 0.9333918474779522\n",
            "15 \t [ 0.80466258  8.06348306  7.          0.77513285 17.          0.96959926]\t 0.7407859484199237\t 0.7260880637055529\t 0.9353731086477794\t 0.9353731086477794\n",
            "16 \t [7.5058071  0.77198166 5.         0.94542975 7.         0.89710815]\t 0.7549620723858046\t 0.7260880637055529\t 0.9332112123578401\t 0.9332112119683625\n",
            "17 \t [9.91439686 1.1223406  9.         0.69987447 9.         0.50079002]\t 0.7935395263864397\t 0.7260880637055529\t 0.9312592710416432\t 0.9312592710416432\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.7615889956561305\t 0.7260880637055529\t 0.9327447716615256\t 0.9327447716615256\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 1.0294400573352889\t 0.7260880637055529\t 0.9297416193881902\t 0.9297416193881902\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.9151572773679874\t 0.7260880637055529\t 0.9334524599939518\t 0.9334524599939518\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7851375921928307\t 0.7260880637055529\t 0.9424593194309508\t 0.9424593194309508\n",
            "22 \t [ 3.39029064  2.39709901 13.          0.66131557 19.          0.59343116]\t 0.7920132766777059\t 0.7260880637055529\t 0.9324128064123338\t 0.9324128064123338\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.9204040683754566\t 0.7260880637055529\t 0.9334609306872919\t 0.9334609306872919\n",
            "24 \t [0.70527907 5.59255728 5.         0.86863619 1.         0.35457337]\t 0.9131884722416652\t 0.7260880637055529\t 0.9367577749610243\t 0.9367577749610243\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7884946222204549\t 0.7260880637055529\t 0.9331654323131845\t 0.9331654323131845\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 1.026659800264627\t 0.7260880637055529\t 0.935481246048497\t 0.935481246048497\n",
            "27 \t [ 5.69797742  9.57419645  5.          0.83200529 19.          0.51994919]\t 0.7903346898520803\t 0.7260880637055529\t 0.9420538072190229\t 0.9420538072152644\n",
            "28 \t [ 7.27114604  3.7137488   9.          0.55194413 17.          0.65085645]\t 0.7913418219905086\t 0.7260880637055529\t 0.9371384408506707\t 0.9371384408506707\n",
            "29 \t [ 9.4564322   8.90732533 12.          0.76283199 19.          0.73059119]\t 0.7869676947248176\t 0.7260880637055529\t 0.9436579473390538\t 0.9436579473390538\n",
            "30 \t [ 0.41344076  0.53197741 10.          0.82623488 16.          0.71102663]\t 0.782525551781882\t 0.7260880637055529\t 0.9421241232612784\t 0.9421241232612784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61351.93418054509"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521b2285-342f-4751-b84f-4b5ce30b2e57"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO_multi(surrogate_approx_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.802823873653181\t 0.7393694249818598\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.7439561063387327\t 0.7393694249818598\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8573744170126428\t 0.7393694249818598\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.7605799870908501\t 0.7393694249818598\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.7393694249818598\t 0.7393694249818598\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.9184544152300995\u001b[0m\t \u001b[1m\u001b[92m0.9184544152300995\u001b[0m\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8873087046852387\t 0.7341650428609557\t 0.9110238714900418\t 0.9110238714900418\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7481675054625107\t 0.7341650428609557\t 0.9183282299988084\t 0.9183282299988084\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8633824421289817\t 0.7341650428609557\t 0.9160703820186414\t 0.9160703820186414\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7484161632696045\t 0.7341650428609557\t 0.9199037557180444\t 0.9199037557180444\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.7356192440307244\t 0.7341650428609557\t 0.9179550794676287\t 0.9179550789588424\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8970855207140378\t 0.7341650428609557\t 0.9158870182532933\t 0.9158870182532933\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8688237885855482\t 0.7341650428609557\t 0.9201163246521669\t 0.9201163246521669\n",
            "9  \t [ 0.45485069  5.92046568 13.          0.54575641 15.          0.3753516 ]\t 0.8113677562605297\t 0.7341650428609557\t 0.9226411480412241\t 0.9226411474676386\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.7505018736047322\t 0.7341650428609557\t 0.9229474834372179\t 0.9229474834372179\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8673094941420189\t 0.7341650428609557\t 0.9215087711023774\t 0.9215087711023774\n",
            "12 \t [3.47378168 0.90493309 7.         0.70332668 6.         0.717685  ]\t 0.7495116962078379\t 0.7341650428609557\t 0.9234242601328292\t 0.9234242601328291\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 1.0006633800011113\t 0.7341650428609557\t 0.922093159940897\t 0.922093159940897\n",
            "14 \t [ 2.60485405  0.1122727  14.          0.63362696 19.          0.53965358]\t 0.7741744043730975\t 0.7341650428609557\t 0.9274791189021452\t 0.9274791189021452\n",
            "15 \t [3.63587924 9.92644255 5.         0.74785877 1.         0.42737692]\t 0.7942979577990048\t 0.7341650428609557\t 0.9266181471715745\t 0.9266181471715745\n",
            "16 \t [ 6.35979139  1.00897047 10.          0.55338934  9.          0.8992107 ]\t 0.7582154255415187\t 0.7341650428609557\t 0.9263411030336431\t 0.9263411030336431\n",
            "17 \t [ 2.12586208  4.01516793 14.          0.99753944  1.          0.59182746]\t 0.7780815499248835\t 0.7341650428609557\t 0.9255168334964305\t 0.9255168334964305\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9980631943644411\t 0.7341650428609557\t 0.9216855208859183\t 0.9216855208859183\n",
            "19 \t [ 1.24817982  5.75156112 12.          0.56532786 19.          0.40494625]\t 0.8074218603040494\t 0.7341650428609557\t 0.9364897088172077\t 0.9364897088172077\n",
            "20 \t [ 6.84951512  0.65690232  5.          0.51903401 13.          0.510251  ]\t 0.8038460886877121\t 0.7341650428609557\t 0.9257165572343572\t 0.9257165572343572\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.7443970340307106\t 0.7341650428609557\t 0.9246371296811912\t 0.9246371296811912\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.869979050273399\t 0.7341650428609557\t 0.9302022418389855\t 0.9302022418389855\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7442995610019533\t 0.7341650428609557\t 0.9298749149986435\t 0.9298749149986435\n",
            "24 \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\t 0.7403513737505086\t 0.7341650428609557\t 0.9327556534753135\t 0.9327556534753133\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8853726892659874\t 0.7341650428609557\t 0.922896001745238\t 0.922896001745238\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9897503949395169\t 0.7341650428609557\t 0.9260900141539572\t 0.9260900141539572\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8013428795907425\t 0.7341650428609557\t 0.9274339603230395\t 0.9274339603230395\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.7439831766925111\t 0.7341650428609557\t 0.9331363094746118\t 0.9331363094746118\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.7400612177024872\t 0.7341650428609557\t 0.9334639552094453\t 0.9334639552094453\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 1.0026563027674915\t 0.7341650428609557\t 0.9298330924752073\t 0.9298330924752073\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60822.98185938519"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229ce03e-ce36-4c31-c3af-1296f2edae8d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO_multi(surrogate_approx_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 1.1242573295906948\t 0.7785306461595496\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 1.1029639839305116\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.7785306461595496\t 0.7785306461595496\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.8502721808074817\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.8007936005920335\t 0.7785306461595496\t    \t    \n",
            "1  \t [ 4.77974014  4.35555465  8.          0.84383705 19.          0.93268007]\t 0.7891134450771025\t 0.7785306461595496\t 1.0196136903897774\t 1.0196136903897774\n",
            "2  \t [ 8.16285902  8.43489929  9.          0.96605421 10.          0.79940153]\t 0.8233816089104812\t 0.7785306461595496\t 1.008913547842395\t 1.008913547842395\n",
            "3  \t [8.19160056 1.69229937 5.         0.74091229 2.         0.59984694]\t 0.8904551452213092\t 0.7785306461595496\t 1.003091974109823\t 1.003091974109823\n",
            "4  \t [ 0.82366685  2.07619267 13.          0.77138611 14.          0.7500631 ]\t 0.8452315111428017\t 0.7785306461595496\t 1.0022125218138418\t 1.0022125218138418\n",
            "5  \t [ 7.63204032  6.91059507 14.          0.55138009 18.          0.62463808]\t 0.8742528386161273\t 0.7785306461595496\t 0.9993954068292781\t 0.9993954068292781\n",
            "6  \t [1.77268072 0.55805065 5.         0.58527637 6.         0.74360757]\t 0.8747713068731116\t 0.7785306461595496\t 0.9983589211371396\t 0.9983589211371396\n",
            "7  \t [2.35864247 8.39991483 7.         0.84216076 6.         0.97103779]\t 0.7968809318910697\t 0.7785306461595496\t 0.9975292542063275\t 0.9975292542063275\n",
            "8  \t [7.87739652 0.18270557 8.         0.51922758 8.         0.11759376]\t 1.1523167367453024\t 0.7785306461595496\t 0.9941586658573037\t 0.9941586658573037\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.9249945564098354\t 0.7785306461595496\t 1.0044036765825568\t 1.0044036765825568\n",
            "10 \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]\t 0.9694253204437654\t 0.7785306461595496\t 1.004903306680582\t 1.004903306680582\n",
            "11 \t [ 2.72183423  9.69902384 13.          0.83330411  1.          0.50869592]\t 0.8649155611168539\t 0.7785306461595496\t 1.0066932727538564\t 1.0066932727538564\n",
            "12 \t [ 1.25503618  7.60831513  7.          0.9480138  16.          0.74909318]\t 0.8360984751450318\t 0.7785306461595496\t 1.0053475820640574\t 1.0053475820640574\n",
            "13 \t [ 9.90759058  1.21564186 12.          0.74911905 17.          0.244927  ]\t 1.1408641960380992\t 0.7785306461595496\t 1.0034692635247795\t 1.0034692635247795\n",
            "14 \t [ 4.02558043  2.43101342 14.          0.52315735 18.          0.26385595]\t 1.0902851242650626\t 0.7785306461595496\t 1.0098869215224493\t 1.0098869215224493\n",
            "15 \t [ 8.18068001  7.70662558  9.          0.60977533 15.          0.35770071]\t 1.0804763940942572\t 0.7785306461595496\t 1.014225814981371\t 1.0142258149562982\n",
            "16 \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]\t 0.8795719018846426\t 0.7785306461595496\t 1.0177866449480146\t 1.0177866449480146\n",
            "17 \t [ 3.27325644  1.7873584  14.          0.93313351  7.          0.76979578]\t 0.8333473505305093\t 0.7785306461595496\t 1.016406006918931\t 1.016406006918931\n",
            "18 \t [2.32449242 8.80135208 8.         0.99642073 4.         0.14576968]\t 1.1331068048862545\t 0.7785306461595496\t 1.0164433677216005\t 1.0164433677216005\n",
            "19 \t [ 1.94208058  0.16964018  6.          0.78727092 15.          0.47432235]\t 0.9262563969908063\t 0.7785306461595496\t 1.0194215158744224\t 1.0194215158744224\n",
            "20 \t [ 9.4006826   2.14529633  7.          0.801278   16.          0.55170588]\t 0.8470358235896462\t 0.7785306461595496\t 1.0188221429126438\t 1.0188221429126438\n",
            "21 \t [ 2.60018347  8.33426121 13.          0.92542949  6.          0.59638435]\t 0.8377766603609096\t 0.7785306461595496\t 1.019122575456515\t 1.0191225654436569\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.9210006183994057\t 0.7785306461595496\t 1.0138578655561175\t 1.0138578655561175\n",
            "23 \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]\t 1.082295397988777\t 0.7785306461595496\t 1.022910725124398\t 1.022910725124398\n",
            "24 \t [ 2.96691153  8.90313633 12.          0.78035302 11.          0.21717364]\t 1.1424377566967083\t 0.7785306461595496\t 1.020652529068152\t 1.020652529068152\n",
            "25 \t [8.2007632  5.80436627 6.         0.76635233 7.         0.49444634]\t 0.9337877394134475\t 0.7785306461595496\t 1.0219538774704937\t 1.0219538774704937\n",
            "26 \t [ 1.2418428   6.11106411 11.          0.60069848 19.          0.74826159]\t 0.8580944166728092\t 0.7785306461595496\t 1.0197447381867222\t 1.0197447381867222\n",
            "27 \t [ 9.86830723  1.60403506 13.          0.75715164  2.          0.47023945]\t 0.9500832164465166\t 0.7785306461595496\t 1.0230490074935534\t 1.0230490074935534\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 1.0854101197025208\t 0.7785306461595496\t 1.0217150417786658\t 1.0217150417786658\n",
            "29 \t [ 5.3574592   5.42167977 11.          0.80739246  3.          0.15190636]\t 1.1426153855251038\t 0.7785306461595496\t 1.0219953618524271\t 1.0219953618524271\n",
            "30 \t [ 0.01153499  2.29531024 11.          0.50673714  7.          0.13750522]\t 1.154363103664814\t 0.7785306461595496\t 1.0267173749716827\t 1.0267173749716827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60590.73520973802"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043980e9-15bf-4d00-80b5-2d662aef6254"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO_multi(surrogate_approx_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 1.0639310256047103\t 0.7797034870948047\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.79580179662759\t 0.7797034870948047\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7797034870948047\t 0.7797034870948047\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7990514117028104\t 0.7797034870948047\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 1.0587036817796267\t 0.7797034870948047\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m1.0051863251810056\u001b[0m\t \u001b[1m\u001b[92m1.0051863251810056\u001b[0m\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.8572799307158145\t 0.7741723447560037\t 0.9916044355603245\t 0.9916044355603245\n",
            "3  \t [ 2.20772511  4.37663949 11.          0.65455258  3.          0.57545511]\t 0.7990049933887924\t 0.7741723447560037\t 0.9897011202232386\t 0.9897011202232386\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.985259653564249\u001b[0m\t \u001b[1m\u001b[92m0.985259653564249\u001b[0m\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 3.75041373  9.81989522 14.          0.71370546 14.          0.97207881]\u001b[0m\t \u001b[1m\u001b[92m0.7583770586009706\u001b[0m\t \u001b[1m\u001b[92m0.7583770586009706\u001b[0m\t \u001b[1m\u001b[92m0.9773603227825991\u001b[0m\t \u001b[1m\u001b[92m0.9773603227825991\u001b[0m\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 1.013338643136875\t 0.7583770586009706\t 0.9638842390828979\t 0.9638842390828979\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 9.67314628  9.09427799  9.          0.82851167 16.          0.96267251]\u001b[0m\t \u001b[1m\u001b[92m0.7578726678207005\u001b[0m\t \u001b[1m\u001b[92m0.7578726678207005\u001b[0m\t \u001b[1m\u001b[92m0.9708116559985612\u001b[0m\t \u001b[1m\u001b[92m0.9708116559985612\u001b[0m\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7966957629406074\t 0.7578726678207005\t 0.9666078987793897\t 0.9666078987793897\n",
            "9  \t [4.90669272 5.41685478 7.         0.5623285  6.         0.34465473]\t 0.9971149123251213\t 0.7578726678207005\t 0.9645512622307313\t 0.9645512622307313\n",
            "10 \t [ 9.68988111  3.14723756  5.          0.57337272 11.          0.12853019]\t 1.0708271865508894\t 0.7578726678207005\t 0.9693188722046399\t 0.9693188721258976\n",
            "11 \t [ 7.42334933  7.43735147 12.          0.74628126  2.          0.54122098]\t 0.7825236551040937\t 0.7578726678207005\t 0.9759830760285617\t 0.9759830760285617\n",
            "12 \t [0.3261262  0.3175016  8.         0.74340245 7.         0.15256221]\t 1.059741130596732\t 0.7578726678207005\t 0.9734150792438261\t 0.9734150792417768\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.9748541191382067\t 0.7578726678207005\t 0.9786732235960998\t 0.9786732185890763\n",
            "14 \t [ 3.89768175  5.29572603  8.          0.92074245 11.          0.31486353]\t 0.9676224176737994\t 0.7578726678207005\t 0.9809322608628692\t 0.9809322608628692\n",
            "15 \t [2.14023913 7.87482927 8.         0.56565632 3.         0.51657322]\t 0.8009512202201602\t 0.7578726678207005\t 0.982789577857947\t 0.982789577857947\n",
            "16 \t [9.19802512 8.95424404 8.         0.64594318 8.         0.43927889]\t 0.8589861402158071\t 0.7578726678207005\t 0.9805410504833921\t 0.9805410504833921\n",
            "17 \t [0.54815519 9.09457687 7.         0.55756737 9.         0.32110491]\t 0.9905916044645892\t 0.7578726678207005\t 0.979716824355908\t 0.979716824355908\n",
            "18 \t [ 6.17394409  4.04114422 10.          0.65058545  1.          0.14583054]\t 1.0756148882202339\t 0.7578726678207005\t 0.9857767543463031\t 0.9857767543463031\n",
            "19 \t [ 1.75909042  8.50460179 10.          0.61596511  8.          0.92202704]\t 0.7724091061782451\t 0.7578726678207005\t 0.9919285700989532\t 0.9919285700989532\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 1.0497516119782428\t 0.7578726678207005\t 0.9835610383669767\t 0.9835610383669767\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7979220004395456\t 0.7578726678207005\t 0.9866616094930769\t 0.9866616094930769\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 1.0727233913162242\t 0.7578726678207005\t 0.9831678744870813\t 0.9831678744870813\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.7738741181601402\t 0.7578726678207005\t 0.9847549171065181\t 0.9847549171065181\n",
            "24 \t [ 8.33810851  9.8990204  14.          0.61893039  5.          0.69227045]\t 0.7823499251514459\t 0.7578726678207005\t 0.9866134607761666\t 0.9866134607761666\n",
            "25 \t [ 5.2762997   0.93188529 12.          0.61134187  6.          0.7031463 ]\t 0.7832304570697484\t 0.7578726678207005\t 0.985982626410357\t 0.9859826201031107\n",
            "26 \t [1.1017928  2.097023   6.         0.71019319 1.         0.77316986]\t 0.7924768119208077\t 0.7578726678207005\t 0.9842209655792878\t 0.9842209655792878\n",
            "27 \t [ 7.88167693  7.97515501  6.          0.78950848 17.          0.19131965]\t 1.0553390354056282\t 0.7578726678207005\t 0.9810199317965197\t 0.9810199317965197\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 1.0555070855921338\t 0.7578726678207005\t 0.9852499834503772\t 0.9852499834503772\n",
            "29 \t [ 8.76678657  9.19944202 14.          0.60876221 15.          0.44634556]\t 0.8507928737892122\t 0.7578726678207005\t 0.9865715169015259\t 0.9865715169015259\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.9718991207487232\t 0.7578726678207005\t 0.9883163238998531\t 0.9883163238998531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60744.35614633767"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbb25c8-1e87-457c-aef8-a51eb0e69f2b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO_multi(surrogate_approx_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.8177825188141039\t 0.7287337628426743\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.7419480115539112\t 0.7287337628426743\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.7287337628426743\t 0.7287337628426743\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7335645848611818\t 0.7287337628426743\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7441537376931249\t 0.7287337628426743\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.7482694480200888\t 0.7287337628426743\t 0.8978277980959898\t 0.8978277980959898\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.8974779426504405\u001b[0m\t \u001b[1m\u001b[92m0.8974779426504405\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7598608339614092\t 0.7070648622170269\t 0.8775715630548442\t 0.8775715630548442\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 1.0312511769390245\t 0.7070648622170269\t 0.8783059225872031\t 0.8783059225872031\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.821741520088635\t 0.7070648622170269\t 0.8940038396807638\t 0.8940038396807638\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.7209540253636189\t 0.7070648622170269\t 0.895797708088889\t 0.895797708088889\n",
            "7  \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]\t 0.7248028462146275\t 0.7070648622170269\t 0.8931080221002436\t 0.8931080221002436\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.9107534784629161\t 0.7070648622170269\t 0.8912194995900354\t 0.8912194995900354\n",
            "9  \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]\t 0.725647375042158\t 0.7070648622170269\t 0.895884283789646\t 0.895884283789646\n",
            "10 \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]\t 0.7416396014125557\t 0.7070648622170269\t 0.8941001994848723\t 0.8941001994848723\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.9287138963597805\t 0.7070648622170269\t 0.8929027642171982\t 0.8929027642171982\n",
            "12 \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]\t 1.0220817994568854\t 0.7070648622170269\t 0.8972658698500687\t 0.89726586836447\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 1.0261353862133127\t 0.7070648622170269\t 0.9039265813104572\t 0.9039265813104572\n",
            "14 \t [ 0.62966465  6.1940162  12.          0.81741232 11.          0.49382371]\t 0.8182502230736013\t 0.7070648622170269\t 0.9099710283967342\t 0.9099710283967342\n",
            "15 \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]\t 1.0235667739127183\t 0.7070648622170269\t 0.9098858299196204\t 0.9098858299011668\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7623000424638748\t 0.7070648622170269\t 0.9151592070017064\t 0.9151592070017064\n",
            "17 \t [0.08327566 8.61614883 7.         0.71686897 9.         0.2323488 ]\t 1.0162942984816756\t 0.7070648622170269\t 0.9134357299210172\t 0.9134357299210172\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.7459513240013139\t 0.7070648622170269\t 0.9179774930761128\t 0.9179774930761128\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 1.0352571936435033\t 0.7070648622170269\t 0.9213307598602234\t 0.9213307598602234\n",
            "20 \t [9.22875209 9.1986098  9.         0.90439491 3.         0.27523226]\t 0.9230186077285822\t 0.7070648622170269\t 0.9236820959637926\t 0.9236820959637926\n",
            "21 \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]\t 0.7362063940289248\t 0.7070648622170269\t 0.9256197526384279\t 0.9256197526384279\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7433881169429852\t 0.7070648622170269\t 0.9220967878275723\t 0.9220967878275723\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7547149277921693\t 0.7070648622170269\t 0.9289504666804302\t 0.9289504666804302\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.9114560559082703\t 0.7070648622170269\t 0.9206499082291408\t 0.9206499082291408\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 1.0248025279634128\t 0.7070648622170269\t 0.9174827873708274\t 0.9174827873708274\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.8261521259015148\t 0.7070648622170269\t 0.9294710040168584\t 0.9294710040168584\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7532872744350481\t 0.7070648622170269\t 0.9228984446016311\t 0.9228984446016311\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[0.37569294 0.30864512 9.         0.6310655  7.         0.92576756]\u001b[0m\t \u001b[1m\u001b[92m0.6982328571669815\u001b[0m\t \u001b[1m\u001b[92m0.6982328571669815\u001b[0m\t \u001b[1m\u001b[92m0.9198165811250684\u001b[0m\t \u001b[1m\u001b[92m0.9198165811250684\u001b[0m\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.7123414924113913\t 0.6982328571669815\t 0.9101082162586396\t 0.9101082162586396\n",
            "30 \t [4.8041921  4.06620309 5.         0.94317975 9.         0.20395595]\t 1.0168771290789498\t 0.6982328571669815\t 0.9156486172415053\t 0.9156486172415053\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62004.49800279091"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bc9e42-0c90-4172-8a28-7cec4d6376dc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO_multi(surrogate_approx_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.992708970032886\t 0.7896346786115067\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.9050380263035862\t 0.7896346786115067\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.8362986807103934\t 0.7896346786115067\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7896346786115067\t 0.7896346786115067\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.9186387829358221\t 0.7896346786115067\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.8115376813007883\t 0.7896346786115067\t 1.005020528732778\t 1.005020528732778\n",
            "2  \t [ 3.78385301  2.21923666 12.          0.57141407  8.          0.55842631]\t 0.8600045769145973\t 0.7896346786115067\t 0.9994533054484285\t 0.9994533054484285\n",
            "3  \t [ 7.48458025  0.82585105 14.          0.62666135 18.          0.34757206]\t 0.9136369680693782\t 0.7896346786115067\t 0.9983202482001414\t 0.9983202482001414\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.9144290525005069\t 0.7896346786115067\t 1.0004110884822648\t 1.0004110884822648\n",
            "5  \t [ 5.83217552  8.53843574 11.          0.58549752 18.          0.26781236]\t 0.9216214538529052\t 0.7896346786115067\t 1.0020723683999166\t 1.0020723683999166\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.9442383814615898\t 0.7896346786115067\t 1.0037228867613677\t 1.0037228867613677\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 6.10107735  0.03652674 11.          0.56244485 13.          0.89741329]\u001b[0m\t \u001b[1m\u001b[92m0.7783701142125483\u001b[0m\t \u001b[1m\u001b[92m0.7783701142125483\u001b[0m\t \u001b[1m\u001b[92m1.0060100135864545\u001b[0m\t \u001b[1m\u001b[92m1.0060100135864545\u001b[0m\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.9239433760752476\t 0.7783701142125483\t 0.993290062354713\t 0.993290062354713\n",
            "9  \t [ 2.73067092  9.86029136  9.          0.98915314 11.          0.78920814]\t 0.7815140040967317\t 0.7783701142125483\t 0.994650157838224\t 0.994650157838224\n",
            "10 \t [ 0.14475494  9.8292754  12.          0.60331385  2.          0.9622215 ]\t 0.7880902159034013\t 0.7783701142125483\t 0.9915168374756214\t 0.9915168374756214\n",
            "11 \t [ 1.81539004  3.97973122 11.          0.55780808 14.          0.86016605]\t 0.8021824021652308\t 0.7783701142125483\t 0.9889616521211896\t 0.9889616521211896\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.786862562407444\t 0.7783701142125483\t 0.9870703448170356\t 0.9870703448170356\n",
            "13 \t [ 8.71378379  5.91732489 10.          0.67395488  5.          0.37191233]\t 0.9140896924023043\t 0.7783701142125483\t 0.9850312284686619\t 0.9850312284686619\n",
            "14 \t [8.72042964 1.18098427 6.         0.87093363 1.         0.1200865 ]\t 0.978708815138663\t 0.7783701142125483\t 0.9862062427976476\t 0.9862062427976476\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9970201710934681\t 0.7783701142125483\t 0.9889101015041284\t 0.9889101015041284\n",
            "16 \t [ 9.50979811  3.16002382 14.          0.62948949 10.          0.39138316]\t 0.9147194483561627\t 0.7783701142125483\t 0.991745608976305\t 0.9917456030700524\n",
            "17 \t [ 2.38620183  1.03950496 13.          0.6257051   6.          0.34211692]\t 0.9194161634890323\t 0.7783701142125483\t 0.9922543673357107\t 0.9922543673357107\n",
            "18 \t [3.82043232 0.90149463 5.         0.93713205 2.         0.73959641]\t 0.7986205174407796\t 0.7783701142125483\t 1.0011294018901127\t 1.0011294018901127\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 4.82116392  7.94441114 13.          0.79896359 10.          0.94409065]\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.9927627591788852\u001b[0m\t \u001b[1m\u001b[92m0.9927627591788852\u001b[0m\n",
            "20 \t [4.88722703 1.05307859 6.         0.84108367 7.         0.32451309]\t 0.9150062445310105\t 0.7656138946809342\t 0.980896793295396\t 0.980896793295396\n",
            "21 \t [ 4.73215091  0.85301789  5.          0.940584   18.          0.80546064]\t 0.7987217033287252\t 0.7656138946809342\t 0.9771940373574347\t 0.9771940373574347\n",
            "22 \t [ 4.22119996  7.99655483  5.          0.78307763 14.          0.79061697]\t 0.7946617241328867\t 0.7656138946809342\t 0.9847245436489941\t 0.9847245436489941\n",
            "23 \t [7.12967992 8.154614   8.         0.5156473  9.         0.21177212]\t 0.9924239421587664\t 0.7656138946809342\t 0.9803514148874852\t 0.9803514148874852\n",
            "24 \t [ 1.47973338  1.45058818 11.          0.74181509 19.          0.60410465]\t 0.8329180373498172\t 0.7656138946809342\t 0.9818667067731871\t 0.9818667067731871\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9785605674881227\t 0.7656138946809342\t 0.9830476724787531\t 0.9830476724787531\n",
            "26 \t [ 4.24823418  9.49681173 13.          0.6150292   7.          0.81414675]\t 0.7903152027969078\t 0.7656138946809342\t 0.9889465208692488\t 0.9889465208692488\n",
            "27 \t [ 9.05280298  4.61821279  7.87449794  1.         12.70660443  0.39889354]\t 0.9185315665019885\t 0.7656138946809342\t 0.9863020615310716\t 0.9863022280346156\n",
            "28 \t [ 3.68821786  5.6786616   8.          0.65862302 12.          0.189801  ]\t 0.9845598727954463\t 0.7656138946809342\t 0.9837424653401508\t 0.9837424653401508\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.8456632041648999\t 0.7656138946809342\t 0.9865131093202533\t 0.9865131093202533\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.979555746560927\t 0.7656138946809342\t 0.982521587206534\t 0.982521587206534\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60877.04939096347"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e86ff4-372e-4c20-86d0-2b5426372a45"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO_multi(surrogate_approx_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.7315012035187541\t 0.7315012035187541\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1319770010327717\t 0.7315012035187541\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.9318565354152348\t 0.7315012035187541\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.7799608780638936\t 0.7315012035187541\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1305934464937346\t 0.7315012035187541\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7922048089873084\t 0.7315012035187541\t 0.9897452001738319\t 0.9897452001738319\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.7364009364353266\t 0.7315012035187541\t 0.9781182916237656\t 0.9781182916237656\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7884892526498699\t 0.7315012035187541\t 0.966644067772357\t 0.966644067772357\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.7531825106193256\t 0.7315012035187541\t 0.960425659552864\t 0.960425659552864\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.1341345349522627\t 0.7315012035187541\t 0.953994605866969\t 0.953994605866969\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 7.68636788  7.27927184 12.          0.97932089  3.          0.87363673]\u001b[0m\t \u001b[1m\u001b[92m0.7306802524366626\u001b[0m\t \u001b[1m\u001b[92m0.7306802524366626\u001b[0m\t \u001b[1m\u001b[92m0.9670253819013697\u001b[0m\t \u001b[1m\u001b[92m0.9670253819013572\u001b[0m\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8347085780850761\t 0.7306802524366626\t 0.9598288950934458\t 0.9598288950934458\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1442757918420738\t 0.7306802524366626\t 0.9577466288702217\t 0.9577466288702217\n",
            "9  \t [ 6.80309585  9.43423094  7.          0.8851539  14.          0.77731456]\t 0.7410022072170401\t 0.7306802524366626\t 0.9678438310144597\t 0.9678438310144597\n",
            "10 \t [ 9.90790911  3.6691837   7.          0.58814302 10.          0.64733993]\t 0.761278126308538\t 0.7306802524366626\t 0.9628655102340932\t 0.9628655102340932\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7577952901048656\t 0.7306802524366626\t 0.9590314469686625\t 0.9590314469686594\n",
            "12 \t [ 9.94337897  0.36950862  8.          0.73485109 19.          0.44537046]\t 0.8200724194646505\t 0.7306802524366626\t 0.9555732573757605\t 0.9555732573757605\n",
            "13 \t [ 0.9801878   7.62207926 11.          0.92097131  8.          0.96474414]\t 0.735225373641723\t 0.7306802524366626\t 0.9540017396279297\t 0.9540017396246198\n",
            "14 \t [0.59196411 2.70489003 6.         0.53471064 2.         0.87047587]\t 0.7564679705296913\t 0.7306802524366626\t 0.9506948450999073\t 0.9506948450999073\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.7438065116890006\t 0.7306802524366626\t 0.9481672057613789\t 0.9481672057613789\n",
            "16 \t [8.92737492 4.97008631 6.         0.51220578 6.         0.80236801]\t 0.7654550444771853\t 0.7306802524366626\t 0.9456382586631769\t 0.9456382586631769\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.1355955958989596\t 0.7306802524366626\t 0.9444117013270679\t 0.9444117013270679\n",
            "18 \t [2.57352577 0.33719112 9.         0.97251025 4.         0.51947396]\t 0.78517596210852\t 0.7306802524366626\t 0.9498447005159412\t 0.9498447005159412\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.1349556164442796\t 0.7306802524366626\t 0.9493105719784624\t 0.9493105719784624\n",
            "20 \t [7.78054327e-03 3.05674801e+00 1.40000000e+01 9.86996551e-01\n",
            " 1.60000000e+01 3.30836599e-01]\t 0.9307728115507239\t 0.7306802524366626\t 0.9539701700658199\t 0.9539701700658199\n",
            "21 \t [4.36648808 8.42254188 6.         0.54886836 3.         0.62627434]\t 0.7616177222343332\t 0.7306802524366626\t 0.953128523450784\t 0.953128523450784\n",
            "22 \t [ 0.18137014  8.57899028  5.          0.96422639 17.          0.43096751]\t 0.818548258747034\t 0.7306802524366626\t 0.9610152668753994\t 0.9610152668753994\n",
            "23 \t [3.55859061 5.61875163 8.         0.5882063  1.         0.57036163]\t 0.8119275659738049\t 0.7306802524366626\t 0.960833706119009\t 0.960833706119009\n",
            "24 \t [ 0.537802    3.33621713  8.          0.77943172 18.          0.5870313 ]\t 0.7903484037271079\t 0.7306802524366626\t 0.9571856332434994\t 0.9571856332434994\n",
            "25 \t [ 1.81729559  6.10959292 13.          0.54665808  2.          0.39489847]\t 0.8392277330367088\t 0.7306802524366626\t 0.9517915999717419\t 0.9517915999717419\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.7463927243485514\t 0.7306802524366626\t 0.9522508487849208\t 0.9522508487849208\n",
            "27 \t [ 5.85240254  2.29607078  6.          0.83156764 14.          0.75611542]\t 0.7463626746911727\t 0.7306802524366626\t 0.9499431876359602\t 0.9499431876359602\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.7956673392227565\t 0.7306802524366626\t 0.9453016992296113\t 0.9453016992296113\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9305364532791108\t 0.7306802524366626\t 0.9482310681209318\t 0.9482310681209318\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.932353773777384\t 0.7306802524366626\t 0.946375839771622\t 0.946375839771622\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62109.01335398378"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e35c850-b972-4d94-bb79-3884609cf4b8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO_multi(surrogate_approx_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.886516450243748\t 0.7696523735238344\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.8159404842786963\t 0.7696523735238344\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.9077084280320982\t 0.7696523735238344\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.7696523735238344\t 0.7696523735238344\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 0.9767143382937844\t 0.7696523735238344\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 0.9945462140035275\t 0.7696523735238344\t 0.9820451508295107\t 0.9820451508295107\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.8956717295899809\t 0.7696523735238344\t 0.9913671144319712\t 0.9913671144319712\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7896752580111073\t 0.7696523735238344\t 0.9913808698799693\t 0.9913808698799693\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 0.9788770650266176\t 0.7696523735238344\t 0.9858516910219304\t 0.9858516910219304\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9068912188410501\t 0.7696523735238344\t 0.9907760968137453\t 0.9907760968137453\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 0.9798753116153296\t 0.7696523735238344\t 0.991344719730295\t 0.991344719730295\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7844376116756365\t 0.7696523735238344\t 0.9948924733512974\t 0.9948924733512974\n",
            "8  \t [ 7.13077184  9.67534636 12.          0.53994085 17.          0.99732292]\t 0.7788814985676316\t 0.7696523735238344\t 0.9907678050202855\t 0.9907678050202855\n",
            "9  \t [ 4.99777324  7.1255563   5.          0.87428718 19.          0.63814647]\t 0.8365647355641779\t 0.7696523735238344\t 0.9870913101724494\t 0.9870913101724494\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.8262334140046084\t 0.7696523735238344\t 0.9855872543126138\t 0.9855872543126138\n",
            "11 \t [ 2.11261802  6.77105261 11.          0.82546435 17.          0.58049877]\t 0.8420672525155452\t 0.7696523735238344\t 0.9839905189010605\t 0.9839905189010605\n",
            "12 \t [ 1.87613733  0.3867672  10.          0.63542614  2.          0.41568093]\t 0.9060376794109418\t 0.7696523735238344\t 0.9830029100667071\t 0.9830029100667071\n",
            "13 \t [8.28996906 3.70835156 8.         0.5062329  4.         0.26839233]\t 0.898234632517687\t 0.7696523735238344\t 0.9837808019427903\t 0.9837808019427903\n",
            "14 \t [ 0.14006525  1.03750573 13.          0.72168802 14.          0.72400369]\t 0.815597828474959\t 0.7696523735238344\t 0.9843207373127624\t 0.9843207373127624\n",
            "15 \t [ 3.12232086  1.45138414 11.          0.68922386  8.          0.99526189]\t 0.7696523959316329\t 0.7696523735238344\t 0.9828893770689023\t 0.9828893770689023\n",
            "16 \t [ 5.21920054  9.35580917 14.          0.81835368  4.          0.54800317]\t 0.8502094404923272\t 0.7696523735238344\t 0.9804319596123485\t 0.9804319596123485\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.778866435123053\t 0.7696523735238344\t 0.9797008549896009\t 0.9797008549896009\n",
            "18 \t [1.97879228 8.99345507 8.         0.55562265 8.         0.49118331]\t 0.8951491505335811\t 0.7696523735238344\t 0.9785204677737473\t 0.9785204677737473\n",
            "19 \t [ 3.46936711  8.05933995 13.          0.63796232  8.          0.58226276]\t 0.8566066993171872\t 0.7696523735238344\t 0.9868390917699092\t 0.9868390917699092\n",
            "20 \t [ 0.91942921  7.15139263  5.26867758  0.5        15.99747546  1.        ]\t 0.788186348144717\t 0.7696523735238344\t 0.9816981672572577\t 0.9816982391092653\n",
            "21 \t [4.16561464 4.3151821  6.         0.76299318 2.         0.59049538]\t 0.8474357581098328\t 0.7696523735238344\t 0.9841759348440735\t 0.9841759348440735\n",
            "22 \t [ 7.78105793  5.48658242 11.          0.92291293 15.          0.11871578]\t 0.9740550290580832\t 0.7696523735238344\t 0.9811980465496876\t 0.9811980465496876\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 0.9821896458721675\t 0.7696523735238344\t 0.984021515446698\t 0.984021515446698\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.7800900414685491\t 0.7696523735238344\t 0.9818199665947007\t 0.9818199665947007\n",
            "25 \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]\t 0.7754504257026212\t 0.7696523735238344\t 0.9867701030422547\t 0.9867701030422547\n",
            "26 \t [ 5.73005003  1.18628884 13.          0.88016467 12.          0.48547975]\t 0.8868749954853754\t 0.7696523735238344\t 0.9806945254677563\t 0.9806945254677563\n",
            "27 \t [8.60914739 9.54673859 7.         0.78963544 7.         0.48348756]\t 0.8811833469490125\t 0.7696523735238344\t 0.9799372176309079\t 0.9799372176309079\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 8.16440635  3.57724702 11.          0.83367572  9.          0.82276147]\u001b[0m\t \u001b[1m\u001b[92m0.7636353158344195\u001b[0m\t \u001b[1m\u001b[92m0.7636353158344195\u001b[0m\t \u001b[1m\u001b[92m0.9807720400702112\u001b[0m\t \u001b[1m\u001b[92m0.9807720400702112\u001b[0m\n",
            "29 \t [ 9.79781036  7.70828329  5.          0.72056878 19.          0.87728226]\t 0.7800481665326269\t 0.7636353158344195\t 0.9727842368083961\t 0.9727842368083961\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.8347983363393409\t 0.7636353158344195\t 0.9796076260207577\t 0.9796076260207577\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59899.945988489686"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe1665f-f75f-431a-87c0-14b87051df97"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO_multi(surrogate_approx_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.7846478010899064\t 0.7846478010899064\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 1.0448868808294456\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 1.0327067294213346\t 0.7846478010899064\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.8536879526704689\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 1.0323325469581077\t 0.7846478010899064\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.810550884613735\t 0.7846478010899064\t 1.029860941447271\t 1.029860941447271\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.9535088265263543\t 0.7846478010899064\t 1.0197101466571634\t 1.0197101466571634\n",
            "3  \t [ 7.5915683   5.13937898 12.          0.70919884  1.          0.76222697]\t 0.8664770530673357\t 0.7846478010899064\t 1.0210159825128817\t 1.0210159825128817\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.9286293360228086\t 0.7846478010899064\t 1.0172598281083693\t 1.0172598281083693\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\u001b[0m\t \u001b[1m\u001b[92m0.7842936215568133\u001b[0m\t \u001b[1m\u001b[92m0.7842936215568133\u001b[0m\t \u001b[1m\u001b[92m1.0173045514584242\u001b[0m\t \u001b[1m\u001b[92m1.0173045514584242\u001b[0m\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.9316923990976885\t 0.7842936215568133\t 1.01110903897397\t 1.01110903897397\n",
            "7  \t [ 9.09795503  1.07150197  7.          0.98191679 19.          0.62951892]\t 0.7965305854630446\t 0.7842936215568133\t 1.011807867685972\t 1.011807867685972\n",
            "8  \t [ 9.21941721  9.79827821 11.          0.81783228 11.          0.53477407]\t 0.813771001201059\t 0.7842936215568133\t 1.007669414444076\t 1.007669414444076\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.8467944167491783\t 0.7842936215568133\t 1.0046718921919744\t 1.0046718921919744\n",
            "10 \t [ 8.47779105  8.43696768  5.          0.73890705 16.          0.66738091]\t 0.8243356733622897\t 0.7842936215568133\t 1.0030479264269891\t 1.0030479264269891\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.8067689920731376\t 0.7842936215568133\t 1.0010289488944908\t 1.0010289488944908\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.8291023984963773\t 0.7842936215568133\t 0.998808360351673\t 0.998808360351673\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\u001b[0m\t \u001b[1m\u001b[92m0.7817258295570644\u001b[0m\t \u001b[1m\u001b[92m0.7817258295570644\u001b[0m\t \u001b[1m\u001b[92m0.9973917874395847\u001b[0m\t \u001b[1m\u001b[92m0.9973917874395847\u001b[0m\n",
            "14 \t [ 0.67244942  9.08791765  7.          0.79067069 13.          0.11985169]\t 1.0335117111523784\t 0.7817258295570644\t 0.9931232007667421\t 0.9931231866912817\n",
            "15 \t [3.91240074 6.5849714  5.         0.97211484 8.         0.11185491]\t 1.0294064674086314\t 0.7817258295570644\t 0.9969242350689206\t 0.9969242350689206\n",
            "16 \t [ 4.45420258  7.59025354  7.          0.50662979 17.          0.94915127]\t 0.7905510453184308\t 0.7817258295570644\t 1.000085750411337\t 1.000085750411337\n",
            "17 \t [4.50435964 1.42883317 8.         0.76583339 3.         0.4306355 ]\t 0.9350949568458088\t 0.7817258295570644\t 0.9991083587064425\t 0.9991083587064425\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.8184266869335748\t 0.7817258295570644\t 1.0041506352737053\t 1.0041506352737053\n",
            "19 \t [ 9.64875283  9.32176949  8.          0.85263567 19.          0.33410227]\t 0.9264535302583298\t 0.7817258295570644\t 0.9983068610980609\t 0.9983068610980609\n",
            "20 \t [ 5.31037667  6.81676807  5.          0.53020463 18.          0.21260061]\t 1.0437596156191435\t 0.7817258295570644\t 0.9967530097119882\t 0.9967530097119882\n",
            "21 \t [ 9.28937895  1.2300363  13.          0.54126463 19.          0.2413571 ]\t 1.0398406285038562\t 0.7817258295570644\t 1.0066122263544313\t 1.0066122263544313\n",
            "22 \t [ 4.90087649  7.40954674 11.          0.53028779  8.          0.43614982]\t 0.9558470479985534\t 0.7817258295570644\t 1.0035265258941157\t 1.0035265258941157\n",
            "23 \t [ 1.04966198  1.72140723 11.          0.68060657  8.          0.5044115 ]\t 0.8422478956054074\t 0.7817258295570644\t 1.0059513512051808\t 1.0059513512051808\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.8523559948324888\t 0.7817258295570644\t 1.0058321168484252\t 1.0058321168484252\n",
            "25 \t [ 1.719002    1.73903169  5.          0.87805761 14.          0.46260902]\t 0.9216282707304624\t 0.7817258295570644\t 1.011003771423078\t 1.011003771423078\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.9727332413478633\t 0.7817258295570644\t 1.0089860081111757\t 1.0089860081111757\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]\u001b[0m\t \u001b[1m\u001b[92m0.7412282900611625\u001b[0m\t \u001b[1m\u001b[92m0.7412282900611625\u001b[0m\t \u001b[1m\u001b[92m1.0074357104985154\u001b[0m\t \u001b[1m\u001b[92m1.0074357104985154\u001b[0m\n",
            "28 \t [ 3.85186676  3.1955202  13.          0.84289144 11.          0.29344016]\t 0.9318426963665122\t 0.7412282900611625\t 0.9712090064169209\t 0.9712090064169209\n",
            "29 \t [ 5.44697951  7.10004131 14.          0.73747864 14.          0.39762384]\t 0.9268634145097335\t 0.7412282900611625\t 0.9709078544846816\t 0.9709078544846816\n",
            "30 \t [ 8.04276314  4.60586342  8.          0.52625867 16.          0.88607792]\t 0.7842475257071028\t 0.7412282900611625\t 0.9735236362607449\t 0.9735236362607449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61931.472044342285"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70873b8-79ce-4349-ada8-a914a177ea50"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO_multi(surrogate_approx_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 1.0442882316794924\t 0.9988899440522335\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 1.034592364984854\t 0.9988899440522335\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.9988899440522335\t 0.9988899440522335\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 1.0616382201607613\t 0.9988899440522335\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 1.0586655163441985\t 0.9988899440522335\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m1.2337309811890973\u001b[0m\t \u001b[1m\u001b[92m1.2337309811890973\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 1.0357720753154218\t 0.7588724777099193\t 1.029815418153565\t 1.029815418153565\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.9957364873565091\t 0.7588724777099193\t 1.032336608481323\t 1.032336608481323\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 1.0230792313624693\t 0.7588724777099193\t 1.0318483987558533\t 1.0318483987558533\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.9990381912537636\t 0.7588724777099193\t 1.0329086899845612\t 1.0329086899845612\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.857846290397769\t 0.7588724777099193\t 1.0326274085511997\t 1.0326274085511997\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 1.0693894233525565\t 0.7588724777099193\t 1.0268764690427696\t 1.0268764690427696\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.8611559732831295\t 0.7588724777099193\t 1.0299435517503475\t 1.0299435513875461\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m1.0253827147243415\u001b[0m\t \u001b[1m\u001b[92m1.0253827147243415\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7415155405776647\t 0.7219532506859043\t 0.9900816640315581\t 0.9900816613798128\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 1.1107767409489193\t 0.7219532506859043\t 0.9837430847254166\t 0.9837430847254166\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.857182327987213\t 0.7219532506859043\t 0.9884784957989965\t 0.9884784957989965\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.9855802099870726\u001b[0m\t \u001b[1m\u001b[92m0.985580209868114\u001b[0m\n",
            "14 \t [ 5.41155711  5.82534705 10.          0.62444801 12.          0.48368067]\t 1.011456246332149\t 0.7195558119979323\t 0.9783078575416909\t 0.9783078575416909\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 1.0073272814467533\t 0.7195558119979323\t 0.9798196240393567\t 0.9798196240393567\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.894093323976883\t 0.7195558119979323\t 0.9810277009079841\t 0.9810277009079841\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 1.096518529758772\t 0.7195558119979323\t 0.9802161295882053\t 0.9802161295882053\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 1.0333946700789831\t 0.7195558119979323\t 0.9862331411789401\t 0.986233141178667\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 1.0221431969128547\t 0.7195558119979323\t 0.9815266721074226\t 0.9815266720846864\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.9054977129617926\t 0.7195558119979323\t 0.9870177371838226\t 0.9870177371838226\n",
            "21 \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]\t 1.0357266754545873\t 0.7195558119979323\t 0.9879139903082425\t 0.9879139903082425\n",
            "22 \t [ 6.72271828  8.33075498 14.          0.78841734 10.          0.48431777]\t 0.9963666823715333\t 0.7195558119979323\t 0.9915990511405932\t 0.9915990225146776\n",
            "23 \t [0.58596137 5.71336149 9.         0.70354751 9.         0.28160967]\t 1.0385062021776466\t 0.7195558119979323\t 0.9867771549976577\t 0.9867771538476927\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7761448350601515\t 0.7195558119979323\t 0.9879229071348317\t 0.9879229071348317\n",
            "25 \t [ 9.01141716  1.23452325  9.          0.70620993 16.          0.46074297]\t 1.0029978093526934\t 0.7195558119979323\t 0.9846698214041727\t 0.9846698214041727\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 1.0050223847057222\t 0.7195558119979323\t 0.9847630573875661\t 0.9847630573875661\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.8647657423877456\t 0.7195558119979323\t 0.9890381983861157\t 0.9890381983861157\n",
            "28 \t [ 1.9619463   0.16028995 10.          0.50330845  2.          0.6207421 ]\t 0.9390116776172818\t 0.7195558119979323\t 0.9861653459301055\t 0.9861653459187913\n",
            "29 \t [ 1.58467279  1.68272877 13.          0.86101343 12.          0.4100987 ]\t 1.004998254560435\t 0.7195558119979323\t 0.9873675483234639\t 0.9873675483234639\n",
            "30 \t [ 1.75338275  3.59236251  5.          0.5        14.90718664  1.        ]\t 0.7479056917991012\t 0.7195558119979323\t 0.9869033737657659\t 0.9869023620809726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60614.22577011115"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e887e5d0-d1bb-414a-df34-51488257819c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO_multi(surrogate_approx_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.8160193762021096\t 0.8160193762021096\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.9345750435828236\t 0.8160193762021096\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.8609997448649105\t 0.8160193762021096\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9816665199899536\t 0.8160193762021096\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.9568167510294832\t 0.8160193762021096\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.9860041719301801\t 0.8160193762021096\t 1.0315255253319489\t 1.0315255253319489\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.8418838401878418\t 0.8160193762021096\t 1.0376358410853028\t 1.0376358410853028\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m1.0330250568115071\u001b[0m\t \u001b[1m\u001b[92m1.0330250568115071\u001b[0m\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9840979999934294\t 0.7805118546901472\t 0.9988054786728285\t 0.9988054786728285\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.955892785185136\t 0.7805118546901472\t 1.0034515115763007\t 1.0034515115763007\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.9781132546552117\t 0.7805118546901472\t 1.0074427827289698\t 1.0074427827289698\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.8404775189371637\t 0.7805118546901472\t 1.0086890093123533\t 1.0086890093123533\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.9731655942341536\t 0.7805118546901472\t 1.0060185747461736\t 1.0060185747461736\n",
            "9  \t [9.85206608 0.28191822 5.         0.52457928 8.         0.84714334]\t 0.8508120667734606\t 0.7805118546901472\t 1.0094995622838137\t 1.0094995622838137\n",
            "10 \t [ 0.2191332   8.51773955  5.          0.60657578 15.          0.49735822]\t 0.9550900145970594\t 0.7805118546901472\t 1.0063007092465677\t 1.0063007092465677\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.9443317250470002\t 0.7805118546901472\t 1.0076541387826812\t 1.0076541387826812\n",
            "12 \t [0.95504342 7.30424524 8.         0.76682007 6.         0.21761275]\t 0.9795870115119684\t 0.7805118546901472\t 1.0095441487302448\t 1.0095441487302448\n",
            "13 \t [ 7.51514915  5.57821555 12.          0.8704045   9.          0.10769764]\t 0.9810647343827711\t 0.7805118546901472\t 1.0109360933266038\t 1.0109360611095466\n",
            "14 \t [ 5.04595194 10.          6.27023006  0.73454214 12.4052877   0.28269332]\t 0.9525235999367077\t 0.7805118546901472\t 1.01126052518764\t 1.011260510561392\n",
            "15 \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]\t 0.9759678380966751\t 0.7805118546901472\t 1.01277552127333\t 1.01277552127333\n",
            "16 \t [ 5.22074709  0.74229772 13.          0.87455275  7.          0.44305495]\t 0.9475819018040168\t 0.7805118546901472\t 1.0144714016525727\t 1.0144714016525727\n",
            "17 \t [ 9.1928307   3.75120063 13.          0.61085648 16.          0.3130605 ]\t 0.9631882478680399\t 0.7805118546901472\t 1.0150497471016813\t 1.0150497471016813\n",
            "18 \t [0.91443767 6.97440714 5.         0.78916973 2.         0.81132272]\t 0.8282909656929418\t 0.7805118546901472\t 1.0157561311859253\t 1.0157561311859253\n",
            "19 \t [ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]\t 0.8425830184404466\t 0.7805118546901472\t 1.0152273232418663\t 1.0152273232418663\n",
            "20 \t [ 8.57333797  0.94219501 14.          0.51089969  3.          0.1953435 ]\t 1.0049178610788712\t 0.7805118546901472\t 1.004821302522637\t 1.0048212190303623\n",
            "21 \t [ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\t 0.7847481688271192\t 0.7805118546901472\t 1.0194393418007202\t 1.0194393418007202\n",
            "22 \t [6.17562703 5.62140054 5.         0.97946506 3.         0.20857904]\t 0.9722212560084632\t 0.7805118546901472\t 1.012109090767452\t 1.012109090767452\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.8589132192206685\t 0.7805118546901472\t 1.0170782646560357\t 1.0170782646560357\n",
            "24 \t [ 0.01662929  3.46629364  8.          0.7460687  11.          0.32343978]\t 0.9599687924042467\t 0.7805118546901472\t 1.0054454067061245\t 1.0054454067061245\n",
            "\u001b[1m\u001b[92m25\u001b[0m\t \u001b[1m\u001b[92m[ 7.46611649  2.42130498  9.26845331  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7434974475145234\u001b[0m\t \u001b[1m\u001b[92m0.7434974475145234\u001b[0m\t \u001b[1m\u001b[92m1.0104594756109209\u001b[0m\t \u001b[1m\u001b[92m1.010458661244816\u001b[0m\n",
            "26 \t [ 9.68199458  9.34620738 11.          0.57663541 14.          0.24521092]\t 0.9882374086058249\t 0.7434974475145234\t 0.9854294636008235\t 0.9854294555262881\n",
            "27 \t [ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]\t 0.7787515875060036\t 0.7434974475145234\t 0.9858129840538667\t 0.9858129840538667\n",
            "28 \t [ 3.3191017   1.36482014 13.          0.77172143  1.          0.73147858]\t 0.8632014318852118\t 0.7434974475145234\t 0.9779901221191721\t 0.9779901217728042\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.860674338231938\t 0.7434974475145234\t 0.9836875085203058\t 0.9836875085203058\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.8118933760299614\t 0.7434974475145234\t 0.9756655775894791\t 0.9756655775894791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60838.5826142282"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01b7511-d8a0-44e0-a483-91633e01ea18"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO_multi(surrogate_approx_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9945504564494708\t 0.8040972705253946\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.8040972705253946\t 0.8040972705253946\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9800705737387579\t 0.8040972705253946\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.8208145553024886\t 0.8040972705253946\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.8099770295888573\t 0.8040972705253946\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8290526771960891\t 0.8040972705253946\t 1.013163068552508\t 1.013163068552508\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.7717526578038573\u001b[0m\t \u001b[1m\u001b[92m0.7717526578038573\u001b[0m\t \u001b[1m\u001b[92m1.0093228508398697\u001b[0m\t \u001b[1m\u001b[92m1.0093228508398697\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.8267998563487631\t 0.7717526578038573\t 0.9778951912143505\t 0.9778951912143505\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.9720368320825408\t 0.7717526578038573\t 0.9760691870899438\t 0.9760691870899438\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.7939440774877953\t 0.7717526578038573\t 0.9825128526526545\t 0.9825128526526545\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 1.0766617046782607\t 0.7717526578038573\t 0.9787711794146935\t 0.9787711794146935\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 1.0814569137184114\t 0.7717526578038573\t 0.9886404048053731\t 0.9886404048053731\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.8167106174903189\t 0.7717526578038573\t 0.996170989873772\t 0.996170989873772\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.8216445533109903\t 0.7717526578038573\t 0.9933739024529707\t 0.9933738973211603\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.7908825942180885\t 0.7717526578038573\t 0.9911091204375566\t 0.9911091128661453\n",
            "11 \t [ 0.2637722   4.11659493  5.          0.61604637 11.          0.22374653]\t 1.0699354655820383\t 0.7717526578038573\t 0.9883211499649922\t 0.9883211499649922\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.8390111546541604\t 0.7717526578038573\t 0.9938611277412938\t 0.9938611277412938\n",
            "13 \t [ 8.34050252  7.45495891 14.          0.58875591  8.          0.92669456]\t 0.7757542421516687\t 0.7717526578038573\t 0.9927261265775383\t 0.9927261265775383\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.9054011377721235\t 0.7717526578038573\t 0.9901881351557323\t 0.9901881351557323\n",
            "15 \t [3.36125149 0.38066674 7.         0.83604387 7.         0.55591318]\t 0.8269535778079307\t 0.7717526578038573\t 0.9900611100113842\t 0.9900611100113842\n",
            "16 \t [ 0.71491502  0.67997826 10.          0.84656193 16.          0.26877596]\t 0.9802989527959\t 0.7717526578038573\t 0.9890666910738324\t 0.9890666910738324\n",
            "17 \t [0.80116063 4.55633099 5.         0.79763457 4.         0.36850753]\t 0.9816472859446954\t 0.7717526578038573\t 0.9913621420827683\t 0.9913621420827683\n",
            "18 \t [ 4.48360078  7.855369   10.          0.64837174 18.          0.21997892]\t 1.069621582520547\t 0.7717526578038573\t 0.9986653200478094\t 0.9986653200478094\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 1.0659804815531757\t 0.7717526578038573\t 1.0029949174477462\t 1.0029949174477462\n",
            "20 \t [ 9.84526946  7.66546924  9.          0.85160345 12.          0.57041046]\t 0.8143407207554997\t 0.7717526578038573\t 1.008007535684124\t 1.008007535684124\n",
            "21 \t [ 9.23733929  4.4641986  14.          0.5618978  13.          0.67359608]\t 0.8084765247236222\t 0.7717526578038573\t 0.9972899679956204\t 0.9972899679956204\n",
            "22 \t [ 3.44634229  0.73068286  6.          0.98116529 13.          0.55221155]\t 0.8186382898037643\t 0.7717526578038573\t 0.9971029551686914\t 0.9971029551686914\n",
            "23 \t [ 9.53885612  7.77476011 11.          0.72419664  1.          0.36894154]\t 0.9940856467171486\t 0.7717526578038573\t 0.9978325212749403\t 0.9978325212749403\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.7803443878774855\t 0.7717526578038573\t 0.9985264363165661\t 0.9985264363165661\n",
            "25 \t [1.70698239 9.19985282 6.         0.50661833 7.         0.29378886]\t 0.9933904701114727\t 0.7717526578038573\t 1.0022843169888203\t 1.0022843169888203\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.8237860321712347\t 0.7717526578038573\t 1.0022836421838108\t 1.0022836421838108\n",
            "27 \t [ 2.49960443  6.35739516  5.          0.82569718 16.          0.24708903]\t 1.0804872789733682\t 0.7717526578038573\t 0.9959244995617107\t 0.9959244995617107\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 1.0695374663391362\t 0.7717526578038573\t 0.9969445830868222\t 0.9969445830868222\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.8216721197517609\t 0.7717526578038573\t 0.9988786423148149\t 0.9988786423148149\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 6.37097579  5.69315713 13.          0.83848815 18.          0.96944598]\u001b[0m\t \u001b[1m\u001b[92m0.7607071092665223\u001b[0m\t \u001b[1m\u001b[92m0.7607071092665223\u001b[0m\t \u001b[1m\u001b[92m1.001246475885919\u001b[0m\t \u001b[1m\u001b[92m1.001246475885919\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61392.39752730621"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61db0ca8-9433-45a0-eede-287de5ef49c2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO_multi(surrogate_approx_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.9238143360620997\t 0.824729580989813\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.9119597092034326\t 0.824729580989813\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.1280473533716002\t 0.824729580989813\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.885331313733569\t 0.824729580989813\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.824729580989813\t 0.824729580989813\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m1.05215671724966\u001b[0m\t \u001b[1m\u001b[92m1.05215671724966\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.8875735409405836\t 0.79346025102973\t 1.0180755893378943\t 1.0180755893378943\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.1322726135322738\t 0.79346025102973\t 1.0164221804106297\t 1.0164221804106297\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.9633601355550562\t 0.79346025102973\t 1.0299707227197825\t 1.0299707227197825\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.9736613453341365\t 0.79346025102973\t 1.0310887358649345\t 1.0310887358649345\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.8962334110364653\t 0.79346025102973\t 1.032453214020836\t 1.0324532139140066\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.8910080545620651\t 0.79346025102973\t 1.0304592438778342\t 1.0304592438778342\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.8893037640708062\t 0.79346025102973\t 1.0286087889945064\t 1.0286087889945064\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.9338815902432167\t 0.79346025102973\t 1.0269831357661876\t 1.0269831357661876\n",
            "10 \t [ 4.45643696  6.43761151 10.          0.59521711 15.          0.91320177]\t 0.8255704645290564\t 0.79346025102973\t 1.0269701145366394\t 1.0269701084936718\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.8287447527880435\t 0.79346025102973\t 1.0239287727917463\t 1.0239287727917463\n",
            "12 \t [ 9.41792853  9.11293681  6.          0.87420995 11.          0.8007601 ]\t 0.8060510151077646\t 0.79346025102973\t 1.02134030570045\t 1.02134030570045\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.1276065677179288\t 0.79346025102973\t 1.018495448167549\t 1.018495448167549\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.8195075556875523\t 0.79346025102973\t 1.0248243495840357\t 1.0248243495840357\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.9367777767954987\t 0.79346025102973\t 1.0218949514309223\t 1.0218949514309223\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.9192069504605914\t 0.79346025102973\t 1.0226305272201877\t 1.0226305272201877\n",
            "17 \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]\t 0.8744339215870263\t 0.79346025102973\t 1.022296250977313\t 1.022296250977313\n",
            "18 \t [ 7.9679648   6.50875696 12.          0.58580991 13.          0.19954847]\t 1.1274997047398325\t 0.79346025102973\t 1.0263224950115175\t 1.0263224950115175\n",
            "19 \t [ 9.97958622  9.03409533 12.          0.51772082  4.          0.45869101]\t 0.9473572626155049\t 0.79346025102973\t 1.0279888654458356\t 1.0279888654458356\n",
            "20 \t [ 3.55165538  9.78370062 13.          0.78750167  1.          0.7976462 ]\t 0.832291165091001\t 0.79346025102973\t 1.02693076721024\t 1.02693076721024\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.8200285178970692\t 0.79346025102973\t 1.0281487523169035\t 1.0281487523169035\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.9223651097826323\t 0.79346025102973\t 1.0201143432979345\t 1.0201143432979345\n",
            "23 \t [ 4.81184079  0.03027405 11.          0.96437956 10.          0.97759806]\t 0.7947258239649384\t 0.79346025102973\t 1.0315924588479684\t 1.0315924586534029\n",
            "24 \t [ 6.30542676  7.71202743  5.          0.69290865 17.          0.68185665]\t 0.9062144692012971\t 0.79346025102973\t 1.0209382189886211\t 1.0209382189886211\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.9381315214046673\t 0.79346025102973\t 1.0190217488477713\t 1.0190217488477713\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.8895644243531041\t 0.79346025102973\t 1.0228223393745182\t 1.0228223393745182\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[10.          0.48868222 12.0090532   1.         18.56354333  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.7706287495844453\u001b[0m\t \u001b[1m\u001b[92m0.7706287495844453\u001b[0m\t \u001b[1m\u001b[92m1.0253454932774244\u001b[0m\t \u001b[1m\u001b[92m1.0253455091618053\u001b[0m\n",
            "28 \t [8.3735996  5.34104024 8.         0.56456303 7.         0.59553385]\t 0.9329548781688652\t 0.7706287495844453\t 1.0001618120278801\t 1.0001618120278801\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.8158422349857315\t 0.7706287495844453\t 0.9996309287490408\t 0.9996309287490408\n",
            "30 \t [9.30545715 2.21896205 9.         0.96965499 5.         0.61228081]\t 0.8966551531404072\t 0.7706287495844453\t 0.9993196513969961\t 0.9993196513969961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61347.40838940825"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a92e1c8-5758-4bd2-f25e-d35b610f7875"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO_multi(surrogate_approx_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.7520109919120059\t 0.7520109919120059\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.7843437690505969\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0380897569172567\t 0.7520109919120059\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.9185289289653313\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.9180724641961298\t 0.7520109919120059\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.9254670555638643\t 0.7520109919120059\t 0.9745508172854711\t 0.9745508172854711\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0314631424665905\t 0.7520109919120059\t 0.9770087627215797\t 0.9770087627215797\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.8949898491028812\t 0.7520109919120059\t 0.9863911537537903\t 0.98639115375379\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7944418105894601\t 0.7520109919120059\t 0.9852933487009422\t 0.9852933487009422\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8997545663056927\t 0.7520109919120059\t 0.9797652723393432\t 0.9797652723393432\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.0239998235141596\t 0.7520109919120059\t 0.9797573806447127\t 0.9797573806447127\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.8480209770499222\t 0.7520109919120059\t 0.9853190723562659\t 0.9853190723562659\n",
            "8  \t [ 2.63649501  9.62311075  7.          0.5192485  13.          0.19746315]\t 1.0350432385289277\t 0.7520109919120059\t 0.9828155411952884\t 0.9828155411952884\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0363798049215616\t 0.7520109919120059\t 0.9876974545588961\t 0.9876974545588961\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.865997699883801\t 0.7520109919120059\t 0.991754674589083\t 0.991754674589083\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0228429225587468\t 0.7520109919120059\t 0.9899406303902705\t 0.9899406303902705\n",
            "12 \t [ 6.27900589  9.12764923  5.          0.84263312 18.          0.79256191]\t 0.7735262251857813\t 0.7520109919120059\t 0.9927655846168092\t 0.9927655846168092\n",
            "13 \t [6.3101326  8.61804899 7.         0.66826014 6.         0.89905701]\t 0.778060148609183\t 0.7520109919120059\t 0.9891568840186934\t 0.9891568840186934\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[ 2.08109501  0.31399789  8.          0.78263012 11.          0.87673239]\u001b[0m\t \u001b[1m\u001b[92m0.7493527307804453\u001b[0m\t \u001b[1m\u001b[92m0.7493527307804453\u001b[0m\t \u001b[1m\u001b[92m0.9858926771508242\u001b[0m\t \u001b[1m\u001b[92m0.9858926771508242\u001b[0m\n",
            "15 \t [ 6.97560183  1.48211849  9.          0.80794429 10.          0.21839694]\t 1.0237787601826196\t 0.7493527307804453\t 0.9802460580055111\t 0.9802460580055111\n",
            "16 \t [ 1.47808653  5.79832114 12.          0.95992435  9.          0.71524706]\t 0.8162777104474938\t 0.7493527307804453\t 0.9827825342925854\t 0.9827825342925854\n",
            "17 \t [ 5.89342875  8.42543819 13.          0.91386769  2.          0.30786126]\t 0.9476026661484042\t 0.7493527307804453\t 0.9809863382503712\t 0.9809863382503712\n",
            "18 \t [ 1.21632555  2.44839139  8.          0.8927599  17.          0.25270381]\t 0.9237148678212173\t 0.7493527307804453\t 0.9810928793681752\t 0.9810928793681752\n",
            "19 \t [4.83067255 2.19904639 7.         0.5680519  3.         0.59514532]\t 0.8957701072181361\t 0.7493527307804453\t 0.9808880769079887\t 0.9808880769079887\n",
            "20 \t [ 6.62295384  9.17069374  8.          0.91336715 18.          0.33402165]\t 0.9207932652757735\t 0.7493527307804453\t 0.9877743871839264\t 0.9877743871839264\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.9203913838650098\t 0.7493527307804453\t 0.9864727573035467\t 0.9864727573035467\n",
            "22 \t [ 2.64391559  1.76519903 14.          0.97943945  7.          0.11710362]\t 1.0222210574453885\t 0.7493527307804453\t 0.9864166551186775\t 0.9864166551186775\n",
            "23 \t [ 5.86852957  9.2552543  14.          0.74343957 14.          0.26209686]\t 0.9228195832204917\t 0.7493527307804453\t 0.9835601401454552\t 0.9835601401454552\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.7797715795229998\t 0.7493527307804453\t 0.9834423394835116\t 0.9834423394835116\n",
            "25 \t [ 9.4251418   2.62898513  5.          0.90450266 19.          0.92733176]\t 0.7703406847213696\t 0.7493527307804453\t 0.9869210517915799\t 0.9869199526154587\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.8602984001975387\t 0.7493527307804453\t 0.9849831176172732\t 0.9849831176172732\n",
            "27 \t [ 3.32529567 10.          5.13244264  1.          1.84561618  1.        ]\t 0.7559844796404921\t 0.7493527307804453\t 0.9885864106274181\t 0.9885849603650368\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.021708916478741\t 0.7493527307804453\t 0.9804544075238584\t 0.9804544075238584\n",
            "29 \t [ 2.05797056  3.5679443  14.          0.67286552 19.          0.3168445 ]\t 0.9202198906523096\t 0.7493527307804453\t 0.9851191795515138\t 0.9851191792252063\n",
            "30 \t [8.73152949 2.51255889 5.         1.         1.         1.        ]\t 0.7542686397136368\t 0.7493527307804453\t 0.9769637516502805\t 0.9769635423091448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60306.50974237256"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25928d2a-8d19-474d-eda1-9fb914c57a0d"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1662391167.095045"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35140afe-9efe-4724-d424-51f51bcd7bbb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 0.848101320876155\t 0.7386468688809501\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7469689781479785\t 0.7386468688809501\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8079963708366673\t 0.7386468688809501\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.7386468688809501\t 0.7386468688809501\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 0.937768916815817\t 0.7386468688809501\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8126185461054997\t 0.7386468688809501\t 0.9338051879731153\t 0.9338051879731153\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 0.9318704004009237\t 0.7386468688809501\t 0.933334069213192\t 0.933334069213192\n",
            "3  \t [7.35353694 6.03494644 5.         0.7919799  3.         0.96282991]\t 0.7646755003247829\t 0.7386468688809501\t 0.9408264992321298\t 0.9408264992321298\n",
            "4  \t [7.54305951 2.10732392 5.         0.87446419 8.         0.37589556]\t 0.8108923609041201\t 0.7386468688809501\t 0.9371189647314604\t 0.9371189647314604\n",
            "5  \t [0.         0.06259682 8.75991068 0.5        1.75991068 0.1       ]\t 0.946529991171609\t 0.7386468688809501\t 0.9363570710472993\t 0.9363570710472923\n",
            "6  \t [ 5.27267456  6.24821294  7.          0.59222531 19.          0.47393711]\t 0.8291149350544922\t 0.7386468688809501\t 0.942006609818678\t 0.942006609818678\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 0.8530932869908747\t 0.7386468688809501\t 0.9416557102520409\t 0.9416557102520409\n",
            "8  \t [ 4.89047813  0.23370061 11.          0.76838416 19.          0.70607293]\t 0.7459015779731059\t 0.7386468688809501\t 0.9422415719967246\t 0.9422415719967246\n",
            "9  \t [0.75623385 3.14055399 6.         0.5417671  8.         0.78866556]\t 0.7758028719550957\t 0.7386468688809501\t 0.9390315617828859\t 0.9390315617828859\n",
            "10 \t [ 5.96287383  6.08688836  6.          0.8615467  13.          0.92804086]\t 0.7417596476834711\t 0.7386468688809501\t 0.9375984490373268\t 0.9375984490373268\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 0.9369155032359574\t 0.7386468688809501\t 0.9352182499031394\t 0.9352182499031394\n",
            "12 \t [0.15776536 8.02750992 5.         0.65248282 3.         0.71659731]\t 0.7752392265192147\t 0.7386468688809501\t 0.9385373419145869\t 0.9385373419145869\n",
            "13 \t [ 0.31984184  8.77960419  5.          0.79374224 16.          0.99761184]\t 0.7565632331819597\t 0.7386468688809501\t 0.9372261761830314\t 0.9372261761830314\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7644930642703252\t 0.7386468688809501\t 0.935544239777465\t 0.935544239777465\n",
            "15 \t [ 7.9550271   0.40017786 11.          0.62618445  2.          0.8802895 ]\t 0.7651166039066666\t 0.7386468688809501\t 0.934293445756047\t 0.934293445756047\n",
            "16 \t [ 0.21685405  7.71152333 13.          0.94772928  9.          0.78016857]\t 0.745641428580208\t 0.7386468688809501\t 0.9332672626464986\t 0.9332672626464986\n",
            "17 \t [1.68476972 5.2908721  8.         0.92839616 1.         0.96471758]\t 0.7413177424377804\t 0.7386468688809501\t 0.9313331044073446\t 0.9313331044073446\n",
            "18 \t [ 1.11955444  5.11272894 10.          0.77604051 14.          0.40977672]\t 0.8088933131983232\t 0.7386468688809501\t 0.9326120485010275\t 0.9326120485010275\n",
            "19 \t [ 9.68760652  2.49858493  5.          0.84574421 13.          0.33692235]\t 0.8343379491664138\t 0.7386468688809501\t 0.934480887739196\t 0.934480887739196\n",
            "20 \t [ 5.68575652  2.73061603 14.          0.61811388 15.          0.91855302]\t 0.7533258737467465\t 0.7386468688809501\t 0.9331997521166255\t 0.9331997521166255\n",
            "21 \t [ 9.72376714  9.82517342 14.          0.96896704 10.          0.66715413]\t 0.7442263922491208\t 0.7386468688809501\t 0.930660889478256\t 0.930660889478256\n",
            "22 \t [ 3.42988222  3.60806268 11.          0.65919672 19.          0.15600267]\t 0.9354453567539931\t 0.7386468688809501\t 0.937451998198265\t 0.937451998198265\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 3.79839517  0.81425404  8.          0.93236393 16.          0.87681693]\u001b[0m\t \u001b[1m\u001b[92m0.7341701271899448\u001b[0m\t \u001b[1m\u001b[92m0.7341701271899448\u001b[0m\t \u001b[1m\u001b[92m0.9378199790670692\u001b[0m\t \u001b[1m\u001b[92m0.9378199790670692\u001b[0m\n",
            "24 \t [ 8.81072016  8.73430439 14.          0.88099125 15.          0.62076623]\t 0.7615233543871561\t 0.7341701271899448\t 0.9309622670672841\t 0.9309622670672841\n",
            "25 \t [ 9.97471031  7.71725552  9.          0.75893438 14.          0.97108888]\t 0.7458665279787168\t 0.7341701271899448\t 0.927698576726773\t 0.927698576726773\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.7500814347067293\t 0.7341701271899448\t 0.9355260264544987\t 0.9355260264544987\n",
            "27 \t [4.30702998 1.603885   6.         0.67957661 1.         0.65896812]\t 0.7722507414442762\t 0.7341701271899448\t 0.9259259467849462\t 0.9259259467849462\n",
            "28 \t [ 0.42024221  1.80970657 14.          0.62730009  9.          0.87538064]\t 0.7568866482811789\t 0.7341701271899448\t 0.9281620817569388\t 0.9281620817569388\n",
            "29 \t [ 0.90304843  2.51853     6.          0.79766891 19.          0.81718316]\t 0.7555224179462046\t 0.7341701271899448\t 0.931242713288684\t 0.931242713288684\n",
            "30 \t [ 5.78896087  1.38910732 11.          0.78824775 11.          0.75054695]\t 0.7424940471862941\t 0.7341701271899448\t 0.9218466342948042\t 0.9218466342948042\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60746.65105051846"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f73b9c0-591b-4d51-9b7d-250221da7e9b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.9157817005982263\t 0.8490988745111359\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.8517975125315337\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.8490988745111359\t 0.8490988745111359\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.9839177202713774\t 0.8490988745111359\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.9688138526063573\t 0.8490988745111359\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m0.7933779577878181\u001b[0m\t \u001b[1m\u001b[92m1.0618732927207701\u001b[0m\t \u001b[1m\u001b[92m1.0618732927207701\u001b[0m\n",
            "2  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0080537575046533\t 0.7933779577878181\t 1.0099054026731076\t 1.009905402673072\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 9.58514067  5.7670966   7.          0.86943542 19.          0.83320355]\u001b[0m\t \u001b[1m\u001b[92m0.781886335686165\u001b[0m\t \u001b[1m\u001b[92m0.781886335686165\u001b[0m\t \u001b[1m\u001b[92m1.017317479263767\u001b[0m\t \u001b[1m\u001b[92m1.017317479263767\u001b[0m\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 0.60781829  7.94471276 14.          0.95131596 14.          0.78401217]\u001b[0m\t \u001b[1m\u001b[92m0.7787563738340587\u001b[0m\t \u001b[1m\u001b[92m0.7787563738340587\u001b[0m\t \u001b[1m\u001b[92m1.0016663176864231\u001b[0m\t \u001b[1m\u001b[92m1.0016663176864231\u001b[0m\n",
            "5  \t [1.25559631 9.8394609  9.         0.52015567 2.         0.32958416]\t 0.9931478086626242\t 0.7787563738340587\t 0.9937940051285623\t 0.9937940051285623\n",
            "6  \t [ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\t 0.8411431281498688\t 0.7787563738340587\t 0.9989892834235689\t 0.9989892834235689\n",
            "7  \t [ 8.76024687  1.86904876 14.          0.55121848 17.          0.91994165]\t 0.779442423558543\t 0.7787563738340587\t 0.9966613268665941\t 0.9966613268665941\n",
            "8  \t [1.55796941 0.         5.59658742 0.5        9.59658742 0.1       ]\t 1.0047151348383163\t 0.7787563738340587\t 0.9928003216711299\t 0.9928003126508902\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.8472224210855768\t 0.7787563738340587\t 0.9973247710368024\t 0.9973247710368024\n",
            "10 \t [ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\t 0.786526849407035\t 0.7787563738340587\t 0.9959236053259408\t 0.9959236053259408\n",
            "11 \t [ 0.10472305  8.04212015  6.          0.60521977 17.          0.5035541 ]\t 0.8662205350111943\t 0.7787563738340587\t 0.993055055161085\t 0.993055055161085\n",
            "12 \t [ 8.76507252  8.76898373 14.          0.51356786  6.          0.73624795]\t 0.8509923386963646\t 0.7787563738340587\t 0.9924273069851592\t 0.9924273069851592\n",
            "13 \t [ 7.2491093   8.84547315 13.          0.7630811  16.          0.49959824]\t 0.9157012741023042\t 0.7787563738340587\t 0.9916761554508476\t 0.9916761554508476\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[ 9.13024626  9.27282591  6.          0.97862401 10.          0.91486977]\u001b[0m\t \u001b[1m\u001b[92m0.7671108242435751\u001b[0m\t \u001b[1m\u001b[92m0.7671108242435751\u001b[0m\t \u001b[1m\u001b[92m0.9926257900986002\u001b[0m\t \u001b[1m\u001b[92m0.9926257900986002\u001b[0m\n",
            "15 \t [ 0.07228431  8.49050584 13.          0.76584781 19.          0.11586428]\t 1.0043179667298694\t 0.7671108242435751\t 0.9813043317022584\t 0.9813043317022584\n",
            "16 \t [ 3.79151097  4.0129324  10.          0.78656319  9.          0.57380624]\t 0.8479506527275633\t 0.7671108242435751\t 0.9842107674816002\t 0.9842107674816002\n",
            "17 \t [6.53156572 9.72376072 9.         0.51610543 1.         0.4929146 ]\t 0.9514823488789619\t 0.7671108242435751\t 0.9829637665972324\t 0.9829637665972324\n",
            "18 \t [ 3.19241925  2.91302128 11.          0.905155   18.          0.71674806]\t 0.812855948594331\t 0.7671108242435751\t 0.9888307967182048\t 0.9888307967182048\n",
            "19 \t [ 6.92673077  1.23845568 10.          0.63463476  8.          0.28240746]\t 0.9737154587401665\t 0.7671108242435751\t 0.9913715345476266\t 0.9913715345476266\n",
            "20 \t [ 2.26812476  6.7571478  13.          0.87941648  6.          0.30778351]\t 0.9759301877372604\t 0.7671108242435751\t 0.9896253715296064\t 0.9896253715296064\n",
            "21 \t [3.55931421 6.11594845 5.         0.61644063 6.         0.25613129]\t 0.9760064198467848\t 0.7671108242435751\t 0.9890479992341511\t 0.9890479992341511\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 5.73129906  9.2176475  11.          0.8835332   4.          0.9298239 ]\u001b[0m\t \u001b[1m\u001b[92m0.7642724935254156\u001b[0m\t \u001b[1m\u001b[92m0.7642724935254156\u001b[0m\t \u001b[1m\u001b[92m0.9874538317935764\u001b[0m\t \u001b[1m\u001b[92m0.9874538317935764\u001b[0m\n",
            "23 \t [2.36161323 4.19936331 9.         0.73250204 1.         0.79018905]\t 0.8150370035678787\t 0.7642724935254156\t 0.9883704838913193\t 0.9883704838913193\n",
            "24 \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]\t 0.9941403780835223\t 0.7642724935254156\t 0.9934374919112692\t 0.9934374919112692\n",
            "25 \t [ 9.70148981  3.84860271 14.          0.8648022   1.          0.77351018]\t 0.8176855829782234\t 0.7642724935254156\t 0.9888735528122281\t 0.9888735528122281\n",
            "26 \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\t 0.7746854783898445\t 0.7642724935254156\t 0.9833035490551998\t 0.9833035490551998\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.8184668279349161\t 0.7642724935254156\t 0.9867914782932212\t 0.9867914782932212\n",
            "28 \t [ 4.9644812   1.12270948  6.          0.71065886 17.          0.26866166]\t 0.9667438219230509\t 0.7642724935254156\t 0.9885442793283463\t 0.9885442793283463\n",
            "29 \t [ 6.25409576  9.66919464  9.          0.55640442 19.          0.48201317]\t 0.9294172904381902\t 0.7642724935254156\t 0.9853959650026983\t 0.9853959650026983\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[5.55301534 4.43776121 9.         0.77874612 6.         0.99491253]\u001b[0m\t \u001b[1m\u001b[92m0.7585656248465545\u001b[0m\t \u001b[1m\u001b[92m0.7585656248465545\u001b[0m\t \u001b[1m\u001b[92m0.9845834901061138\u001b[0m\t \u001b[1m\u001b[92m0.9845834901061138\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62513.455753809474"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6605c1-1c96-4334-8a72-3569c6e65a4a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.1001019572672721\t 0.8205570570239384\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.0968690738660336\t 0.8205570570239384\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.8205570570239384\t 0.8205570570239384\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0984076753833096\t 0.8205570570239384\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8540219347978375\t 0.8205570570239384\t    \t    \n",
            "1  \t [4.88873245 9.27936348 6.         0.94344906 8.         0.25949204]\t 0.9493824618206954\t 0.8205570570239384\t 1.0781785092241796\t 1.0781785092241796\n",
            "2  \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]\t 1.1006737709479968\t 0.8205570570239384\t 1.0743020477741974\t 1.0743020477741974\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0951088390242933\t 0.8205570570239384\t 1.0815045845173918\t 1.0815045845173918\n",
            "4  \t [2.8109707  8.5584448  5.         0.58095261 1.         0.63920091]\t 0.8313480595740355\t 0.8205570570239384\t 1.086519856497887\t 1.086519856497887\n",
            "5  \t [ 0.24010242  9.80847714 13.          0.63702721  3.          0.56729929]\t 0.8241986609721416\t 0.8205570570239384\t 1.077809013054612\t 1.077809013054612\n",
            "6  \t [ 9.64653748  6.72353381  8.          0.90513452 12.          0.37287596]\t 0.9460821806843785\t 0.8205570570239384\t 1.0704933893644744\t 1.0704933893644744\n",
            "7  \t [8.71334312 0.05751618 6.         0.96160691 6.         0.14416297]\t 1.099780473093716\t 0.8205570570239384\t 1.06893325043495\t 1.06893325043495\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[3.50549632 8.04483305 8.         0.95341936 1.         0.79512535]\u001b[0m\t \u001b[1m\u001b[92m0.792713810458564\u001b[0m\t \u001b[1m\u001b[92m0.792713810458564\u001b[0m\t \u001b[1m\u001b[92m1.0735846937105449\u001b[0m\t \u001b[1m\u001b[92m1.0735846937105449\u001b[0m\n",
            "9  \t [9.68641233 7.7212035  5.         0.60078619 2.         0.57796031]\t 0.8398283365570345\t 0.792713810458564\t 1.046044520959063\t 1.046044520959063\n",
            "10 \t [ 2.71723833  2.08347502  5.          0.57784675 10.          0.79058878]\t 0.8140934540169763\t 0.792713810458564\t 1.0418724250907514\t 1.0418724250907514\n",
            "11 \t [0.37792975 2.0218935  5.         0.52559515 2.30166725 0.1       ]\t 1.1035523752824918\t 0.792713810458564\t 1.0375727449634233\t 1.0375727449634233\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.7986988788225304\t 0.792713810458564\t 1.041939879673749\t 1.041939879673749\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 4.62595246  0.8232495  14.          0.57883859 18.          0.96402221]\u001b[0m\t \u001b[1m\u001b[92m0.7902358770996643\u001b[0m\t \u001b[1m\u001b[92m0.7902358770996643\u001b[0m\t \u001b[1m\u001b[92m1.0375021234027193\u001b[0m\t \u001b[1m\u001b[92m1.0375021234027193\u001b[0m\n",
            "14 \t [ 0.68308523  3.05829619  5.          0.71250074 17.          0.5517841 ]\t 0.8259670617924225\t 0.7902358770996643\t 1.0320853684136682\t 1.0320853684136682\n",
            "15 \t [ 9.51708919  0.58391709 12.          0.88753946  6.          0.24646931]\t 1.099594508712044\t 0.7902358770996643\t 1.0286521943062845\t 1.0286521943062845\n",
            "16 \t [ 9.86273212  5.79963604 13.          0.69696961 16.          0.70097151]\t 0.7997906121728535\t 0.7902358770996643\t 1.0327377061019487\t 1.0327377061019487\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 1.10659828  9.06323562  6.          0.78045487 14.          0.88521866]\u001b[0m\t \u001b[1m\u001b[92m0.784416787160292\u001b[0m\t \u001b[1m\u001b[92m0.784416787160292\u001b[0m\t \u001b[1m\u001b[92m1.0299122445905244\u001b[0m\t \u001b[1m\u001b[92m1.0299122445905244\u001b[0m\n",
            "18 \t [ 8.50267404  2.17033522  6.          0.50604942 19.          0.82390736]\t 0.81342047359141\t 0.784416787160292\t 1.0236938008483685\t 1.0236938008483685\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8394856040419147\t 0.784416787160292\t 1.0233952194014426\t 1.0233952194014426\n",
            "20 \t [ 4.6450566   0.          5.33952552  0.5        15.33952552  0.1       ]\t 1.1052475346010042\t 0.784416787160292\t 1.0182820229660179\t 1.018282017665546\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 4.64864154  8.87598512 13.          0.88153635  6.          0.95606382]\u001b[0m\t \u001b[1m\u001b[92m0.7749641578984813\u001b[0m\t \u001b[1m\u001b[92m0.7749641578984813\u001b[0m\t \u001b[1m\u001b[92m1.0208815900638604\u001b[0m\t \u001b[1m\u001b[92m1.0208815900638604\u001b[0m\n",
            "22 \t [ 1.72284944  3.60586849 11.          0.66060764 19.          0.20496895]\t 1.0986312231816027\t 0.7749641578984813\t 1.0147052127714276\t 1.0147052127714276\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8627583512307193\t 0.7749641578984813\t 1.0219447661795187\t 1.0219447661795187\n",
            "24 \t [7.31522244 5.66276563 8.         0.72233105 6.         0.34066511]\t 0.9488616299798448\t 0.7749641578984813\t 1.0180074179622252\t 1.0180074179622252\n",
            "25 \t [ 3.76231631  7.22695293  6.          0.99331542 15.          0.98845508]\t 0.7859921669897617\t 0.7749641578984813\t 1.017663563659669\t 1.017663563659669\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 5.14922359  3.99125459 13.          0.75235058 15.          0.80541007]\u001b[0m\t \u001b[1m\u001b[92m0.7727600972953066\u001b[0m\t \u001b[1m\u001b[92m0.7727600972953066\u001b[0m\t \u001b[1m\u001b[92m1.0135297123892628\u001b[0m\t \u001b[1m\u001b[92m1.0135297123892628\u001b[0m\n",
            "27 \t [ 9.34898446  5.34322646 13.          0.67871499  9.          0.59530523]\t 0.814738168073687\t 0.7727600972953066\t 1.0079204106030375\t 1.0079204106030375\n",
            "28 \t [ 9.01763405  8.9342346  11.          0.78253186 14.          0.5899614 ]\t 0.8008497075757127\t 0.7727600972953066\t 1.009195364353798\t 1.009195364353798\n",
            "29 \t [ 8.92640491  5.86829423 11.          0.69146564 16.          0.20693725]\t 1.095967263497375\t 0.7727600972953066\t 1.0050612497037723\t 1.0050612497037723\n",
            "30 \t [6.73898941 3.54735303 5.         0.70575667 2.         0.14846127]\t 1.0942930452502178\t 0.7727600972953066\t 1.0111435127848916\t 1.0111435127848916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59806.801758392685"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdDTsSEtNuf-",
        "outputId": "907d66c6-2a55-45d0-c4b8-5752cb59653e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7650622398140196\t 0.7505823286451517\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7710732234684645\t 0.7505823286451517\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 1.127900018061083\t 0.7505823286451517\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.7505823286451517\t 0.7505823286451517\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.9579573664970923\t 0.7505823286451517\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 1.1269429525174437\t 0.7505823286451517\t 0.9728582294431205\t 0.9728582294431205\n",
            "2  \t [ 8.38710697  4.03810262 13.          0.67620396  7.          0.21955781]\t 1.129364536434021\t 0.7505823286451517\t 0.992763038272654\t 0.992763038272654\n",
            "3  \t [7.47521879 1.08446649 5.         0.82092246 1.         0.87686231]\t 0.7774252651714006\t 0.7505823286451517\t 1.0068048565962269\t 1.0068048565962269\n",
            "4  \t [ 1.21913591  5.39021078 12.          0.52306788  2.          0.57375676]\t 0.8175628207948187\t 0.7505823286451517\t 0.9971736203804549\t 0.9971736203804549\n",
            "5  \t [0.  0.  5.  0.5 1.  0.1]\t 1.1272044052520684\t 0.7505823286451517\t 0.9913208939481808\t 0.9913208938391448\n",
            "6  \t [ 9.06307728  4.86114267 13.          0.58554955 19.          0.71395167]\t 0.7663633049670207\t 0.7505823286451517\t 1.0012279228123526\t 1.0012279228123526\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.8044591218487582\t 0.7505823286451517\t 0.9943153987593247\t 0.9943153987593247\n",
            "8  \t [ 0.97097474  0.01976884  5.83446925  0.55815311 11.74316558  0.1       ]\t 1.1224498314743827\t 0.7505823286451517\t 0.9897189705639363\t 0.9897189705639295\n",
            "9  \t [ 1.11038107  0.47615514 11.          0.89886404  7.          0.4182336 ]\t 0.856011038154356\t 0.7505823286451517\t 0.9972946628103726\t 0.9972946628103726\n",
            "10 \t [ 3.07807355  8.11709345  7.          0.6375573  19.          0.82418508]\t 0.7831232773234176\t 0.7505823286451517\t 0.9946461236935203\t 0.9946461236935203\n",
            "11 \t [ 8.70159525  5.9637615  11.          0.74540579 12.          0.86209737]\t 0.7628779305698078\t 0.7505823286451517\t 0.9904007945656691\t 0.9904007945656691\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.7753874640601797\t 0.7505823286451517\t 0.9861823182846042\t 0.9861823182846042\n",
            "13 \t [ 1.7362541   5.97112729 13.          0.63266105 15.          0.64795059]\t 0.7682506610307644\t 0.7505823286451517\t 0.9827333102665597\t 0.9827333102665597\n",
            "14 \t [ 2.08775457  7.02338406 10.          0.93711543  6.          0.24688511]\t 1.1273094322038202\t 0.7505823286451517\t 0.9794845296326419\t 0.9794845296326419\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.8233136201842758\t 0.7505823286451517\t 0.9853584859603061\t 0.9853584859603061\n",
            "16 \t [ 4.96117219  0.19149034 14.          0.77604099 18.          0.36193386]\t 0.9491548702672767\t 0.7505823286451517\t 0.9834677777951297\t 0.9834677777951297\n",
            "17 \t [3.55913665 1.752351   8.         0.70851016 3.         0.2473213 ]\t 1.1312533914126544\t 0.7505823286451517\t 0.9842403597200441\t 0.9842403597200441\n",
            "18 \t [ 5.7913209   0.66562836 12.          0.88967575 12.          0.45276187]\t 0.8489279760422116\t 0.7505823286451517\t 0.9913438579645814\t 0.9913438579645814\n",
            "19 \t [ 2.28250676  8.57781075 10.          0.71780124 12.          0.3772521 ]\t 0.8627736627545619\t 0.7505823286451517\t 0.9887949827310741\t 0.9887949827310741\n",
            "20 \t [ 7.39797184  8.7826296  13.          0.53377308 19.          0.69293054]\t 0.7675713222438754\t 0.7505823286451517\t 0.9881106093700113\t 0.9881106093700113\n",
            "21 \t [ 8.38684604  2.03564345  5.          0.88957543 17.          0.94491074]\t 0.7639768007614606\t 0.7505823286451517\t 0.9838092809437541\t 0.9838092809437541\n",
            "22 \t [ 0.34343537  0.75830465 14.          0.57372847 18.          0.51234475]\t 0.7987111680789081\t 0.7505823286451517\t 0.9855039890011227\t 0.9855039890011227\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 1.1250394819981728\t 0.7505823286451517\t 0.9804539000490461\t 0.9804539000490461\n",
            "24 \t [5.87233788 6.93253231 8.         0.71079844 3.         0.57913783]\t 0.7993682157943708\t 0.7505823286451517\t 0.9858664859757256\t 0.9858664859757256\n",
            "25 \t [9.14387233 8.82409497 7.         0.87227821 8.         0.52464991]\t 0.7895388146683674\t 0.7505823286451517\t 0.9841292069589197\t 0.9841292069589197\n",
            "26 \t [3.60524491 1.19236957 9.         0.73012056 6.         0.89243922]\t 0.7693194850407705\t 0.7505823286451517\t 0.9846908920791367\t 0.9846908920791367\n",
            "27 \t [ 4.49307362  3.04333385  6.          0.66403041 14.          0.6962521 ]\t 0.7745150970768204\t 0.7505823286451517\t 0.9787517389431396\t 0.9787518408155905\n",
            "28 \t [ 9.66783768  8.10064412 14.          0.62265803  5.          0.39317258]\t 0.8744920899085123\t 0.7505823286451517\t 0.9775908163539603\t 0.9775908163539603\n",
            "29 \t [ 8.18178764  9.98869521 14.          0.83418368 10.          0.41151726]\t 0.8537499901780559\t 0.7505823286451517\t 0.9760611399987703\t 0.9760611399987703\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 1.40912589  1.93204629 14.          0.88642674  6.          0.63288273]\u001b[0m\t \u001b[1m\u001b[92m0.7488234092324056\u001b[0m\t \u001b[1m\u001b[92m0.7488234092324056\u001b[0m\t \u001b[1m\u001b[92m0.9765121058394821\u001b[0m\t \u001b[1m\u001b[92m0.9765121058394821\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61608.55586827657"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5484dcd8-233d-47de-ecbf-953d45d38b4f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7978949387548113\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7689238087022429\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9009085979032214\t 0.7689238087022429\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.9616956128686873\t 0.7689238087022429\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.8968042534595716\t 0.7689238087022429\t    \t    \n",
            "1  \t [0.12369412 8.59706887 7.         0.73916952 1.         0.56326417]\t 0.8174537431547186\t 0.7689238087022429\t 0.9742106670178746\t 0.9742106670178746\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9657302753232895\t 0.7689238087022429\t 0.9713604364644681\t 0.9713604364644681\n",
            "3  \t [0.40431765 1.0477683  5.         0.5        7.66897557 0.1       ]\t 0.9791274079412189\t 0.7689238087022429\t 0.978893533356427\t 0.9788935333564263\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.961106002845105\t 0.7689238087022429\t 0.9881244975109478\t 0.9881244975109478\n",
            "5  \t [ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\t 0.7812267618464406\t 0.7689238087022429\t 0.9892753337923819\t 0.9892753337923819\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6983890373172288\u001b[0m\t \u001b[1m\u001b[92m0.6983890373172288\u001b[0m\t \u001b[1m\u001b[92m0.984668188291511\u001b[0m\t \u001b[1m\u001b[92m0.9846681882588718\u001b[0m\n",
            "7  \t [ 0.21271144  2.1876624  12.          0.54947319  1.          0.2251972 ]\t 0.9806349783557413\t 0.6983890373172288\t 0.9237425394530525\t 0.9237425394530525\n",
            "8  \t [ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\t 0.7060994227407983\t 0.6983890373172288\t 0.9283189650113111\t 0.9283189650113514\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9684252162072007\t 0.6983890373172288\t 0.922907587205523\t 0.922907587205523\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.7212789829160808\t 0.6983890373172288\t 0.92645575650482\t 0.92645575650482\n",
            "11 \t [6.22509123 2.58001899 5.         0.88395827 2.         0.12704608]\t 0.9721917237916324\t 0.6983890373172288\t 0.9222619395543384\t 0.9222619395543384\n",
            "12 \t [ 0.49416106  7.25080418  6.          0.86593272 15.          0.18239415]\t 0.9681667382285498\t 0.6983890373172288\t 0.9255100275444386\t 0.9255100275444386\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9827144549301592\t 0.6983890373172288\t 0.9282702774685372\t 0.928270276674163\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.7343751804493104\t 0.6983890373172288\t 0.9317746363423169\t 0.9317746363423169\n",
            "15 \t [ 0.25930711  3.55471756  9.          0.55258914 13.          0.38425071]\t 0.8698615740055157\t 0.6983890373172288\t 0.9290639136119435\t 0.9290639136119435\n",
            "16 \t [5.30961885 6.55500461 5.         0.71406005 9.         0.48551501]\t 0.8740132634042277\t 0.6983890373172288\t 0.9286974894269749\t 0.9286974894269749\n",
            "17 \t [3.35483601 6.04519575 9.         0.66543363 5.         0.97731627]\t 0.7137833679191798\t 0.6983890373172288\t 0.9299599534815802\t 0.9299599534815802\n",
            "18 \t [ 6.81824956  0.34511024  6.          0.68216555 12.          0.49718858]\t 0.8681631536247483\t 0.6983890373172288\t 0.931943013511269\t 0.931943013511269\n",
            "19 \t [ 2.91927839  7.3392069   6.          0.85847684 14.          0.50487035]\t 0.7952024688472059\t 0.6983890373172288\t 0.9250934159285564\t 0.9250934159285564\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7650562704693341\t 0.6983890373172288\t 0.931390080726031\t 0.931390080726031\n",
            "21 \t [ 3.87687792  9.24471285 10.          0.79467506 14.          0.58974564]\t 0.7875791905388638\t 0.6983890373172288\t 0.9269706259814366\t 0.9269706259814366\n",
            "22 \t [4.07754006 0.11652617 9.         0.95821235 4.         0.97462432]\t 0.7180491944002949\t 0.6983890373172288\t 0.9220281644661652\t 0.9220281644661652\n",
            "23 \t [ 8.85833446  6.12544872 14.          0.9709687  16.          0.80797559]\t 0.7341207450419127\t 0.6983890373172288\t 0.9275148388190928\t 0.9275148388190928\n",
            "24 \t [ 2.58093922  2.05616509  5.60286566  0.5        16.04395614  0.52976027]\t 0.8288149295309672\t 0.6983890373172288\t 0.914693837757065\t 0.9146944926570609\n",
            "25 \t [ 2.60956706  4.4745251   9.          0.69330349 17.          0.83988084]\t 0.7495093963493484\t 0.6983890373172288\t 0.9173239805549029\t 0.9173239805549029\n",
            "26 \t [ 0.65904826  3.00639193 10.          0.88267232 10.          0.15011078]\t 0.9700037688440479\t 0.6983890373172288\t 0.9160252741751223\t 0.9160252741751223\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 6.72997514  0.60780575 14.          0.89835235 18.          0.97859978]\u001b[0m\t \u001b[1m\u001b[92m0.6974052019541508\u001b[0m\t \u001b[1m\u001b[92m0.6974052019541508\u001b[0m\t \u001b[1m\u001b[92m0.916041259255914\u001b[0m\t \u001b[1m\u001b[92m0.916041259255914\u001b[0m\n",
            "28 \t [ 8.6598151   9.62485551  8.          0.71851231 16.          0.71522574]\t 0.7558432662300643\t 0.6974052019541508\t 0.9222293165106721\t 0.9222293165106721\n",
            "29 \t [ 9.89240609  4.6385061   5.          0.77405056 16.          0.99983452]\t 0.7196023005131863\t 0.6974052019541508\t 0.9114315308568137\t 0.9114315308568137\n",
            "30 \t [ 5.90384667  3.96200532 14.          0.84987246  4.          0.95106268]\t 0.7043006010788118\t 0.6974052019541508\t 0.9206921131753072\t 0.9206921131753072\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59612.82267483437"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i707LrINxei",
        "outputId": "e4346da0-cfae-4375-d164-3b0735ae1196"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8708842589582968\t 0.8009237324889021\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.868843701878103\t 0.8009237324889021\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.8009237324889021\t 0.8009237324889021\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.8412285708806564\t 0.8009237324889021\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0874405633037085\t 0.8009237324889021\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.077285755760575\t 0.8009237324889021\t 1.0171726820382654\t 1.0171726820382654\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.1030510584286708\t 0.8009237324889021\t 1.0312734667229346\t 1.0312734667229346\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0698458362482097\t 0.8009237324889021\t 1.0430456627740696\t 1.0430456627740696\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0952568725496277\t 0.8009237324889021\t 1.0496622076939837\t 1.0496622076939837\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m0.7880607112692197\u001b[0m\t \u001b[1m\u001b[92m1.0561667225936209\u001b[0m\t \u001b[1m\u001b[92m1.0561667225936209\u001b[0m\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.8829825605031049\t 0.7880607112692197\t 1.0382196572049611\t 1.0382196572049611\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.1024724416092895\t 0.7880607112692197\t 1.034850557046576\t 1.034850557046576\n",
            "8  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0806850045968446\t 0.7880607112692197\t 1.040617313229862\t 1.040617313229862\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0634397583136046\t 0.7880607112692197\t 1.0445265569427824\t 1.0445265569427824\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\u001b[0m\t \u001b[1m\u001b[92m0.7744953455912423\u001b[0m\t \u001b[1m\u001b[92m0.7744953455912423\u001b[0m\t \u001b[1m\u001b[92m1.047251873236831\u001b[0m\t \u001b[1m\u001b[92m1.047251873236831\u001b[0m\n",
            "11 \t [ 6.40351874  0.13565515 11.          0.58564403 18.          0.80232868]\t 0.8054080042258512\t 0.7744953455912423\t 1.0311287452898161\t 1.0311287452898161\n",
            "12 \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]\t 1.0699439848269314\t 0.7744953455912423\t 1.0266566407100377\t 1.0266566407100377\n",
            "13 \t [ 8.99192553  1.90550776  5.          0.73207647 17.          0.22584338]\t 1.0891382129882101\t 0.7744953455912423\t 1.0296156881883824\t 1.0296156881883824\n",
            "14 \t [ 2.2090794   1.72971319  6.          0.60057564 19.          0.94862894]\t 0.7876772577427523\t 0.7744953455912423\t 1.0327384208802886\t 1.0327384208802886\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 0.19887638  4.80873048 13.          0.98258992 19.          0.95584094]\u001b[0m\t \u001b[1m\u001b[92m0.7622505819201761\u001b[0m\t \u001b[1m\u001b[92m0.7622505819201761\u001b[0m\t \u001b[1m\u001b[92m1.0283663163309027\u001b[0m\t \u001b[1m\u001b[92m1.0283663163309027\u001b[0m\n",
            "16 \t [6.55109905 2.29203942 6.         0.7269974  8.         0.87997636]\t 0.7880946868581832\t 0.7622505819201761\t 1.0152497321120761\t 1.0152497321120761\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.8987315752344891\t 0.7622505819201761\t 1.0117195170749667\t 1.0117195170749667\n",
            "18 \t [0.75190021 2.99821111 7.         0.73112778 8.         0.11979456]\t 1.0909386577928757\t 0.7622505819201761\t 1.012660191225948\t 1.012660191225948\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.1009731307154418\t 0.7622505819201761\t 1.0157164699097807\t 1.0157164699097807\n",
            "20 \t [ 7.65515729  8.3524801  13.          0.94320546  2.          0.37856462]\t 0.9255377827812661\t 0.7622505819201761\t 1.0153171677892558\t 1.0153171677892558\n",
            "21 \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]\t 1.0850491230057298\t 0.7622505819201761\t 1.0224085401077507\t 1.0224085401077507\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.7871483295077344\t 0.7622505819201761\t 1.0145854743573886\t 1.0145854743573886\n",
            "23 \t [ 7.36797889  8.11394282  7.          0.58550636 12.          0.48664462]\t 0.9004861276725805\t 0.7622505819201761\t 1.0157640325820805\t 1.0157640325820805\n",
            "24 \t [8.12249915 9.52146586 8.         0.55686302 4.         0.21818921]\t 1.0775852264383317\t 0.7622505819201761\t 1.0117850402126325\t 1.0117850402126325\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.7882906269305859\t 0.7622505819201761\t 1.021664042622599\t 1.021664042622599\n",
            "26 \t [ 1.76346732  7.41255372 13.          0.55954485  5.          0.82537699]\t 0.80192465196928\t 0.7622505819201761\t 1.0109021042836763\t 1.0109021042836763\n",
            "27 \t [ 3.07145128  8.24536112 10.          0.9499357   1.          0.14212758]\t 1.1048931852017705\t 0.7622505819201761\t 1.0138847989391755\t 1.0138847989391755\n",
            "28 \t [ 3.86031457  2.79254313 11.          0.81134713  7.          0.51906134]\t 0.8669435791539841\t 0.7622505819201761\t 1.0147688892126898\t 1.0147695766418976\n",
            "29 \t [ 9.18133243  4.09376148 10.          0.96038921  5.          0.75655401]\t 0.7946263770809028\t 0.7622505819201761\t 1.0152265231378357\t 1.0152265231378357\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.8423134170816156\t 0.7622505819201761\t 1.0100297212470701\t 1.0100297212470701\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59260.747037503046"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh0IJf8zNy9E",
        "outputId": "df2a9d85-9d1f-4fe3-8555-b7555a6fdd3c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.7260880637055529\t 0.7260880637055529\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.7424588384015385\t 0.7260880637055529\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.8412720456029797\t 0.7260880637055529\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7736412232573235\t 0.7260880637055529\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.7650415360356615\t 0.7260880637055529\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.9222990750260575\t 0.7260880637055529\t 0.9030968322036044\t 0.9030968322036044\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7908681556639724\t 0.7260880637055529\t 0.9147889551710234\t 0.9147889551710234\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.7532691574021181\t 0.7260880637055529\t 0.9143518278113293\t 0.9143518278113293\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7781432084155051\t 0.7260880637055529\t 0.9120532467112259\t 0.9120532467112259\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.8455317589117171\t 0.7260880637055529\t 0.9114128028141715\t 0.9114128028141715\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.7441046132441587\t 0.7260880637055529\t 0.9138739634974152\t 0.9138739634974152\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.938335419027365\t 0.7260880637055529\t 0.9119061835675228\t 0.9119061835675228\n",
            "8  \t [ 0.46626117  2.25760624  6.          0.85367342 17.          0.48531791]\t 0.8357006200561671\t 0.7260880637055529\t 0.9176442992365856\t 0.9176442992365856\n",
            "9  \t [2.13213943 0.33619788 8.         0.65805012 9.         0.21235962]\t 1.0382579820366014\t 0.7260880637055529\t 0.9187013204006689\t 0.9187013204006689\n",
            "10 \t [ 3.23063104  1.13251329 14.          0.56093148  7.          0.35241226]\t 0.9263052453028615\t 0.7260880637055529\t 0.9268458441772504\t 0.9268458441772504\n",
            "11 \t [9.32031429 7.90309325 6.         0.69040988 5.         0.24485333]\t 1.0379873808842273\t 0.7260880637055529\t 0.9299577645436146\t 0.9299577645436146\n",
            "12 \t [7.0602652  6.93790534 9.         0.99868525 6.         0.93828193]\t 0.7346015930490536\t 0.7260880637055529\t 0.9362620355634323\t 0.9362620355634323\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.8350939262618722\t 0.7260880637055529\t 0.9334788556880398\t 0.9334788556880398\n",
            "14 \t [ 6.2861962   7.16518546 10.          0.67477466  3.          0.33961227]\t 0.9218090224938408\t 0.7260880637055529\t 0.9333918474779522\t 0.9333918474779522\n",
            "15 \t [ 0.80466258  8.06348306  7.          0.77513285 17.          0.96959926]\t 0.7407859484199237\t 0.7260880637055529\t 0.9353731086477794\t 0.9353731086477794\n",
            "16 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0415683120125263\t 0.7260880637055529\t 0.9332112123578401\t 0.9332112119683625\n",
            "17 \t [9.91439686 1.1223406  9.         0.69987447 9.         0.50079002]\t 0.7935395263864397\t 0.7260880637055529\t 0.9378111660356131\t 0.9378111660356131\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.7615889956561305\t 0.7260880637055529\t 0.9362052949416102\t 0.9362052949416102\n",
            "19 \t [ 7.50373907  5.41854764 11.          0.90174644  5.          0.21227631]\t 1.0294400573352889\t 0.7260880637055529\t 0.9341686472439374\t 0.9341686472439374\n",
            "20 \t [ 5.0541702   1.72413952  9.          0.76132059 15.          0.37444251]\t 0.9151572773679874\t 0.7260880637055529\t 0.9388428003174331\t 0.9388428003174331\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7851375921928307\t 0.7260880637055529\t 0.9475638462822173\t 0.9475638462822173\n",
            "22 \t [ 3.39029064  2.39709901 13.          0.66131557 19.          0.59343116]\t 0.7920132766777059\t 0.7260880637055529\t 0.9374089189276334\t 0.9374089189276334\n",
            "23 \t [ 4.56796849  7.2276288  12.          0.69041532 11.          0.25650596]\t 0.9204040683754566\t 0.7260880637055529\t 0.9382711704116987\t 0.9382711704116987\n",
            "24 \t [0.70527907 5.59255728 5.         0.86863619 1.         0.35457337]\t 0.9131884722416652\t 0.7260880637055529\t 0.941378190277564\t 0.941378190277564\n",
            "25 \t [2.62154521 9.82821247 5.         0.94306877 2.         0.54997602]\t 0.7884946222204549\t 0.7260880637055529\t 0.9376582900222941\t 0.9376582900222941\n",
            "26 \t [ 2.06002331  9.88106062 13.          0.81874566 19.          0.24780841]\t 1.026659800264627\t 0.7260880637055529\t 0.9398134901703604\t 0.9398134901703604\n",
            "27 \t [ 5.69797742  9.57419645  5.          0.83200529 19.          0.51994919]\t 0.7903346898520803\t 0.7260880637055529\t 0.9462070996181543\t 0.9462070996181543\n",
            "28 \t [ 7.27114604  3.7137488   9.          0.55194413 17.          0.65085645]\t 0.7913418219905086\t 0.7260880637055529\t 0.94119814998048\t 0.94119814998048\n",
            "29 \t [ 9.4564322   8.90732533 12.          0.76283199 19.          0.73059119]\t 0.7869676947248176\t 0.7260880637055529\t 0.9475576965757604\t 0.9475576965757604\n",
            "30 \t [ 0.41344076  0.53197741 10.          0.82623488 16.          0.71102663]\t 0.782525551781882\t 0.7260880637055529\t 0.9459220738047586\t 0.9459220738047586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61351.93418054509"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e428e8eb-4515-434d-e708-4181ba6744c2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.802823873653181\t 0.7393694249818598\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.7439561063387327\t 0.7393694249818598\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8573744170126428\t 0.7393694249818598\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.7605799870908501\t 0.7393694249818598\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.7393694249818598\t 0.7393694249818598\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.7341650428609557\u001b[0m\t \u001b[1m\u001b[92m0.9184544152300995\u001b[0m\t \u001b[1m\u001b[92m0.9184544152300995\u001b[0m\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8873087046852387\t 0.7341650428609557\t 0.9110238714900418\t 0.9110238714900418\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7481675054625107\t 0.7341650428609557\t 0.9183282299988084\t 0.9183282299988084\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8633824421289817\t 0.7341650428609557\t 0.9160703820186414\t 0.9160703820186414\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7484161632696045\t 0.7341650428609557\t 0.9199037557180444\t 0.9199037557180444\n",
            "6  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0139942030593216\t 0.7341650428609557\t 0.9179550794676287\t 0.9179550789588424\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8970855207140378\t 0.7341650428609557\t 0.9278028421598384\t 0.9278028421598384\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8688237885855482\t 0.7341650428609557\t 0.9309734094341054\t 0.9309734094341054\n",
            "9  \t [ 9.16110768  0.82855476 11.          0.56324568 19.          0.26608005]\t 0.8851620440332848\t 0.7341650428609557\t 0.9326293426960378\t 0.9326293426960378\n",
            "10 \t [ 6.33546486  6.1965483  14.          0.77082014  7.          0.18999946]\t 0.9988543513403749\t 0.7341650428609557\t 0.9345847323315936\t 0.9345847323315936\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[ 9.26508171  9.34518462 13.          0.88022704 15.          0.76128095]\u001b[0m\t \u001b[1m\u001b[92m0.7337975963107388\u001b[0m\t \u001b[1m\u001b[92m0.7337975963107388\u001b[0m\t \u001b[1m\u001b[92m0.9400136038909958\u001b[0m\t \u001b[1m\u001b[92m0.9400136038909958\u001b[0m\n",
            "12 \t [ 6.07416022  0.73060636  9.          0.91953118 17.          0.26381452]\t 0.859827902225879\t 0.7337975963107388\t 0.9369587159809976\t 0.9369587159809976\n",
            "13 \t [8.84715023 2.54200416 9.         0.79480608 3.         0.41227405]\t 0.8010874238977076\t 0.7337975963107388\t 0.9376095088500763\t 0.9376095088500763\n",
            "14 \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]\t 1.0049152342399188\t 0.7337975963107388\t 0.9367491597429933\t 0.9367491597429933\n",
            "15 \t [ 4.87514922  0.84022954  6.58560095  0.5        10.14312769  0.1       ]\t 1.009284871352286\t 0.7337975963107388\t 0.9411138300960618\t 0.9411138300915672\n",
            "16 \t [ 7.9422818   9.38756024  5.          0.82722729 18.          0.59098418]\t 0.7800852402921715\t 0.7337975963107388\t 0.9449878675081487\t 0.9449878675081487\n",
            "17 \t [ 2.12586208  4.01516793 14.          0.99753944  1.          0.59182746]\t 0.7780815499248835\t 0.7337975963107388\t 0.9433215854035161\t 0.9433215854035161\n",
            "18 \t [ 1.35322101  2.96172691 10.          0.82171324  9.          0.2070415 ]\t 0.9980631943644411\t 0.7337975963107388\t 0.9545768794972161\t 0.9545768794972161\n",
            "19 \t [ 1.24817982  5.75156112 12.          0.56532786 19.          0.40494625]\t 0.8074218603040494\t 0.7337975963107388\t 0.9483355532128456\t 0.9483355532128456\n",
            "20 \t [ 8.93418131  3.3975571  13.          0.55371621 13.          0.77332285]\t 0.7567538981032991\t 0.7337975963107388\t 0.9478933347013513\t 0.9478933347013513\n",
            "21 \t [ 4.96181193  2.91089923  6.          0.69167509 15.          0.83383245]\t 0.7443970340307106\t 0.7337975963107388\t 0.9387043472068178\t 0.9387043472068178\n",
            "22 \t [ 3.36538587  9.88859923 13.          0.74640712 14.          0.34166583]\t 0.869979050273399\t 0.7337975963107388\t 0.9436223211919991\t 0.9436223211919991\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7442995610019533\t 0.7337975963107388\t 0.9428175143056947\t 0.9428175143056947\n",
            "24 \t [ 1.01106536  1.91323701  8.          0.85516417 17.          0.54957799]\t 0.7640063361557158\t 0.7337975963107388\t 0.9451886457788292\t 0.9451886457788292\n",
            "25 \t [0.16001103 3.6224827  6.         0.58145757 6.         0.34057575]\t 0.8853726892659874\t 0.7337975963107388\t 0.9354150669365848\t 0.9354150669365848\n",
            "26 \t [ 3.21551212  3.04157433  6.          0.9055065  17.          0.2304952 ]\t 0.9897503949395169\t 0.7337975963107388\t 0.9381373144249925\t 0.9381373144249925\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8013428795907425\t 0.7337975963107388\t 0.9390740319393185\t 0.9390740319393185\n",
            "28 \t [ 5.29841112  4.74245374 11.          0.68146799 19.          0.79014882]\t 0.7439831766925111\t 0.7337975963107388\t 0.9443144155173211\t 0.9443144155173211\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.7400612177024872\t 0.7337975963107388\t 0.9443021079002444\t 0.9443021079002444\n",
            "30 \t [ 6.13227177  4.9471251  12.          0.70151646  5.          0.22031339]\t 1.0026563027674915\t 0.7337975963107388\t 0.9412253841884445\t 0.9412253841884445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59918.08173896548"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632e11a2-4842-4e07-e399-42081403b022"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 1.1242573295906948\t 0.7785306461595496\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 1.1029639839305116\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.7785306461595496\t 0.7785306461595496\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.8502721808074817\t 0.7785306461595496\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.8007936005920335\t 0.7785306461595496\t    \t    \n",
            "1  \t [ 4.77974014  4.35555465  8.          0.84383705 19.          0.93268007]\t 0.7891134450771025\t 0.7785306461595496\t 1.0196136903897774\t 1.0196136903897774\n",
            "2  \t [ 8.16285902  8.43489929  9.          0.96605421 10.          0.79940153]\t 0.8233816089104812\t 0.7785306461595496\t 1.008913547842395\t 1.008913547842395\n",
            "3  \t [8.19160056 1.69229937 5.         0.74091229 2.         0.59984694]\t 0.8904551452213092\t 0.7785306461595496\t 1.003091974109823\t 1.003091974109823\n",
            "4  \t [ 0.82366685  2.07619267 13.          0.77138611 14.          0.7500631 ]\t 0.8452315111428017\t 0.7785306461595496\t 1.0022125218138418\t 1.0022125218138418\n",
            "5  \t [ 7.63204032  6.91059507 14.          0.55138009 18.          0.62463808]\t 0.8742528386161273\t 0.7785306461595496\t 0.9993954068292781\t 0.9993954068292781\n",
            "6  \t [1.77268072 0.55805065 5.         0.58527637 6.         0.74360757]\t 0.8747713068731116\t 0.7785306461595496\t 0.9983589211371396\t 0.9983589211371396\n",
            "7  \t [2.35864247 8.39991483 7.         0.84216076 6.         0.97103779]\t 0.7968809318910697\t 0.7785306461595496\t 0.9975292542063275\t 0.9975292542063275\n",
            "8  \t [7.87739652 0.18270557 8.         0.51922758 8.         0.11759376]\t 1.1523167367453024\t 0.7785306461595496\t 0.9941586658573037\t 0.9941586658573037\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.9249945564098354\t 0.7785306461595496\t 1.0044036765825568\t 1.0044036765825568\n",
            "10 \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]\t 0.9694253204437654\t 0.7785306461595496\t 1.004903306680582\t 1.004903306680582\n",
            "11 \t [ 2.72183423  9.69902384 13.          0.83330411  1.          0.50869592]\t 0.8649155611168539\t 0.7785306461595496\t 1.0066932727538564\t 1.0066932727538564\n",
            "12 \t [ 1.25503618  7.60831513  7.          0.9480138  16.          0.74909318]\t 0.8360984751450318\t 0.7785306461595496\t 1.0053475820640574\t 1.0053475820640574\n",
            "13 \t [ 9.90759058  1.21564186 12.          0.74911905 17.          0.244927  ]\t 1.1408641960380992\t 0.7785306461595496\t 1.0034692635247795\t 1.0034692635247795\n",
            "14 \t [ 4.02558043  2.43101342 14.          0.52315735 18.          0.26385595]\t 1.0902851242650626\t 0.7785306461595496\t 1.0098869215224493\t 1.0098869215224493\n",
            "15 \t [ 2.61017403  0.          5.          0.5        12.          0.1       ]\t 1.144657295624582\t 0.7785306461595496\t 1.014225814981371\t 1.0142258149562982\n",
            "16 \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]\t 0.8795719018846426\t 0.7785306461595496\t 1.0196305946159336\t 1.0196305946159336\n",
            "17 \t [0.43950021 8.29523238 9.         0.76958686 4.         0.37701029]\t 0.9407116107281341\t 0.7785306461595496\t 1.0168247749443862\t 1.0168247749443862\n",
            "18 \t [ 9.83243796  9.24783475  8.          0.81909175 16.          0.38831784]\t 0.9238611230678089\t 0.7785306461595496\t 1.0180188352368897\t 1.0180188352368897\n",
            "19 \t [ 1.10074219  7.21527001 11.          0.9344949  10.          0.68007155]\t 0.8257348238483819\t 0.7785306461595496\t 1.018464178035563\t 1.018464178035563\n",
            "20 \t [ 9.4006826   2.14529633  7.          0.801278   16.          0.55170588]\t 0.8470358235896462\t 0.7785306461595496\t 1.0142864803719156\t 1.0142864803719156\n",
            "21 \t [1.74310887 0.73965133 7.50853848 0.54770236 1.         0.41289974]\t 0.9709440695338456\t 0.7785306461595496\t 1.0166475898552985\t 1.0166475363716905\n",
            "22 \t [ 0.3768638   0.98456584  9.          0.99441364 13.          0.49763585]\t 0.9210006183994057\t 0.7785306461595496\t 1.0132052525321837\t 1.0132052525321837\n",
            "23 \t [ 8.84354923  0.30921958 13.          0.61293397  5.          0.55740225]\t 0.870674006678524\t 0.7785306461595496\t 1.0228767468790132\t 1.0228767468790132\n",
            "24 \t [5.32123068 5.0235719  6.         0.74326391 5.         0.69285739]\t 0.8660849677593985\t 0.7785306461595496\t 1.0170134677614038\t 1.0170134677614038\n",
            "25 \t [ 5.67341092  9.51862022 11.          0.63162006 16.          0.7493994 ]\t 0.8472034317422935\t 0.7785306461595496\t 1.0139927559073307\t 1.0139927559073307\n",
            "26 \t [ 1.2418428   6.11106411 11.          0.60069848 19.          0.74826159]\t 0.8580944166728092\t 0.7785306461595496\t 1.0108155620350054\t 1.0108155620350054\n",
            "27 \t [4.53470958 7.69586812 7.         0.98725149 1.         0.67884522]\t 0.8425478909117624\t 0.7785306461595496\t 1.0144436094442533\t 1.0144436094442533\n",
            "28 \t [3.83388461 2.85611667 7.         0.74640655 5.         0.27473638]\t 1.0854101197025208\t 0.7785306461595496\t 1.0119496140817714\t 1.0119496140817714\n",
            "29 \t [ 5.3574592   5.42167977 11.          0.80739246  3.          0.15190636]\t 1.1426153855251038\t 0.7785306461595496\t 1.0125231775354884\t 1.0125231775354884\n",
            "30 \t [ 0.01153499  2.29531024 11.          0.50673714  7.          0.13750522]\t 1.154363103664814\t 0.7785306461595496\t 1.017582449757219\t 1.017582449757219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60590.73520973802"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fb1be3-5f67-44b1-de4b-4c9c711d856f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 1.0639310256047103\t 0.7797034870948047\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.79580179662759\t 0.7797034870948047\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7797034870948047\t 0.7797034870948047\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7990514117028104\t 0.7797034870948047\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 1.0587036817796267\t 0.7797034870948047\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m0.7741723447560037\u001b[0m\t \u001b[1m\u001b[92m1.0051863251810056\u001b[0m\t \u001b[1m\u001b[92m1.0051863251810056\u001b[0m\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.8572799307158145\t 0.7741723447560037\t 0.9916044355603245\t 0.9916044355603245\n",
            "3  \t [ 2.20772511  4.37663949 11.          0.65455258  3.          0.57545511]\t 0.7990049933887924\t 0.7741723447560037\t 0.9897011202232386\t 0.9897011202232386\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.7701333999187374\u001b[0m\t \u001b[1m\u001b[92m0.985259653564249\u001b[0m\t \u001b[1m\u001b[92m0.985259653564249\u001b[0m\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 3.75041373  9.81989522 14.          0.71370546 14.          0.97207881]\u001b[0m\t \u001b[1m\u001b[92m0.7583770586009706\u001b[0m\t \u001b[1m\u001b[92m0.7583770586009706\u001b[0m\t \u001b[1m\u001b[92m0.9773603227825991\u001b[0m\t \u001b[1m\u001b[92m0.9773603227825991\u001b[0m\n",
            "6  \t [9.5129367  9.98430937 6.         0.51699097 2.         0.32133886]\t 1.013338643136875\t 0.7583770586009706\t 0.9638842390828979\t 0.9638842390828979\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 9.67314628  9.09427799  9.          0.82851167 16.          0.96267251]\u001b[0m\t \u001b[1m\u001b[92m0.7578726678207005\u001b[0m\t \u001b[1m\u001b[92m0.7578726678207005\u001b[0m\t \u001b[1m\u001b[92m0.9708116559985612\u001b[0m\t \u001b[1m\u001b[92m0.9708116559985612\u001b[0m\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7966957629406074\t 0.7578726678207005\t 0.9666078987793897\t 0.9666078987793897\n",
            "9  \t [4.90669272 5.41685478 7.         0.5623285  6.         0.34465473]\t 0.9971149123251213\t 0.7578726678207005\t 0.9645512622307313\t 0.9645512622307313\n",
            "10 \t [3.10386854 0.50516321 5.23950994 0.57998532 1.         0.12581451]\t 1.0742081581566398\t 0.7578726678207005\t 0.9693188722046399\t 0.9693188721258976\n",
            "11 \t [ 7.42334933  7.43735147 12.          0.74628126  2.          0.54122098]\t 0.7825236551040937\t 0.7578726678207005\t 0.9761028888674581\t 0.9761028888674581\n",
            "12 \t [0.         0.         5.         0.5        7.97739825 0.1       ]\t 1.0736299079624174\t 0.7578726678207005\t 0.9735342034699968\t 0.9735342034678577\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.9748541191382067\t 0.7578726678207005\t 0.9792071715701309\t 0.9792071715701309\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.9834501292605996\t 0.7578726678207005\t 0.9814418795329674\t 0.9814418795329674\n",
            "15 \t [2.14023913 7.87482927 8.         0.56565632 3.         0.51657322]\t 0.8009512202201602\t 0.7578726678207005\t 0.9836530097286995\t 0.9836530097286995\n",
            "16 \t [9.19802512 8.95424404 8.         0.64594318 8.         0.43927889]\t 0.8589861402158071\t 0.7578726678207005\t 0.9818820676931492\t 0.9818820676931492\n",
            "17 \t [0.54815519 9.09457687 7.         0.55756737 9.         0.32110491]\t 0.9905916044645892\t 0.7578726678207005\t 0.9803261491091994\t 0.9803261491091994\n",
            "18 \t [ 0.17864568  6.30557409 14.          0.94841763 16.          0.27279561]\t 0.9675815216770769\t 0.7578726678207005\t 0.9847005132769998\t 0.9847005132769998\n",
            "19 \t [ 8.14238487  0.94959912 14.          0.64655907  3.          0.97997402]\t 0.7737935872211852\t 0.7578726678207005\t 0.996411979595332\t 0.996411979595332\n",
            "20 \t [ 5.75608238  3.36114356  7.          0.8888975  17.          0.1085544 ]\t 1.0497516119782428\t 0.7578726678207005\t 0.9820753836604432\t 0.9820753836604432\n",
            "21 \t [ 1.40673694  2.81853826  8.          0.57005206 17.          0.51239648]\t 0.7979220004395456\t 0.7578726678207005\t 0.9852280813823324\t 0.9852280813823324\n",
            "22 \t [ 7.61103017  3.62093566 13.          0.5614452  13.          0.12084556]\t 1.0727233913162242\t 0.7578726678207005\t 0.9817800513433341\t 0.9817800513433341\n",
            "23 \t [ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\t 0.7738741181601402\t 0.7578726678207005\t 0.9834199804771424\t 0.9834199804771424\n",
            "24 \t [ 8.33810851  9.8990204  14.          0.61893039  5.          0.69227045]\t 0.7823499251514459\t 0.7578726678207005\t 0.9853284611850002\t 0.9853284611850002\n",
            "25 \t [ 1.3293311   3.90781025  8.          0.63161029 11.          0.2553852 ]\t 0.9917301150886619\t 0.7578726678207005\t 0.9848642072319872\t 0.9848642072319872\n",
            "26 \t [ 9.76455747  9.71578983 14.          0.66293675 18.          0.1137209 ]\t 1.0681711815285222\t 0.7578726678207005\t 0.9860404698870653\t 0.9860404698870653\n",
            "27 \t [ 7.88167693  7.97515501  6.          0.78950848 17.          0.19131965]\t 1.0553390354056282\t 0.7578726678207005\t 0.9866924752692794\t 0.9866924752692794\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 1.0555070855921338\t 0.7578726678207005\t 0.9907158711832564\t 0.9907158711832564\n",
            "29 \t [ 7.25858886  0.05284455 11.          0.66498317  6.          0.51372905]\t 0.789614662217095\t 0.7578726678207005\t 0.9918982223605621\t 0.9918982223605621\n",
            "30 \t [ 9.44119737  4.83052802 12.          0.87311968 19.          0.35147834]\t 0.9718991207487232\t 0.7578726678207005\t 0.9927462058867218\t 0.9927462058867218\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60744.35614633767"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a0e188-24c2-4d93-9dc6-01afcbbe9fd0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.8177825188141039\t 0.7287337628426743\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.7419480115539112\t 0.7287337628426743\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.7287337628426743\t 0.7287337628426743\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7335645848611818\t 0.7287337628426743\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7441537376931249\t 0.7287337628426743\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.7482694480200888\t 0.7287337628426743\t 0.8978277980959898\t 0.8978277980959898\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.7070648622170269\u001b[0m\t \u001b[1m\u001b[92m0.8974779426504405\u001b[0m\t \u001b[1m\u001b[92m0.8974779426504405\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7598608339614092\t 0.7070648622170269\t 0.8775715630548442\t 0.8775715630548442\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 1.0312511769390245\t 0.7070648622170269\t 0.8783059225872031\t 0.8783059225872031\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.821741520088635\t 0.7070648622170269\t 0.8940038396807638\t 0.8940038396807638\n",
            "6  \t [ 4.3826391   8.63134178  8.          0.99312919 13.          0.76681566]\t 0.7209540253636189\t 0.7070648622170269\t 0.895797708088889\t 0.895797708088889\n",
            "7  \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]\t 0.7248028462146275\t 0.7070648622170269\t 0.8931080221002436\t 0.8931080221002436\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.9107534784629161\t 0.7070648622170269\t 0.8912194995900354\t 0.8912194995900354\n",
            "9  \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]\t 0.725647375042158\t 0.7070648622170269\t 0.895884283789646\t 0.895884283789646\n",
            "10 \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]\t 0.7416396014125557\t 0.7070648622170269\t 0.8941001994848723\t 0.8941001994848723\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.9287138963597805\t 0.7070648622170269\t 0.8929027642171982\t 0.8929027642171982\n",
            "12 \t [0.         6.5073192  5.         0.5        8.79303202 0.1       ]\t 1.0313740539935339\t 0.7070648622170269\t 0.8972658698500687\t 0.89726586836447\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 1.0261353862133127\t 0.7070648622170269\t 0.9042175450231951\t 0.9042175450231951\n",
            "14 \t [ 0.62966465  6.1940162  12.          0.81741232 11.          0.49382371]\t 0.8182502230736013\t 0.7070648622170269\t 0.9102549039634985\t 0.9102549039634985\n",
            "15 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0356192288020616\t 0.7070648622170269\t 0.9101779911962133\t 0.9101779911663244\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7623000424638748\t 0.7070648622170269\t 0.9157092519304947\t 0.9157092519304947\n",
            "17 \t [4.68258101 8.96288202 5.         0.97630328 6.         0.39227084]\t 0.8117335898829253\t 0.7070648622170269\t 0.9140199064715974\t 0.9140199064715974\n",
            "18 \t [3.18406715 1.58064049 6.         0.76689583 8.         0.57153508]\t 0.7563310569550799\t 0.7070648622170269\t 0.9129395410305776\t 0.9129395410305776\n",
            "19 \t [ 2.16727134  8.25338567 14.          0.51858242  5.          0.20747401]\t 1.0352571936435033\t 0.7070648622170269\t 0.9128566868927294\t 0.9128566868927294\n",
            "20 \t [9.22875209 9.1986098  9.         0.90439491 3.         0.27523226]\t 0.9230186077285822\t 0.7070648622170269\t 0.9203712746606851\t 0.9203712746606851\n",
            "21 \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]\t 0.7362063940289248\t 0.7070648622170269\t 0.9224383243756541\t 0.9224383243756541\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7433881169429852\t 0.7070648622170269\t 0.9190156621444028\t 0.9190156621444028\n",
            "23 \t [5.65101211 8.94413403 7.         0.64809449 8.         0.59228465]\t 0.7547149277921693\t 0.7070648622170269\t 0.926012930791088\t 0.926012930791088\n",
            "24 \t [ 3.1808698   6.08364786 11.          0.83908038 16.          0.30036907]\t 0.9114560559082703\t 0.7070648622170269\t 0.9177749181217264\t 0.9177749181217264\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 1.0248025279634128\t 0.7070648622170269\t 0.914689250962471\t 0.914689250962471\n",
            "26 \t [ 4.35725957  3.75495843 10.          0.8962831   7.          0.47601782]\t 0.8261521259015148\t 0.7070648622170269\t 0.9268206218020208\t 0.9268206218020208\n",
            "27 \t [ 3.02633699  5.92948093 12.          0.75060687  4.          0.57938735]\t 0.7532872744350481\t 0.7070648622170269\t 0.9203032075494192\t 0.9203032075494192\n",
            "28 \t [ 8.4194991   8.27446809 13.          0.60543789  8.          0.33710004]\t 0.9308501095030286\t 0.7070648622170269\t 0.9172850387220478\t 0.9172850387220478\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.7123414924113913\t 0.7070648622170269\t 0.9173994608509559\t 0.9173994608509559\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 8.69363194  5.58726529 10.          0.7161638  14.          0.98763741]\u001b[0m\t \u001b[1m\u001b[92m0.6964329562749413\u001b[0m\t \u001b[1m\u001b[92m0.6964329562749413\u001b[0m\t \u001b[1m\u001b[92m0.9226942052950121\u001b[0m\t \u001b[1m\u001b[92m0.9226942052950121\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60640.37138457343"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfafdc1-d797-44f1-8b5f-1faffb2ce50d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.992708970032886\t 0.7896346786115067\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.9050380263035862\t 0.7896346786115067\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.8362986807103934\t 0.7896346786115067\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7896346786115067\t 0.7896346786115067\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.9186387829358221\t 0.7896346786115067\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.8115376813007883\t 0.7896346786115067\t 1.005020528732778\t 1.005020528732778\n",
            "2  \t [ 3.78385301  2.21923666 12.          0.57141407  8.          0.55842631]\t 0.8600045769145973\t 0.7896346786115067\t 0.9994533054484285\t 0.9994533054484285\n",
            "3  \t [ 7.48458025  0.82585105 14.          0.62666135 18.          0.34757206]\t 0.9136369680693782\t 0.7896346786115067\t 0.9983202482001414\t 0.9983202482001414\n",
            "4  \t [6.38266166 3.66323517 5.         0.6972131  9.         0.47709595]\t 0.9144290525005069\t 0.7896346786115067\t 1.0004110884822648\t 1.0004110884822648\n",
            "5  \t [ 5.83217552  8.53843574 11.          0.58549752 18.          0.26781236]\t 0.9216214538529052\t 0.7896346786115067\t 1.0020723683999166\t 1.0020723683999166\n",
            "6  \t [ 3.52118615  0.23388076 12.          0.56204237  1.          0.44568429]\t 0.9442383814615898\t 0.7896346786115067\t 1.0037228867613677\t 1.0037228867613677\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 6.10107735  0.03652674 11.          0.56244485 13.          0.89741329]\u001b[0m\t \u001b[1m\u001b[92m0.7783701142125483\u001b[0m\t \u001b[1m\u001b[92m0.7783701142125483\u001b[0m\t \u001b[1m\u001b[92m1.0060100135864545\u001b[0m\t \u001b[1m\u001b[92m1.0060100135864545\u001b[0m\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.9239433760752476\t 0.7783701142125483\t 0.993290062354713\t 0.993290062354713\n",
            "9  \t [ 2.73067092  9.86029136  9.          0.98915314 11.          0.78920814]\t 0.7815140040967317\t 0.7783701142125483\t 0.994650157838224\t 0.994650157838224\n",
            "10 \t [ 0.14475494  9.8292754  12.          0.60331385  2.          0.9622215 ]\t 0.7880902159034013\t 0.7783701142125483\t 0.9915168374756214\t 0.9915168374756214\n",
            "11 \t [ 1.81539004  3.97973122 11.          0.55780808 14.          0.86016605]\t 0.8021824021652308\t 0.7783701142125483\t 0.9889616521211896\t 0.9889616521211896\n",
            "12 \t [ 0.10274077  3.67012236  6.          0.81389509 11.          0.83682267]\t 0.786862562407444\t 0.7783701142125483\t 0.9870703448170356\t 0.9870703448170356\n",
            "13 \t [ 8.71378379  5.91732489 10.          0.67395488  5.          0.37191233]\t 0.9140896924023043\t 0.7783701142125483\t 0.9850312284686619\t 0.9850312284686619\n",
            "14 \t [8.72042964 1.18098427 6.         0.87093363 1.         0.1200865 ]\t 0.978708815138663\t 0.7783701142125483\t 0.9862062427976476\t 0.9862062427976476\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9970201710934681\t 0.7783701142125483\t 0.9889101015041284\t 0.9889101015041284\n",
            "16 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0013095349981458\t 0.7783701142125483\t 0.991745608976305\t 0.9917456030700524\n",
            "17 \t [6.02563339 8.022786   5.         0.85676853 1.         0.25300442]\t 0.9124161582646213\t 0.7783701142125483\t 0.9944295184251882\t 0.9944295184251882\n",
            "18 \t [ 8.67711993  0.94245409 13.          0.97898512  7.          0.6115193 ]\t 0.8325312518402525\t 0.7783701142125483\t 1.0027571693948705\t 1.0027571693948705\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 4.82116392  7.94441114 13.          0.79896359 10.          0.94409065]\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.7656138946809342\u001b[0m\t \u001b[1m\u001b[92m0.9934073644887272\u001b[0m\t \u001b[1m\u001b[92m0.9934073644887272\u001b[0m\n",
            "20 \t [4.88722703 1.05307859 6.         0.84108367 7.         0.32451309]\t 0.9150062445310105\t 0.7656138946809342\t 0.9818240662489537\t 0.9818240662489537\n",
            "21 \t [ 4.73215091  0.85301789  5.          0.940584   18.          0.80546064]\t 0.7987217033287252\t 0.7656138946809342\t 0.9792089941104836\t 0.9792089941104836\n",
            "22 \t [ 4.22119996  7.99655483  5.          0.78307763 14.          0.79061697]\t 0.7946617241328867\t 0.7656138946809342\t 0.9866426372779706\t 0.9866426372779706\n",
            "23 \t [7.12967992 8.154614   8.         0.5156473  9.         0.21177212]\t 0.9924239421587664\t 0.7656138946809342\t 0.9822477035202604\t 0.9822477035202604\n",
            "24 \t [ 1.47973338  1.45058818 11.          0.74181509 19.          0.60410465]\t 0.8329180373498172\t 0.7656138946809342\t 0.9837043213117411\t 0.9837043213117411\n",
            "25 \t [ 1.04159226  4.03780394  5.          0.9134339  15.          0.13519165]\t 0.9785605674881227\t 0.7656138946809342\t 0.9847786595708091\t 0.9847786595708091\n",
            "26 \t [ 4.24823418  9.49681173 13.          0.6150292   7.          0.81414675]\t 0.7903152027969078\t 0.7656138946809342\t 0.9906066713122209\t 0.9906066713122209\n",
            "27 \t [ 9.48577803  3.67088742  8.          0.57966698 12.          0.6677145 ]\t 0.7926582622847888\t 0.7656138946809342\t 0.9880622554452326\t 0.9880626671069159\n",
            "28 \t [ 0.17262698  1.68498662 10.          0.69482304  6.          0.13687299]\t 0.9798880020801095\t 0.7656138946809342\t 0.9836899464813906\t 0.9836899464813906\n",
            "29 \t [4.85059817 0.59059416 8.         0.66375786 6.         0.57600536]\t 0.8456632041648999\t 0.7656138946809342\t 0.9863950558590776\t 0.9863950558590776\n",
            "30 \t [ 0.42138623  7.7269096  13.          0.72605204 19.          0.17338535]\t 0.979555746560927\t 0.7656138946809342\t 0.9824062011709077\t 0.9824062011709077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60877.04939096347"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c0195d-ae08-4cf2-e840-72889e5761d7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.7315012035187541\t 0.7315012035187541\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1319770010327717\t 0.7315012035187541\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.9318565354152348\t 0.7315012035187541\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.7799608780638936\t 0.7315012035187541\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1305934464937346\t 0.7315012035187541\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7922048089873084\t 0.7315012035187541\t 0.9897452001738319\t 0.9897452001738319\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.7364009364353266\t 0.7315012035187541\t 0.9781182916237656\t 0.9781182916237656\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7884892526498699\t 0.7315012035187541\t 0.966644067772357\t 0.966644067772357\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.7531825106193256\t 0.7315012035187541\t 0.960425659552864\t 0.960425659552864\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.1341345349522627\t 0.7315012035187541\t 0.953994605866969\t 0.953994605866969\n",
            "6  \t [0.         2.60296494 5.         0.5        1.         0.1       ]\t 1.1357880386522623\t 0.7315012035187541\t 0.9670253819013697\t 0.9670253819013572\n",
            "7  \t [ 9.02205177  6.25193027 13.          0.53959181  5.          0.35908499]\t 0.9293340981174595\t 0.7315012035187541\t 0.9775781239282699\t 0.9775781239282699\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1442757918420738\t 0.7315012035187541\t 0.9775677985149671\t 0.9775677985149671\n",
            "9  \t [ 6.80309585  9.43423094  7.          0.8851539  14.          0.77731456]\t 0.7410022072170401\t 0.7315012035187541\t 0.9859301183541408\t 0.9859301183541408\n",
            "10 \t [ 6.60596124  8.35313787  6.          0.72167152 19.          0.94552853]\t 0.7474061753992649\t 0.7315012035187541\t 0.9798463383126579\t 0.9798463383126579\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7577952901048656\t 0.7315012035187541\t 0.974681780359209\t 0.974681780359209\n",
            "12 \t [ 9.46545841  2.71414127  5.          0.83512297 13.          0.70984642]\t 0.7590243643409933\t 0.7315012035187541\t 0.9703775487034709\t 0.9703775487034709\n",
            "13 \t [ 0.9801878   7.62207926 11.          0.92097131  8.          0.96474414]\t 0.735225373641723\t 0.7315012035187541\t 0.9665747220965643\t 0.9665747220965643\n",
            "14 \t [ 6.64335896  4.21317694 13.          0.67704359  4.          0.77970128]\t 0.7492274689494482\t 0.7315012035187541\t 0.9627064584062144\t 0.9627064584062144\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.7438065116890006\t 0.7315012035187541\t 0.9594681922898596\t 0.9594681922898596\n",
            "16 \t [ 2.06284179  6.9068961   5.          0.9448545  18.          0.13792391]\t 1.1296197909572616\t 0.7315012035187541\t 0.9562835653173645\t 0.9562835653173645\n",
            "17 \t [ 6.20565504  8.79840282 14.          0.71344255  6.          0.21980806]\t 1.1355955958989596\t 0.7315012035187541\t 0.9623143963291495\t 0.9623143963291495\n",
            "18 \t [2.57352577 0.33719112 9.         0.97251025 4.         0.51947396]\t 0.78517596210852\t 0.7315012035187541\t 0.966390782903648\t 0.966390782903648\n",
            "19 \t [ 0.786033    9.84105109  9.          0.91945518 19.          0.21791409]\t 1.1349556164442796\t 0.7315012035187541\t 0.9656285554088706\t 0.9656285554088706\n",
            "20 \t [ 9.58084219  5.11523797 14.          0.72421628 17.          0.10103214]\t 1.1267986297487531\t 0.7315012035187541\t 0.9711906152002552\t 0.9711906152002552\n",
            "21 \t [ 1.23850137  5.96524691 14.          0.65167204 16.          0.56763255]\t 0.7987790499738011\t 0.7315012035187541\t 0.9764845257014327\t 0.9764845257014327\n",
            "22 \t [8.1634571  7.58766207 7.         0.64490867 1.         0.97002079]\t 0.7514301027178281\t 0.7315012035187541\t 0.9795526684181526\t 0.9795526684181526\n",
            "23 \t [2.60467387 1.69759745 7.         0.66029575 2.         0.33596206]\t 0.937574907726539\t 0.7315012035187541\t 0.9778211462734949\t 0.9778211462734949\n",
            "24 \t [9.58119431 4.08928042 5.         0.53767664 4.         0.31130369]\t 0.922946959484098\t 0.7315012035187541\t 0.9755777198583011\t 0.9755777198583011\n",
            "25 \t [ 1.44946746  0.85565524 13.          0.60407529 19.          0.46878967]\t 0.8305786471816836\t 0.7315012035187541\t 0.971627712136467\t 0.971627712136467\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.7463927243485514\t 0.7315012035187541\t 0.9713475475971535\t 0.9713475475971535\n",
            "27 \t [ 4.30271104  7.67529814 14.          0.73770848  1.          0.87787505]\t 0.756228394612864\t 0.7315012035187541\t 0.9685359062070552\t 0.9685359062070552\n",
            "28 \t [ 3.21523099  9.01411529  5.          0.71759952 10.          0.55614635]\t 0.7956673392227565\t 0.7315012035187541\t 0.9635993098981426\t 0.9635993098981426\n",
            "29 \t [ 5.91501296  1.79061927 12.          0.95089632 11.          0.34299477]\t 0.9305364532791108\t 0.7315012035187541\t 0.9659365026659006\t 0.9659365026659006\n",
            "30 \t [ 2.32893999  0.70568143 10.          0.95982734 18.          0.36824695]\t 0.932353773777384\t 0.7315012035187541\t 0.9636487780809033\t 0.9636487780809033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59500.46682850479"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f726e07a-c82f-44aa-e4bb-5b5b685ca33a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.886516450243748\t 0.7696523735238344\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.8159404842786963\t 0.7696523735238344\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.9077084280320982\t 0.7696523735238344\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.7696523735238344\t 0.7696523735238344\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 0.9767143382937844\t 0.7696523735238344\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 0.9945462140035275\t 0.7696523735238344\t 0.9820451508295107\t 0.9820451508295107\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.8956717295899809\t 0.7696523735238344\t 0.9913671144319712\t 0.9913671144319712\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7896752580111073\t 0.7696523735238344\t 0.9913808698799693\t 0.9913808698799693\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 0.9788770650266176\t 0.7696523735238344\t 0.9858516910219304\t 0.9858516910219304\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9068912188410501\t 0.7696523735238344\t 0.9907760968137453\t 0.9907760968137453\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 0.9798753116153296\t 0.7696523735238344\t 0.991344719730295\t 0.991344719730295\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7844376116756365\t 0.7696523735238344\t 0.9948924733512974\t 0.9948924733512974\n",
            "8  \t [ 7.13077184  9.67534636 12.          0.53994085 17.          0.99732292]\t 0.7788814985676316\t 0.7696523735238344\t 0.9907678050202855\t 0.9907678050202855\n",
            "9  \t [ 4.99777324  7.1255563   5.          0.87428718 19.          0.63814647]\t 0.8365647355641779\t 0.7696523735238344\t 0.9870913101724494\t 0.9870913101724494\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.8262334140046084\t 0.7696523735238344\t 0.9855872543126138\t 0.9855872543126138\n",
            "11 \t [ 2.11261802  6.77105261 11.          0.82546435 17.          0.58049877]\t 0.8420672525155452\t 0.7696523735238344\t 0.9839905189010605\t 0.9839905189010605\n",
            "12 \t [ 1.87613733  0.3867672  10.          0.63542614  2.          0.41568093]\t 0.9060376794109418\t 0.7696523735238344\t 0.9830029100667071\t 0.9830029100667071\n",
            "13 \t [8.28996906 3.70835156 8.         0.5062329  4.         0.26839233]\t 0.898234632517687\t 0.7696523735238344\t 0.9837808019427903\t 0.9837808019427903\n",
            "14 \t [ 0.14006525  1.03750573 13.          0.72168802 14.          0.72400369]\t 0.815597828474959\t 0.7696523735238344\t 0.9843207373127624\t 0.9843207373127624\n",
            "15 \t [ 3.12232086  1.45138414 11.          0.68922386  8.          0.99526189]\t 0.7696523959316329\t 0.7696523735238344\t 0.9828893770689023\t 0.9828893770689023\n",
            "16 \t [ 5.21920054  9.35580917 14.          0.81835368  4.          0.54800317]\t 0.8502094404923272\t 0.7696523735238344\t 0.9804319596123485\t 0.9804319596123485\n",
            "17 \t [ 1.36823932  1.07854751  6.          0.59486343 17.          0.76880686]\t 0.778866435123053\t 0.7696523735238344\t 0.9797008549896009\t 0.9797008549896009\n",
            "18 \t [1.97879228 8.99345507 8.         0.55562265 8.         0.49118331]\t 0.8951491505335811\t 0.7696523735238344\t 0.9785204677737473\t 0.9785204677737473\n",
            "19 \t [ 3.46936711  8.05933995 13.          0.63796232  8.          0.58226276]\t 0.8566066993171872\t 0.7696523735238344\t 0.9868390917699092\t 0.9868390917699092\n",
            "20 \t [5.97224362 8.03394616 7.         0.96002317 1.         0.52715411]\t 0.8425927764201626\t 0.7696523735238344\t 0.9816981672572577\t 0.9816982391092653\n",
            "21 \t [4.16561464 4.3151821  6.         0.76299318 2.         0.59049538]\t 0.8474357581098328\t 0.7696523735238344\t 0.9850276633357178\t 0.9850276633357178\n",
            "22 \t [ 0.05037086  7.50461284  5.          0.70076046 19.          0.10543546]\t 0.9739763925924159\t 0.7696523735238344\t 0.9820220656909486\t 0.9820220656909486\n",
            "23 \t [ 7.23492203  5.17054691  8.          0.53461021 18.          0.11544004]\t 0.9821896458721675\t 0.7696523735238344\t 0.9848112655217465\t 0.9848112655217465\n",
            "24 \t [1.12842654 4.49436112 8.         0.68703394 7.         0.83701659]\t 0.7800900414685491\t 0.7696523735238344\t 0.9825850831857951\t 0.9825850831857951\n",
            "25 \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]\t 0.7754504257026212\t 0.7696523735238344\t 0.9875041330827518\t 0.9875041330827518\n",
            "26 \t [ 5.73005003  1.18628884 13.          0.88016467 12.          0.48547975]\t 0.8868749954853754\t 0.7696523735238344\t 0.9814115482771103\t 0.9814115482771103\n",
            "27 \t [8.60914739 9.54673859 7.         0.78963544 7.         0.48348756]\t 0.8811833469490125\t 0.7696523735238344\t 0.9806326547505192\t 0.9806326547505192\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 8.16440635  3.57724702 11.          0.83367572  9.          0.82276147]\u001b[0m\t \u001b[1m\u001b[92m0.7636353158344195\u001b[0m\t \u001b[1m\u001b[92m0.7636353158344195\u001b[0m\t \u001b[1m\u001b[92m0.9814455481109379\u001b[0m\t \u001b[1m\u001b[92m0.9814455481109379\u001b[0m\n",
            "29 \t [ 9.79781036  7.70828329  5.          0.72056878 19.          0.87728226]\t 0.7800481665326269\t 0.7636353158344195\t 0.9734434188145531\t 0.9734434188145531\n",
            "30 \t [ 4.33442518  0.21201691 11.          0.77606546  3.          0.66988451]\t 0.8347983363393409\t 0.7636353158344195\t 0.9802412582322856\t 0.9802412582322856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59899.945988489686"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e198020-3f01-4651-c62d-81ca3e6e1143"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.7846478010899064\t 0.7846478010899064\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 1.0448868808294456\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 1.0327067294213346\t 0.7846478010899064\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.8536879526704689\t 0.7846478010899064\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 1.0323325469581077\t 0.7846478010899064\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.810550884613735\t 0.7846478010899064\t 1.029860941447271\t 1.029860941447271\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.9535088265263543\t 0.7846478010899064\t 1.0197101466571634\t 1.0197101466571634\n",
            "3  \t [ 7.5915683   5.13937898 12.          0.70919884  1.          0.76222697]\t 0.8664770530673357\t 0.7846478010899064\t 1.0210159825128817\t 1.0210159825128817\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.9286293360228086\t 0.7846478010899064\t 1.0172598281083693\t 1.0172598281083693\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\u001b[0m\t \u001b[1m\u001b[92m0.7842936215568133\u001b[0m\t \u001b[1m\u001b[92m0.7842936215568133\u001b[0m\t \u001b[1m\u001b[92m1.0173045514584242\u001b[0m\t \u001b[1m\u001b[92m1.0173045514584242\u001b[0m\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.9316923990976885\t 0.7842936215568133\t 1.01110903897397\t 1.01110903897397\n",
            "7  \t [ 9.09795503  1.07150197  7.          0.98191679 19.          0.62951892]\t 0.7965305854630446\t 0.7842936215568133\t 1.011807867685972\t 1.011807867685972\n",
            "8  \t [ 9.21941721  9.79827821 11.          0.81783228 11.          0.53477407]\t 0.813771001201059\t 0.7842936215568133\t 1.007669414444076\t 1.007669414444076\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.8467944167491783\t 0.7842936215568133\t 1.0046718921919744\t 1.0046718921919744\n",
            "10 \t [ 8.47779105  8.43696768  5.          0.73890705 16.          0.66738091]\t 0.8243356733622897\t 0.7842936215568133\t 1.0030479264269891\t 1.0030479264269891\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.8067689920731376\t 0.7842936215568133\t 1.0010289488944908\t 1.0010289488944908\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.8291023984963773\t 0.7842936215568133\t 0.998808360351673\t 0.998808360351673\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\u001b[0m\t \u001b[1m\u001b[92m0.7817258295570644\u001b[0m\t \u001b[1m\u001b[92m0.7817258295570644\u001b[0m\t \u001b[1m\u001b[92m0.9973917874395847\u001b[0m\t \u001b[1m\u001b[92m0.9973917874395847\u001b[0m\n",
            "14 \t [3.34569903 7.54138147 5.         0.69594877 6.68136268 0.37283981]\t 0.9371101988786995\t 0.7817258295570644\t 0.9931232007667421\t 0.9931231866912817\n",
            "15 \t [ 0.16461509  2.47453913  6.          0.69159787 16.          0.61162096]\t 0.8390246298076309\t 0.7817258295570644\t 0.9944628947812667\t 0.9944628947812667\n",
            "16 \t [8.78569544 0.14730956 7.         0.66172647 2.         0.54513841]\t 0.8379589954382076\t 0.7817258295570644\t 0.9934713747802922\t 0.9934713747802922\n",
            "17 \t [4.50435964 1.42883317 8.         0.76583339 3.         0.4306355 ]\t 0.9350949568458088\t 0.7817258295570644\t 0.992996390292205\t 0.992996390292205\n",
            "18 \t [ 3.30019767  4.93644704 14.          0.76077125 17.          0.73607537]\t 0.8184266869335748\t 0.7817258295570644\t 0.9976003862268892\t 0.9976003862268892\n",
            "19 \t [ 9.64875283  9.32176949  8.          0.85263567 19.          0.33410227]\t 0.9264535302583298\t 0.7817258295570644\t 0.9934741189981067\t 0.9934741189981067\n",
            "20 \t [ 5.31037667  6.81676807  5.          0.53020463 18.          0.21260061]\t 1.0437596156191435\t 0.7817258295570644\t 0.9959302039893673\t 0.9959302039893673\n",
            "21 \t [ 9.28937895  1.2300363  13.          0.54126463 19.          0.2413571 ]\t 1.0398406285038562\t 0.7817258295570644\t 1.002286478207672\t 1.002286478207672\n",
            "22 \t [ 4.90087649  7.40954674 11.          0.53028779  8.          0.43614982]\t 0.9558470479985534\t 0.7817258295570644\t 0.9995570471590789\t 0.9995570471590789\n",
            "23 \t [ 1.04966198  1.72140723 11.          0.68060657  8.          0.5044115 ]\t 0.8422478956054074\t 0.7817258295570644\t 1.0018822394823956\t 1.0018822394824245\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.8523559948324888\t 0.7817258295570644\t 1.0019155542337057\t 1.0019155542337057\n",
            "25 \t [ 1.719002    1.73903169  5.          0.87805761 14.          0.46260902]\t 0.9216282707304624\t 0.7817258295570644\t 1.0072183703476052\t 1.0072183703476052\n",
            "26 \t [ 6.59000923  9.78665977 14.          0.63113594  1.          0.38899025]\t 0.9727332413478633\t 0.7817258295570644\t 1.0053119075616037\t 1.0053119075616037\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]\u001b[0m\t \u001b[1m\u001b[92m0.7412282900611625\u001b[0m\t \u001b[1m\u001b[92m0.7412282900611625\u001b[0m\t \u001b[1m\u001b[92m1.0038888581737824\u001b[0m\t \u001b[1m\u001b[92m1.0038888581737824\u001b[0m\n",
            "28 \t [ 3.85186676  3.1955202  13.          0.84289144 11.          0.29344016]\t 0.9318426963665122\t 0.7412282900611625\t 0.9676740888094\t 0.9676740888094\n",
            "29 \t [ 5.44697951  7.10004131 14.          0.73747864 14.          0.39762384]\t 0.9268634145097335\t 0.7412282900611625\t 0.9674530614766146\t 0.9674530614766146\n",
            "30 \t [ 8.04276314  4.60586342  8.          0.52625867 16.          0.88607792]\t 0.7842475257071028\t 0.7412282900611625\t 0.9701815980352879\t 0.9701815980352879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61931.472044342285"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa6d4cf-cc66-4779-a8be-357adf6f9602"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 1.0442882316794924\t 0.9988899440522335\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 1.034592364984854\t 0.9988899440522335\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.9988899440522335\t 0.9988899440522335\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 1.0616382201607613\t 0.9988899440522335\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 1.0586655163441985\t 0.9988899440522335\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m0.7588724777099193\u001b[0m\t \u001b[1m\u001b[92m1.2337309811890973\u001b[0m\t \u001b[1m\u001b[92m1.2337309811890973\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 1.0357720753154218\t 0.7588724777099193\t 1.029815418153565\t 1.029815418153565\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.9957364873565091\t 0.7588724777099193\t 1.032336608481323\t 1.032336608481323\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 1.0230792313624693\t 0.7588724777099193\t 1.0318483987558533\t 1.0318483987558533\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.9990381912537636\t 0.7588724777099193\t 1.0329086899845612\t 1.0329086899845612\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.857846290397769\t 0.7588724777099193\t 1.0326274085511997\t 1.0326274085511997\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 1.0693894233525565\t 0.7588724777099193\t 1.0268764690427696\t 1.0268764690427696\n",
            "8  \t [0.  0.  5.  0.5 1.  0.1]\t 1.110440514541687\t 0.7588724777099193\t 1.0299435517503475\t 1.0299435513875461\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m0.7219532506859043\u001b[0m\t \u001b[1m\u001b[92m1.034137349201623\u001b[0m\t \u001b[1m\u001b[92m1.034137349201623\u001b[0m\n",
            "10 \t [ 9.49073008  1.95543967  6.          0.82312132 10.          0.92175057]\t 0.7290063369184493\t 0.7219532506859043\t 0.9984345343038483\t 0.9984345343038483\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 1.1107767409489193\t 0.7219532506859043\t 0.9913214346500427\t 0.9913214346500427\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.857182327987213\t 0.7219532506859043\t 0.9955443142063457\t 0.9955443142063457\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.7195558119979323\u001b[0m\t \u001b[1m\u001b[92m0.9922026634179688\u001b[0m\t \u001b[1m\u001b[92m0.9922026634179688\u001b[0m\n",
            "14 \t [ 9.63904847  1.13624975 14.          0.67706869  2.          0.95236673]\t 0.7547666064805034\t 0.7195558119979323\t 0.9846841306081677\t 0.9846841306081677\n",
            "15 \t [ 3.80611843  6.00578786 13.          0.99755611 17.          0.8390553 ]\t 0.7514294400526927\t 0.7195558119979323\t 0.9800777059650433\t 0.9800777059650433\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.894093323976883\t 0.7195558119979323\t 0.975875100610967\t 0.975875100610967\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 1.096518529758772\t 0.7195558119979323\t 0.9747427534805311\t 0.9747427534805311\n",
            "18 \t [ 0.8452211   8.12709454  6.          0.97612433 13.          0.80107738]\t 0.7563996497977579\t 0.7195558119979323\t 0.9816909099508931\t 0.9816909099508931\n",
            "19 \t [ 2.38304891  0.39103582  5.          0.8629475  11.          0.24144597]\t 1.0887929481666194\t 0.7195558119979323\t 0.9764249831079171\t 0.9764249831079171\n",
            "20 \t [ 8.60177792  1.89933469  8.          0.92909045 16.          0.35782775]\t 1.0219773849247542\t 0.7195558119979323\t 0.9791825975838355\t 0.9791825975838355\n",
            "21 \t [ 6.66300191  0.19049997 11.          0.78724655  5.          0.59145595]\t 0.8975212398886476\t 0.7195558119979323\t 0.9827097340548577\t 0.9827097340548577\n",
            "22 \t [ 9.03366199  7.80955039  7.          0.58807038 16.          0.37530235]\t 1.0032309771479204\t 0.7195558119979323\t 0.9742880348796645\t 0.9742880348796645\n",
            "23 \t [ 0.05470781  0.71851494 10.01705356  0.5         3.01705356  0.1       ]\t 1.122761981799073\t 0.7195558119979323\t 0.979745815256796\t 0.9797458147514584\n",
            "24 \t [ 9.0325587   6.33846411 10.          0.53479661 11.          0.73333026]\t 0.8792760345725806\t 0.7195558119979323\t 0.9826716859168242\t 0.9826716859168242\n",
            "25 \t [ 3.18112946  5.08778536  9.25132348  0.5        11.25132348  0.1       ]\t 1.1093383333847557\t 0.7195558119979323\t 0.9809501722705417\t 0.980950172270498\n",
            "26 \t [ 3.73420217  8.22730904 13.          0.84562785  9.          0.47506411]\t 1.0050223847057222\t 0.7195558119979323\t 0.9829182664424508\t 0.9829182664424508\n",
            "27 \t [ 3.87907908  1.7609891  11.          0.72159537 13.          0.66065913]\t 0.8647657423877456\t 0.7195558119979323\t 0.9872627970283876\t 0.9872627970283876\n",
            "28 \t [ 7.60544167  6.18545412 10.          0.53482906 19.          0.11760698]\t 1.10591732784562\t 0.7195558119979323\t 0.9844357196748441\t 0.9844357196748441\n",
            "29 \t [ 0.07133277  0.91368388 13.          0.65353856  5.          0.96196496]\t 0.7348336825290495\t 0.7195558119979323\t 0.9881044019289928\t 0.9881044019289928\n",
            "30 \t [ 4.22064162  2.10569977  5.          0.5        16.29991738  0.1       ]\t 1.1073015800381791\t 0.7195558119979323\t 0.9844321935893617\t 0.9844377442336245\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60614.22577011115"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a64e99-3430-4e18-c476-0b48ea8f7914"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.8160193762021096\t 0.8160193762021096\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.9345750435828236\t 0.8160193762021096\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.8609997448649105\t 0.8160193762021096\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9816665199899536\t 0.8160193762021096\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.9568167510294832\t 0.8160193762021096\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.9860041719301801\t 0.8160193762021096\t 1.0315255253319489\t 1.0315255253319489\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.8418838401878418\t 0.8160193762021096\t 1.0376358410853028\t 1.0376358410853028\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m0.7805118546901472\u001b[0m\t \u001b[1m\u001b[92m1.0330250568115071\u001b[0m\t \u001b[1m\u001b[92m1.0330250568115071\u001b[0m\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9840979999934294\t 0.7805118546901472\t 0.9988054786728285\t 0.9988054786728285\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.955892785185136\t 0.7805118546901472\t 1.0034515115763007\t 1.0034515115763007\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.9781132546552117\t 0.7805118546901472\t 1.0074427827289698\t 1.0074427827289698\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.8404775189371637\t 0.7805118546901472\t 1.0086890093123533\t 1.0086890093123533\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.9731655942341536\t 0.7805118546901472\t 1.0060185747461736\t 1.0060185747461736\n",
            "9  \t [9.85206608 0.28191822 5.         0.52457928 8.         0.84714334]\t 0.8508120667734606\t 0.7805118546901472\t 1.0094995622838137\t 1.0094995622838137\n",
            "10 \t [ 0.2191332   8.51773955  5.          0.60657578 15.          0.49735822]\t 0.9550900145970594\t 0.7805118546901472\t 1.0063007092465677\t 1.0063007092465677\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.9443317250470002\t 0.7805118546901472\t 1.0076541387826812\t 1.0076541387826812\n",
            "12 \t [0.95504342 7.30424524 8.         0.76682007 6.         0.21761275]\t 0.9795870115119684\t 0.7805118546901472\t 1.0095441487302448\t 1.0095441487302448\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9987994924328458\t 0.7805118546901472\t 1.0109360933266038\t 1.0109360611095466\n",
            "14 \t [ 7.35111323  4.42247898 14.          0.92954426  7.          0.31778445]\t 0.959605938976237\t 0.7805118546901472\t 1.0123068849639563\t 1.0123068849639563\n",
            "15 \t [ 4.97204887  2.40072226  5.          0.54268748 19.          0.30995407]\t 0.9759678380966751\t 0.7805118546901472\t 1.0136283299130406\t 1.0136283299130406\n",
            "16 \t [ 5.22074709  0.74229772 13.          0.87455275  7.          0.44305495]\t 0.9475819018040168\t 0.7805118546901472\t 1.0151576461550413\t 1.0151576461550413\n",
            "17 \t [ 9.1928307   3.75120063 13.          0.61085648 16.          0.3130605 ]\t 0.9631882478680399\t 0.7805118546901472\t 1.0155804658459888\t 1.0155804658459888\n",
            "18 \t [0.91443767 6.97440714 5.         0.78916973 2.         0.81132272]\t 0.8282909656929418\t 0.7805118546901472\t 1.0162636319592222\t 1.0162636319592222\n",
            "19 \t [ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]\t 0.8425830184404466\t 0.7805118546901472\t 1.0157136890024872\t 1.0157136890024872\n",
            "20 \t [6.96594084 1.0683262  5.         0.5        1.         0.1       ]\t 0.9988005138659297\t 0.7805118546901472\t 1.0052951850523717\t 1.0052951641890813\n",
            "21 \t [ 4.48878711  5.49356507 14.          0.56680442 14.          0.88105297]\t 0.7847481688271192\t 0.7805118546901472\t 1.0197731406521489\t 1.0197731406521489\n",
            "22 \t [ 6.72796419  6.10053296 14.          0.56325639  2.          0.91580991]\t 0.7914341277502726\t 0.7805118546901472\t 1.012434020722665\t 1.012434020722665\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.8589132192206685\t 0.7805118546901472\t 1.0146595496522044\t 1.0146595496522044\n",
            "24 \t [ 0.01662929  3.46629364  8.          0.7460687  11.          0.32343978]\t 0.9599687924042467\t 0.7805118546901472\t 1.003069085159323\t 1.003069085159323\n",
            "25 \t [ 8.43519692  6.85584373 12.          0.94840609 12.          0.74591712]\t 0.8465068431307433\t 0.7805118546901472\t 1.0081784257481143\t 1.0081785760650934\n",
            "26 \t [ 3.99246805  6.83201211 11.          0.71474953  9.          0.42871617]\t 0.9476761941856809\t 0.7805118546901472\t 1.0127997801190731\t 1.0127997801190731\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]\u001b[0m\t \u001b[1m\u001b[92m0.7787515875060036\u001b[0m\t \u001b[1m\u001b[92m0.7787515875060036\u001b[0m\t \u001b[1m\u001b[92m1.012614882261497\u001b[0m\t \u001b[1m\u001b[92m1.012614882261497\u001b[0m\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 4.55919043  8.6591134   6.          0.8884863  12.          0.96165246]\u001b[0m\t \u001b[1m\u001b[92m0.768672041990598\u001b[0m\t \u001b[1m\u001b[92m0.768672041990598\u001b[0m\t \u001b[1m\u001b[92m1.003599418932469\u001b[0m\t \u001b[1m\u001b[92m1.003599418932469\u001b[0m\n",
            "29 \t [ 7.57643221  2.75634527 14.          0.54972325 18.          0.56026463]\t 0.860674338231938\t 0.768672041990598\t 1.0003991923837954\t 1.0003991923837954\n",
            "30 \t [ 3.17187998  4.13355162  8.          0.8657932  13.          0.82446402]\t 0.8118933760299614\t 0.768672041990598\t 0.9925181536234869\t 0.9925181536234869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62590.97423708343"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91e03c5-7aad-4f9a-b840-bbcdacc797e1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9747807501509798\t 0.8413213471093884\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.8434056917425027\t 0.8413213471093884\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9720565145525129\t 0.8413213471093884\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.8568115101817837\t 0.8413213471093884\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.8413213471093884\t 0.8413213471093884\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8631585877624761\t 0.8413213471093884\t 1.0483721353562445\t 1.0483721353562445\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.7571977630434763\u001b[0m\t \u001b[1m\u001b[92m0.7571977630434763\u001b[0m\t \u001b[1m\u001b[92m1.0459665870340993\u001b[0m\t \u001b[1m\u001b[92m1.0459665870340993\u001b[0m\n",
            "3  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0836382758107443\t 0.7571977630434763\t 0.972238479355585\t 0.9722384793425185\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.9891420999894684\t 0.7571977630434763\t 0.9850537976331112\t 0.9850537976331112\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.8235970122668114\t 0.7571977630434763\t 0.99006740601572\t 0.99006740601572\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 1.0897095171845277\t 0.7571977630434763\t 0.9857070479330056\t 0.9857070479330056\n",
            "7  \t [9.62350533 1.2688885  9.         0.94775659 1.         0.72317258]\t 0.8324419101287693\t 0.7571977630434763\t 0.9943911484887719\t 0.9943911484887719\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.8576035440570304\t 0.7571977630434763\t 0.9907294904713908\t 0.9907294904713908\n",
            "9  \t [ 1.12290378  2.42329419  6.3666064   0.5        11.22515847  0.45045934]\t 0.9181985322675807\t 0.7571977630434763\t 0.9887891237138884\t 0.9887891179487355\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.7756483594844651\t 0.7571977630434763\t 0.9890152321032436\t 0.9890152400696144\n",
            "11 \t [2.26673282 9.18109909 5.         0.89654818 1.         0.23064839]\t 1.0833498845487965\t 0.7571977630434763\t 0.9855708915575403\t 0.9855708915575403\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.8715037274175815\t 0.7571977630434763\t 0.9906991851222295\t 0.9906991851222295\n",
            "13 \t [ 8.34050252  7.45495891 14.          0.58875591  8.          0.92669456]\t 0.773443620396543\t 0.7571977630434763\t 0.9898483006635059\t 0.9898483006635059\n",
            "14 \t [ 9.17553299  1.41421886 11.          0.77317761 11.          0.82263086]\t 0.7842845189628849\t 0.7571977630434763\t 0.9869477696626963\t 0.9869477696626963\n",
            "15 \t [ 2.3725221   1.25906939 10.          0.50882646  1.          0.22780426]\t 1.0802845503934737\t 0.7571977630434763\t 0.9834864531415425\t 0.9834864531415425\n",
            "16 \t [ 0.71491502  0.67997826 10.          0.84656193 16.          0.26877596]\t 0.9581986121938494\t 0.7571977630434763\t 0.9883812043575705\t 0.9883812043575705\n",
            "17 \t [ 0.017361    7.59703381  6.          0.77583169 15.          0.50356816]\t 0.8519969034927322\t 0.7571977630434763\t 0.9891570743351145\t 0.9891570743351145\n",
            "18 \t [ 7.49379106  4.28777418 12.          0.51562956  7.          0.83771026]\t 0.8108696725518876\t 0.7571977630434763\t 0.9891292226254695\t 0.9891292226254695\n",
            "19 \t [4.04182654 9.20971563 7.         0.51320154 2.         0.19216643]\t 1.074666312917558\t 0.7571977630434763\t 0.9906584163117845\t 0.9906584163117845\n",
            "20 \t [ 8.57925159  8.55545018 10.          0.57600729 15.          0.49617531]\t 0.9055138677926629\t 0.7571977630434763\t 0.9901773649658183\t 0.9901773649658183\n",
            "21 \t [ 1.18347798  2.03195078 14.          0.62549517 10.          0.6517083 ]\t 0.8296072072295889\t 0.7571977630434763\t 0.9885524057612489\t 0.9885524057612489\n",
            "22 \t [ 2.87349863  9.89224042 14.          0.78812561 15.          0.55198401]\t 0.8465116985613793\t 0.7571977630434763\t 0.9885562165841602\t 0.9885562165841602\n",
            "23 \t [ 6.72349545  5.27194732 13.          0.74776676 17.          0.30949491]\t 0.960458435595567\t 0.7571977630434763\t 0.9896467972085607\t 0.9896467972085607\n",
            "24 \t [ 6.53986112  7.86486911  8.          0.51123614 12.          0.99656982]\t 0.7689475410076321\t 0.7571977630434763\t 0.9896825965987415\t 0.9896825965987415\n",
            "25 \t [1.70698239 9.19985282 6.         0.50661833 7.         0.29378886]\t 0.9723820490672533\t 0.7571977630434763\t 0.9932320457181424\t 0.9932320457181424\n",
            "26 \t [ 0.40678625  1.26787537  5.          0.70261051 12.          0.55749237]\t 0.874691617323094\t 0.7571977630434763\t 0.9928382661375764\t 0.9928382661375764\n",
            "27 \t [ 4.54391832  5.01814427  8.          0.94238921 19.          0.48685375]\t 0.8948858318122767\t 0.7571977630434763\t 0.9866699576914046\t 0.9866699576914046\n",
            "28 \t [ 0.21959499  5.23035289 12.          0.91796248  7.          0.20873253]\t 1.0750435829982965\t 0.7571977630434763\t 0.9852736652001212\t 0.9852736652001212\n",
            "29 \t [9.31614024 4.63885987 7.         0.54659744 6.         0.74814245]\t 0.8437734790413737\t 0.7571977630434763\t 0.9873224892269219\t 0.9873224892269219\n",
            "30 \t [6.65163782 6.39807144 6.         0.64802115 8.         0.12708916]\t 1.0861773102884364\t 0.7571977630434763\t 0.9899773627597023\t 0.9899773627597023\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61434.57002697744"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186d2eaa-582f-4717-d871-867187c1188d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.9238143360620997\t 0.824729580989813\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.9119597092034326\t 0.824729580989813\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.1280473533716002\t 0.824729580989813\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.885331313733569\t 0.824729580989813\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.824729580989813\t 0.824729580989813\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m0.79346025102973\u001b[0m\t \u001b[1m\u001b[92m1.05215671724966\u001b[0m\t \u001b[1m\u001b[92m1.05215671724966\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.8875735409405836\t 0.79346025102973\t 1.0180755893378943\t 1.0180755893378943\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.1322726135322738\t 0.79346025102973\t 1.0164221804106297\t 1.0164221804106297\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.9633601355550562\t 0.79346025102973\t 1.0299707227197825\t 1.0299707227197825\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.9736613453341365\t 0.79346025102973\t 1.0310887358649345\t 1.0310887358649345\n",
            "6  \t [ 3.40319086  6.78940093  5.          0.5        10.72367495  0.24682134]\t 1.1218182087640183\t 0.79346025102973\t 1.032453214020836\t 1.0324532139140066\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.8910080545620651\t 0.79346025102973\t 1.040183323424377\t 1.040183323424377\n",
            "8  \t [ 8.78531367  5.16236615 10.          0.71284072  9.          0.88546543]\t 0.8147284111173498\t 0.79346025102973\t 1.037552483382859\t 1.037552483382859\n",
            "9  \t [ 2.19431997  0.03640407  7.          0.62674231 12.          0.80025129]\t 0.8323976121313962\t 0.79346025102973\t 1.0329613055118656\t 1.0329613055118656\n",
            "10 \t [0.         0.         5.         0.5        1.35555278 0.1       ]\t 1.1268790789785779\t 0.79346025102973\t 1.0294957077296523\t 1.0294957011543653\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.8287447527880435\t 0.79346025102973\t 1.0355752580322386\t 1.0355752598524546\n",
            "12 \t [ 6.11039048  8.9398787   9.          0.84431675 14.          0.73928782]\t 0.8643545186031654\t 0.79346025102973\t 1.0323015597725465\t 1.0323015597725465\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.1276065677179288\t 0.79346025102973\t 1.0302436877076904\t 1.0302436877076904\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.8195075556875523\t 0.79346025102973\t 1.0358560982546994\t 1.0358560982546994\n",
            "15 \t [ 8.99876272  0.14180428 14.          0.5207566  10.          0.28841204]\t 0.9622998965203461\t 0.79346025102973\t 1.0322367368320133\t 1.0322367368320133\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.9192069504605914\t 0.79346025102973\t 1.0332823735623415\t 1.0332823735623415\n",
            "17 \t [ 4.34521215  5.28934175 10.          0.70701942 19.          0.12854445]\t 1.1342187055239956\t 0.79346025102973\t 1.0322235453192572\t 1.0322235453192572\n",
            "18 \t [ 7.9679648   6.50875696 12.          0.58580991 13.          0.19954847]\t 1.1274997047398325\t 0.79346025102973\t 1.040446962489069\t 1.040446962489069\n",
            "19 \t [ 9.97958622  9.03409533 12.          0.51772082  4.          0.45869101]\t 0.9473572626155049\t 0.79346025102973\t 1.041751929510511\t 1.041751929510511\n",
            "20 \t [ 3.55165538  9.78370062 13.          0.78750167  1.          0.7976462 ]\t 0.832291165091001\t 0.79346025102973\t 1.0412668160621634\t 1.0412668160621634\n",
            "21 \t [ 9.95530246  5.50525097  9.          0.72320589 18.          0.9960274 ]\t 0.8200285178970692\t 0.79346025102973\t 1.0408599419634526\t 1.0408599419634526\n",
            "22 \t [ 2.60768732  9.91933042 11.          0.69532366 12.          0.51088157]\t 0.9223651097826323\t 0.79346025102973\t 1.0325031105756521\t 1.0325031105756521\n",
            "23 \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]\t 0.94182282306325\t 0.79346025102973\t 1.0433446191793594\t 1.0433446191793594\n",
            "24 \t [ 6.30542676  7.71202743  5.          0.69290865 17.          0.68185665]\t 0.9062144692012971\t 0.79346025102973\t 1.0345410692834964\t 1.0345410692834964\n",
            "25 \t [3.50392351 6.35497601 9.         0.51577921 5.         0.45370698]\t 0.9381315214046673\t 0.79346025102973\t 1.0322124061904\t 1.0322124061904\n",
            "26 \t [ 3.26806392  8.03852835 12.          0.60354247 16.          0.69840157]\t 0.8895644243531041\t 0.79346025102973\t 1.035520792480942\t 1.035520792480942\n",
            "27 \t [ 0.          0.26880967 11.3792097   0.5        15.3792097   0.1       ]\t 1.1221593094524043\t 0.79346025102973\t 1.0377149199574753\t 1.0377139471505756\n",
            "28 \t [ 4.53470807  2.6500816   5.          0.70480421 17.          0.65004423]\t 0.9072821036838956\t 0.79346025102973\t 1.0345828696611437\t 1.0345828696611437\n",
            "29 \t [ 6.19086368  8.47911079  6.          0.770382   12.          0.93751062]\t 0.8158422349857315\t 0.79346025102973\t 1.0332553810068539\t 1.0332553810068539\n",
            "30 \t [ 2.86565463  3.78697029  7.          0.72408842 16.          0.37974907]\t 0.9315807591745389\t 0.79346025102973\t 1.0325032490731096\t 1.0325032490731096\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60977.67575935616"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fbb5d1-66fb-451a-8494-a2a51296a945"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dtStudentProcess(cov_func, optimize=opt, nu = df)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.7520109919120059\t 0.7520109919120059\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.7843437690505969\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0380897569172567\t 0.7520109919120059\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.9185289289653313\t 0.7520109919120059\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.9180724641961298\t 0.7520109919120059\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.9254670555638643\t 0.7520109919120059\t 0.9745508172854711\t 0.9745508172854711\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0314631424665905\t 0.7520109919120059\t 0.9770087627215797\t 0.9770087627215797\n",
            "3  \t [1.23171766 1.54308988 5.17270364 0.50845057 1.50176166 0.1       ]\t 1.0405730789440135\t 0.7520109919120059\t 0.9863911537537903\t 0.98639115375379\n",
            "4  \t [ 0.68429579  6.1707671  14.          0.68319892 12.          0.92995252]\t 0.7575601181568882\t 0.7520109919120059\t 0.9939141324047188\t 0.9939141324047188\n",
            "5  \t [ 7.50758902  2.31989813 13.          0.92794435  1.          0.52943075]\t 0.8956526888001509\t 0.7520109919120059\t 0.9859352350561461\t 0.9859352350561461\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.0239998235141596\t 0.7520109919120059\t 0.9851314913337382\t 0.9851314913337382\n",
            "7  \t [ 1.01837104  4.41995744  6.          0.52021829 12.          0.99601116]\t 0.7870781259906151\t 0.7520109919120059\t 0.9901649264520143\t 0.9901649264520143\n",
            "8  \t [ 0.54239845  2.74182658 10.          0.793938    8.          0.40512022]\t 0.9132516270639195\t 0.7520109919120059\t 0.9852329908006622\t 0.9852329908006622\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0363798049215616\t 0.7520109919120059\t 0.9854325566281923\t 0.9854325566281923\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.865997699883801\t 0.7520109919120059\t 0.9896665221874652\t 0.9896665221874652\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0228429225587468\t 0.7520109919120059\t 0.9879944237197001\t 0.9879944237197001\n",
            "12 \t [ 1.82697381  3.23883023 14.          0.52727974  1.          0.42452427]\t 0.947464381947352\t 0.7520109919120059\t 0.991098881297473\t 0.991098881297473\n",
            "13 \t [ 6.23595836  9.32810182 13.          0.66281123 18.          0.41679152]\t 0.9158015362279499\t 0.7520109919120059\t 0.9917293179406301\t 0.9917293179406301\n",
            "14 \t [ 2.78517086  0.20608894 12.          0.52669069 17.          0.68320382]\t 0.8287385075376639\t 0.7520109919120059\t 0.9912391861329015\t 0.9912391861329015\n",
            "15 \t [ 6.97560183  1.48211849  9.          0.80794429 10.          0.21839694]\t 1.0237787601826196\t 0.7520109919120059\t 0.9892632516898753\t 0.9892632516898753\n",
            "16 \t [ 7.31252146  8.98299937  5.          0.81221269 16.          0.68394735]\t 0.817631747849487\t 0.7520109919120059\t 0.9918783596608035\t 0.9918783596608035\n",
            "17 \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]\t 0.8155570453490526\t 0.7520109919120059\t 0.9894012880177003\t 0.9894012880177003\n",
            "18 \t [ 1.21632555  2.44839139  8.          0.8927599  17.          0.25270381]\t 0.9237148678212173\t 0.7520109919120059\t 0.986425459952446\t 0.986425459952446\n",
            "19 \t [ 7.81161289  7.58582803  9.          0.86075987 18.          0.65204948]\t 0.8066198378796496\t 0.7520109919120059\t 0.9860848628461533\t 0.9860848628461533\n",
            "20 \t [9.77613663 2.80327235 8.         0.65089037 2.         0.68605672]\t 0.8306072795844661\t 0.7520109919120059\t 0.9856473120502652\t 0.9856473120502652\n",
            "21 \t [ 7.41954815  2.80862624  9.          0.85591029 17.          0.3641919 ]\t 0.9203913838650098\t 0.7520109919120059\t 0.988480808669948\t 0.988480808669948\n",
            "22 \t [ 2.39999736  8.25935251 10.          0.76621897 14.          0.97994917]\t 0.7522537228179459\t 0.7520109919120059\t 0.9884255247522088\t 0.9884255247522088\n",
            "23 \t [ 7.7259419   7.24070659 12.          0.78792483 13.          0.54558593]\t 0.8585735817607519\t 0.7520109919120059\t 0.9813938070390097\t 0.9813938070390097\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.7797715795229998\t 0.7520109919120059\t 0.9803958182850866\t 0.9803958182850866\n",
            "25 \t [0.         0.         5.         0.5        7.64547333 0.1       ]\t 1.0333107683100464\t 0.7520109919120059\t 0.984121632898533\t 0.9841216205746285\n",
            "26 \t [ 8.41587592  4.63136717 11.          0.99322381 16.          0.53340451]\t 0.8602984001975387\t 0.7520109919120059\t 0.9860508296322382\t 0.9860508296322382\n",
            "27 \t [0.70943159 7.31899918 8.         0.58469333 8.         0.56649675]\t 0.8773770572777302\t 0.7520109919120059\t 0.9897377852833603\t 0.9897408334568676\n",
            "28 \t [ 5.02199529  8.17608785 14.          0.82123354 16.          0.12042445]\t 1.021708916478741\t 0.7520109919120059\t 0.9830671718858442\t 0.9830671718858442\n",
            "29 \t [ 0.39565672  8.50724472  5.          0.74462587 17.          0.73375146]\t 0.8184975369779084\t 0.7520109919120059\t 0.9878593010139732\t 0.9878593010139732\n",
            "30 \t [ 0.89195001  6.01604215 14.          0.84121292  7.          0.44798682]\t 0.914590967204553\t 0.7520109919120059\t 0.9784966637670729\t 0.9784966637670729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59312.96896149271"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8543c4-18ff-489e-bea6-4fc2f25d40b7"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2499.378153324127"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495c599b-f841-4129-fc42-63673ca43af3"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60974.01991176682"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718524ff-475b-42d0-f376-d93532908c0b"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60696.69309054078"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec1a30c-d3f5-45be-f584-762c61f34b3b"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([60746.65105051846,\n",
              "  60746.65105051846,\n",
              "  60027.427603108896,\n",
              "  60027.427603108896,\n",
              "  60027.427603108896,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525baa19-ae1b-429f-bd7e-7aea17400746"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([60746.65105051846,\n",
              "  60746.65105051846,\n",
              "  59806.801758392685,\n",
              "  59806.801758392685,\n",
              "  59612.82267483437,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046,\n",
              "  59260.747037503046],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "7d559d2d-32f5-4ee5-a4bd-8971e2b5ae8e"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Yellow', label='RMSE: Approx STP EI gradients', ls='--')\n",
        "plt.plot(min_rmse_exact, color = 'Red', label='RMSE: Exact STP dEI gradients', ls='-')# r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualize!\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577c74f1-b402-4372-fbd1-8e20d4da3802"
      },
      "source": [
        "time_approx, time_exact\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2484.6202385425568, 2499.378153324127)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdfbc47-d024-4346-de5d-b2121fe0eb3b"
      },
      "source": [
        "min(min_rmse_exact), min(min_rmse_approx)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59260.747037503046, 59260.747037503046)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": 69,
      "outputs": []
    }
  ]
}